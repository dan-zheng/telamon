<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-us" xml:lang="en-us">
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8"></meta>
      <meta http-equiv="X-UA-Compatible" content="IE=edge"></meta>
      <meta name="copyright" content="(C) Copyright 2005"></meta>
      <meta name="DC.rights.owner" content="(C) Copyright 2005"></meta>
      <meta name="DC.Type" content="concept"></meta>
      <meta name="DC.Title" content="Abstract"></meta>
      <meta name="abstract" content="This cuDNN Developer Guide provides an overview of cuDNN v7.6.2, and details about the types, enums, and routines within the cuDNN library API."></meta>
      <meta name="description" content="This cuDNN Developer Guide provides an overview of cuDNN v7.6.2, and details about the types, enums, and routines within the cuDNN library API."></meta>
      <meta name="DC.Coverage" content="Training Library"></meta>
      <meta name="DC.subject" content="cuDNN Developer Guide"></meta>
      <meta name="keywords" content="cuDNN Developer Guide"></meta>
      <meta name="DC.Format" content="XHTML"></meta>
      <meta name="DC.Identifier" content="abstract"></meta>
      <link rel="stylesheet" type="text/css" href="../common/formatting/commonltr.css"></link>
      <link rel="stylesheet" type="text/css" href="../common/formatting/site.css"></link>
      <title>cuDNN Developer Guide :: Deep Learning SDK Documentation</title>
      <!--[if lt IE 9]>
      <script src="../common/formatting/html5shiv-printshiv.min.js"></script>
      <![endif]-->
      <script src="//assets.adobedtm.com/b92787824f2e0e9b68dc2e993f9bd995339fe417/satelliteLib-7ba51e58dc61bcb0e9311aadd02a0108ab24cc6c.js"></script>
      <script type="text/javascript" charset="utf-8" src="../common/formatting/jquery.min.js"></script>
      <script type="text/javascript" charset="utf-8" src="../common/formatting/jquery.ba-hashchange.min.js"></script>
      <script type="text/javascript" charset="utf-8" src="../common/formatting/jquery.scrollintoview.min.js"></script>
      <script type="text/javascript" src="../search/htmlFileList.js"></script>
      <script type="text/javascript" src="../search/htmlFileInfoList.js"></script>
      <script type="text/javascript" src="../search/nwSearchFnt.min.js"></script>
      <script type="text/javascript" src="../search/stemmers/en_stemmer.min.js"></script>
      <script type="text/javascript" src="../search/index-1.js"></script>
      <script type="text/javascript" src="../search/index-2.js"></script>
      <script type="text/javascript" src="../search/index-3.js"></script>
      <link rel="canonical" href="http://docs.nvidia.com/deeplearning/sdk/cudnn-developer-guide/index.html"></link>
      <link rel="stylesheet" type="text/css" href="../common/formatting/qwcode.highlight.css"></link>
   </head>
   <body>
      
      <header id="header"><span id="company">NVIDIA</span><span id="site-title">Deep Learning SDK Documentation</span><form id="search" method="get" action="search">
            <input type="text" name="search-text"></input><fieldset id="search-location">
               <legend>Search In:</legend>
               <label><input type="radio" name="search-type" value="site"></input>Entire Site</label>
               <label><input type="radio" name="search-type" value="document"></input>Just This Document</label></fieldset>
            <button type="reset">clear search</button>
            <button id="submit" type="submit">search</button></form>
      </header>
      <div id="site-content">
         <nav id="site-nav">
            <div class="category closed"><a href="../index.html" title="The root of the site.">NVIDIA Deep Learning SDK</a></div>
            <div class="category"><a href="index.html" title="cuDNN Developer Guide">cuDNN Developer Guide</a></div>
            <ul>
               <li>
                  <div class="section-link"><a href="#overview">1.&nbsp;Overview</a></div>
               </li>
               <li>
                  <div class="section-link"><a href="#general-description">2.&nbsp;General Description</a></div>
                  <ul>
                     <li>
                        <div class="section-link"><a href="#programming-model">2.1.&nbsp;Programming Model</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#convolution-formulas">2.2.&nbsp;Convolution Formulas</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#notation">2.3.&nbsp;Notation</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#tensor-descriptor">2.4.&nbsp;Tensor Descriptor</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#WXWZ-tensor-descriptor">2.4.1.&nbsp;WXYZ Tensor Descriptor</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#four-D-tensor-descriptor">2.4.2.&nbsp;4-D Tensor Descriptor</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#five-D-tensor-descriptor">2.4.3.&nbsp;5-D Tensor Description</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#Fully-packed-tensors">2.4.4.&nbsp;Fully-packed tensors</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#Partially-packed-tensors">2.4.5.&nbsp;Partially-packed tensors</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#Spatially-packed-tensors">2.4.6.&nbsp;Spatially packed tensors</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#Overlapping-tensors">2.4.7.&nbsp;Overlapping tensors</a></div>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="#data-layout-formats">2.5.&nbsp;Data Layout Formats</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#data-layout-formats-example-x32">2.5.1.&nbsp;Example</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#nchw-layout-x32">2.5.2.&nbsp;NCHW Memory Layout</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#nhwc-layout-x32">2.5.3.&nbsp;NHWC Memory Layout</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#nc32hw32-layout-x32">2.5.4.&nbsp;NC/32HW32 Memory Layout</a></div>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="#thread-safety">2.6.&nbsp;Thread Safety</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#reproducibility">2.7.&nbsp;Reproducibility (determinism)</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#scaling-parameters">2.8.&nbsp;Scaling Parameters</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#tensor_ops">2.9.&nbsp;Tensor Core Operations</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#tensor-ops-basics">2.9.1.&nbsp;Basics</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#tensor-ops-conv-functions">2.9.2.&nbsp;Convolution Functions</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#tensor-ops-conv-functions-pre-req">2.9.2.1.&nbsp;Prerequisite</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#tensor-ops-conv-functions-supported-algos">2.9.2.2.&nbsp;Supported Algorithms</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#tensor-ops-conv-functions-data-filter-formats">2.9.2.3.&nbsp;Data and Filter Formats</a></div>
                                 </li>
                              </ul>
                           </li>
                           <li>
                              <div class="section-link"><a href="#tensor-ops-rnn-functions">2.9.3.&nbsp;RNN Functions</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#tensor-ops-rnn-functions-pre-req">2.9.3.1.&nbsp;Prerequisite</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#tensor-ops-rnn-functions-supported-algos">2.9.3.2.&nbsp;Supported Algorithms</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#tensor-ops-rnn-functions-data-filter-formats">2.9.3.3.&nbsp;Data and Filter Formats</a></div>
                                 </li>
                              </ul>
                           </li>
                           <li>
                              <div class="section-link"><a href="#tensor-ops-tensor-transformations">2.9.4.&nbsp;Tensor Transformations </a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#tensor-ops-tensor-transformations-fp16">2.9.4.1.&nbsp;FP16 Data </a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#tensor-ops-tensor-transformations-fp32-to-fp16">2.9.4.2.&nbsp;FP32-to-FP16 Conversion </a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#tensor-ops-tensor-transformations-padding">2.9.4.3.&nbsp;Padding </a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#tensor-ops-tensor-transformations-folding">2.9.4.4.&nbsp;Folding </a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#tensor-ops-tensor-transformations-conversion">2.9.4.5.&nbsp;Conversion Between NCHW and NHWC </a></div>
                                 </li>
                              </ul>
                           </li>
                           <li>
                              <div class="section-link"><a href="#tensor-ops-guidelines-for-dl-compiler">2.9.5.&nbsp;Guidelines for a Deep Learning Compiler</a></div>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="#requirements">2.10.&nbsp;GPU and driver requirements</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#backward-compatibility">2.11.&nbsp;Backward compatibility and deprecation policy</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#grouped-convolutions">2.12.&nbsp;Grouped Convolutions</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#api-logging">2.13.&nbsp;API Logging</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#features-of-rnn-functions">2.14.&nbsp;Features of RNN Functions</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#mixed-precision-numerical-accuracy">2.15.&nbsp;Mixed Precision Numerical Accuracy</a></div>
                     </li>
                  </ul>
               </li>
               <li>
                  <div class="section-link"><a href="#datatypes-reference">3.&nbsp;cuDNN Datatypes Reference</a></div>
                  <ul>
                     <li>
                        <div class="section-link"><a href="#cudnnActivationDescriptor_t">3.1.&nbsp;cudnnActivationDescriptor_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnActivationMode_t">3.2.&nbsp;cudnnActivationMode_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnAttnDescriptor_t">3.3.&nbsp;cudnnAttnDescriptor_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnAttnQueryMap_t">3.4.&nbsp;cudnnAttnQueryMap_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnBatchNormMode_t">3.5.&nbsp;cudnnBatchNormMode_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnBatchNormOps_t">3.6.&nbsp;cudnnBatchNormOps_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnConvolutionBwdDataAlgo_t">3.7.&nbsp;cudnnConvolutionBwdDataAlgo_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnConvolutionBwdDataAlgoPerf_t">3.8.&nbsp;cudnnConvolutionBwdDataAlgoPerf_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnConvolutionBwdDataPreference_t">3.9.&nbsp;cudnnConvolutionBwdDataPreference_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnConvolutionBwdFilterAlgo_t">3.10.&nbsp;cudnnConvolutionBwdFilterAlgo_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnConvolutionBwdFilterAlgoPerf_t">3.11.&nbsp;cudnnConvolutionBwdFilterAlgoPerf_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnConvolutionBwdFilterPreference_t">3.12.&nbsp;cudnnConvolutionBwdFilterPreference_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnConvolutionDescriptor_t">3.13.&nbsp;cudnnConvolutionDescriptor_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnConvolutionFwdAlgo_t">3.14.&nbsp;cudnnConvolutionFwdAlgo_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnConvolutionFwdAlgoPerf_t">3.15.&nbsp;cudnnConvolutionFwdAlgoPerf_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnConvolutionFwdPreference_t">3.16.&nbsp;cudnnConvolutionFwdPreference_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnConvolutionMode_t">3.17.&nbsp;cudnnConvolutionMode_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnCTCLossAlgo_t">3.18.&nbsp;cudnnCTCLossAlgo_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnCTCLossDescriptor_t">3.19.&nbsp;cudnnCTCLossDescriptor_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnDataType_t">3.20.&nbsp;cudnnDataType_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnDeterminism_t">3.21.&nbsp;cudnnDeterminism_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnDirectionMode_t">3.22.&nbsp;cudnnDirectionMode_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnDivNormMode_t">3.23.&nbsp;cudnnDivNormMode_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnDropoutDescriptor_t">3.24.&nbsp;cudnnDropoutDescriptor_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnErrQueryMode_t">3.25.&nbsp;cudnnErrQueryMode_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnFilterDescriptor_t">3.26.&nbsp;cudnnFilterDescriptor_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnFoldingDirection_t">3.27.&nbsp;cudnnFoldingDirection_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnFusedOps_t">3.28.&nbsp;cudnnFusedOps_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnFusedOpsConstParamLabel_t">3.29.&nbsp;cudnnFusedOpsConstParamLabel_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnFusedOpsConstParamPack_t">3.30.&nbsp;cudnnFusedOpsConstParamPack_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnFusedOpsPlan_t">3.31.&nbsp;cudnnFusedOpsPlan_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnFusedOpsPointerPlaceHolder_t">3.32.&nbsp;cudnnFusedOpsPointerPlaceHolder_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnFusedOpsVariantParamLabel_t">3.33.&nbsp;cudnnFusedOpsVariantParamLabel_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnFusedOpsVariantParamPack_t">3.34.&nbsp;cudnnFusedOpsVariantParamPack_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnHandle_t">3.35.&nbsp;cudnnHandle_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnIndicesType_t">3.36.&nbsp;cudnnIndicesType_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnLossNormalizationMode_t">3.37.&nbsp;cudnnLossNormalizationMode_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnLRNMode_t">3.38.&nbsp;cudnnLRNMode_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnMathType_t">3.39.&nbsp;cudnnMathType_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnMultiHeadAttnWeightKind_t">3.40.&nbsp;cudnnMultiHeadAttnWeightKind_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnNanPropagation_t">3.41.&nbsp;cudnnNanPropagation_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnOpTensorDescriptor_t">3.42.&nbsp;cudnnOpTensorDescriptor_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnOpTensorOp_t">3.43.&nbsp;cudnnOpTensorOp_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnPersistentRNNPlan_t">3.44.&nbsp;cudnnPersistentRNNPlan_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnPoolingDescriptor_t">3.45.&nbsp;cudnnPoolingDescriptor_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnPoolingMode_t">3.46.&nbsp;cudnnPoolingMode_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnReduceTensorDescriptor_t">3.47.&nbsp;cudnnReduceTensorDescriptor_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#unique_274979723">3.48.&nbsp;cudnnReduceTensorIndices_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnReduceTensorOp_t">3.49.&nbsp;cudnnReduceTensorOp_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnReorderType_t">3.50.&nbsp;cudnnReorderType_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnRNNAlgo_t">3.51.&nbsp;cudnnRNNAlgo_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnRNNBiasMode_t">3.52.&nbsp;cudnnRNNBiasMode_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnRNNClipMode_t">3.53.&nbsp;cudnnRNNClipMode_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnRNNDataDescriptor_t">3.54.&nbsp;cudnnRNNDataDescriptor_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnRNNDataLayout_t">3.55.&nbsp;cudnnRNNDataLayout_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnRNNDescriptor_t">3.56.&nbsp;cudnnRNNDescriptor_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnRNNInputMode_t">3.57.&nbsp;cudnnRNNInputMode_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnRNNMode_t">3.58.&nbsp;cudnnRNNMode_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnRNNPaddingMode_t">3.59.&nbsp;cudnnRNNPaddingMode_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSamplerType_t">3.60.&nbsp;cudnnSamplerType_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSeqDataAxis_t">3.61.&nbsp;cudnnSeqDataAxis_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSeqDataDescriptor_t">3.62.&nbsp;cudnnSeqDataDescriptor_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSoftmaxAlgorithm_t">3.63.&nbsp;cudnnSoftmaxAlgorithm_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSoftmaxMode_t">3.64.&nbsp;cudnnSoftmaxMode_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSpatialTransformerDescriptor_t">3.65.&nbsp;cudnnSpatialTransformerDescriptor_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnStatus_t">3.66.&nbsp;cudnnStatus_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnTensorDescriptor_t">3.67.&nbsp;cudnnTensorDescriptor_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnTensorFormat_t">3.68.&nbsp;cudnnTensorFormat_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnTensorTransformDescriptor_t">3.69.&nbsp;cudnnTensorTransformDescriptor_t</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnWgradMode_t">3.70.&nbsp;cudnnWgradMode_t</a></div>
                     </li>
                  </ul>
               </li>
               <li>
                  <div class="section-link"><a href="#api-introduction">4.&nbsp;cuDNN API Reference</a></div>
                  <ul>
                     <li>
                        <div class="section-link"><a href="#cudnnActivationBackward">4.1.&nbsp;cudnnActivationBackward</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnActivationForward">4.2.&nbsp;cudnnActivationForward</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnAddTensor">4.3.&nbsp;cudnnAddTensor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnBatchNormalizationBackward">4.4.&nbsp;cudnnBatchNormalizationBackward</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnBatchNormalizationBackwardEx">4.5.&nbsp;cudnnBatchNormalizationBackwardEx</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnBatchNormalizationForwardInference">4.6.&nbsp;cudnnBatchNormalizationForwardInference</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnBatchNormalizationForwardTraining">4.7.&nbsp;cudnnBatchNormalizationForwardTraining</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnBatchNormalizationForwardTrainingEx">4.8.&nbsp;cudnnBatchNormalizationForwardTrainingEx</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnConvolutionBackwardBias">4.9.&nbsp;cudnnConvolutionBackwardBias</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnConvolutionBackwardData">4.10.&nbsp;cudnnConvolutionBackwardData</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnConvolutionBackwardFilter">4.11.&nbsp;cudnnConvolutionBackwardFilter</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnConvolutionBiasActivationForward">4.12.&nbsp;cudnnConvolutionBiasActivationForward</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnConvolutionForward">4.13.&nbsp;cudnnConvolutionForward</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnCreate">4.14.&nbsp;cudnnCreate</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnCreateActivationDescriptor">4.15.&nbsp;cudnnCreateActivationDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnCreateAlgorithmDescriptor">4.16.&nbsp;cudnnCreateAlgorithmDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnCreateAlgorithmPerformance">4.17.&nbsp;cudnnCreateAlgorithmPerformance</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnCreateAttnDescriptor">4.18.&nbsp;cudnnCreateAttnDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnCreateConvolutionDescriptor">4.19.&nbsp;cudnnCreateConvolutionDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnCreateCTCLossDescriptor">4.20.&nbsp;cudnnCreateCTCLossDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnCreateDropoutDescriptor">4.21.&nbsp;cudnnCreateDropoutDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnCreateFilterDescriptor">4.22.&nbsp;cudnnCreateFilterDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnCreateFusedOpsConstParamPack">4.23.&nbsp;cudnnCreateFusedOpsConstParamPack</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnCreateFusedOpsPlan">4.24.&nbsp;cudnnCreateFusedOpsPlan</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnCreateFusedOpsVariantParamPack">4.25.&nbsp;cudnnCreateFusedOpsVariantParamPack</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnCreateLRNDescriptor">4.26.&nbsp;cudnnCreateLRNDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnCreateOpTensorDescriptors">4.27.&nbsp;cudnnCreateOpTensorDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnCreatePersistentRNNPlan">4.28.&nbsp;cudnnCreatePersistentRNNPlan</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnCreatePoolingDescriptor">4.29.&nbsp;cudnnCreatePoolingDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnCreateReduceTensorDescriptor">4.30.&nbsp;cudnnCreateReduceTensorDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnCreateRNNDataDescriptor">4.31.&nbsp;cudnnCreateRNNDataDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnCreateRNNDescriptor">4.32.&nbsp;cudnnCreateRNNDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnCreateSeqDataDescriptor">4.33.&nbsp;cudnnCreateSeqDataDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnCreateSpatialTransformerDescriptor">4.34.&nbsp;cudnnCreateSpatialTransformerDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnCreateTensorDescriptor">4.35.&nbsp;cudnnCreateTensorDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnCreateTensorTransformDescriptor">4.36.&nbsp;cudnnCreateTensorTransformDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnCTCLoss">4.37.&nbsp;cudnnCTCLoss</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnDeriveBNTensorDescriptor">4.38.&nbsp;cudnnDeriveBNTensorDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnDestroy">4.39.&nbsp;cudnnDestroy</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnDestroyActivationDescriptor">4.40.&nbsp;cudnnDestroyActivationDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnDestroyAlgorithmDescriptor">4.41.&nbsp;cudnnDestroyAlgorithmDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnDestroyAlgorithmPerformance">4.42.&nbsp;cudnnDestroyAlgorithmPerformance</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnDestroyAttnDescriptor">4.43.&nbsp;cudnnDestroyAttnDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnDestroyConvolutionDescriptor">4.44.&nbsp;cudnnDestroyConvolutionDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnDestroyCTCLossDescriptor">4.45.&nbsp;cudnnDestroyCTCLossDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnDestroyDropoutDescriptor">4.46.&nbsp;cudnnDestroyDropoutDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnDestroyFilterDescriptor">4.47.&nbsp;cudnnDestroyFilterDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnDestroyFusedOpsConstParamPack">4.48.&nbsp;cudnnDestroyFusedOpsConstParamPack</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnDestroyFusedOpsPlan">4.49.&nbsp;cudnnDestroyFusedOpsPlan</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnDestroyFusedOpsVariantParamPack">4.50.&nbsp;cudnnDestroyFusedOpsVariantParamPack</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnDestroyLRNDescriptor">4.51.&nbsp;cudnnDestroyLRNDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnDestroyOpTensorDescriptor">4.52.&nbsp;cudnnDestroyOpTensorDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnDestroyPersistentRNNPlan">4.53.&nbsp;cudnnDestroyPersistentRNNPlan</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnDestroyPoolingDescriptor">4.54.&nbsp;cudnnDestroyPoolingDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnDestroyReduceTensorDescriptor">4.55.&nbsp;cudnnDestroyReduceTensorDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnDestroyRNNDataDescriptor">4.56.&nbsp;cudnnDestroyRNNDataDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnDestroyRNNDescriptor">4.57.&nbsp;cudnnDestroyRNNDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnDestroySeqDataDescriptor">4.58.&nbsp;cudnnDestroySeqDataDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnDestroySpatialTransformerDescriptor">4.59.&nbsp;cudnnDestroySpatialTransformerDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnDestroyTensorDescriptor">4.60.&nbsp;cudnnDestroyTensorDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnDestroyTensorTransformDescriptor">4.61.&nbsp;cudnnDestroyTensorTransformDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnDivisiveNormalizationBackward">4.62.&nbsp;cudnnDivisiveNormalizationBackward</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnDivisiveNormalizationForward">4.63.&nbsp;cudnnDivisiveNormalizationForward</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnDropoutBackward">4.64.&nbsp;cudnnDropoutBackward</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnDropoutForward">4.65.&nbsp;cudnnDropoutForward</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnDropoutGetReserveSpaceSize">4.66.&nbsp;cudnnDropoutGetReserveSpaceSize</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnDropoutGetStatesSize">4.67.&nbsp;cudnnDropoutGetStatesSize</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnFindConvolutionBackwardDataAlgorithm">4.68.&nbsp;cudnnFindConvolutionBackwardDataAlgorithm</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnFindConvolutionBackwardDataAlgorithmEx">4.69.&nbsp;cudnnFindConvolutionBackwardDataAlgorithmEx</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnFindConvolutionBackwardFilterAlgorithm">4.70.&nbsp;cudnnFindConvolutionBackwardFilterAlgorithm</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnFindConvolutionBackwardFilterAlgorithmEx">4.71.&nbsp;cudnnFindConvolutionBackwardFilterAlgorithmEx</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnFindConvolutionForwardAlgorithm">4.72.&nbsp;cudnnFindConvolutionForwardAlgorithm</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnFindConvolutionForwardAlgorithmEx">4.73.&nbsp;cudnnFindConvolutionForwardAlgorithmEx</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnFindRNNBackwardDataAlgorithmEx">4.74.&nbsp;cudnnFindRNNBackwardDataAlgorithmEx</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnFindRNNBackwardWeightsAlgorithmEx">4.75.&nbsp;cudnnFindRNNBackwardWeightsAlgorithmEx</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnFindRNNForwardInferenceAlgorithmEx">4.76.&nbsp;cudnnFindRNNForwardInferenceAlgorithmEx</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnFindRNNForwardTrainingAlgorithmEx">4.77.&nbsp;cudnnFindRNNForwardTrainingAlgorithmEx</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnFusedOpsExecute">4.78.&nbsp;cudnnFusedOpsExecute</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetActivationDescriptor">4.79.&nbsp;cudnnGetActivationDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetAlgorithmDescriptor">4.80.&nbsp;cudnnGetAlgorithmDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetAlgorithmPerformance">4.81.&nbsp;cudnnGetAlgorithmPerformance</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetAlgorithmSpaceSize">4.82.&nbsp;cudnnGetAlgorithmSpaceSize</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetAttnDescriptor">4.83.&nbsp;cudnnGetAttnDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnBatchNormalizationBackwardExWorkspaceSize">4.84.&nbsp;cudnnBatchNormalizationBackwardExWorkspaceSize</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnBatchNormalizationForwardTrainingExWorkspaceSize">4.85.&nbsp;cudnnBatchNormalizationForwardTrainingExWorkspaceSize</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetBatchNormalizationTrainingExReserveSpaceSize">4.86.&nbsp;cudnnGetBatchNormalizationTrainingExReserveSpaceSize</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetCallback">4.87.&nbsp;cudnnGetCallback</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetConvolution2dDescriptor">4.88.&nbsp;cudnnGetConvolution2dDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetConvolution2dForwardOutputDim">4.89.&nbsp;cudnnGetConvolution2dForwardOutputDim</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetConvolutionBackwardDataAlgorithm">4.90.&nbsp;cudnnGetConvolutionBackwardDataAlgorithm</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetConvolutionBackwardDataAlgorithm_v7">4.91.&nbsp;cudnnGetConvolutionBackwardDataAlgorithm_v7</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetConvolutionBackwardDataAlgorithmMaxCount">4.92.&nbsp;cudnnGetConvolutionBackwardDataAlgorithmMaxCount</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetConvolutionBackwardDataWorkspaceSize">4.93.&nbsp;cudnnGetConvolutionBackwardDataWorkspaceSize</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetConvolutionBackwardFilterAlgorithm">4.94.&nbsp;cudnnGetConvolutionBackwardFilterAlgorithm</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetConvolutionBackwardFilterAlgorithm_v7">4.95.&nbsp;cudnnGetConvolutionBackwardFilterAlgorithm_v7</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetConvolutionBackwardFilterAlgorithmMaxCount">4.96.&nbsp;cudnnGetConvolutionBackwardFilterAlgorithmMaxCount</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetConvolutionBackwardFilterWorkspaceSize">4.97.&nbsp;cudnnGetConvolutionBackwardFilterWorkspaceSize</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetConvolutionForwardAlgorithm">4.98.&nbsp;cudnnGetConvolutionForwardAlgorithm</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetConvolutionForwardAlgorithm_v7">4.99.&nbsp;cudnnGetConvolutionForwardAlgorithm_v7</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetConvolutionForwardAlgorithmMaxCount">4.100.&nbsp;cudnnGetConvolutionForwardAlgorithmMaxCount</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetConvolutionForwardWorkspaceSize">4.101.&nbsp;cudnnGetConvolutionForwardWorkspaceSize</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetConvolutionGroupCount">4.102.&nbsp;cudnnGetConvolutionGroupCount</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetConvolutionMathType">4.103.&nbsp;cudnnGetConvolutionMathType</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetConvolutionNdDescriptor">4.104.&nbsp;cudnnGetConvolutionNdDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetConvolutionNdForwardOutputDim">4.105.&nbsp;cudnnGetConvolutionNdForwardOutputDim</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetConvolutionReorderType">4.106.&nbsp;cudnnGetConvolutionReorderType</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetCTCLossDescriptor">4.107.&nbsp;cudnnGetCTCLossDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetCTCLossWorkspaceSize">4.108.&nbsp;cudnnGetCTCLossWorkspaceSize</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetCudartVersion">4.109.&nbsp;cudnnGetCudartVersion</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetDropoutDescriptor">4.110.&nbsp;cudnnGetDropoutDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetErrorString">4.111.&nbsp;cudnnGetErrorString</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetFilter4dDescriptor">4.112.&nbsp;cudnnGetFilter4dDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetFilterNdDescriptor">4.113.&nbsp;cudnnGetFilterNdDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetFusedOpsConstParamPackAttribute">4.114.&nbsp;cudnnGetFusedOpsConstParamPackAttribute</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetFusedOpsVariantParamPackAttribute">4.115.&nbsp;cudnnGetFusedOpsVariantParamPackAttribute</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetLRNDescriptor">4.116.&nbsp;cudnnGetLRNDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetMultiHeadAttnBuffers">4.117.&nbsp;cudnnGetMultiHeadAttnBuffers</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetMultiHeadAttnWeights">4.118.&nbsp;cudnnGetMultiHeadAttnWeights</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetOpTensorDescriptor">4.119.&nbsp;cudnnGetOpTensorDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetPooling2dDescriptor">4.120.&nbsp;cudnnGetPooling2dDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetPooling2dForwardOutputDim">4.121.&nbsp;cudnnGetPooling2dForwardOutputDim</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetPoolingNdDescriptor">4.122.&nbsp;cudnnGetPoolingNdDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetPoolingNdForwardOutputDim">4.123.&nbsp;cudnnGetPoolingNdForwardOutputDim</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetProperty">4.124.&nbsp;cudnnGetProperty</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetReduceTensorDescriptor">4.125.&nbsp;cudnnGetReduceTensorDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetReductionIndicesSize">4.126.&nbsp;cudnnGetReductionIndicesSize</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetReductionWorkspaceSize">4.127.&nbsp;cudnnGetReductionWorkspaceSize</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetRNNBiasMode">4.128.&nbsp;cudnnGetRNNBiasMode</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetRNNDataDescriptor">4.129.&nbsp;cudnnGetRNNDataDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetRNNDescriptor">4.130.&nbsp;cudnnGetRNNDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetRNNLinLayerBiasParams">4.131.&nbsp;cudnnGetRNNLinLayerBiasParams</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetRNNLinLayerMatrixParams">4.132.&nbsp;cudnnGetRNNLinLayerMatrixParams</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetRNNPaddingMode">4.133.&nbsp;cudnnGetRNNPaddingMode</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetRNNParamsSize">4.134.&nbsp;cudnnGetRNNParamsSize</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetRNNProjectionLayers">4.135.&nbsp;cudnnGetRNNProjectionLayers</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetRNNTrainingReserveSize">4.136.&nbsp;cudnnGetRNNTrainingReserveSize</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetRNNWorkspaceSize">4.137.&nbsp;cudnnGetRNNWorkspaceSize</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetSeqDataDescriptor">4.138.&nbsp;cudnnGetSeqDataDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetStream">4.139.&nbsp;cudnnGetStream</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetTensor4dDescriptor">4.140.&nbsp;cudnnGetTensor4dDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetTensorNdDescriptor">4.141.&nbsp;cudnnGetTensorNdDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetTensorSizeInBytes">4.142.&nbsp;cudnnGetTensorSizeInBytes</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetTensorTransformDescriptor">4.143.&nbsp;cudnnGetTensorTransformDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnGetVersion">4.144.&nbsp;cudnnGetVersion</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnIm2Col">4.145.&nbsp;cudnnIm2Col</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnInitTransformDest">4.146.&nbsp;cudnnInitTransformDest</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnLRNCrossChannelBackward">4.147.&nbsp;cudnnLRNCrossChannelBackward</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnLRNCrossChannelForward">4.148.&nbsp;cudnnLRNCrossChannelForward</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnMakeFusedOpsPlan">4.149.&nbsp;cudnnMakeFusedOpsPlan</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnMultiHeadAttnBackwardData">4.150.&nbsp;cudnnMultiHeadAttnBackwardData</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnMultiHeadAttnBackwardWeights">4.151.&nbsp;cudnnMultiHeadAttnBackwardWeights</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnMultiHeadAttnForward">4.152.&nbsp;cudnnMultiHeadAttnForward</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnOpTensor">4.153.&nbsp;cudnnOpTensor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnPoolingBackward">4.154.&nbsp;cudnnPoolingBackward</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnPoolingForward">4.155.&nbsp;cudnnPoolingForward</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnQueryRuntimeError">4.156.&nbsp;cudnnQueryRuntimeError</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnReduceTensor">4.157.&nbsp;cudnnReduceTensor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnReorderFilterAndBias">4.158.&nbsp;cudnnReorderFilterAndBias</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnRestoreAlgorithm">4.159.&nbsp;cudnnRestoreAlgorithm</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnRestoreDropoutDescriptor">4.160.&nbsp;cudnnRestoreDropoutDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnRNNBackwardData">4.161.&nbsp;cudnnRNNBackwardData</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnRNNBackwardDataEx">4.162.&nbsp;cudnnRNNBackwardDataEx</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnRNNBackwardWeights">4.163.&nbsp;cudnnRNNBackwardWeights</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnRNNBackwardWeightsEx">4.164.&nbsp;cudnnRNNBackwardWeightsEx</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnRNNForwardInference">4.165.&nbsp;cudnnRNNForwardInference</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnRNNForwardInferenceEx">4.166.&nbsp;cudnnRNNForwardInferenceEx</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnRNNForwardTraining">4.167.&nbsp;cudnnRNNForwardTraining</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnRNNForwardTrainingEx">4.168.&nbsp;cudnnRNNForwardTrainingEx</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnRNNGetClip">4.169.&nbsp;cudnnRNNGetClip</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnRNNSetClip">4.170.&nbsp;cudnnRNNSetClip</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSaveAlgorithm">4.171.&nbsp;cudnnSaveAlgorithm</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnScaleTensor">4.172.&nbsp;cudnnScaleTensor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSetActivationDescriptor">4.173.&nbsp;cudnnSetActivationDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSetAlgorithmDescriptor">4.174.&nbsp;cudnnSetAlgorithmDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSetAlgorithmPerformance">4.175.&nbsp;cudnnSetAlgorithmPerformance</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSetAttnDescriptor">4.176.&nbsp;cudnnSetAttnDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSetCallback">4.177.&nbsp;cudnnSetCallback</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSetConvolution2dDescriptor">4.178.&nbsp;cudnnSetConvolution2dDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSetConvolutionGroupCount">4.179.&nbsp;cudnnSetConvolutionGroupCount</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSetConvolutionMathType">4.180.&nbsp;cudnnSetConvolutionMathType</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSetConvolutionNdDescriptor">4.181.&nbsp;cudnnSetConvolutionNdDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSetConvolutionReorderType">4.182.&nbsp;cudnnSetConvolutionReorderType</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSetCTCLossDescriptor">4.183.&nbsp;cudnnSetCTCLossDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSetCTCLossDescriptorEx">4.184.&nbsp;cudnnSetCTCLossDescriptorEx</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSetDropoutDescriptor">4.185.&nbsp;cudnnSetDropoutDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSetFilter4dDescriptor">4.186.&nbsp;cudnnSetFilter4dDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSetFilterNdDescriptor">4.187.&nbsp;cudnnSetFilterNdDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSetFusedOpsConstParamPackAttribute">4.188.&nbsp;cudnnSetFusedOpsConstParamPackAttribute</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSetFusedOpsVariantParamPackAttribute">4.189.&nbsp;cudnnSetFusedOpsVariantParamPackAttribute</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSetLRNDescriptor">4.190.&nbsp;cudnnSetLRNDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSetOpTensorDescriptor">4.191.&nbsp;cudnnSetOpTensorDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSetPersistentRNNPlan">4.192.&nbsp;cudnnSetPersistentRNNPlan</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSetPooling2dDescriptor">4.193.&nbsp;cudnnSetPooling2dDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSetPoolingNdDescriptor">4.194.&nbsp;cudnnSetPoolingNdDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSetReduceTensorDescriptor">4.195.&nbsp;cudnnSetReduceTensorDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSetRNNBiasMode">4.196.&nbsp;cudnnSetRNNBiasMode</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSetRNNDataDescriptor">4.197.&nbsp;cudnnSetRNNDataDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSetRNNDescriptor">4.198.&nbsp;cudnnSetRNNDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSetRNNDescriptor_v5">4.199.&nbsp;cudnnSetRNNDescriptor_v5</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSetRNNDescriptor_v6">4.200.&nbsp;cudnnSetRNNDescriptor_v6</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSetRNNMatrixMathType">4.201.&nbsp;cudnnSetRNNMatrixMathType</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSetRNNPaddingMode">4.202.&nbsp;cudnnSetRNNPaddingMode</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSetRNNProjectionLayers">4.203.&nbsp;cudnnSetRNNProjectionLayers</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSetSeqDataDescriptor">4.204.&nbsp;cudnnSetSeqDataDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSetSpatialTransformerNdDescriptor">4.205.&nbsp;cudnnSetSpatialTransformerNdDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSetStream">4.206.&nbsp;cudnnSetStream</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSetTensor4dDescriptor">4.207.&nbsp;cudnnSetTensor4dDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSetTensor4dDescriptorEx">4.208.&nbsp;cudnnSetTensor4dDescriptorEx</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSetTensor">4.209.&nbsp;cudnnSetTensor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSetTensorNdDescriptor">4.210.&nbsp;cudnnSetTensorNdDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSetTensorNdDescriptorEx">4.211.&nbsp;cudnnSetTensorNdDescriptorEx</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSetTensorTransformDescriptor">4.212.&nbsp;cudnnSetTensorTransformDescriptor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSoftmaxBackward">4.213.&nbsp;cudnnSoftmaxBackward</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSoftmaxForward">4.214.&nbsp;cudnnSoftmaxForward</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSpatialTfGridGeneratorBackward">4.215.&nbsp;cudnnSpatialTfGridGeneratorBackward</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSpatialTfGridGeneratorForward">4.216.&nbsp;cudnnSpatialTfGridGeneratorForward</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSpatialTfSamplerBackward">4.217.&nbsp;cudnnSpatialTfSamplerBackward</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnSpatialTfSamplerForward">4.218.&nbsp;cudnnSpatialTfSamplerForward</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnTransformTensor">4.219.&nbsp;cudnnTransformTensor</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cudnnTransformTensorEx">4.220.&nbsp;cudnnTransformTensorEx</a></div>
                     </li>
                  </ul>
               </li>
               <li>
                  <div class="section-link"><a href="#acknowledgments">5.&nbsp;Acknowledgments</a></div>
                  <ul>
                     <li>
                        <div class="section-link"><a href="#university-of-tennessee">5.1.&nbsp;University of Tennessee</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#university-of-california-berkeley">5.2.&nbsp;University of California, Berkeley</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#facebook-ai-research">5.3.&nbsp;Facebook AI Research, New York</a></div>
                     </li>
                  </ul>
               </li>
            </ul>
         </nav>
         <div id="resize-nav"></div>
         <nav id="search-results">
            <h2>Search Results</h2>
            <ol></ol>
         </nav>
         
         <div id="contents-container">
            <div id="breadcrumbs-container">
               <div id="eqn-warning">This document includes math equations
                  (highlighted in red) which are best viewed with <a target="_blank" href="https://www.mozilla.org/firefox">Firefox</a> version 4.0
                  or higher, or another <a target="_blank" href="http://www.w3.org/Math/Software/mathml_software_cat_browsers.html">MathML-aware
                     browser</a>.  
                   There is also a <a href="../pdf/cuDNN-Developer-Guide.pdf">PDF version of this document</a>.
                  
               </div>
               <div id="release-info">cuDNN Developer Guide
                  
                  
                  
                  
                  (<a href="../pdf/cuDNN-Developer-Guide.pdf">PDF</a>)
                  -
                  
                  
                  
                  Last updated June 26, 2019
                  -
                  
                  
                  <span class="st_facebook"></span><span class="st_twitter"></span><span class="st_linkedin"></span><span class="st_reddit"></span><span class="st_slashdot"></span><span class="st_tumblr"></span><span class="st_sharethis"></span></div>
            </div>
            <article id="contents">
               <div class="topic nested0" id="abstract"><a name="abstract" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#abstract" name="abstract" shape="rect">Abstract</a></h2>
                  <div class="body conbody">
                     <p class="shortdesc">This cuDNN Developer Guide provides an overview of cuDNN v7.6.2, and details about the
                        		types, enums, and routines within the cuDNN library API. 
                     </p>
                     <p class="p">For previously released cuDNN developer documentation, see <a class="xref" href="https://docs.nvidia.com/deeplearning/sdk/cudnn-archived/index.html" target="_blank" shape="rect">cuDNN Archives</a>.
                     </p>
                  </div>
               </div>
               <div class="topic concept nested0" id="overview"><a name="overview" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#overview" name="overview" shape="rect">1.&nbsp;Overview</a></h2>
                  <div class="body conbody">
                     <div class="abstract"><span class="shortdesc"></span></div>
                     <p class="p">NVIDIA<sup>®</sup> cuDNN is a GPU-accelerated library of primitives for deep
                        neural networks. It provides highly tuned implementations of routines arising frequently
                        in DNN applications:
                     </p><a name="overview__ul_u1j_bvx_r1b" shape="rect">
                        <!-- --></a><ul class="ul" id="overview__ul_u1j_bvx_r1b">
                        <li class="li">Convolution forward and backward, including cross-correlation</li>
                        <li class="li">Pooling forward and backward</li>
                        <li class="li">Softmax forward and backward</li>
                        <li class="li">Neuron activations forward and backward: <a name="overview__ul_jbj_bvx_r1b" shape="rect">
                              <!-- --></a><ul class="ul" id="overview__ul_jbj_bvx_r1b">
                              <li class="li">Rectified linear (ReLU)</li>
                              <li class="li">Sigmoid</li>
                              <li class="li">Hyperbolic tangent (TANH)</li>
                           </ul>
                        </li>
                        <li class="li">Tensor transformation functions</li>
                        <li class="li">LRN, LCN and batch normalization forward and backward</li>
                     </ul>
                     <p class="p">cuDNN's convolution routines aim for a performance that is competitive with the fastest
                        GEMM (matrix multiply)-based implementations of such routines, while using significantly
                        less memory.
                     </p>
                     <p class="p">cuDNN features include customizable data layouts, supporting flexible dimension ordering,
                        striding, and subregions for the 4D tensors used as inputs and outputs to all of its
                        routines. This flexibility allows easy integration into any neural network
                        implementation, and avoids the input/output transposition steps sometimes necessary with
                        GEMM-based convolutions.
                     </p>
                     <p class="p">cuDNN offers a context-based API that allows for easy multithreading and (optional)
                        interoperability with CUDA streams.
                     </p>
                  </div>
               </div>
               <div class="topic concept nested0" id="general-description"><a name="general-description" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#general-description" name="general-description" shape="rect">2.&nbsp;General Description</a></h2>
                  <div class="body conbody">
                     <div class="abstract"><span class="shortdesc"></span></div>
                     <p class="p">Basic concepts are described in this section.</p>
                  </div>
                  <div class="topic concept nested1" id="programming-model"><a name="programming-model" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#programming-model" name="programming-model" shape="rect">2.1.&nbsp;Programming Model</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p">The cuDNN Library exposes a Host API but assumes that for operations using the GPU, the
                           necessary data is directly accessible from the device.
                        </p>
                        <p class="p">An application using cuDNN must initialize a handle to the library context by calling
                           <samp class="ph codeph"><a class="xref" href="index.html#cudnnCreate" shape="rect">cudnnCreate()</a></samp>. This handle is
                           explicitly passed to every subsequent library function that operates on GPU data. Once
                           the application finishes using cuDNN, it can release the resources associated with the
                           library handle using <samp class="ph codeph"><a class="xref" href="index.html#cudnnDestroy" shape="rect">cudnnDestroy()</a></samp>.
                           This approach allows the user to explicitly control the library's functioning when using
                           multiple host threads, GPUs and CUDA Streams. 
                        </p>
                        <p class="p">For example, an application can use <samp class="ph codeph"><a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g69e73c7dda3fc05306ae7c811a690fac" target="_blank" shape="rect">cudaSetDevice</a>()</samp> to associate
                           different devices with different host threads, and in each of those host threads, use a
                           unique cuDNN handle that directs the library calls to the device associated with it.
                           Thus the cuDNN library calls made with different handles will automatically run on
                           different devices. 
                        </p>
                        <p class="p">The device associated with a particular cuDNN context is assumed to remain unchanged
                           between the corresponding <samp class="ph codeph">cudnnCreate()</samp> and
                           <samp class="ph codeph">cudnnDestroy()</samp> calls. In order for the cuDNN library to use a
                           different device within the same host thread, the application must set the new device to
                           be used by calling <samp class="ph codeph">cudaSetDevice()</samp> and then create another cuDNN
                           context, which will be associated with the new device, by calling
                           <samp class="ph codeph">cudnnCreate()</samp>. 
                        </p>
                        <p class="p"><strong class="ph b">cuDNN API Compatibility</strong></p>
                        <p class="p">Beginning in cuDNN 7, the binary compatibility of patch and minor releases is maintained
                           as follows:
                        </p>
                        <ul class="ul">
                           <li class="li">Any patch release x.y.z is forward- or backward-compatible with applications built against another cuDNN patch release x.y.w
                              (i.e., of the same major and minor version number, but having w!=z)
                           </li>
                           <li class="li">cuDNN minor releases beginning with cuDNN 7 are binary backward-compatible with applications built against the same or earlier
                              patch release (i.e., an app built against cuDNN 7.x is binary compatible with cuDNN library 7.y, where y&gt;=x)
                           </li>
                           <li class="li">Applications compiled with a cuDNN version 7.y are not guaranteed to work with 7.x release when y &gt; x.</li>
                        </ul>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="convolution-formulas"><a name="convolution-formulas" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#convolution-formulas" name="convolution-formulas" shape="rect">2.2.&nbsp;Convolution Formulas</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p">This section describes the various convolution formulas implemented in cuDNN convolution
                           			functions. 
                        </p>
                        <p class="p"></p>
                        <p class="p">The convolution terms described in the table below apply to all the convolution formulas
                           			that follow.
                        </p>
                        <p class="p"><strong class="ph b">TABLE OF CONVOLUTION TERMS</strong></p>
                        <div class="tablenoborder"><a name="convolution-formulas__table_ztl_dly_cfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="convolution-formulas__table_ztl_dly_cfb" class="table" frame="border" border="1" rules="all">
                              <thead class="thead" align="left">
                                 <tr class="row">
                                    <th class="entry" valign="top" width="24.509803921568626%" id="d54e236" rowspan="1" colspan="1">Term</th>
                                    <th class="entry" valign="top" width="75.49019607843137%" id="d54e239" rowspan="1" colspan="1">Description</th>
                                 </tr>
                              </thead>
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" valign="top" width="24.509803921568626%" headers="d54e236" rowspan="1" colspan="1">
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <mi>x</mi>
                                          </mrow>
                                       </math>
                                    </td>
                                    <td class="entry" valign="top" width="75.49019607843137%" headers="d54e239" rowspan="1" colspan="1">Input (image) Tensor</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="24.509803921568626%" headers="d54e236" rowspan="1" colspan="1">
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <mi>w</mi>
                                          </mrow>
                                       </math>
                                    </td>
                                    <td class="entry" valign="top" width="75.49019607843137%" headers="d54e239" rowspan="1" colspan="1">Weight Tensor</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="24.509803921568626%" headers="d54e236" rowspan="1" colspan="1">
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <mi>y</mi>
                                          </mrow>
                                       </math>
                                    </td>
                                    <td class="entry" valign="top" width="75.49019607843137%" headers="d54e239" rowspan="1" colspan="1">Output Tensor</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="24.509803921568626%" headers="d54e236" rowspan="1" colspan="1">
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <mi>n</mi>
                                          </mrow>
                                       </math>
                                    </td>
                                    <td class="entry" valign="top" width="75.49019607843137%" headers="d54e239" rowspan="1" colspan="1">Current Batch Size</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="24.509803921568626%" headers="d54e236" rowspan="1" colspan="1">
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <mi>c</mi>
                                          </mrow>
                                       </math>
                                    </td>
                                    <td class="entry" valign="top" width="75.49019607843137%" headers="d54e239" rowspan="1" colspan="1">Current Input Channel</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="24.509803921568626%" headers="d54e236" rowspan="1" colspan="1">
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <mi>C</mi>
                                          </mrow>
                                       </math>
                                    </td>
                                    <td class="entry" valign="top" width="75.49019607843137%" headers="d54e239" rowspan="1" colspan="1">Total Input Channels</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="24.509803921568626%" headers="d54e236" rowspan="1" colspan="1">
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <mi>H</mi>
                                          </mrow>
                                       </math>
                                    </td>
                                    <td class="entry" valign="top" width="75.49019607843137%" headers="d54e239" rowspan="1" colspan="1">Input Image Height</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="24.509803921568626%" headers="d54e236" rowspan="1" colspan="1">
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <mi>W</mi>
                                          </mrow>
                                       </math>
                                    </td>
                                    <td class="entry" valign="top" width="75.49019607843137%" headers="d54e239" rowspan="1" colspan="1">Input Image Width</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="24.509803921568626%" headers="d54e236" rowspan="1" colspan="1">
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <mi>k</mi>
                                          </mrow>
                                       </math>
                                    </td>
                                    <td class="entry" valign="top" width="75.49019607843137%" headers="d54e239" rowspan="1" colspan="1">Current Output Channel </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="24.509803921568626%" headers="d54e236" rowspan="1" colspan="1">
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <mi>K</mi>
                                          </mrow>
                                       </math>
                                    </td>
                                    <td class="entry" valign="top" width="75.49019607843137%" headers="d54e239" rowspan="1" colspan="1">Total Output Channels</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="24.509803921568626%" headers="d54e236" rowspan="1" colspan="1">
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <mi>p</mi>
                                          </mrow>
                                       </math>
                                    </td>
                                    <td class="entry" valign="top" width="75.49019607843137%" headers="d54e239" rowspan="1" colspan="1">Current Output Height Position</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="24.509803921568626%" headers="d54e236" rowspan="1" colspan="1">
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <mi>q</mi>
                                          </mrow>
                                       </math>
                                    </td>
                                    <td class="entry" valign="top" width="75.49019607843137%" headers="d54e239" rowspan="1" colspan="1">Current Output Width Position</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="24.509803921568626%" headers="d54e236" rowspan="1" colspan="1">
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <mi>G</mi>
                                          </mrow>
                                       </math>
                                    </td>
                                    <td class="entry" valign="top" width="75.49019607843137%" headers="d54e239" rowspan="1" colspan="1">Group Count</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="24.509803921568626%" headers="d54e236" rowspan="1" colspan="1">
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <mi mathvariant="italic">pad</mi>
                                          </mrow>
                                       </math>
                                    </td>
                                    <td class="entry" valign="top" width="75.49019607843137%" headers="d54e239" rowspan="1" colspan="1">Padding Value</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="24.509803921568626%" headers="d54e236" rowspan="1" colspan="1">
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <mi>u</mi>
                                          </mrow>
                                       </math>
                                    </td>
                                    <td class="entry" valign="top" width="75.49019607843137%" headers="d54e239" rowspan="1" colspan="1">Vertical Subsample Stride (along Height)</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="24.509803921568626%" headers="d54e236" rowspan="1" colspan="1">
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <mi mathvariant="italic">v</mi>
                                          </mrow>
                                       </math>
                                    </td>
                                    <td class="entry" valign="top" width="75.49019607843137%" headers="d54e239" rowspan="1" colspan="1">Horizontal Subsample Stride (along Width)</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="24.509803921568626%" headers="d54e236" rowspan="1" colspan="1">
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <msub>
                                                <mi mathvariant="italic">dil</mi>
                                                <mi mathvariant="italic">h</mi>
                                             </msub>
                                          </mrow>
                                       </math>
                                    </td>
                                    <td class="entry" valign="top" width="75.49019607843137%" headers="d54e239" rowspan="1" colspan="1">Vertical Dilation (along Height)</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="24.509803921568626%" headers="d54e236" rowspan="1" colspan="1">
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <msub>
                                                <mi mathvariant="italic">dil</mi>
                                                <mi mathvariant="italic">w</mi>
                                             </msub>
                                          </mrow>
                                       </math>
                                    </td>
                                    <td class="entry" valign="top" width="75.49019607843137%" headers="d54e239" rowspan="1" colspan="1">Horizontal Dilation (along Width)</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="24.509803921568626%" headers="d54e236" rowspan="1" colspan="1">
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <mi>r</mi>
                                          </mrow>
                                       </math>
                                    </td>
                                    <td class="entry" valign="top" width="75.49019607843137%" headers="d54e239" rowspan="1" colspan="1">Current Filter Height </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="24.509803921568626%" headers="d54e236" rowspan="1" colspan="1">
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <mi>R</mi>
                                          </mrow>
                                       </math>
                                    </td>
                                    <td class="entry" valign="top" width="75.49019607843137%" headers="d54e239" rowspan="1" colspan="1">Total Filter Height</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="24.509803921568626%" headers="d54e236" rowspan="1" colspan="1">
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <mi>s</mi>
                                          </mrow>
                                       </math>
                                    </td>
                                    <td class="entry" valign="top" width="75.49019607843137%" headers="d54e239" rowspan="1" colspan="1">Current Filter Width </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="24.509803921568626%" headers="d54e236" rowspan="1" colspan="1">
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <mi>S</mi>
                                          </mrow>
                                       </math>
                                    </td>
                                    <td class="entry" valign="top" width="75.49019607843137%" headers="d54e239" rowspan="1" colspan="1">Total Filter Width</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="24.509803921568626%" headers="d54e236" rowspan="1" colspan="1">
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <msub>
                                                <mi>C</mi>
                                                <mi>g</mi>
                                             </msub>
                                          </mrow>
                                       </math>
                                    </td>
                                    <td class="entry" valign="top" width="75.49019607843137%" headers="d54e239" rowspan="1" colspan="1">
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <mfrac>
                                                <mi>C</mi>
                                                <mi>G</mi>
                                             </mfrac>
                                          </mrow>
                                       </math>
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="24.509803921568626%" headers="d54e236" rowspan="1" colspan="1">
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <msub>
                                                <mi>K</mi>
                                                <mi>g</mi>
                                             </msub>
                                          </mrow>
                                       </math>
                                    </td>
                                    <td class="entry" valign="top" width="75.49019607843137%" headers="d54e239" rowspan="1" colspan="1">
                                       <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mrow>
                                             <mfrac>
                                                <mi>K</mi>
                                                <mi>G</mi>
                                             </mfrac>
                                          </mrow>
                                       </math>
                                    </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                        <div class="section">
                           <h3 class="title sectiontitle">Normal Convolution (using cross-correlation mode)</h3>
                           <p class="p">
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <msub>
                                    <mi>y</mi>
                                    <mi mathvariant="italic">n, k, p, q</mi>
                                 </msub>
                                 <mo>=</mo>
                                 <munderover>
                                    <mo>∑</mo>
                                    <mrow>
                                       <mi>c</mi>
                                    </mrow>
                                    <mrow>
                                       <mi>C</mi>
                                    </mrow>
                                 </munderover>
                                 <mspace width="5px"></mspace>
                                 <munderover>
                                    <mo>∑</mo>
                                    <mrow>
                                       <mi>r</mi>
                                    </mrow>
                                    <mrow>
                                       <mi>R</mi>
                                    </mrow>
                                 </munderover>
                                 <mspace width="5px"></mspace>
                                 <munderover>
                                    <mo>∑</mo>
                                    <mrow>
                                       <mi>s</mi>
                                    </mrow>
                                    <mrow>
                                       <mi>S</mi>
                                    </mrow>
                                 </munderover>
                                 <mspace width="10px"></mspace>
                                 <msub>
                                    <mi>x</mi>
                                    <mi mathvariant="italic">n, c, p+r, q+s </mi>
                                 </msub>
                                 <mspace width="15px"></mspace>
                                 <mrow>
                                    <mi>×</mi>
                                 </mrow>
                                 <mspace width="15px"></mspace>
                                 <mrow>
                                    <msub>
                                       <mi>w</mi>
                                       <mi mathvariant="italic">k,c,r,s</mi>
                                    </msub>
                                 </mrow>
                              </math>
                           </p>
                        </div>
                        <div class="section">
                           <h3 class="title sectiontitle">Convolution with Padding</h3>
                           <p class="p">
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <msub>
                                    <mi>x</mi>
                                    <mi mathvariant="italic"> &lt;0, &lt;0 </mi>
                                 </msub>
                                 <mspace width="5px"></mspace>
                                 <mo>=</mo>
                                 <mrow>
                                    <mi>0</mi>
                                 </mrow>
                              </math>
                           </p>
                           <p class="p">
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <msub>
                                    <mi>x</mi>
                                    <mi mathvariant="italic"> &gt;H, &gt;W </mi>
                                 </msub>
                                 <mspace width="5px"></mspace>
                                 <mo>=</mo>
                                 <mrow>
                                    <mi>0</mi>
                                 </mrow>
                              </math>
                           </p>
                           <p class="p">
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <msub>
                                    <mi>y</mi>
                                    <mi mathvariant="italic">n, k, p, q</mi>
                                 </msub>
                                 <mo>=</mo>
                                 <munderover>
                                    <mo>∑</mo>
                                    <mrow>
                                       <mi>c</mi>
                                    </mrow>
                                    <mrow>
                                       <mi>C</mi>
                                    </mrow>
                                 </munderover>
                                 <mspace width="5px"></mspace>
                                 <munderover>
                                    <mo>∑</mo>
                                    <mrow>
                                       <mi>r</mi>
                                    </mrow>
                                    <mrow>
                                       <mi>R</mi>
                                    </mrow>
                                 </munderover>
                                 <mspace width="5px"></mspace>
                                 <munderover>
                                    <mo>∑</mo>
                                    <mrow>
                                       <mi>s</mi>
                                    </mrow>
                                    <mrow>
                                       <mi>S</mi>
                                    </mrow>
                                 </munderover>
                                 <mspace width="10px"></mspace>
                                 <msub>
                                    <mi>x</mi>
                                    <mi mathvariant="italic">n, c, p+r-pad, q+s-pad </mi>
                                 </msub>
                                 <mspace width="15px"></mspace>
                                 <mrow>
                                    <mi>×</mi>
                                 </mrow>
                                 <mspace width="15px"></mspace>
                                 <mrow>
                                    <msub>
                                       <mi>w</mi>
                                       <mi mathvariant="italic">k,c,r,s</mi>
                                    </msub>
                                 </mrow>
                              </math>
                           </p>
                        </div>
                        <div class="section">
                           <h3 class="title sectiontitle">Convolution with Subsample-Striding</h3>
                           <p class="p">
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <msub>
                                    <mi>y</mi>
                                    <mi mathvariant="italic">n, k, p, q</mi>
                                 </msub>
                                 <mo>=</mo>
                                 <munderover>
                                    <mo>∑</mo>
                                    <mrow>
                                       <mi>c</mi>
                                    </mrow>
                                    <mrow>
                                       <mi>C</mi>
                                    </mrow>
                                 </munderover>
                                 <mspace width="5px"></mspace>
                                 <munderover>
                                    <mo>∑</mo>
                                    <mrow>
                                       <mi>r</mi>
                                    </mrow>
                                    <mrow>
                                       <mi>R</mi>
                                    </mrow>
                                 </munderover>
                                 <mspace width="5px"></mspace>
                                 <munderover>
                                    <mo>∑</mo>
                                    <mrow>
                                       <mi>s</mi>
                                    </mrow>
                                    <mrow>
                                       <mi>S</mi>
                                    </mrow>
                                 </munderover>
                                 <mspace width="10px"></mspace>
                                 <msub>
                                    <mi>x</mi>
                                    <mi mathvariant="italic">n, c, (p*u) + r, (q*v) + s </mi>
                                 </msub>
                                 <mspace width="15px"></mspace>
                                 <mrow>
                                    <mi>×</mi>
                                 </mrow>
                                 <mspace width="15px"></mspace>
                                 <mrow>
                                    <msub>
                                       <mi>w</mi>
                                       <mi mathvariant="italic">k,c,r,s</mi>
                                    </msub>
                                 </mrow>
                              </math>
                           </p>
                        </div>
                        <div class="section">
                           <h3 class="title sectiontitle">Convolution with Dilation</h3>
                           <p class="p">
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <msub>
                                    <mi>y</mi>
                                    <mi mathvariant="italic">n, k, p, q</mi>
                                 </msub>
                                 <mo>=</mo>
                                 <munderover>
                                    <mo>∑</mo>
                                    <mrow>
                                       <mi>c</mi>
                                    </mrow>
                                    <mrow>
                                       <mi>C</mi>
                                    </mrow>
                                 </munderover>
                                 <mspace width="5px"></mspace>
                                 <munderover>
                                    <mo>∑</mo>
                                    <mrow>
                                       <mi>r</mi>
                                    </mrow>
                                    <mrow>
                                       <mi>R</mi>
                                    </mrow>
                                 </munderover>
                                 <mspace width="5px"></mspace>
                                 <munderover>
                                    <mo>∑</mo>
                                    <mrow>
                                       <mi>s</mi>
                                    </mrow>
                                    <mrow>
                                       <mi>S</mi>
                                    </mrow>
                                 </munderover>
                                 <mspace width="10px"></mspace>
                                 <msub>
                                    <mi>x</mi>
                                    <mi mathvariant="italic">n, c, p + (r*dilh), q + (s*dilw) </mi>
                                 </msub>
                                 <mspace width="15px"></mspace>
                                 <mrow>
                                    <mi>×</mi>
                                 </mrow>
                                 <mspace width="15px"></mspace>
                                 <mrow>
                                    <msub>
                                       <mi>w</mi>
                                       <mi mathvariant="italic">k,c,r,s</mi>
                                    </msub>
                                 </mrow>
                              </math>
                           </p>
                        </div>
                        <div class="section">
                           <h3 class="title sectiontitle">Convolution using Convolution Mode</h3>
                           <p class="p">
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <msub>
                                    <mi>y</mi>
                                    <mi mathvariant="italic">n, k, p, q</mi>
                                 </msub>
                                 <mo>=</mo>
                                 <munderover>
                                    <mo>∑</mo>
                                    <mrow>
                                       <mi>c</mi>
                                    </mrow>
                                    <mrow>
                                       <mi>C</mi>
                                    </mrow>
                                 </munderover>
                                 <mspace width="5px"></mspace>
                                 <munderover>
                                    <mo>∑</mo>
                                    <mrow>
                                       <mi>r</mi>
                                    </mrow>
                                    <mrow>
                                       <mi>R</mi>
                                    </mrow>
                                 </munderover>
                                 <mspace width="5px"></mspace>
                                 <munderover>
                                    <mo>∑</mo>
                                    <mrow>
                                       <mi>s</mi>
                                    </mrow>
                                    <mrow>
                                       <mi>S</mi>
                                    </mrow>
                                 </munderover>
                                 <mspace width="10px"></mspace>
                                 <msub>
                                    <mi>x</mi>
                                    <mi mathvariant="italic">n, c, p + r, q + s </mi>
                                 </msub>
                                 <mspace width="15px"></mspace>
                                 <mrow>
                                    <mi>×</mi>
                                 </mrow>
                                 <mspace width="15px"></mspace>
                                 <mrow>
                                    <msub>
                                       <mi>w</mi>
                                       <mi mathvariant="italic">k, c, R-r-1, S-s-1</mi>
                                    </msub>
                                 </mrow>
                              </math>
                           </p>
                        </div>
                        <div class="section">
                           <h3 class="title sectiontitle">Convolution using Grouped Convolution</h3>
                           <p class="p">
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <msub>
                                       <mi>C</mi>
                                       <mi>g</mi>
                                    </msub>
                                 </mrow>
                                 <mo>=</mo>
                                 <mrow>
                                    <mfrac>
                                       <mi>C</mi>
                                       <mi>G</mi>
                                    </mfrac>
                                 </mrow>
                              </math>
                           </p>
                           <p class="p">
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <mrow>
                                    <msub>
                                       <mi>K</mi>
                                       <mi>g</mi>
                                    </msub>
                                 </mrow>
                                 <mo>=</mo>
                                 <mrow>
                                    <mfrac>
                                       <mi>K</mi>
                                       <mi>G</mi>
                                    </mfrac>
                                 </mrow>
                              </math>
                           </p>
                        </div>
                        <div class="section">
                           <p class="p">
                              <math xmlns="http://www.w3.org/1998/Math/MathML">
                                 <msub>
                                    <mi>y</mi>
                                    <mi mathvariant="italic">n, k, p, q</mi>
                                 </msub>
                                 <mo>=</mo>
                                 <munderover>
                                    <mo>∑</mo>
                                    <mrow>
                                       <mi>c</mi>
                                    </mrow>
                                    <mrow>
                                       <msub>
                                          <mi>C</mi>
                                          <mi>g</mi>
                                       </msub>
                                    </mrow>
                                 </munderover>
                                 <mspace width="5px"></mspace>
                                 <munderover>
                                    <mo>∑</mo>
                                    <mrow>
                                       <mi>r</mi>
                                    </mrow>
                                    <mrow>
                                       <mi>R</mi>
                                    </mrow>
                                 </munderover>
                                 <mspace width="5px"></mspace>
                                 <munderover>
                                    <mo>∑</mo>
                                    <mrow>
                                       <mi>s</mi>
                                    </mrow>
                                    <mrow>
                                       <mi>S</mi>
                                    </mrow>
                                 </munderover>
                                 <mspace width="10px"></mspace>
                                 <msub>
                                    <mi>x</mi>
                                    <mi mathvariant="italic">n, Cg*floor(k/Kg)+c, p+r, q+s </mi>
                                 </msub>
                                 <mspace width="15px"></mspace>
                                 <mrow>
                                    <mi>×</mi>
                                 </mrow>
                                 <mspace width="15px"></mspace>
                                 <mrow>
                                    <msub>
                                       <mi>w</mi>
                                       <mi mathvariant="italic">k,c,r,s</mi>
                                    </msub>
                                 </mrow>
                              </math>
                           </p>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="notation"><a name="notation" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#notation" name="notation" shape="rect">2.3.&nbsp;Notation</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p">As of CUDNN v4 we have adopted a mathematicaly-inspired notation for layer inputs and
                           outputs using <samp class="ph codeph">x,y,dx,dy,b,w</samp> for common layer parameters. This was done
                           to improve the readability and ease of understanding of the meaning of the parameters.
                           All layers now follow a uniform convention as below:
                        </p>
                        <p class="p"><strong class="ph b">During Inference:</strong></p>
                        <p class="p"><samp class="ph codeph">y = layerFunction(x, otherParams)</samp>.
                        </p>
                        <p class="p"></p>
                        <p class="p"><strong class="ph b">During backpropagation:</strong></p>
                        <p class="p"><samp class="ph codeph">(dx, dOtherParams) = layerFunctionGradient(x,y,dy,otherParams)</samp></p>
                        <p class="p"></p>
                        <p class="p">For <strong class="ph b">convolution</strong> the notation is
                        </p>
                        <p class="p"><samp class="ph codeph">y = x*w+b</samp></p>
                        <p class="p">where <samp class="ph codeph">w</samp> is the matrix of filter weights, <samp class="ph codeph">x</samp> is the
                           previous layer's data (during inference), <samp class="ph codeph">y</samp> is the next layer's data,
                           <samp class="ph codeph">b</samp> is the bias and <samp class="ph codeph">*</samp> is the convolution operator. 
                        </p>
                        <p class="p">In backpropagation routines the parameters keep their meanings. </p>
                        <p class="p">The parameters <samp class="ph codeph">dx,dy,dw,db</samp> always refer to the gradient of the final
                           network error function with respect to a given parameter. So <samp class="ph codeph">dy</samp> in all
                           backpropagation routines always refers to error gradient backpropagated through the
                           network computation graph so far. Similarly other parameters in more specialized layers,
                           such as, for instance, <samp class="ph codeph">dMeans</samp> or <samp class="ph codeph">dBnBias</samp> refer to
                           gradients of the loss function wrt those parameters.
                        </p>
                        <p class="p"></p>
                        <div class="note note"><span class="notetitle">Note:</span><samp class="ph codeph">w</samp> is used in the API for both the width of the <samp class="ph codeph">x</samp>
                           tensor and convolution filter matrix. To resolve this ambiguity we use
                           <samp class="ph codeph">w</samp> and <samp class="ph codeph">filter</samp> notation interchangeably for
                           convolution filter weight matrix. The meaning is clear from the context since the layer
                           width is always referenced near its height.
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="tensor-descriptor"><a name="tensor-descriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#tensor-descriptor" name="tensor-descriptor" shape="rect">2.4.&nbsp;Tensor Descriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"> The cuDNN Library describes data holding images, videos and any other data with contents
                           with a generic n-D tensor defined with the following parameters :
                        </p><a name="tensor-descriptor__ul_v12_h1y_r1b" shape="rect">
                           <!-- --></a><ul class="ul" id="tensor-descriptor__ul_v12_h1y_r1b">
                           <li class="li">a dimension <samp class="ph codeph">nbDims</samp> from 3 to 8
                           </li>
                           <li class="li">a data type (32-bit floating point, 64 bit-floating point, 16 bit floating
                              point...)
                           </li>
                           <li class="li"><samp class="ph codeph">dimA</samp> integer array defining the size of each dimension
                           </li>
                           <li class="li"><samp class="ph codeph">strideA</samp> integer array defining the stride of each dimension (e.g
                              the number of elements to add to reach the next element from the same
                              dimension)
                           </li>
                        </ul>
                        <p class="p">The first dimension of the tensor defines the batch size <samp class="ph codeph">n</samp>, and the
                           second dimension defines the number of features maps <samp class="ph codeph">c</samp>. This tensor
                           definition allows for example to have some dimensions overlapping each others within the
                           same tensor by having the stride of one dimension smaller than the product of the
                           dimension and the stride of the next dimension. In cuDNN, unless specified otherwise,
                           all routines will support tensors with overlapping dimensions for forward pass input
                           tensors, however, dimensions of the output tensors cannot overlap. Even though this
                           tensor format supports negative strides (which can be useful for data mirroring), cuDNN
                           routines do not support tensors with negative strides unless specified otherwise. 
                        </p>
                     </div>
                     <div class="topic concept nested2" id="WXWZ-tensor-descriptor"><a name="WXWZ-tensor-descriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#WXWZ-tensor-descriptor" name="WXWZ-tensor-descriptor" shape="rect">2.4.1.&nbsp;WXYZ Tensor Descriptor</a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc"></span></div>
                           <p class="p"> Tensor descriptor formats are identified using acronyms, with each letter referencing a
                              corresponding dimension. In this document, the usage of this terminology implies : 
                           </p><a name="WXWZ-tensor-descriptor__ul_fss_n1y_r1b" shape="rect">
                              <!-- --></a><ul class="ul" id="WXWZ-tensor-descriptor__ul_fss_n1y_r1b">
                              <li class="li">all the strides are strictly positive</li>
                              <li class="li">the dimensions referenced by the letters are sorted in decreasing order of their
                                 respective strides
                              </li>
                           </ul>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="four-D-tensor-descriptor"><a name="four-D-tensor-descriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#four-D-tensor-descriptor" name="four-D-tensor-descriptor" shape="rect">2.4.2.&nbsp;4-D Tensor Descriptor</a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc"></span></div>
                           <p class="p">A 4-D Tensor descriptor is used to define the format for batches of 2D images with 4
                              letters : N,C,H,W for respectively the batch size, the number of feature maps, the
                              height and the width. The letters are sorted in decreasing order of the strides. The
                              commonly used 4-D tensor formats are :
                           </p><a name="four-D-tensor-descriptor__ul_trf_t1y_r1b" shape="rect">
                              <!-- --></a><ul class="ul" id="four-D-tensor-descriptor__ul_trf_t1y_r1b">
                              <li class="li">NCHW</li>
                              <li class="li">NHWC</li>
                              <li class="li">CHWN</li>
                           </ul>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="five-D-tensor-descriptor"><a name="five-D-tensor-descriptor" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#five-D-tensor-descriptor" name="five-D-tensor-descriptor" shape="rect">2.4.3.&nbsp;5-D Tensor Description</a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc"></span></div>
                           <p class="p">A 5-D Tensor descriptor is used to define the format of batch of 3D images with 5 letters
                              : N,C,D,H,W for respectively the batch size, the number of feature maps, the depth, the
                              height and the width. The letters are sorted in descreasing order of the strides. The
                              commonly used 5-D tensor formats are called :
                           </p><a name="five-D-tensor-descriptor__ul_gk5_w1y_r1b" shape="rect">
                              <!-- --></a><ul class="ul" id="five-D-tensor-descriptor__ul_gk5_w1y_r1b">
                              <li class="li">NCDHW</li>
                              <li class="li">NDHWC</li>
                              <li class="li">CDHWN</li>
                           </ul>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="Fully-packed-tensors"><a name="Fully-packed-tensors" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#Fully-packed-tensors" name="Fully-packed-tensors" shape="rect">2.4.4.&nbsp;Fully-packed tensors</a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc"></span></div>
                           <p class="p"> A tensor is defined as <samp class="ph codeph">XYZ-fully-packed</samp> if and only if :
                           </p><a name="Fully-packed-tensors__ul_zxr_1by_r1b" shape="rect">
                              <!-- --></a><ul class="ul" id="Fully-packed-tensors__ul_zxr_1by_r1b">
                              <li class="li">the number of tensor dimensions is equal to the number of letters preceding the
                                 <samp class="ph codeph">fully-packed</samp> suffix.
                              </li>
                              <li class="li">the stride of the i-th dimension is equal to the product of the (i+1)-th dimension
                                 by the (i+1)-th stride.
                              </li>
                              <li class="li">the stride of the last dimension is 1.</li>
                           </ul>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="Partially-packed-tensors"><a name="Partially-packed-tensors" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#Partially-packed-tensors" name="Partially-packed-tensors" shape="rect">2.4.5.&nbsp;Partially-packed tensors</a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc"></span></div>
                           <p class="p"> The partially 'XYZ-packed' terminology only applies in a context of a tensor format
                              described with a superset of the letters used to define a partially-packed tensor. A
                              WXYZ tensor is defined as <samp class="ph codeph">XYZ-packed</samp> if and only if : 
                           </p><a name="Partially-packed-tensors__ul_ty1_2by_r1b" shape="rect">
                              <!-- --></a><ul class="ul" id="Partially-packed-tensors__ul_ty1_2by_r1b">
                              <li class="li"> the strides of all dimensions NOT referenced in the -packed suffix are greater or
                                 equal to the product of the next dimension by the next stride.
                              </li>
                              <li class="li"> the stride of each dimension referenced in the -packed suffix in position i is
                                 equal to the product of the (i+1)-st dimension by the (i+1)-st stride.
                              </li>
                              <li class="li"> if last tensor's dimension is present in the -packed suffix, its stride is 1.</li>
                           </ul>
                           <p class="p"> For example a NHWC tensor WC-packed means that the c_stride is equal to 1 and w_stride
                              is equal to c_dim x c_stride. In practice, the -packed suffix is usually with slowest
                              changing dimensions of a tensor but it is also possible to refer to a NCHW tensor that
                              is only N-packed. 
                           </p>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="Spatially-packed-tensors"><a name="Spatially-packed-tensors" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#Spatially-packed-tensors" name="Spatially-packed-tensors" shape="rect">2.4.6.&nbsp;Spatially packed tensors</a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc"></span></div>
                           <p class="p">Spatially-packed tensors are defined as partially-packed in spatial dimensions.</p>
                           <p class="p">For example a spatially-packed 4D tensor would mean that the tensor is either NCHW
                              HW-packed or CNHW HW-packed.
                           </p>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="Overlapping-tensors"><a name="Overlapping-tensors" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#Overlapping-tensors" name="Overlapping-tensors" shape="rect">2.4.7.&nbsp;Overlapping tensors</a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc"></span></div>
                           <p class="p">A tensor is defined to be overlapping if a iterating over a full range of dimensions
                              produces the same address more than once.
                           </p>
                           <p class="p">In practice an overlapped tensor will have stride[i-1] &lt; stride[i]*dim[i] for some of
                              the i from [1,nbDims] interval.
                           </p>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="data-layout-formats"><a name="data-layout-formats" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#data-layout-formats" name="data-layout-formats" shape="rect">2.5.&nbsp;Data Layout Formats</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p dir="ltr" class="p" id="data-layout-formats__docs-internal-guid-fa86afe8-7fff-695d-2514-5eee6963ffc3"><a name="data-layout-formats__docs-internal-guid-fa86afe8-7fff-695d-2514-5eee6963ffc3" shape="rect">
                              <!-- --></a>This section
                           			describes how cuDNN Tensors are arranged in memory. See <a class="xref" href="https://docs.nvidia.com/deeplearning/sdk/cudnn-developer-guide/index.html#cudnnTensorFormat_t" target="_blank" shape="rect">cudnnTensorFormat_t</a> for enumerated Tensor format
                           			types. 
                        </p>
                     </div>
                     <div class="topic concept nested2" id="data-layout-formats-example-x32"><a name="data-layout-formats-example-x32" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#data-layout-formats-example-x32" name="data-layout-formats-example-x32" shape="rect">2.5.1.&nbsp;Example</a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc"></span></div>
                           <div class="p" dir="ltr" id="data-layout-formats-example-x32__docs-internal-guid-fa86afe8-7fff-695d-2514-5eee6963ffc3"><a name="data-layout-formats-example-x32__docs-internal-guid-fa86afe8-7fff-695d-2514-5eee6963ffc3" shape="rect">
                                 <!-- --></a>Consider a batch of
                              			images in 4D with the following dimensions: <a name="data-layout-formats-example-x32__ul_ldz_f2d_mhb" shape="rect">
                                 <!-- --></a><ul class="ul" id="data-layout-formats-example-x32__ul_ldz_f2d_mhb">
                                 <li class="li"><strong class="ph b">N</strong>, the batch size, is 1 
                                 </li>
                                 <li class="li"><strong class="ph b">C</strong>, the number of feature maps (i.e., number of channels), is 64 
                                 </li>
                                 <li class="li"><strong class="ph b">H</strong>, the image height, is 5, and 
                                 </li>
                                 <li class="li"><strong class="ph b">W</strong>, the image width, is 4 
                                 </li>
                              </ul>
                           </div>
                           <p class="p">To keep the example simple, the image pixel elements are expressed as a sequence of
                              			integers, 0, 1, 2, 3, and so on. See <a class="xref" href="index.html#data-layout-formats-example-x32__fig-example-x32" shape="rect">Figure 1</a>.
                           </p>
                           <div class="fig fignone" id="data-layout-formats-example-x32__fig-example-x32"><a name="data-layout-formats-example-x32__fig-example-x32" shape="rect">
                                 <!-- --></a><span class="figcap">Figure 1. Example with N=1, C=64, H=5, W=4.</span><br clear="none"></br><div class="imagecenter">
                                 <embed class="image imagecenter" src="graphics/fig-example-x32.svg"></embed>
                              </div><br clear="none"></br></div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="nchw-layout-x32"><a name="nchw-layout-x32" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#nchw-layout-x32" name="nchw-layout-x32" shape="rect">2.5.2.&nbsp;NCHW Memory Layout</a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc"></span></div>
                           <p dir="ltr" class="p" id="nchw-layout-x32__docs-internal-guid-2cbac0b4-7fff-cd1d-53d9-ed617e0fa26b"><a name="nchw-layout-x32__docs-internal-guid-2cbac0b4-7fff-cd1d-53d9-ed617e0fa26b" shape="rect">
                                 <!-- --></a>The above 4D Tensor is
                              			laid out in the memory in the NCHW format as below: 
                           </p><a name="nchw-layout-x32__ol_rl5_5kd_mhb" shape="rect">
                              <!-- --></a><ol class="ol" id="nchw-layout-x32__ol_rl5_5kd_mhb">
                              <li dir="ltr" class="li">Beginning with the first channel (c=0), the elements are arranged
                                 				contiguously in row-major order. 
                              </li>
                              <li dir="ltr" class="li">Continue with second and subsequent channels until the elements of all the
                                 				channels are laid out. 
                                 <p class="p">See <a class="xref" href="index.html#nchw-layout-x32__fig-nchw-layout-x32" shape="rect">Figure 2</a>.
                                 </p>
                              </li>
                              <li dir="ltr" class="li">Proceed to the next batch (if <strong class="ph b">N</strong> is &gt; 1).
                              </li>
                           </ol>
                           <div class="fig fignone" id="nchw-layout-x32__fig-nchw-layout-x32"><a name="nchw-layout-x32__fig-nchw-layout-x32" shape="rect">
                                 <!-- --></a><span class="figcap">Figure 2. NCHW Memory Layout</span><br clear="none"></br><div class="imagecenter">
                                 <embed class="image imagecenter" src="graphics/fig-nchw-layout-x32.svg"></embed>
                              </div><br clear="none"></br></div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="nhwc-layout-x32"><a name="nhwc-layout-x32" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#nhwc-layout-x32" name="nhwc-layout-x32" shape="rect">2.5.3.&nbsp;NHWC Memory Layout</a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc"></span></div>
                           <p dir="ltr" class="p" id="nhwc-layout-x32__docs-internal-guid-368c54b5-7fff-822e-0fd6-5c5eb7d7f32c"><a name="nhwc-layout-x32__docs-internal-guid-368c54b5-7fff-822e-0fd6-5c5eb7d7f32c" shape="rect">
                                 <!-- --></a>For the NHWC memory
                              			layout, the corresponding elements in all the <strong class="ph b">C</strong> channels are laid out first, as
                              			below:
                           </p><a name="nhwc-layout-x32__ol_uvl_f4d_mhb" shape="rect">
                              <!-- --></a><ol class="ol" id="nhwc-layout-x32__ol_uvl_f4d_mhb">
                              <li dir="ltr" class="li">Begin with the first element of channel 0, then proceed to the first element
                                 				of channel 1, and so on, until the first elements of all the <strong class="ph b">C</strong> channels are laid
                                 				out. 
                              </li>
                              <li dir="ltr" class="li">Next, select the second element of channel 0, then proceed to the second
                                 				element of channel 1, and so on, until the second element of all the channels are laid
                                 				out. 
                              </li>
                              <li dir="ltr" class="li">Follow the row-major order in channel 0 and complete all the elements. See <a class="xref" href="index.html#nhwc-layout-x32__fig-nchw-layout-x32" shape="rect">Figure 3</a>.
                              </li>
                              <li dir="ltr" class="li">Proceed to the next batch (if <strong class="ph b">N</strong> is &gt; 1).
                              </li>
                           </ol>
                           <div class="fig fignone" id="nhwc-layout-x32__fig-nchw-layout-x32"><a name="nhwc-layout-x32__fig-nchw-layout-x32" shape="rect">
                                 <!-- --></a><span class="figcap">Figure 3. NHWC Memory Layout</span><br clear="none"></br><div class="imagecenter">
                                 <embed class="image imagecenter" src="graphics/fig-nhwc-layout-x32.svg"></embed>
                              </div><br clear="none"></br></div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="nc32hw32-layout-x32"><a name="nc32hw32-layout-x32" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#nc32hw32-layout-x32" name="nc32hw32-layout-x32" shape="rect">2.5.4.&nbsp;NC/32HW32 Memory Layout</a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc"></span></div>
                           <p dir="ltr" class="p" id="nc32hw32-layout-x32__docs-internal-guid-41dd0da9-7fff-b711-1203-9a4d12171bb4"><a name="nc32hw32-layout-x32__docs-internal-guid-41dd0da9-7fff-b711-1203-9a4d12171bb4" shape="rect">
                                 <!-- --></a>The NC/32HW32 is similar
                              			to NHWC, with a key difference. For the NC/32HW32 memory layout, the 64 channels are
                              			grouped into two groups of 32 channels each—first group consisting of channels c0 through
                              			c31, and the second group consisting of channels c32 through c63. Then each group is laid
                              			out using the NHWC format. See <a class="xref" href="index.html#nc32hw32-layout-x32__fig-nc32hw32-layout-x32" shape="rect">Figure 4</a>.
                           </p>
                           <div class="fig fignone" id="nc32hw32-layout-x32__fig-nc32hw32-layout-x32"><a name="nc32hw32-layout-x32__fig-nc32hw32-layout-x32" shape="rect">
                                 <!-- --></a><span class="figcap">Figure 4. NC/32HW32 Memory Layout</span><br clear="none"></br><div class="imagecenter">
                                 <embed class="image imagecenter" src="graphics/fig-nc32hw32-layout-x32.svg"></embed>
                              </div><br clear="none"></br></div>
                           <p dir="ltr" class="p" id="nc32hw32-layout-x32__docs-internal-guid-03e0300e-7fff-a179-0d44-218765f22245"><a name="nc32hw32-layout-x32__docs-internal-guid-03e0300e-7fff-a179-0d44-218765f22245" shape="rect">
                                 <!-- --></a>For the generalized
                              			NC/xHWx layout format, the following observations apply:
                           </p><a name="nc32hw32-layout-x32__ul_w2n_jtd_mhb" shape="rect">
                              <!-- --></a><ul class="ul" id="nc32hw32-layout-x32__ul_w2n_jtd_mhb">
                              <li dir="ltr" class="li">
                                 <p dir="ltr" class="p">Only the channel dimension, <strong class="ph b">C</strong>, is grouped into x channels each.
                                 </p>
                              </li>
                              <li dir="ltr" class="li">
                                 <p dir="ltr" class="p">When x = 1, each group has only one channel. Hence, the elements of one
                                    					channel (i.e, one group) are arranged contiguously (in the row-major order), before
                                    					proceeding to the next group (i.e., next channel). This is the same as NCHW
                                    					format.
                                 </p>
                              </li>
                              <li dir="ltr" class="li">
                                 <p dir="ltr" class="p">When x = C, then NC/xHWx is identical to NHWC, i.e., the entire channel
                                    					depth C is considered as a single group. The case x = C can be thought of as
                                    					vectorizing entire C dimension as one big vector, laying out all the Cs, followed by
                                    					the remaining dimensions, just like NHWC.  
                                 </p>
                              </li>
                              <li class="li">
                                 <p class="p">The tensor format <a class="xref" href="index.html#cudnnTensorFormat_t" shape="rect">CUDNN_TENSOR_NCHW_VECT_C</a>
                                    					can also be interpreted in the following way: The NCHW INT8x32 format is really N x
                                    					(C/32) x H x W x 32 (32 Cs for every W), just as the NCHW INT8x4 format is N x (C/4)
                                    					x H x W x 4 (4 Cs for every W). Hence the "VECT_C" name - each W is a vector (4 or
                                    					32) of Cs. 
                                 </p>
                              </li>
                           </ul>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="thread-safety"><a name="thread-safety" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#thread-safety" name="thread-safety" shape="rect">2.6.&nbsp;Thread Safety</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p">The library is thread safe and its functions can be called from multiple host threads, as
                           long as threads to do not share the same cuDNN handle simultaneously.
                        </p>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="reproducibility"><a name="reproducibility" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#reproducibility" name="reproducibility" shape="rect">2.7.&nbsp;Reproducibility (determinism)</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p">By design, most of cuDNN's routines from a given version generate the same bit-wise
                           results across runs when executed on GPUs with the same architecture and the same number
                           of SMs. However, bit-wise reproducibility is not guaranteed across versions, as the
                           implementation of a given routine may change. With the current release, the following
                           routines do not guarantee reproducibility because they use atomic operations: 
                        </p><a name="reproducibility__ul_pzy_xby_r1b" shape="rect">
                           <!-- --></a><ul class="ul" id="reproducibility__ul_pzy_xby_r1b">
                           <li class="li"><samp class="ph codeph">cudnnConvolutionBackwardFilter</samp> when
                              <samp class="ph codeph">CUDNN_CONVOLUTION_BWD_FILTER_ALGO_0</samp> or
                              <samp class="ph codeph">CUDNN_CONVOLUTION_BWD_FILTER_ALGO_3</samp> is used
                           </li>
                           <li class="li"><samp class="ph codeph">cudnnConvolutionBackwardData</samp> when
                              <samp class="ph codeph">CUDNN_CONVOLUTION_BWD_DATA_ALGO_0 </samp> is used
                           </li>
                           <li class="li"><samp class="ph codeph">cudnnPoolingBackward</samp> when <samp class="ph codeph">CUDNN_POOLING_MAX </samp> is
                              used
                           </li>
                           <li class="li"><samp class="ph codeph">cudnnSpatialTfSamplerBackward</samp></li>
                        </ul>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="scaling-parameters"><a name="scaling-parameters" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#scaling-parameters" name="scaling-parameters" shape="rect">2.8.&nbsp;Scaling Parameters</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p dir="ltr" class="p" id="scaling-parameters__docs-internal-guid-dfa7322a-7fff-334c-3d52-50831889f351"><a name="scaling-parameters__docs-internal-guid-dfa7322a-7fff-334c-3d52-50831889f351" shape="rect">
                              <!-- --></a>Many cuDNN routines like
                           					<a class="xref" href="index.html#cudnnConvolutionForward" shape="rect">cudnnConvolutionForward</a> accept pointers in host memory to scaling factors
                           				<samp class="ph codeph">alpha</samp> and <samp class="ph codeph">beta</samp>. These scaling factors are used to blend
                           			the computed values with the prior values in the destination tensor as follows (see <a class="xref" href="index.html#scaling-parameters__fig-scaling-params-conv" shape="rect">Figure 5</a>): 
                        </p>
                        <p dir="ltr" class="p"><samp class="ph codeph">dstValue = alpha*computedValue + beta*priorDstValue.</samp></p>
                        <div class="p" dir="ltr" id="scaling-parameters__docs-internal-guid-390d9160-7fff-308b-2f61-c7e2ab1d2ac5"><a name="scaling-parameters__docs-internal-guid-390d9160-7fff-308b-2f61-c7e2ab1d2ac5" shape="rect">
                              <!-- --></a><div class="note note"><span class="notetitle">Note:</span> The <samp class="ph codeph">dstValue</samp> is written to after being read. 
                           </div>
                           <div class="fig fignone" id="scaling-parameters__fig-scaling-params-conv"><a name="scaling-parameters__fig-scaling-params-conv" shape="rect">
                                 <!-- --></a><span class="figcap">Figure 5. Scaling Parameters for Convolution</span><br clear="none"></br><div class="imagecenter">
                                 <embed class="image imagecenter" src="graphics/alpha-beta-dstValue.svg" width="800"></embed>
                              </div><br clear="none"></br></div>
                        </div>
                        <p dir="ltr" class="p" id="scaling-parameters__docs-internal-guid-e47f3542-7fff-8c7a-284c-e3e50b73f69f"><a name="scaling-parameters__docs-internal-guid-e47f3542-7fff-8c7a-284c-e3e50b73f69f" shape="rect">
                              <!-- --></a>When
                           				<samp class="ph codeph">beta</samp> is zero, the output is not read and may contain uninitialized data
                           			(including NaN). 
                        </p>
                        <p dir="ltr" class="p">These parameters are passed using a host memory pointer. The storage data types for
                           				<samp class="ph codeph">alpha</samp> and <samp class="ph codeph">beta</samp> are:
                        </p><a name="scaling-parameters__ul_m5g_nn2_cgb" shape="rect">
                           <!-- --></a><ul class="ul" id="scaling-parameters__ul_m5g_nn2_cgb">
                           <li dir="ltr" class="li">
                              <p dir="ltr" class="p"><samp class="ph codeph">float</samp> for HALF and FLOAT tensors, and 
                              </p>
                           </li>
                           <li dir="ltr" class="li">
                              <p dir="ltr" class="p"><samp class="ph codeph">double</samp> for DOUBLE tensors. 
                              </p>
                           </li>
                        </ul>
                        <div class="p" dir="ltr">
                           <div class="note note"><span class="notetitle">Note:</span> For improved performance use <samp class="ph codeph">beta</samp> = 0.0. Use a non-zero value for beta
                              				only when you need to blend the current output tensor values with the prior values of the
                              				output tensor.
                           </div>
                        </div>
                        <div class="section" id="scaling-parameters__section_n5g_nn2_cgb"><a name="scaling-parameters__section_n5g_nn2_cgb" shape="rect">
                              <!-- --></a><h3 class="title sectiontitle">Type Conversion</h3>
                           <p dir="ltr" class="p">When the data input <samp class="ph codeph">x</samp>, the filter input <samp class="ph codeph">w</samp> and the
                              				output <samp class="ph codeph">y</samp> are all in INT8 data type, the function <samp class="ph codeph"><a class="xref" href="index.html#cudnnConvolutionBiasActivationForward" shape="rect">cudnnConvolutionBiasActivationForward()</a></samp> will perform the type
                              				conversion as shown in <a class="xref" href="index.html#scaling-parameters__fig-conv-bias-activation-forward" shape="rect">Figure 6</a>:
                           </p>
                           <div class="note note"><span class="notetitle">Note:</span> Accumulators are 32-bit integers which wrap on overflow. 
                           </div>
                           <div class="fig fignone" id="scaling-parameters__fig-conv-bias-activation-forward"><a name="scaling-parameters__fig-conv-bias-activation-forward" shape="rect">
                                 <!-- --></a><span class="figcap">Figure 6. INT8 for cudnnConvolutionBiasActivationForward</span><br clear="none"></br><div class="imagecenter">
                                 <embed class="image imagecenter" src="graphics/cudnnConvolutionBiasActivationForward.svg" width="900"></embed>
                              </div><br clear="none"></br></div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="tensor_ops"><a name="tensor_ops" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#tensor_ops" name="tensor_ops" shape="rect">2.9.&nbsp;Tensor Core Operations</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p dir="ltr" class="p" id="tensor_ops__docs-internal-guid-0e6643ef-7fff-7291-98d4-9466206daa99"><a name="tensor_ops__docs-internal-guid-0e6643ef-7fff-7291-98d4-9466206daa99" shape="rect">
                              <!-- --></a>The cuDNN v7 library
                           			introduced the acceleration of compute-intensive routines using Tensor Core hardware on
                           			supported GPU SM versions. Tensor core operations are supported on the Volta and Turing GPU
                           			families.
                        </p>
                     </div>
                     <div class="topic concept nested2" id="tensor-ops-basics"><a name="tensor-ops-basics" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#tensor-ops-basics" name="tensor-ops-basics" shape="rect">2.9.1.&nbsp;Basics</a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc"></span></div>
                           <p dir="ltr" class="p" id="tensor-ops-basics__docs-internal-guid-04ea8531-7fff-2b3b-ad45-3fbe30701105"><a name="tensor-ops-basics__docs-internal-guid-04ea8531-7fff-2b3b-ad45-3fbe30701105" shape="rect">
                                 <!-- --></a>Tensor core
                              			operations perform parallel floating point accumulation of multiple floating point product
                              			terms. Setting the math mode to CUDNN_TENSOR_OP_MATH via the <a class="xref" href="index.html#cudnnMathType_t" shape="rect">cudnnMathType_t</a> enumerator indicates that the library will use Tensor Core
                              			operations. This enumerator specifies the available options to enable the Tensor Core, and
                              			should be applied on a per-routine basis.
                           </p>
                           <p dir="ltr" class="p">The default math mode is CUDNN_DEFAULT_MATH, which indicates that the Tensor Core
                              			operations will be avoided by the library. Because the CUDNN_TENSOR_OP_MATH mode uses the
                              			Tensor Cores, it is possible that these two modes generate slightly different numerical
                              			results due to different sequencing of the floating point operations.
                           </p>
                           <p dir="ltr" class="p">For example, the result of multiplying two matrices using Tensor Core operations
                              			is very close to, but not always identical, the result achieved using a sequence of scalar
                              			floating point operations. For this reason, the cuDNN library requires an explicit user
                              			opt-in before enabling the use of Tensor Core operations.
                           </p>
                           <p dir="ltr" class="p">However, experiments with training common deep learning models show negligible
                              			differences between using Tensor Core operations and scalar floating point paths, as
                              			measured by both the final network accuracy and the iteration count to convergence.
                              			Consequently, the cuDNN library treats both modes of operation as functionally
                              			indistinguishable, and allows for the scalar paths to serve as legitimate fallbacks for
                              			cases in which the use of Tensor Core operations is unsuitable.
                           </p>
                           <p dir="ltr" class="p">Kernels using Tensor Core operations are available for both convolutions and
                              			RNNs.
                           </p>
                           <p class="p">See also <a class="xref" href="http://docs.nvidia.com/deeplearning/sdk/mixed-precision-training/index.html" target="_blank" shape="rect"><u class="ph u">Training with Mixed Precision</u></a>.
                           </p>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="tensor-ops-conv-functions"><a name="tensor-ops-conv-functions" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#tensor-ops-conv-functions" name="tensor-ops-conv-functions" shape="rect">2.9.2.&nbsp;Convolution Functions</a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc"></span></div>
                        </div>
                        <div class="topic concept nested3" id="tensor-ops-conv-functions-pre-req"><a name="tensor-ops-conv-functions-pre-req" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#tensor-ops-conv-functions-pre-req" name="tensor-ops-conv-functions-pre-req" shape="rect">2.9.2.1.&nbsp;Prerequisite</a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc"></span></div>
                              <p dir="ltr" class="p" id="tensor-ops-conv-functions-pre-req__docs-internal-guid-cce0ad3f-7fff-02ac-180e-a9d7a21922da"><a name="tensor-ops-conv-functions-pre-req__docs-internal-guid-cce0ad3f-7fff-02ac-180e-a9d7a21922da" shape="rect">
                                    <!-- --></a>For the supported GPUs,
                                 			the Tensor Core operations will be triggered for convolution functions only when <a class="xref" href="index.html#cudnnSetConvolutionMathType" shape="rect">cudnnSetConvolutionMathType</a> is called on the appropriate convolution
                                 			descriptor by setting the <samp class="ph codeph">mathType</samp> to CUDNN_TENSOR_OP_MATH or
                                 			CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION.
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="tensor-ops-conv-functions-supported-algos"><a name="tensor-ops-conv-functions-supported-algos" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#tensor-ops-conv-functions-supported-algos" name="tensor-ops-conv-functions-supported-algos" shape="rect">2.9.2.2.&nbsp;Supported Algorithms</a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc"></span></div>
                              <p dir="ltr" class="p" id="tensor-ops-conv-functions-supported-algos__docs-internal-guid-e9162840-7fff-af71-3d9b-b512782108ae"><a name="tensor-ops-conv-functions-supported-algos__docs-internal-guid-e9162840-7fff-af71-3d9b-b512782108ae" shape="rect">
                                    <!-- --></a>When the
                                 			prerequisite is met, the below convolution functions can be run as Tensor Core operations: 
                              </p><a name="tensor-ops-conv-functions-supported-algos__ul_vgy_q1v_fhb" shape="rect">
                                 <!-- --></a><ul class="ul" id="tensor-ops-conv-functions-supported-algos__ul_vgy_q1v_fhb">
                                 <li class="li liexpand" dir="ltr">
                                    <p dir="ltr" class="p"><a class="xref" href="index.html#cudnnConvolutionForward" shape="rect">cudnnConvolutionForward</a></p>
                                 </li>
                                 <li class="li liexpand" dir="ltr">
                                    <p dir="ltr" class="p"><a class="xref" href="index.html#cudnnConvolutionBackwardData" shape="rect">cudnnConvolutionBackwardData</a></p>
                                 </li>
                                 <li class="li liexpand" dir="ltr">
                                    <p dir="ltr" class="p"><a class="xref" href="index.html#cudnnConvolutionBackwardFilter" shape="rect">cudnnConvolutionBackwardFilter</a></p>
                                 </li>
                              </ul>
                              <p dir="ltr" class="p">See the table below for supported algorithms:</p>
                              <div class="p">
                                 <div class="tablenoborder"><a name="tensor-ops-conv-functions-supported-algos__table_rmh_w1v_fhb" shape="rect">
                                       <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="tensor-ops-conv-functions-supported-algos__table_rmh_w1v_fhb" class="table" frame="border" border="1" rules="all">
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" dir="ltr" valign="top" width="33.33333333333333%" rowspan="1" colspan="1"><strong class="ph b">Supported Convolution Function</strong></td>
                                             <td class="entry" dir="ltr" valign="top" width="66.66666666666666%" rowspan="1" colspan="1"><strong class="ph b">Supported Algos</strong></td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" dir="ltr" valign="top" width="33.33333333333333%" rowspan="1" colspan="1">cudnnConvolutionForward </td>
                                             <td class="entry" valign="top" width="66.66666666666666%" rowspan="1" colspan="1">
                                                <p dir="ltr" class="p">-CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM,</p>
                                                <p dir="ltr" class="p">-CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED</p>
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" dir="ltr" valign="top" width="33.33333333333333%" rowspan="1" colspan="1">cudnnConvolutionBackwardData </td>
                                             <td class="entry" valign="top" width="66.66666666666666%" rowspan="1" colspan="1">
                                                <p dir="ltr" class="p">-CUDNN_CONVOLUTION_BWD_DATA_ALGO_1, </p>
                                                <p dir="ltr" class="p">-CUDNN_CONVOLUTION_BWD_DATA_ALGO_WINOGRAD_NONFUSED</p>
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" dir="ltr" valign="top" width="33.33333333333333%" rowspan="1" colspan="1">cudnnConvolutionBackwardFilter </td>
                                             <td class="entry" valign="top" width="66.66666666666666%" rowspan="1" colspan="1">
                                                <p dir="ltr" class="p">-CUDNN_CONVOLUTION_BWD_FILTER_ALGO_1,</p>
                                                <p dir="ltr" class="p">-CUDNN_CONVOLUTION_BWD_FILTER_ALGO_WINOGRAD_NONFUSED</p>
                                             </td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="tensor-ops-conv-functions-data-filter-formats"><a name="tensor-ops-conv-functions-data-filter-formats" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#tensor-ops-conv-functions-data-filter-formats" name="tensor-ops-conv-functions-data-filter-formats" shape="rect">2.9.2.3.&nbsp;Data and Filter Formats</a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc"></span></div>
                              <p dir="ltr" class="p" id="tensor-ops-conv-functions-data-filter-formats__docs-internal-guid-1719ba6d-7fff-4575-c3fe-047e600560a8"><a name="tensor-ops-conv-functions-data-filter-formats__docs-internal-guid-1719ba6d-7fff-4575-c3fe-047e600560a8" shape="rect">
                                    <!-- --></a>The cuDNN library may
                                 			use padding, folding, and NCHW-to-NHWC transformations to call the Tensor Core operations.
                                 			See <a class="xref" href="index.html#tensor-ops-tensor-transformations" shape="rect">Tensor Transformations</a>.
                              </p>
                              <p dir="ltr" class="p">For algorithms other than *_ALGO_WINOGRAD_NONFUSED, when the following
                                 			requirements are met, the cuDNN library will trigger the Tensor Core operations:
                              </p><a name="tensor-ops-conv-functions-data-filter-formats__ul_rlt_2bv_fhb" shape="rect">
                                 <!-- --></a><ul class="ul" id="tensor-ops-conv-functions-data-filter-formats__ul_rlt_2bv_fhb">
                                 <li class="li liexpand" dir="ltr">
                                    <p dir="ltr" class="p">Input, filter, and output descriptors (<samp class="ph codeph">xDesc</samp>,
                                       						<samp class="ph codeph">yDesc</samp>, <samp class="ph codeph">wDesc</samp>, <samp class="ph codeph">dxDesc</samp>,
                                       						<samp class="ph codeph">dyDesc</samp> and <samp class="ph codeph">dwDesc</samp> as applicable) are of the
                                       						<samp class="ph codeph">dataType</samp> = CUDNN_DATA_HALF (i.e., FP16). For FP32
                                       						<samp class="ph codeph">dataType</samp> see <a class="xref" href="index.html#tensor-ops-tensor-transformations-fp32-to-fp16" shape="rect">FP32-to-FP16 Conversion</a>.
                                    </p>
                                 </li>
                                 <li class="li liexpand" dir="ltr">
                                    <p dir="ltr" class="p">The number of input and output feature maps (i.e., channel dimension
                                       						<samp class="ph codeph">C</samp>) is a multiple of 8. When the channel dimension is not a
                                       					multiple of 8, see <a class="xref" href="index.html#tensor-ops-tensor-transformations-padding" shape="rect">Padding</a>.
                                    </p>
                                 </li>
                                 <li class="li liexpand" dir="ltr">
                                    <p dir="ltr" class="p">The filter is of type CUDNN_TENSOR_NCHW or CUDNN_TENSOR_NHWC.</p>
                                 </li>
                                 <li class="li liexpand" dir="ltr">
                                    <p dir="ltr" class="p">If using a filter of type CUDNN_TENSOR_NHWC, then: the input, filter, and output
                                       					data pointers (<samp class="ph codeph">X</samp>, <samp class="ph codeph">Y</samp>, <samp class="ph codeph">W</samp>,
                                       						<samp class="ph codeph">dX</samp>, <samp class="ph codeph">dY</samp>, and <samp class="ph codeph">dW</samp> as applicable)
                                       					are aligned to 128-bit boundaries.
                                    </p>
                                 </li>
                              </ul>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="tensor-ops-rnn-functions"><a name="tensor-ops-rnn-functions" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#tensor-ops-rnn-functions" name="tensor-ops-rnn-functions" shape="rect">2.9.3.&nbsp;RNN Functions</a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc"></span></div>
                        </div>
                        <div class="topic concept nested3" id="tensor-ops-rnn-functions-pre-req"><a name="tensor-ops-rnn-functions-pre-req" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#tensor-ops-rnn-functions-pre-req" name="tensor-ops-rnn-functions-pre-req" shape="rect">2.9.3.1.&nbsp;Prerequisite</a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc"></span></div>
                              <p class="p">Tensor core operations will be triggered for these RNN functions only when <a class="xref" href="index.html#cudnnSetRNNMatrixMathType" shape="rect">cudnnSetRNNMatrixMathType</a> is called on the
                                 			appropriate RNN descriptor setting <samp class="ph codeph">mathType</samp> to CUDNN_TENSOR_OP_MATH or
                                 			CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION.
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="tensor-ops-rnn-functions-supported-algos"><a name="tensor-ops-rnn-functions-supported-algos" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#tensor-ops-rnn-functions-supported-algos" name="tensor-ops-rnn-functions-supported-algos" shape="rect">2.9.3.2.&nbsp;Supported Algorithms</a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc"></span></div>
                              <p dir="ltr" class="p" id="tensor-ops-rnn-functions-supported-algos__docs-internal-guid-8b6abdab-7fff-d50b-af59-ac78ddc78b50"><a name="tensor-ops-rnn-functions-supported-algos__docs-internal-guid-8b6abdab-7fff-d50b-af59-ac78ddc78b50" shape="rect">
                                    <!-- --></a>When the above
                                 			prerequisite is met, the RNN functions below can be run as Tensor Core operations:
                              </p><a name="tensor-ops-rnn-functions-supported-algos__ul_xlj_m21_ghb" shape="rect">
                                 <!-- --></a><ul class="ul" id="tensor-ops-rnn-functions-supported-algos__ul_xlj_m21_ghb">
                                 <li class="li liexpand" dir="ltr"><a class="xref" href="index.html#cudnnRNNForwardInference" shape="rect">cudnnRNNForwardInference</a></li>
                                 <li class="li liexpand" dir="ltr"><a class="xref" href="index.html#cudnnRNNForwardTraining" shape="rect">cudnnRNNForwardTraining</a></li>
                                 <li class="li liexpand" dir="ltr"><a class="xref" href="index.html#cudnnRNNBackwardData" shape="rect">cudnnRNNBackwardData</a></li>
                                 <li class="li liexpand" dir="ltr"><a class="xref" href="index.html#cudnnRNNBackwardWeights" shape="rect">cudnnRNNBackwardWeights</a></li>
                                 <li class="li liexpand" dir="ltr"><a class="xref" href="index.html#cudnnRNNForwardInferenceEx" shape="rect">cudnnRNNForwardInferenceEx</a></li>
                                 <li class="li liexpand" dir="ltr"><a class="xref" href="index.html#cudnnRNNForwardTrainingEx" shape="rect">cudnnRNNForwardTrainingEx</a></li>
                                 <li class="li liexpand" dir="ltr"><a class="xref" href="index.html#cudnnRNNBackwardDataEx" shape="rect">cudnnRNNBackwardDataEx</a></li>
                                 <li class="li liexpand" dir="ltr"><a class="xref" href="index.html#cudnnRNNBackwardWeightsEx" shape="rect">cudnnRNNBackwardWeightsEx</a></li>
                              </ul>
                              <p dir="ltr" class="p">See the table below for the supported algorithms:</p>
                              <div class="tablenoborder"><a name="tensor-ops-rnn-functions-supported-algos__table_ylj_m21_ghb" shape="rect">
                                    <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="tensor-ops-rnn-functions-supported-algos__table_ylj_m21_ghb" class="table" frame="border" border="1" rules="all">
                                    <tbody class="tbody">
                                       <tr class="row">
                                          <td class="entry" dir="ltr" valign="top" width="36.36363636363637%" rowspan="1" colspan="1"><strong class="ph b">RNN Function</strong></td>
                                          <td class="entry" dir="ltr" valign="top" width="63.63636363636363%" rowspan="1" colspan="1"><strong class="ph b">Support Algos</strong></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" dir="ltr" valign="top" width="36.36363636363637%" rowspan="1" colspan="1">All RNN functions that support Tensor Core operations</td>
                                          <td class="entry" valign="top" width="63.63636363636363%" rowspan="1" colspan="1">
                                             <p dir="ltr" class="p">-CUDNN_RNN_ALGO_STANDARD </p>
                                             <p dir="ltr" class="p">-CUDNN_RNN_ALGO_PERSIST_STATIC (new for cuDNN 7.1)</p>
                                          </td>
                                       </tr>
                                    </tbody>
                                 </table>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="tensor-ops-rnn-functions-data-filter-formats"><a name="tensor-ops-rnn-functions-data-filter-formats" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#tensor-ops-rnn-functions-data-filter-formats" name="tensor-ops-rnn-functions-data-filter-formats" shape="rect">2.9.3.3.&nbsp;Data and Filter Formats</a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc"></span></div>
                              <p dir="ltr" class="p" id="tensor-ops-rnn-functions-data-filter-formats__docs-internal-guid-1fc1a07c-7fff-9df1-733c-2e6b4a5c1f11"><a name="tensor-ops-rnn-functions-data-filter-formats__docs-internal-guid-1fc1a07c-7fff-9df1-733c-2e6b4a5c1f11" shape="rect">
                                    <!-- --></a>When the following
                                 			requirements are met, then the cuDNN library will trigger the Tensor Core operations:
                              </p><a name="tensor-ops-rnn-functions-data-filter-formats__ul_k3r_lf1_ghb" shape="rect">
                                 <!-- --></a><ul class="ul" id="tensor-ops-rnn-functions-data-filter-formats__ul_k3r_lf1_ghb">
                                 <li class="li liexpand" dir="ltr">For algo = CUDNN_RNN_ALGO_STANDARD:<a name="tensor-ops-rnn-functions-data-filter-formats__ul_oyr_tf1_ghb" shape="rect">
                                       <!-- --></a><ul class="ul" id="tensor-ops-rnn-functions-data-filter-formats__ul_oyr_tf1_ghb">
                                       <li dir="ltr" class="li">The hidden state size, input size and the batch size is a multiple of
                                          						8.
                                       </li>
                                       <li dir="ltr" class="li">All user-provided tensors, workspace, and reserve space are aligned to
                                          						128 bit boundaries.
                                       </li>
                                       <li dir="ltr" class="li">For FP16 input/output, the CUDNN_TENSOR_OP_MATH or
                                          						CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION is selected.
                                       </li>
                                       <li dir="ltr" class="li">For FP32 input/output, CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION is
                                          						selected.
                                       </li>
                                    </ul>
                                 </li>
                                 <li class="li liexpand" dir="ltr">For algo = CUDNN_RNN_ALGO_PERSIST_STATIC:<a name="tensor-ops-rnn-functions-data-filter-formats__ul_emd_wf1_ghb" shape="rect">
                                       <!-- --></a><ul class="ul" id="tensor-ops-rnn-functions-data-filter-formats__ul_emd_wf1_ghb">
                                       <li dir="ltr" class="li">The hidden state size and the input size is a multiple of 32.</li>
                                       <li dir="ltr" class="li">The batch size is a multiple of 8.</li>
                                       <li dir="ltr" class="li">If the batch size exceeds 96 (for forward training or inference) or 32
                                          						(for backward data), then the batch sizes constraints may be stricter, and large
                                          						power-of-two batch sizes may be needed. (new for 7.1).
                                       </li>
                                       <li dir="ltr" class="li">All user-provided tensors, workspace, and reserve space are aligned to
                                          						128 bit boundaries.
                                       </li>
                                       <li dir="ltr" class="li">For FP16 input/output, CUDNN_TENSOR_OP_MATH or
                                          						CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION is selected.
                                       </li>
                                       <li dir="ltr" class="li">For FP32 input/output, CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION is
                                          						selected.
                                       </li>
                                    </ul>
                                 </li>
                              </ul>
                              <p dir="ltr" class="p">See also <a class="xref" href="https://docs.nvidia.com/deeplearning/sdk/cudnn-developer-guide/index.html#features-of-rnn-functions" target="_blank" shape="rect"><u class="ph u">Features of RNN Functions.</u></a></p>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="tensor-ops-tensor-transformations"><a name="tensor-ops-tensor-transformations" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#tensor-ops-tensor-transformations" name="tensor-ops-tensor-transformations" shape="rect">2.9.4.&nbsp;Tensor Transformations </a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc"></span></div>
                           <p dir="ltr" class="p" id="tensor-ops-tensor-transformations__docs-internal-guid-73d2b2ee-7fff-9d35-b614-b90ed993ef86"><a name="tensor-ops-tensor-transformations__docs-internal-guid-73d2b2ee-7fff-9d35-b614-b90ed993ef86" shape="rect">
                                 <!-- --></a>A few functions in the
                              			cuDNN library will perform transformations such as folding, padding, and NCHW-to-NHWC
                              			conversion while performing the actual function operation. See below.
                           </p>
                        </div>
                        <div class="topic concept nested3" id="tensor-ops-tensor-transformations-fp16"><a name="tensor-ops-tensor-transformations-fp16" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#tensor-ops-tensor-transformations-fp16" name="tensor-ops-tensor-transformations-fp16" shape="rect">2.9.4.1.&nbsp;FP16 Data </a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc"></span></div>
                              <p dir="ltr" class="p" id="tensor-ops-tensor-transformations-fp16__docs-internal-guid-fa86afe8-7fff-695d-2514-5eee6963ffc3"><a name="tensor-ops-tensor-transformations-fp16__docs-internal-guid-fa86afe8-7fff-695d-2514-5eee6963ffc3" shape="rect">
                                    <!-- --></a>Tensor Cores operate
                                 			on FP16 input data with FP32 accumulation. The FP16 multiply leads to a full-precision
                                 			result that is accumulated in FP32 operations with the other products in a given dot
                                 			product for a matrix with <samp class="ph codeph">m x n x k</samp> dimensions. 
                                 			See <a class="xref" href="index.html#tensor-ops-tensor-transformations-fp16__fig-tensor-op-fp16-inputs" shape="rect">Figure 7</a>.
                              </p>
                              <div class="fig fignone" id="tensor-ops-tensor-transformations-fp16__fig-tensor-op-fp16-inputs"><a name="tensor-ops-tensor-transformations-fp16__fig-tensor-op-fp16-inputs" shape="rect">
                                    <!-- --></a><span class="figcap">Figure 7. Tensor Operation with FP16 Inputs</span><br clear="none"></br><div class="imagecenter">
                                    <embed class="image imagecenter" src="graphics/tensor-op-fp16-input.svg" width="600"></embed>
                                 </div><br clear="none"></br></div>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="tensor-ops-tensor-transformations-fp32-to-fp16"><a name="tensor-ops-tensor-transformations-fp32-to-fp16" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#tensor-ops-tensor-transformations-fp32-to-fp16" name="tensor-ops-tensor-transformations-fp32-to-fp16" shape="rect">2.9.4.2.&nbsp;FP32-to-FP16 Conversion </a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc"></span></div>
                              <p dir="ltr" class="p" id="tensor-ops-tensor-transformations-fp32-to-fp16__docs-internal-guid-d05752cd-7fff-8dcd-9225-29e2e08cac74"><a name="tensor-ops-tensor-transformations-fp32-to-fp16__docs-internal-guid-d05752cd-7fff-8dcd-9225-29e2e08cac74" shape="rect">
                                    <!-- --></a>The cuDNN API for allows
                                 			the user to specify that FP32 input data may be copied and converted to FP16 data
                                 			internally to use Tensor Core Operations for potentially improved performance. This can be
                                 			achieved by selecting CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION enum for <a class="xref" href="index.html#cudnnMathType_t" shape="rect">cudnnMathType_t</a>. In this mode, the FP32 Tensors are
                                 			internally down-converted to FP16, the Tensor Op math is performed, and finally
                                 			up-converted to FP32 as outputs. See <a class="xref" href="index.html#tensor-ops-tensor-transformations-fp32-to-fp16__fig-tensor-op-fp32-to-fp16" shape="rect">Figure 8</a>.
                              </p>
                              <div class="fig fignone" id="tensor-ops-tensor-transformations-fp32-to-fp16__fig-tensor-op-fp32-to-fp16"><a name="tensor-ops-tensor-transformations-fp32-to-fp16__fig-tensor-op-fp32-to-fp16" shape="rect">
                                    <!-- --></a><span class="figcap">Figure 8. Tensor Operation with FP32 Inputs</span><br clear="none"></br><div class="imagecenter">
                                    <embed class="image imagecenter" src="graphics/tensor-op-fp32-to-fp16.svg" width="600"></embed>
                                 </div><br clear="none"></br></div>
                              <p class="p"><strong class="ph b">For Convolutions:</strong></p>
                              <p dir="ltr" class="p" id="tensor-ops-tensor-transformations-fp32-to-fp16__docs-internal-guid-64e7b153-7fff-566a-6a8c-513eeb9f5f02"><a name="tensor-ops-tensor-transformations-fp32-to-fp16__docs-internal-guid-64e7b153-7fff-566a-6a8c-513eeb9f5f02" shape="rect">
                                    <!-- --></a>For convolutions,
                                 			the FP32-to-FP16 conversion can be achieved by passing the
                                 			CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION enum value to the <a class="xref" href="index.html#cudnnSetConvolutionMathType" shape="rect">cudnnSetConvolutionMathType()</a> call. See the
                                 			below code snippet:
                              </p><pre xml:space="preserve">// Set the math type to allow cuDNN to use Tensor Cores:
checkCudnnErr(cudnnSetConvolutionMathType(cudnnConvDesc, CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION));</pre><p class="p"><strong class="ph b">For RNNs:</strong></p>
                              <p dir="ltr" class="p" id="tensor-ops-tensor-transformations-fp32-to-fp16__docs-internal-guid-bc6267da-7fff-159a-b767-0c8de9cf4af9"><a name="tensor-ops-tensor-transformations-fp32-to-fp16__docs-internal-guid-bc6267da-7fff-159a-b767-0c8de9cf4af9" shape="rect">
                                    <!-- --></a>For RNNs, the
                                 			FP32-to-FP16 conversion can be achieved by passing the
                                 			CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION enum value to the <a class="xref" href="index.html#cudnnSetRNNMatrixMathType" shape="rect">cudnnSetRNNMatrixMathType()</a> call to allow FP32
                                 			data to be converted for use in RNNs. See the below code snippet example:
                              </p><pre xml:space="preserve">// Set the math type to allow cuDNN to use Tensor Cores:
checkCudnnErr(cudnnSetRNNMatrixMathType(cudnnRnnDesc, CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION));</pre></div>
                        </div>
                        <div class="topic concept nested3" id="tensor-ops-tensor-transformations-padding"><a name="tensor-ops-tensor-transformations-padding" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#tensor-ops-tensor-transformations-padding" name="tensor-ops-tensor-transformations-padding" shape="rect">2.9.4.3.&nbsp;Padding </a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc"></span></div>
                              <p dir="ltr" class="p" id="tensor-ops-tensor-transformations-padding__docs-internal-guid-9d718f7e-7fff-6f05-0e49-ab885110f1c6"><a name="tensor-ops-tensor-transformations-padding__docs-internal-guid-9d718f7e-7fff-6f05-0e49-ab885110f1c6" shape="rect">
                                    <!-- --></a>For packed NCHW
                                 			data, when the channel dimension is not a multiple of 8, then the cuDNN library will pad
                                 			the tensors as needed to enable Tensor Core operations. This padding is automatic for
                                 			packed NCHW data in both the CUDNN_TENSOR_OP_MATH and the
                                 			CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION cases.
                              </p>
                              <p dir="ltr" class="p">The padding occurs with a negligible loss of performance. Hence, the NCHW Tensor
                                 			dimensions such as below are allowed:
                              </p><pre xml:space="preserve">// Set NCHW Tensor dimensions, not necessarily as multiples of eight (only the input tensor is shown here):
int dimA[] = {1, 7, 32, 32};
int strideA[] = {7168, 1024, 32, 1};
</pre></div>
                        </div>
                        <div class="topic concept nested3" id="tensor-ops-tensor-transformations-folding"><a name="tensor-ops-tensor-transformations-folding" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#tensor-ops-tensor-transformations-folding" name="tensor-ops-tensor-transformations-folding" shape="rect">2.9.4.4.&nbsp;Folding </a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc"></span></div>
                              <p dir="ltr" class="p" id="tensor-ops-tensor-transformations-folding__docs-internal-guid-8c9bd28c-7fff-10d4-ff53-2d686e0096fe"><a name="tensor-ops-tensor-transformations-folding__docs-internal-guid-8c9bd28c-7fff-10d4-ff53-2d686e0096fe" shape="rect">
                                    <!-- --></a>In the folding
                                 			operation the cuDNN library implicitly performs the formatting of input tensors and saves
                                 			the input tensors in an internal workspace. This can lead to an acceleration of the call to
                                 			Tensor Cores.
                              </p>
                              <p dir="ltr" class="p">Folding enables the input Tensors to be transformed to a format that the Tensor Cores
                                 			support (i.e., no strides).
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" id="tensor-ops-tensor-transformations-conversion"><a name="tensor-ops-tensor-transformations-conversion" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#tensor-ops-tensor-transformations-conversion" name="tensor-ops-tensor-transformations-conversion" shape="rect">2.9.4.5.&nbsp;Conversion Between NCHW and NHWC </a></h3>
                           <div class="body conbody">
                              <div class="abstract"><span class="shortdesc"></span></div>
                              <p dir="ltr" class="p">Tensor Cores require that the Tensors be in NHWC data layout. Conversion between
                                 			NCHW and NHWC is performed when the user requests Tensor Op math. However, as stated in
                                 				<a class="xref" href="index.html#tensor-ops-basics" shape="rect">Basics</a>, a request to use Tensor Cores is just that, a
                                 			request, and Tensor Cores may not be used in some cases. The cuDNN library converts between
                                 			NCHW and NHWC if and only if Tensor Cores are requested and are actually used.
                              </p>
                              <p dir="ltr" class="p">If your input (and output) are NCHW, then expect a layout change. See also   for
                                 			packed NCHW data.
                              </p>
                              <p dir="ltr" class="p">Non-Tensor Op convolutions will not perform conversions between NCHW and
                                 			NHWC.
                              </p>
                              <p dir="ltr" class="p">In very rare, and difficult-to-qualify, cases that are a complex function of
                                 			padding and filter sizes, it is possible that Tensor Ops are not enabled. In such cases,
                                 			users should pre-pad.
                              </p>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" id="tensor-ops-guidelines-for-dl-compiler"><a name="tensor-ops-guidelines-for-dl-compiler" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#tensor-ops-guidelines-for-dl-compiler" name="tensor-ops-guidelines-for-dl-compiler" shape="rect">2.9.5.&nbsp;Guidelines for a Deep Learning Compiler</a></h3>
                        <div class="body conbody">
                           <div class="abstract"><span class="shortdesc"></span></div>
                           <p dir="ltr" class="p" id="tensor-ops-guidelines-for-dl-compiler__docs-internal-guid-3cb70324-7fff-cfa6-51d9-abe5561e3e82"><a name="tensor-ops-guidelines-for-dl-compiler__docs-internal-guid-3cb70324-7fff-cfa6-51d9-abe5561e3e82" shape="rect">
                                 <!-- --></a>For a deep learning
                              			compiler, the following are the key guidelines:
                           </p><a name="tensor-ops-guidelines-for-dl-compiler__ul_dqx_vy1_ghb" shape="rect">
                              <!-- --></a><ul class="ul" id="tensor-ops-guidelines-for-dl-compiler__ul_dqx_vy1_ghb">
                              <li class="li liexpand" dir="ltr">
                                 <p dir="ltr" class="p">Make sure that the convolution operation is eligible for Tensor Cores by
                                    					avoiding any combinations of large padding and large filters.
                                 </p>
                              </li>
                              <li class="li liexpand" dir="ltr">
                                 <p dir="ltr" class="p">Transform the inputs and filters to NHWC, pre-pad channel and batch size to
                                    					be a multiple of 8.
                                 </p>
                              </li>
                              <li class="li liexpand" dir="ltr">
                                 <p dir="ltr" class="p">Make sure that all user-provided tensors, workspace and reserve space are
                                    					aligned to 128 bit boundaries.
                                 </p>
                              </li>
                           </ul>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="requirements"><a name="requirements" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#requirements" name="requirements" shape="rect">2.10.&nbsp;GPU and driver requirements</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p">cuDNN v7.0 supports NVIDIA GPUs of compute capability 3.0 and higher. For x86_64
                           platform, cuDNN v7.0 comes with two deliverables: one requires a NVIDIA Driver
                           compatible with CUDA Toolkit 8.0, the other requires a NVIDIA Driver compatible with
                           CUDA Toolkit 9.0. 
                        </p>
                        <p class="p">If you are using cuDNN with a Volta GPU, version 7 or later is required.</p>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="backward-compatibility"><a name="backward-compatibility" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#backward-compatibility" name="backward-compatibility" shape="rect">2.11.&nbsp;Backward compatibility and deprecation policy</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p">When changing the API of an existing cuDNN function "foo" (usually to support some new
                           functionality), first, a new routine "foo_v<samp class="ph codeph">&lt;n&gt;</samp>" is created where
                           <samp class="ph codeph">n</samp> represents the cuDNN version where the new API is first
                           introduced, leaving "foo" untouched. This ensures backward compatibility with the
                           version <samp class="ph codeph">n-1</samp> of cuDNN. At this point, "foo" is considered deprecated,
                           and should be treated as such by users of cuDNN. We gradually eliminate deprecated and
                           suffixed API entries over the course of a few releases of the library per the following
                           policy:
                        </p><a name="backward-compatibility__ul_md3_ddy_r1b" shape="rect">
                           <!-- --></a><ul class="ul" id="backward-compatibility__ul_md3_ddy_r1b">
                           <li class="li liexpand">In release <samp class="ph codeph">n+1</samp>, the legacy API entry "foo" is remapped to a new API
                              "foo_v<samp class="ph codeph">&lt;f&gt;</samp>" where <samp class="ph codeph">f</samp> is some cuDNN version
                              anterior to <samp class="ph codeph">n</samp>.
                           </li>
                           <li class="li liexpand">Also in release <samp class="ph codeph">n+1</samp>, the unsuffixed API entry "foo" is modified to
                              have the same signature as "foo_<samp class="ph codeph">&lt;n&gt;</samp>".
                              "foo_<samp class="ph codeph">&lt;n&gt;</samp>" is retained as-is.
                           </li>
                           <li class="li liexpand">The deprecated former API entry with an anterior suffix _v<samp class="ph codeph">&lt;f&gt;</samp>
                              and new API entry with suffix _v<samp class="ph codeph">&lt;n&gt;</samp> are maintained in this
                              release.
                           </li>
                           <li class="li liexpand">In release <samp class="ph codeph">n+2</samp>, both suffixed entries of a given entry are
                              removed.
                           </li>
                        </ul>
                        <p class="p"> As a rule of thumb, when a routine appears in two forms, one with a suffix and one with
                           no suffix, the non-suffixed entry is to be treated as deprecated. In this case, it is
                           strongly advised that users migrate to the new suffixed API entry to guarantee backwards
                           compatibility in the following cuDNN release. When a routine appears with multiple
                           suffixes, the unsuffixed API entry is mapped to the higher numbered suffix. In that case
                           it is strongly advised to use the non-suffixed API entry to guarantee backward
                           compatibiliy with the following cuDNN release. 
                        </p>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="grouped-convolutions"><a name="grouped-convolutions" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#grouped-convolutions" name="grouped-convolutions" shape="rect">2.12.&nbsp;Grouped Convolutions</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p">cuDNN supports grouped convolutions by setting groupCount &gt; 1 for the convolution
                           			descriptor <samp class="ph codeph">convDesc</samp>, using <samp class="ph codeph">
                              				cudnnSetConvolutionGroupCount()</samp>. 
                        </p>
                        <div class="p">
                           <div class="note note"><span class="notetitle">Note:</span> By default the convolution descriptor <samp class="ph codeph">convDesc</samp> is set to
                              				groupCount of 1. 
                           </div>
                        </div>
                        <p class="p"><strong class="ph b">Basic Idea</strong></p>
                        <p class="p">Conceptually, in grouped convolutions the input channels and the filter channels are split into
                           			groupCount number of independent groups, with each group having a reduced number of
                           			channels. Convolution operation is then performed separately on these input and filter
                           			groups. 
                        </p>
                        <p class="p">For example, consider the following: if the number of input channels is 4, and the number
                           			of filter channels of 12. For a normal, ungrouped convolution, the number of computation
                           			operations performed are 12*4. 
                        </p>
                        <p class="p">If the groupCount is set to 2, then there are now two input channel groups of two input
                           			channels each, and two filter channel groups of six filter channels each. 
                        </p>
                        <p class="p">As a result, each grouped convolution will now perform 2*6 computation operations, and
                           			two such grouped convolutions are performed. Hence the computation savings are 2x:
                           			(12*4)/(2*(2*6)) 
                        </p>
                        <p class="p"><strong class="ph b">cuDNN Grouped Convolution </strong></p>
                        <div class="p"><a name="grouped-convolutions__ul_m1c_pn1_bfb" shape="rect">
                              <!-- --></a><ul class="ul" id="grouped-convolutions__ul_m1c_pn1_bfb">
                              <li class="li liexpand">When using <samp class="ph codeph">groupCount</samp> for grouped convolutions, you must still
                                 					define all tensor descriptors so that they describe the size of the entire
                                 					convolution, instead of specifying the sizes per group. 
                              </li>
                              <li class="li liexpand">Grouped convolutions are supported for all formats that are currently supported
                                 					by the functions <samp class="ph codeph">cuDNNConvolutionForward()</samp>,
                                 						<samp class="ph codeph">cudnnConvolutionBackwardData()</samp> and
                                 						<samp class="ph codeph">cudnnConvolutionBackwardFilter()</samp>. 
                              </li>
                              <li class="li liexpand">The tensor stridings that are set for <samp class="ph codeph">groupCount</samp> of 1 are also
                                 					valid for any group count. 
                              </li>
                              <li class="li liexpand">By default the convolution descriptor <samp class="ph codeph">convDesc</samp> is set to
                                 						<samp class="ph codeph">groupCount</samp> of 1. 
                              </li>
                           </ul>
                        </div>
                        <p class="p"></p>
                        <div class="p">
                           <div class="note note"><span class="notetitle">Note:</span> See <a class="xref" href="index.html#convolution-formulas" shape="rect">Convolution Formulas</a> for the math behind the
                              				cuDNN Grouped Convolution. 
                           </div>
                        </div>
                        <p class="p"></p>
                        <p class="p"><strong class="ph b">Example</strong></p>
                        <p class="p">Below is an example showing the dimensions and strides for grouped convolutions for NCHW
                           			format, for 2D convolution. 
                        </p>
                        <div class="p">
                           <div class="note note"><span class="notetitle">Note:</span> Note that the symbols "*" and "/" are used to indicate multiplication and
                              				division. 
                           </div>
                        </div>
                        <p class="p"><samp class="ph codeph">xDesc or dxDesc: </samp></p><a name="grouped-convolutions__ul_xrx_5r1_bfb" shape="rect">
                           <!-- --></a><ul class="ul" id="grouped-convolutions__ul_xrx_5r1_bfb">
                           <li class="li liexpand"><strong class="ph b">Dimensions</strong>: <samp class="ph codeph">[batch_size, input_channel, x_height, x_width]
                                 				</samp></li>
                           <li class="li liexpand"><strong class="ph b">Strides</strong>: <samp class="ph codeph">[input_channels*x_height*x_width, x_height*x_width, x_width,
                                 					1] </samp></li>
                        </ul>
                        <p class="p"><samp class="ph codeph">wDesc or dwDesc:  </samp></p><a name="grouped-convolutions__ul_gqb_xr1_bfb" shape="rect">
                           <!-- --></a><ul class="ul" id="grouped-convolutions__ul_gqb_xr1_bfb">
                           <li class="li liexpand"><strong class="ph b">Dimensions</strong>: <samp class="ph codeph">[output_channels, input_channels/groupCount, w_height,
                                 					w_width] </samp></li>
                           <li class="li liexpand"><strong class="ph b">Format</strong>: <samp class="ph codeph">NCHW </samp></li>
                        </ul>
                        <p class="p"><samp class="ph codeph">convDesc: </samp></p><a name="grouped-convolutions__ul_i4s_yr1_bfb" shape="rect">
                           <!-- --></a><ul class="ul" id="grouped-convolutions__ul_i4s_yr1_bfb">
                           <li class="li"><strong class="ph b">Group Count</strong>: <samp class="ph codeph">groupCount </samp><p class="p"></p>
                           </li>
                        </ul>
                        <p class="p"><samp class="ph codeph">yDesc or dyDesc: </samp></p><a name="grouped-convolutions__ul_elf_zr1_bfb" shape="rect">
                           <!-- --></a><ul class="ul" id="grouped-convolutions__ul_elf_zr1_bfb">
                           <li class="li liexpand"><strong class="ph b">Dimensions</strong>: <samp class="ph codeph">[batch_size, output_channels, y_height, y_width]
                                 				</samp></li>
                           <li class="li liexpand"><samp class="ph codeph"><strong class="ph b">Strides</strong>: [output_channels*y_height*y_width, y_height*y_width,
                                 					y_width, 1] </samp></li>
                        </ul>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="api-logging"><a name="api-logging" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#api-logging" name="api-logging" shape="rect">2.13.&nbsp;API Logging</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p">cuDNN API logging is a tool that records all input parameters passed into every cuDNN API
                           function call. This functionality is disabled by default, and can be enabled through
                           methods described in this section. 
                        </p>
                        <p class="p">The log output contains variable names, data types, parameter values, device pointers,
                           process ID, thread ID, cuDNN handle, cuda stream ID, and metadata such as time of the
                           function call in microseconds. 
                        </p>
                        <p class="p">When logging is enabled, the log output will be handled by the built-in default callback
                           function. The user may also write their own callback function, and use the <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetCallback" shape="rect">cudnnSetCallback</a></samp> to pass in the function pointer of their
                           own callback function. The following is a sample output of the API log.
                        </p><pre xml:space="preserve">
Function cudnnSetActivationDescriptor() called:
mode: type=cudnnActivationMode_t; val=CUDNN_ACTIVATION_RELU (1);
reluNanOpt: type=cudnnNanPropagation_t; val=CUDNN_NOT_PROPAGATE_NAN (0);
coef: type=<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>; val=1000.000000;
Time: 2017-11-21T14:14:21.366171 (0d+0h+1m+5s since start)
Process: 21264, Thread: 21264, cudnn_handle: NULL, cudnn_stream: NULL.
</pre><p class="p">There are two methods to enable API logging.</p>
                        <div class="section">
                           <h3 class="title sectiontitle">Method 1: Using Environment Variables</h3>
                           <div class="p">To enable API logging using environment variables, follow these steps:<a name="api-logging__ul_j41_ztr_mfb" shape="rect">
                                 <!-- --></a><ul class="ul" id="api-logging__ul_j41_ztr_mfb">
                                 <li class="li liexpand">Set the environment variable <samp class="ph codeph">CUDNN_LOGINFO_DBG</samp> to “1”, and 
                                 </li>
                                 <li class="li liexpand">Set the environment varialbe <samp class="ph codeph">CUDNN_LOGDEST_DBG</samp> to one of
                                    the following: <a name="api-logging__ul_czg_c5r_mfb" shape="rect">
                                       <!-- --></a><ul class="ul" id="api-logging__ul_czg_c5r_mfb">
                                       <li class="li"><samp class="ph codeph">stdout</samp>, <samp class="ph codeph">stderr</samp>, or a user-desired
                                          file path, for example, <samp class="ph codeph">/home/userName1/log.txt</samp>. 
                                       </li>
                                    </ul>
                                 </li>
                                 <li class="li liexpand">Include the conversion specifiers in the file name. For example:<a name="api-logging__ul_xkw_dyr_mfb" shape="rect">
                                       <!-- --></a><ul class="ul" id="api-logging__ul_xkw_dyr_mfb">
                                       <li class="li">To include date and time in the file name, use the date and time
                                          conversion specificers: <samp class="ph codeph">log_%Y_%m_%d_%H_%M_%S.txt</samp>.
                                          The conversion specifiers will be automatically replaced with the
                                          date and time when the program is initiated, resulting in
                                          <samp class="ph codeph">log_2017_11_21_09_41_00.txt</samp>. 
                                       </li>
                                       <li class="li">To include the process id in the file name, use the
                                          <samp class="ph codeph">%i</samp> conversion specifier:
                                          <samp class="ph codeph">log_%Y_%m_%d_%H_%M_%S_%i.txt</samp> for the result:
                                          <samp class="ph codeph">log_2017_11_21_09_41_00_21264.txt</samp> when the
                                          process id is <samp class="ph codeph">21264</samp>.  When you have several
                                          processes running, using the process id conversion specifier will
                                          prevent these processes writing to the same file at the same time.
                                          
                                       </li>
                                    </ul>
                                    <div class="p">
                                       <div class="note note"><span class="notetitle">Note:</span> The supported conversion specifiers are similar to the
                                          <samp class="ph codeph">strftime</samp> function. 
                                       </div>
                                    </div>
                                    <p class="p">If the file already exists, the log will overwrite the existing
                                       file.
                                    </p>
                                    <div class="note note"><span class="notetitle">Note:</span> These environmental variables are only checked once at
                                       the initialization. Any subsequent changes in these environmental
                                       variables will not be effective in the current run. Also note that these
                                       environment settings can be overridden by the Method 2
                                       below.
                                    </div>
                                 </li>
                              </ul>
                           </div>
                           <p class="p">See also <a class="xref" href="index.html#api-logging__table_api_logging" shape="rect">Table 1</a> for the impact on performance
                              of API logging using environment variables.
                           </p>
                           <div class="p">
                              <div class="tablenoborder"><a name="api-logging__table_api_logging" shape="rect">
                                    <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="api-logging__table_api_logging" class="table" frame="border" border="1" rules="all">
                                    <caption><span class="tablecap">Table 1. API Logging Using Environment Variables</span></caption>
                                    <thead class="thead" align="left">
                                       <tr class="row">
                                          <th class="entry" valign="top" id="d54e3593" rowspan="1" colspan="1"> Environment variables </th>
                                          <th class="entry" valign="top" id="d54e3596" rowspan="1" colspan="1"> CUDNN_LOGINFO_DBG=0 </th>
                                          <th class="entry" valign="top" id="d54e3599" rowspan="1" colspan="1"> CUDNN_LOGINFO_DBG=1 </th>
                                       </tr>
                                    </thead>
                                    <tbody class="tbody">
                                       <tr class="row">
                                          <td class="entry" valign="top" headers="d54e3593" rowspan="1" colspan="1">
                                             <p class="p">CUDNN_LOGDEST_DBG not set</p>
                                          </td>
                                          <td class="entry" valign="top" headers="d54e3596" rowspan="1" colspan="1">
                                             <p class="p">- No logging output</p>
                                             <p class="p">- No performance loss</p>
                                          </td>
                                          <td class="entry" valign="top" headers="d54e3599" rowspan="1" colspan="1">
                                             <p class="p">- No logging output</p>
                                             <p class="p">- No performance loss</p>
                                          </td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" headers="d54e3593" rowspan="1" colspan="1">
                                             <p class="p">CUDNN_LOGDEST_DBG=<samp class="ph codeph">NULL</samp></p>
                                          </td>
                                          <td class="entry" valign="top" headers="d54e3596" rowspan="1" colspan="1">
                                             <p class="p">- No logging output</p>
                                             <p class="p">- No performance loss</p>
                                          </td>
                                          <td class="entry" valign="top" headers="d54e3599" rowspan="1" colspan="1">
                                             <p class="p">- No logging output</p>
                                             <p class="p">- No performance loss</p>
                                          </td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" headers="d54e3593" rowspan="1" colspan="1">
                                             <p class="p">CUDNN_LOGDEST_DBG=<samp class="ph codeph">stdout</samp> or
                                                <samp class="ph codeph">stderr</samp></p>
                                          </td>
                                          <td class="entry" valign="top" headers="d54e3596" rowspan="1" colspan="1">
                                             <p class="p">- No logging output</p>
                                             <p class="p">- No performance loss</p>
                                          </td>
                                          <td class="entry" valign="top" headers="d54e3599" rowspan="1" colspan="1">
                                             <p class="p">- Logging to <samp class="ph codeph">stdout</samp> or
                                                <samp class="ph codeph">stderr</samp></p>
                                             <p class="p">- Some performance loss</p>
                                          </td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" headers="d54e3593" rowspan="1" colspan="1">
                                             <p class="p">CUDNN_LOGDEST_DBG=</p>
                                             <p class="p"><samp class="ph codeph">filename.txt</samp></p>
                                          </td>
                                          <td class="entry" valign="top" headers="d54e3596" rowspan="1" colspan="1">
                                             <p class="p">- No logging output</p>
                                             <p class="p">- No performance loss</p>
                                          </td>
                                          <td class="entry" valign="top" headers="d54e3599" rowspan="1" colspan="1">
                                             <p class="p">- Logging to <samp class="ph codeph">filename.txt</samp></p>
                                             <p class="p">- Some performance loss</p>
                                          </td>
                                       </tr>
                                    </tbody>
                                 </table>
                              </div>
                           </div>
                        </div>
                        <div class="section">
                           <h3 class="title sectiontitle">Method 2</h3>
                           <p class="p">Method 2: To use API function calls to enable API logging, refer to the API
                              description of <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetCallback" shape="rect">cudnnSetCallback()</a></samp> and <samp class="ph codeph"><a class="xref" href="index.html#cudnnGetCallback" shape="rect">cudnnGetCallback()</a></samp>.
                           </p>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="features-of-rnn-functions"><a name="features-of-rnn-functions" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#features-of-rnn-functions" name="features-of-rnn-functions" shape="rect">2.14.&nbsp;Features of RNN Functions</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p">The <strong class="ph b">RNN</strong> functions are:
                        </p><a name="features-of-rnn-functions__ul_pfb_gcy_r1b" shape="rect">
                           <!-- --></a><ul class="ul" id="features-of-rnn-functions__ul_pfb_gcy_r1b">
                           <li class="li liexpand"><a class="xref" href="index.html#cudnnRNNForwardInference" shape="rect">cudnnRNNForwardInference</a></li>
                           <li class="li liexpand"><a class="xref" href="index.html#cudnnRNNForwardTraining" shape="rect">cudnnRNNForwardTraining</a></li>
                           <li class="li liexpand"><a class="xref" href="index.html#cudnnRNNBackwardData" shape="rect">cudnnRNNBackwardData</a></li>
                           <li class="li liexpand"><a class="xref" href="index.html#cudnnRNNBackwardWeights" shape="rect">cudnnRNNBackwardWeights</a></li>
                           <li class="li liexpand"><a class="xref" href="index.html#cudnnRNNForwardInferenceEx" shape="rect">cudnnRNNForwardInferenceEx</a></li>
                           <li class="li liexpand"><a class="xref" href="index.html#cudnnRNNForwardTrainingEx" shape="rect">cudnnRNNForwardTrainingEx</a></li>
                           <li class="li liexpand"><a class="xref" href="index.html#cudnnRNNBackwardDataEx" shape="rect">cudnnRNNBackwardDataEx</a></li>
                           <li class="li liexpand"><a class="xref" href="index.html#cudnnRNNBackwardWeightsEx" shape="rect">cudnnRNNBackwardWeightsEx</a></li>
                        </ul>
                        <p class="p">See the table below for a list of features supported by each RNN function:</p>
                        <div class="note note"><span class="notetitle">Note:</span><p class="p">For each of these terms, the short-form versions shown in the paranthesis are used in
                              				the tables below for brevity: <samp class="ph codeph">CUDNN_RNN_ALGO_STANDARD</samp>
                              				(_ALGO_STANDARD), <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_STATIC</samp>
                              				(_ALGO_PERSIST_STATIC), <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_DYNAMIC</samp>
                              				(_ALGO_PERSIST_DYNAMIC), and <samp class="ph codeph">CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION</samp>
                              				(_ALLOW_CONVERSION).
                           </p>
                        </div>
                        <div class="p">
                           <div class="tablenoborder"><a name="features-of-rnn-functions__table_ykb_g11_32b" shape="rect">
                                 <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="features-of-rnn-functions__table_ykb_g11_32b" class="table" frame="border" border="1" rules="all">
                                 <tbody class="tbody">
                                    <tr class="row">
                                       <td class="entry" valign="top" width="34.5360824742268%" rowspan="1" colspan="1"><strong class="ph b">Functions</strong></td>
                                       <td class="entry" valign="top" width="17.182130584192443%" rowspan="1" colspan="1"><strong class="ph b">Input output layout supported</strong></td>
                                       <td class="entry" valign="top" width="18.900343642611688%" rowspan="1" colspan="1"><strong class="ph b">Supports variable sequence length in batch</strong></td>
                                       <td class="entry" valign="top" width="29.381443298969074%" rowspan="1" colspan="1"><strong class="ph b">Commonly supported</strong></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="34.5360824742268%" rowspan="1" colspan="1"><strong class="ph b"><samp class="ph codeph">cudnnRNNForwardInference</samp></strong></td>
                                       <td class="entry" rowspan="4" valign="top" width="17.182130584192443%" colspan="1">Only Sequence major, packed (non-padded)</td>
                                       <td class="entry" rowspan="4" valign="top" width="18.900343642611688%" colspan="1">
                                          <p class="p">Only with <samp class="ph codeph">_ALGO_STANDARD</samp></p>
                                          <p class="p"></p>
                                          <p class="p">Require input sequences descending sorted according to length</p>
                                       </td>
                                       <td class="entry" rowspan="8" valign="top" width="29.381443298969074%" colspan="1">
                                          <p class="p">Mode (cell type)
                                             									supported:
                                          </p><samp class="ph codeph">CUDNN_RNN_RELU, CUDNN_RNN_TANH, <br clear="none"></br>CUDNN_LSTM,
                                             									CUDNN_GRU</samp><p class="p">Algo supported* (see the table below for an
                                             									elaboration on these algorithms):
                                          </p>
                                          <p class="p"><samp class="ph codeph">_ALGO_STANDARD,
                                                										_ALGO_PERSIST_STATIC, _ALGO_PERSIST_DYNAMIC </samp></p>
                                          <p class="p">Math mode
                                             									supported:
                                          </p>
                                          <p class="p"><samp class="ph codeph">CUDNN_DEFAULT_MATH,<br clear="none"></br>CUDNN_TENSOR_OP_MATH</samp></p>
                                          <p class="p">(will
                                             									automatically fall back if run on pre-Volta or if algo doesn’t support
                                             									Tensor Cores)
                                          </p>
                                          <p class="p"><samp class="ph codeph">_ALLOW_CONVERSION</samp> (may do down conversion to utilize
                                             									Tensor Cores)
                                          </p>
                                          <p class="p">Direction mode
                                             										supported:
                                          </p>
                                          <p class="p"><samp class="ph codeph">CUDNN_UNIDIRECTIONAL,
                                                										<br clear="none"></br>CUDNN_BIDIRECTIONAL</samp></p>
                                          <p class="p"></p>
                                          <p class="p">RNN input
                                             									mode:
                                          </p><samp class="ph codeph">CUDNN_LINEAR_INPUT, CUDNN_SKIP_INPUT</samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="34.5360824742268%" rowspan="1" colspan="1">
                                          <p class="p"><samp class="ph codeph"><strong class="ph b">cudnnRNNForwardTraining</strong></samp></p>
                                          <p class="p"></p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="34.5360824742268%" rowspan="1" colspan="1"><samp class="ph codeph"><strong class="ph b">cudnnRNNBackwardData</strong></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="34.5360824742268%" rowspan="1" colspan="1">
                                          <p class="p"><samp class="ph codeph"><strong class="ph b">cudnnRNNBackwardWeights</strong></samp></p>
                                          <p class="p"></p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="34.5360824742268%" rowspan="1" colspan="1"><samp class="ph codeph"><strong class="ph b">cudnnRNNForwardInferenceEx</strong></samp></td>
                                       <td class="entry" rowspan="4" valign="top" width="17.182130584192443%" colspan="1">
                                          <p class="p">Sequence major unpacked,</p>
                                          <p class="p">Batch major unpacked**,</p>
                                          <p class="p">Sequence major packed**</p>
                                          <p class="p"></p>
                                       </td>
                                       <td class="entry" rowspan="4" valign="top" width="18.900343642611688%" colspan="1">
                                          <p class="p">Only with <samp class="ph codeph">_ALGO_STANDARD</samp></p>
                                          <p class="p"></p>
                                          <p class="p">For unpacked layout**, no input sorting required.</p>
                                          <p class="p"></p>
                                          <p class="p">For packed layout, require input sequences descending sorted
                                             according to length
                                          </p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="34.5360824742268%" rowspan="1" colspan="1">
                                          <p class="p"><samp class="ph codeph"><strong class="ph b">cudnnRNNForwardTrainingEx</strong></samp></p>
                                          <p class="p"></p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="34.5360824742268%" rowspan="1" colspan="1"><samp class="ph codeph"><strong class="ph b">cudnnRNNBackwardDataEx</strong></samp></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="34.5360824742268%" rowspan="1" colspan="1"><samp class="ph codeph"><strong class="ph b">cudnnRNNBackwardWeightsEx</strong></samp></td>
                                    </tr>
                                 </tbody>
                              </table>
                           </div>
                        </div>
                        <p class="p">* Do not mix different algos for different steps of training. It’s also not recommended
                           to mix non-extended and extended API for different steps of training. 
                        </p>
                        <p class="p">** To use unpacked layout, user need to set CUDNN_RNN_PADDED_IO_ENABLED through
                           <samp class="ph codeph">cudnnSetRNNPaddingMode</samp>. 
                        </p>
                        <p class="p">The following table provides the features supported by the algorithms referred in the
                           above table: <samp class="ph codeph">CUDNN_RNN_ALGO_STANDARD</samp>,
                           <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_STATIC</samp>, and
                           <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_DYNAMIC</samp>.
                        </p>
                        <div class="tablenoborder"><a name="features-of-rnn-functions__table_alc_xxz_h2b" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="features-of-rnn-functions__table_alc_xxz_h2b" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" valign="top" width="16.55629139072848%" rowspan="1" colspan="1"><strong class="ph b">Features</strong></td>
                                    <td class="entry" valign="top" width="24.006622516556295%" rowspan="1" colspan="1"><samp class="ph codeph"><strong class="ph b">_ALGO_STANDARD</strong></samp></td>
                                    <td class="entry" valign="top" width="25.82781456953643%" rowspan="1" colspan="1"><samp class="ph codeph"><strong class="ph b">_ALGO_PERSIST_STATIC</strong></samp></td>
                                    <td class="entry" valign="top" width="33.609271523178805%" rowspan="1" colspan="1"><samp class="ph codeph"><strong class="ph b">_ALGO_PERSIST_DYNAMIC</strong></samp></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="16.55629139072848%" rowspan="1" colspan="1">
                                       <p class="p"><strong class="ph b">Half input</strong></p>
                                       <p class="p"><strong class="ph b">Single accumulation</strong></p>
                                       <p class="p"><strong class="ph b">Half output</strong></p>
                                    </td>
                                    <td class="entry" colspan="3" valign="top" rowspan="1">
                                       <p class="p">Supported</p>
                                       <p class="p">Half intermediate storage</p>
                                       <p class="p">Single accumulation</p>
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="16.55629139072848%" rowspan="1" colspan="1">
                                       <p class="p"><strong class="ph b">Single input</strong></p>
                                       <p class="p"><strong class="ph b">Single accumulation</strong></p>
                                       <p class="p"><strong class="ph b">Single output</strong></p>
                                    </td>
                                    <td class="entry" colspan="3" valign="top" rowspan="1">
                                       <p class="p">Supported</p>
                                       <p class="p">If running on Volta, with
                                          <samp class="ph codeph">CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION<sup class="ph sup">!</sup></samp>,
                                          will down-convert and use half intermediate storage.
                                       </p>
                                       <p class="p">Otherwise: Single intermediate storage</p>
                                       <p class="p">Single accumulation</p>
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="16.55629139072848%" rowspan="1" colspan="1">
                                       <p class="p"><strong class="ph b">Double input</strong></p>
                                       <p class="p"><strong class="ph b">Double accumulation</strong></p>
                                       <p class="p"><strong class="ph b">Double output</strong></p>
                                    </td>
                                    <td class="entry" valign="top" width="24.006622516556295%" rowspan="1" colspan="1">
                                       <p class="p">Supported</p>
                                       <p class="p">Double intermediate storage</p>
                                       <p class="p">Double accumulation</p>
                                    </td>
                                    <td class="entry" valign="top" width="25.82781456953643%" rowspan="1" colspan="1">Not Supported</td>
                                    <td class="entry" valign="top" width="33.609271523178805%" rowspan="1" colspan="1">
                                       <p class="p">Supported</p>
                                       <p class="p">Double intermediate storage</p>
                                       <p class="p">Double accumulation</p>
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="16.55629139072848%" rowspan="1" colspan="1"><strong class="ph b">LSTM recurrent projection</strong></td>
                                    <td class="entry" valign="top" width="24.006622516556295%" rowspan="1" colspan="1">Supported</td>
                                    <td class="entry" valign="top" width="25.82781456953643%" rowspan="1" colspan="1">Not Supported</td>
                                    <td class="entry" valign="top" width="33.609271523178805%" rowspan="1" colspan="1">Not Supported</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="16.55629139072848%" rowspan="1" colspan="1"><strong class="ph b">LSTM cell clipping</strong></td>
                                    <td class="entry" colspan="3" valign="top" rowspan="1">Supported</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="16.55629139072848%" rowspan="1" colspan="1"><strong class="ph b">Variable sequence length in batch</strong></td>
                                    <td class="entry" valign="top" width="24.006622516556295%" rowspan="1" colspan="1">Supported</td>
                                    <td class="entry" valign="top" width="25.82781456953643%" rowspan="1" colspan="1">Not Supported</td>
                                    <td class="entry" valign="top" width="33.609271523178805%" rowspan="1" colspan="1">Not Supported</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="16.55629139072848%" rowspan="1" colspan="1"><strong class="ph b">Tensor Cores on Volta/Xavier</strong></td>
                                    <td class="entry" colspan="2" valign="top" rowspan="1">
                                       <p class="p">Supported</p>
                                       <p class="p"></p>
                                       <p class="p">For half input/output, acceleration requires setting</p>
                                       <p class="p"><samp class="ph codeph">CUDNN_TENSOR_OP_MATH<sup class="ph sup">!</sup></samp> or
                                          <samp class="ph codeph">CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION<sup class="ph sup">!</sup></samp></p>
                                       <p class="p">Acceleration requires <samp class="ph codeph">inputSize</samp> and
                                          <samp class="ph codeph">hiddenSize</samp> to be multiple of 8
                                       </p>
                                       <p class="p">For single input/output, acceleration requires setting</p>
                                       <p class="p"><samp class="ph codeph">CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION<sup class="ph sup">!</sup></samp></p>
                                       <p class="p">Acceleration requires <samp class="ph codeph">inputSize</samp> and
                                          <samp class="ph codeph">hiddenSize</samp> to be multiple of 8
                                       </p>
                                    </td>
                                    <td class="entry" valign="top" width="33.609271523178805%" rowspan="1" colspan="1">Not Supported, will execute normally ignoring
                                       <samp class="ph codeph">CUDNN_TENSOR_OP_MATH<sup class="ph sup">!</sup></samp> or
                                       <samp class="ph codeph"><br clear="none"></br>_ALLOW_CONVERSION<sup class="ph sup">!</sup></samp></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="16.55629139072848%" rowspan="1" colspan="1"><strong class="ph b">Other limitations</strong></td>
                                    <td class="entry" valign="top" width="24.006622516556295%" rowspan="1" colspan="1"></td>
                                    <td class="entry" valign="top" width="25.82781456953643%" rowspan="1" colspan="1">Max problem size is limited by GPU specifications.</td>
                                    <td class="entry" valign="top" width="33.609271523178805%" rowspan="1" colspan="1">Requires real time compilation through NVRTC</td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                        <p class="p">!<samp class="ph codeph">CUDNN_TENSOR_OP_MATH</samp> or
                           <samp class="ph codeph">CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION</samp> can be set through
                           <samp class="ph codeph">cudnnSetRNNMatrixMathType</samp>. 
                        </p>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="mixed-precision-numerical-accuracy"><a name="mixed-precision-numerical-accuracy" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#mixed-precision-numerical-accuracy" name="mixed-precision-numerical-accuracy" shape="rect">2.15.&nbsp;Mixed Precision Numerical Accuracy</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p">When the computation precision and the output precision are not the same, it is possible
                           that the numerical accuracy will vary from one algorithm to the other. 
                        </p>
                        <p class="p">For example, when the computation is performed in FP32 and the output is in FP16, the
                           CUDNN_CONVOLUTION_BWD_FILTER_ALGO_0 ("ALGO_0")  has lower accuracy compared to the
                           CUDNN_CONVOLUTION_BWD_FILTER_ALGO_1 ("ALGO_1"). This is because ALGO_0 does not use
                           extra workspace, and is forced to accumulate the intermediate results in FP16, i.e.,
                           half precision float, and this reduces the accuracy. The ALGO_1, on the other  hand,
                           uses additonal workspace to accumulate the intermediate values in FP32, i.e., full
                           precision float. 
                        </p>
                     </div>
                  </div>
               </div>
               <div class="topic concept nested0" id="datatypes-reference"><a name="datatypes-reference" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#datatypes-reference" name="datatypes-reference" shape="rect">3.&nbsp;cuDNN Datatypes Reference</a></h2>
                  <div class="body conbody">
                     <div class="abstract"><span class="shortdesc"></span></div>
                     <p class="p">This chapter describes all the types and enums of the cuDNN library API. </p>
                  </div>
                  <div class="topic concept nested1" id="cudnnActivationDescriptor_t"><a name="cudnnActivationDescriptor_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnActivationDescriptor_t" name="cudnnActivationDescriptor_t" shape="rect">3.1.&nbsp;cudnnActivationDescriptor_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnActivationDescriptor_t</samp> is a pointer to an opaque structure holding
                           the description of a activation operation.
                           <samp class="ph codeph">cudnnCreateActivationDescriptor()</samp> is used to create one instance,
                           and <samp class="ph codeph">cudnnSetActivationDescriptor()</samp> must be used to initialize this
                           instance. 
                        </p>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnActivationMode_t"><a name="cudnnActivationMode_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnActivationMode_t" name="cudnnActivationMode_t" shape="rect">3.2.&nbsp;cudnnActivationMode_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnActivationMode_t</samp> is an enumerated type used to select the neuron
                           activation function used in <samp class="ph codeph">cudnnActivationForward()</samp>, <samp class="ph codeph">cudnnActivationBackward()</samp> and <samp class="ph codeph">cudnnConvolutionBiasActivationForward()</samp>. 
                        </p>
                        <p class="p"><strong class="ph b">Values</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_ACTIVATION_SIGMOID</samp></dt>
                           <dd class="dd">
                              <p class="p">Selects the sigmoid function.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_ACTIVATION_RELU</samp></dt>
                           <dd class="dd">
                              <p class="p">Selects the rectified linear function.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_ACTIVATION_TANH</samp></dt>
                           <dd class="dd">
                              <p class="p">Selects the hyperbolic tangent function.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_ACTIVATION_CLIPPED_RELU</samp></dt>
                           <dd class="dd">
                              <p class="p">Selects the clipped rectified linear function.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_ACTIVATION_ELU</samp></dt>
                           <dd class="dd">
                              <p class="p">Selects the exponential linear function.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_ACTIVATION_IDENTITY (new for 7.1)</samp></dt>
                           <dd class="dd">
                              <p class="p">Selects the identity function, intended for bypassing the activation step in
                                 <samp class="ph codeph">cudnnConvolutionBiasActivationForward().</samp> (The
                                 <samp class="ph codeph">cudnnConvolutionBiasActivationForward()</samp> function must
                                 use CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_​PRECOMP_GEMM.) Does not work with
                                 <samp class="ph codeph">cudnnActivationForward()</samp> or
                                 <samp class="ph codeph">cudnnActivationBackward()</samp>.
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnAttnDescriptor_t"><a name="cudnnAttnDescriptor_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnAttnDescriptor_t" name="cudnnAttnDescriptor_t" shape="rect">3.3.&nbsp;cudnnAttnDescriptor_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p">cudnnAttnDescriptor_t is a pointer to an opaque structure holding the description of attention.
                           			Use the function <a class="xref" href="index.html#cudnnCreateAttnDescriptor" shape="rect">cudnnCreateAttnDescriptor</a> to create one instance, and
                           			<a class="xref" href="index.html#cudnnDestroyAttnDescriptor" shape="rect">cudnnDestroyAttnDescriptor</a> to destroy a previously created descriptor. 
                        </p>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnAttnQueryMap_t"><a name="cudnnAttnQueryMap_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnAttnQueryMap_t" name="cudnnAttnQueryMap_t" shape="rect">3.4.&nbsp;cudnnAttnQueryMap_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p">cudnnAttnQueryMap_t is an enumerated type to select the query mapping type. </p>
                        <div class="tablenoborder"><a name="cudnnAttnQueryMap_t__table_hpj_hcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnAttnQueryMap_t__table_hpj_hcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="42.6056338028169%" rowspan="1" colspan="1"><strong class="ph b">Member</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="57.3943661971831%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="42.6056338028169%" rowspan="1" colspan="1">CUDNN_ATTN_QUERYMAP_ALL_TO_ONE = 0</td>
                                    <td class="entry" dir="ltr" valign="top" width="57.3943661971831%" rowspan="1" colspan="1">When beam width &gt; 1, multiple query sequences are mapped to the same key and
                                       							value sequences.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="42.6056338028169%" rowspan="1" colspan="1">CUDNN_ATTN_QUERYMAP_ONE_TO_ONE = 1</td>
                                    <td class="entry" dir="ltr" valign="top" width="57.3943661971831%" rowspan="1" colspan="1">When beam width &gt; 1, multiple query sequences are mapped to corresponding key
                                       							and value sequences.
                                    </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnBatchNormMode_t"><a name="cudnnBatchNormMode_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnBatchNormMode_t" name="cudnnBatchNormMode_t" shape="rect">3.5.&nbsp;cudnnBatchNormMode_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormMode_t" shape="rect">cudnnBatchNormMode_t</a></samp> is an
                           enumerated type used to specify the mode of operation in <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormalizationForwardInference" shape="rect">cudnnBatchNormalizationForwardInference()</a></samp>, <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormalizationForwardTraining" shape="rect">cudnnBatchNormalizationForwardTraining</a>()</samp>, <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormalizationBackward" shape="rect">cudnnBatchNormalizationBackward()</a></samp> and <samp class="ph codeph"><a class="xref" href="index.html#cudnnDeriveBNTensorDescriptor" shape="rect">cudnnDeriveBNTensorDescriptor()</a></samp> routines. 
                        </p>
                        <p class="p"><strong class="ph b">Values</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_BATCHNORM_PER_ACTIVATION</samp></dt>
                           <dd class="dd">
                              <p class="p">Normalization is performed per-activation. This mode is intended to be used
                                 after non-convolutional network layers. In this mode the tensor dimensions
                                 of <samp class="ph codeph">bnBias</samp> and <samp class="ph codeph">bnScale</samp>, the parameters used
                                 in the cudnnBatchNormalization* functions, are 1xCxHxW. 
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_BATCHNORM_SPATIAL</samp></dt>
                           <dd class="dd">
                              <p class="p">Normalization is performed over N+spatial dimensions. This mode is intended
                                 for use after convolutional layers (where spatial invariance is desired). In
                                 this mode the <samp class="ph codeph">bnBias</samp>, <samp class="ph codeph">bnScale</samp> tensor
                                 dimensions are 1xCx1x1. 
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_BATCHNORM_SPATIAL_PERSISTENT</samp></dt>
                           <dd class="dd">
                              <p class="p">This mode is similar to CUDNN_BATCHNORM_SPATIAL but it can be faster for some
                                 tasks. 
                              </p>
                              <p class="p">An optimized path may be selected for CUDNN_DATA_FLOAT and CUDNN_DATA_HALF
                                 types, compute capability 6.0 or higher for the following two batch
                                 normalization API calls: <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormalizationForwardTraining" shape="rect">cudnnBatchNormalizationForwardTraining()</a></samp>, and
                                 <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormalizationBackward" shape="rect">cudnnBatchNormalizationBackward()</a></samp>. In the case of
                                 cudnnBatchNormalizationBackward(), the <samp class="ph codeph">savedMean</samp> and
                                 <samp class="ph codeph">savedInvVariance</samp> arguments should not be NULL. 
                              </p>
                              <p class="p"><strong class="ph b">The rest of this section applies for </strong><samp class="ph codeph">NCHW</samp><strong class="ph b"> mode
                                    only:</strong></p>
                              <p class="p">This mode may use a scaled atomic integer reduction that is deterministic but
                                 imposes more restrictions on the input data range. When a numerical overflow
                                 occurs the algorithm may produce NaN-s or Inf-s (infinity) in output
                                 buffers. 
                              </p>
                              <p class="p">When Inf-s/NaN-s are present in the input data, the output in this mode is
                                 the same as from a pure floating-point implementation. 
                              </p>
                              <p class="p">For finite but very large input values, the algorithm may encounter overflows
                                 more frequently due to a lower dynamic range and emit Inf-s/NaN-s while
                                 CUDNN_BATCHNORM_SPATIAL will produce finite results. The user can invoke
                                 <samp class="ph codeph"><a class="xref" href="index.html#cudnnQueryRuntimeError" shape="rect">cudnnQueryRuntimeError()</a></samp> to check if a numerical
                                 overflow occurred in this mode.
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnBatchNormOps_t"><a name="cudnnBatchNormOps_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnBatchNormOps_t" name="cudnnBatchNormOps_t" shape="rect">3.6.&nbsp;cudnnBatchNormOps_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnBatchNormOps_t</samp> is an enumerated type used to specify the mode of
                           operation in
                           <samp class="ph codeph">cudnnGetBatchNormalizationForwardTrainingExWorkspaceSize()</samp>,
                           <samp class="ph codeph">cudnnBatchNormalizationForwardTrainingEx()</samp>,
                           <samp class="ph codeph">cudnnGetBatchNormalizationBackwardExWorkspaceSize()</samp>,
                           <samp class="ph codeph">cudnnBatchNormalizationBackwardEx()</samp>, and
                           <samp class="ph codeph">cudnnGetBatchNormalizationTrainingExReserveSpaceSize()</samp> functions. 
                        </p>
                        <p class="p"><strong class="ph b">Values</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_BATCHNORM_OPS_BN </samp></dt>
                           <dd class="dd">
                              <p class="p">Only batch normalization is performed, per-activation. </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_BATCHNORM_OPS_BN_ACTIVATION </samp></dt>
                           <dd class="dd">
                              <p dir="ltr" class="p" id="cudnnBatchNormOps_t__docs-internal-guid-407af307-7fff-cbe2-4d7b-933af83609a6"><a name="cudnnBatchNormOps_t__docs-internal-guid-407af307-7fff-cbe2-4d7b-933af83609a6" shape="rect">
                                    <!-- --></a>First
                                 the batch normalization is performed, and then the activation is performed. 
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_BATCHNORM_OPS_BN_ADD_ACTIVATION </samp></dt>
                           <dd class="dd">
                              <p class="p">Performs the batch normalization, then element-wise addition, followed by the
                                 activation operation. 
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnConvolutionBwdDataAlgo_t"><a name="cudnnConvolutionBwdDataAlgo_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnConvolutionBwdDataAlgo_t" name="cudnnConvolutionBwdDataAlgo_t" shape="rect">3.7.&nbsp;cudnnConvolutionBwdDataAlgo_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnConvolutionBwdDataAlgo_t</samp> is an enumerated type that exposes the
                           different algorithms available to execute the backward data convolution operation. 
                        </p>
                        <p class="p"><strong class="ph b">Values</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_CONVOLUTION_BWD_DATA_ALGO_0</samp></dt>
                           <dd class="dd">
                              <p class="p">This algorithm expresses the convolution as a sum of matrix product without
                                 actually explicitly form the matrix that holds the input tensor data. The
                                 sum is done using atomic adds operation, thus the results are
                                 non-deterministic. 
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_CONVOLUTION_BWD_DATA_ALGO_1</samp></dt>
                           <dd class="dd">
                              <p class="p">This algorithm expresses the convolution as a matrix product without actually
                                 explicitly form the matrix that holds the input tensor data. The results are
                                 deterministic. 
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_CONVOLUTION_BWD_DATA_ALGO_FFT</samp></dt>
                           <dd class="dd">
                              <p class="p">This algorithm uses a Fast-Fourier Transform approach to compute the
                                 convolution. A significant memory workspace is needed to store intermediate
                                 results. The results are deterministic. 
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_CONVOLUTION_BWD_DATA_ALGO_​FFT_TILING</samp></dt>
                           <dd class="dd">
                              <p class="p">This algorithm uses the Fast-Fourier Transform approach but splits the inputs
                                 into tiles. A significant memory workspace is needed to store intermediate
                                 results but less than CUDNN_CONVOLUTION_BWD_DATA_ALGO_FFT for large size
                                 images. The results are deterministic. 
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_CONVOLUTION_BWD_DATA_ALGO_WINOGRAD</samp></dt>
                           <dd class="dd">
                              <p class="p">This algorithm uses the Winograd Transform approach to compute the
                                 convolution. A reasonably sized workspace is needed to store intermediate
                                 results. The results are deterministic. 
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_CONVOLUTION_BWD_DATA_ALGO_​WINOGRAD_NONFUSED</samp></dt>
                           <dd class="dd">
                              <p class="p">This algorithm uses the Winograd Transform approach to compute the
                                 convolution. Significant workspace may be needed to store intermediate
                                 results. The results are deterministic. 
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnConvolutionBwdDataAlgoPerf_t"><a name="cudnnConvolutionBwdDataAlgoPerf_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnConvolutionBwdDataAlgoPerf_t" name="cudnnConvolutionBwdDataAlgoPerf_t" shape="rect">3.8.&nbsp;cudnnConvolutionBwdDataAlgoPerf_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnConvolutionBwdDataAlgoPerf_t</samp> is a structure containing performance
                           results returned by <samp class="ph codeph">cudnnFindConvolutionBackwardDataAlgorithm()</samp> or
                           heuristic results returned by
                           <samp class="ph codeph">cudnnGetConvolutionBackwardDataAlgorithm_v7()</samp>. 
                        </p>
                        <p class="p"><strong class="ph b">Data Members</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">cudnnConvolutionBwdDataAlgo_t algo</samp></dt>
                           <dd class="dd">
                              <p class="p">The algorithm run to obtain the associated performance metrics. </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">cudnnStatus_t status</samp></dt>
                           <dd class="dd">
                              <p class="p">If any error occurs during the workspace allocation or timing of
                                 <samp class="ph codeph">cudnnConvolutionBackwardData()</samp>, this status will
                                 represent that error. Otherwise, this status will be the return status of
                                 <samp class="ph codeph">cudnnConvolutionBackwardData()</samp>.
                              </p><a name="cudnnConvolutionBwdDataAlgoPerf_t__ul_lwp_lsz_r1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnConvolutionBwdDataAlgoPerf_t__ul_lwp_lsz_r1b">
                                 <li class="li"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp> if any error occured during
                                    workspace allocation or if provided workspace is insufficient.
                                 </li>
                                 <li class="li"><samp class="ph codeph">CUDNN_STATUS_INTERNAL_ERROR</samp> if any error occured during
                                    timing calculations or workspace deallocation.
                                 </li>
                                 <li class="li">Otherwise, this will be the return status of
                                    <samp class="ph codeph">cudnnConvolutionBackwardData()</samp>.
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">float time</samp></dt>
                           <dd class="dd">
                              <p class="p">The execution time of <samp class="ph codeph">cudnnConvolutionBackwardData()</samp> (in
                                 milliseconds). 
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">size_t memory</samp></dt>
                           <dd class="dd">
                              <p class="p">The workspace size (in bytes). </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">cudnnDeterminism_t determinism</samp></dt>
                           <dd class="dd">
                              <p class="p">The determinism of the algorithm. </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">cudnnMathType_t mathType</samp></dt>
                           <dd class="dd">
                              <p class="p">The math type provided to the algorithm. </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">int reserved[3]</samp></dt>
                           <dd class="dd">
                              <p class="p">Reserved space for future properties. </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnConvolutionBwdDataPreference_t"><a name="cudnnConvolutionBwdDataPreference_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnConvolutionBwdDataPreference_t" name="cudnnConvolutionBwdDataPreference_t" shape="rect">3.9.&nbsp;cudnnConvolutionBwdDataPreference_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnConvolutionBwdDataPreference_t</samp> is an enumerated type used by
                           <samp class="ph codeph">cudnnGetConvolutionBackwardDataAlgorithm()</samp> to help the choice of
                           the algorithm used for the backward data convolution. 
                        </p>
                        <p class="p"><strong class="ph b">Values</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_CONVOLUTION_BWD_DATA_NO_WORKSPACE</samp></dt>
                           <dd class="dd">
                              <p class="p">In this configuration, the routine
                                 <samp class="ph codeph">cudnnGetConvolutionBackwardDataAlgorithm()</samp> is
                                 guaranteed to return an algorithm that does not require any extra workspace
                                 to be provided by the user. 
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_CONVOLUTION_BWD_DATA_​PREFER_FASTEST</samp></dt>
                           <dd class="dd">
                              <p class="p">In this configuration, the routine
                                 <samp class="ph codeph">cudnnGetConvolutionBackwardDataAlgorithm()</samp> will return
                                 the fastest algorithm regardless how much workspace is needed to execute it.
                                 
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_CONVOLUTION_BWD_DATA_​SPECIFY_WORKSPACE_LIMIT</samp></dt>
                           <dd class="dd">
                              <p class="p">In this configuration, the routine
                                 <samp class="ph codeph">cudnnGetConvolutionBackwardDataAlgorithm()</samp> will return
                                 the fastest algorithm that fits within the memory limit that the user
                                 provided. 
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnConvolutionBwdFilterAlgo_t"><a name="cudnnConvolutionBwdFilterAlgo_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnConvolutionBwdFilterAlgo_t" name="cudnnConvolutionBwdFilterAlgo_t" shape="rect">3.10.&nbsp;cudnnConvolutionBwdFilterAlgo_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnConvolutionBwdFilterAlgo_t</samp> is an enumerated type that exposes the
                           different algorithms available to execute the backward filter convolution operation. 
                        </p>
                        <p class="p"><strong class="ph b">Values</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_CONVOLUTION_BWD_FILTER_ALGO_0</samp></dt>
                           <dd class="dd">
                              <p class="p">This algorithm expresses the convolution as a sum of matrix product without
                                 actually explicitly form the matrix that holds the input tensor data. The
                                 sum is done using atomic adds operation, thus the results are
                                 non-deterministic. 
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_CONVOLUTION_BWD_FILTER_ALGO_1</samp></dt>
                           <dd class="dd">
                              <p class="p">This algorithm expresses the convolution as a matrix product without actually
                                 explicitly form the matrix that holds the input tensor data. The results are
                                 deterministic. 
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_CONVOLUTION_BWD_FILTER_ALGO_FFT</samp></dt>
                           <dd class="dd">
                              <p class="p">This algorithm uses the Fast-Fourier Transform approach to compute the
                                 convolution. Significant workspace is needed to store intermediate results.
                                 The results are deterministic. 
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_CONVOLUTION_BWD_FILTER_ALGO_3</samp></dt>
                           <dd class="dd">
                              <p class="p">This algorithm is similar to
                                 <samp class="ph codeph">CUDNN_CONVOLUTION_BWD_FILTER_ALGO_0</samp> but uses some small
                                 workspace to precomputes some indices. The results are also
                                 non-deterministic. 
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_CONVOLUTION_BWD_FILTER_​WINOGRAD_NONFUSED</samp></dt>
                           <dd class="dd">
                              <p class="p">This algorithm uses the Winograd Transform approach to compute the
                                 convolution. Significant workspace may be needed to store intermediate
                                 results. The results are deterministic. 
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_CONVOLUTION_BWD_FILTER_ALGO_​FFT_TILING</samp></dt>
                           <dd class="dd">
                              <p class="p">This algorithm uses the Fast-Fourier Transform approach to compute the
                                 convolution but splits the input tensor into tiles. Significant workspace
                                 may be needed to store intermediate results. The results are deterministic.
                                 
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnConvolutionBwdFilterAlgoPerf_t"><a name="cudnnConvolutionBwdFilterAlgoPerf_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnConvolutionBwdFilterAlgoPerf_t" name="cudnnConvolutionBwdFilterAlgoPerf_t" shape="rect">3.11.&nbsp;cudnnConvolutionBwdFilterAlgoPerf_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnConvolutionBwdFilterAlgoPerf_t</samp> is a structure containing
                           performance results returned by
                           <samp class="ph codeph">cudnnFindConvolutionBackwardFilterAlgorithm()</samp> or heuristic results
                           returned by <samp class="ph codeph">cudnnGetConvolutionBackwardFilterAlgorithm_v7()</samp>. 
                        </p>
                        <p class="p"><strong class="ph b">Data Members</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">cudnnConvolutionBwdFilterAlgo_t algo</samp></dt>
                           <dd class="dd">
                              <p class="p">The algorithm run to obtain the associated performance metrics. </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">cudnnStatus_t status</samp></dt>
                           <dd class="dd">
                              <p class="p">If any error occurs during the workspace allocation or timing of
                                 <samp class="ph codeph">cudnnConvolutionBackwardFilter()</samp>, this status will
                                 represent that error. Otherwise, this status will be the return status of
                                 <samp class="ph codeph">cudnnConvolutionBackwardFilter()</samp>.
                              </p><a name="cudnnConvolutionBwdFilterAlgoPerf_t__ul_d3y_csz_r1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnConvolutionBwdFilterAlgoPerf_t__ul_d3y_csz_r1b">
                                 <li class="li"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp> if any error occured during
                                    workspace allocation or if provided workspace is insufficient.
                                 </li>
                                 <li class="li"><samp class="ph codeph">CUDNN_STATUS_INTERNAL_ERROR</samp> if any error occured during
                                    timing calculations or workspace deallocation.
                                 </li>
                                 <li class="li">Otherwise, this will be the return status of
                                    <samp class="ph codeph">cudnnConvolutionBackwardFilter()</samp>.
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">float time</samp></dt>
                           <dd class="dd">
                              <p class="p">The execution time of <samp class="ph codeph">cudnnConvolutionBackwardFilter()</samp> (in
                                 milliseconds). 
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">size_t memory</samp></dt>
                           <dd class="dd">
                              <p class="p">The workspace size (in bytes). </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">cudnnDeterminism_t determinism</samp></dt>
                           <dd class="dd">
                              <p class="p">The determinism of the algorithm. </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">cudnnMathType_t mathType</samp></dt>
                           <dd class="dd">
                              <p class="p">The math type provided to the algorithm. </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">int reserved[3]</samp></dt>
                           <dd class="dd">
                              <p class="p">Reserved space for future properties. </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnConvolutionBwdFilterPreference_t"><a name="cudnnConvolutionBwdFilterPreference_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnConvolutionBwdFilterPreference_t" name="cudnnConvolutionBwdFilterPreference_t" shape="rect">3.12.&nbsp;cudnnConvolutionBwdFilterPreference_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnConvolutionBwdFilterPreference_t</samp> is an enumerated type used by
                           <samp class="ph codeph">cudnnGetConvolutionBackwardFilterAlgorithm()</samp> to help the choice of
                           the algorithm used for the backward filter convolution. 
                        </p>
                        <p class="p"><strong class="ph b">Values</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_CONVOLUTION_BWD_FILTER_​NO_WORKSPACE</samp></dt>
                           <dd class="dd">
                              <p class="p">In this configuration, the routine
                                 <samp class="ph codeph">cudnnGetConvolutionBackwardFilterAlgorithm()</samp> is
                                 guaranteed to return an algorithm that does not require any extra workspace
                                 to be provided by the user. 
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_CONVOLUTION_BWD_FILTER_​PREFER_FASTEST</samp></dt>
                           <dd class="dd">
                              <p class="p">In this configuration, the routine
                                 <samp class="ph codeph">cudnnGetConvolutionBackwardFilterAlgorithm()</samp> will
                                 return the fastest algorithm regardless how much workspace is needed to
                                 execute it. 
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_CONVOLUTION_BWD_FILTER_​SPECIFY_WORKSPACE_LIMIT</samp></dt>
                           <dd class="dd">
                              <p class="p">In this configuration, the routine
                                 <samp class="ph codeph">cudnnGetConvolutionBackwardFilterAlgorithm()</samp> will
                                 return the fastest algorithm that fits within the memory limit that the user
                                 provided. 
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnConvolutionDescriptor_t"><a name="cudnnConvolutionDescriptor_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnConvolutionDescriptor_t" name="cudnnConvolutionDescriptor_t" shape="rect">3.13.&nbsp;cudnnConvolutionDescriptor_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnConvolutionDescriptor_t</samp> is a pointer to an opaque structure holding
                           the description of a convolution operation.
                           <samp class="ph codeph">cudnnCreateConvolutionDescriptor()</samp> is used to create one instance,
                           and <samp class="ph codeph">cudnnSetConvolutionNdDescriptor()</samp> or
                           <samp class="ph codeph">cudnnSetConvolution2dDescriptor()</samp> must be used to initialize this
                           instance. 
                        </p>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnConvolutionFwdAlgo_t"><a name="cudnnConvolutionFwdAlgo_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnConvolutionFwdAlgo_t" name="cudnnConvolutionFwdAlgo_t" shape="rect">3.14.&nbsp;cudnnConvolutionFwdAlgo_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnConvolutionFwdAlgo_t</samp> is an enumerated type that exposes the
                           different algorithms available to execute the forward convolution operation. 
                        </p>
                        <p class="p"><strong class="ph b">Values</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM</samp></dt>
                           <dd class="dd">
                              <p class="p">This algorithm expresses the convolution as a matrix product without actually
                                 explicitly form the matrix that holds the input tensor data. 
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_​PRECOMP_GEMM</samp></dt>
                           <dd class="dd">
                              <p class="p">This algorithm expresses the convolution as a matrix product without actually
                                 explicitly form the matrix that holds the input tensor data, but still needs
                                 some memory workspace to precompute some indices in order to facilitate the
                                 implicit construction of the matrix that holds the input tensor data. 
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_CONVOLUTION_FWD_ALGO_GEMM</samp></dt>
                           <dd class="dd">
                              <p class="p">This algorithm expresses the convolution as an explicit matrix product. A
                                 significant memory workspace is needed to store the matrix that holds the
                                 input tensor data. 
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_CONVOLUTION_FWD_ALGO_DIRECT</samp></dt>
                           <dd class="dd">
                              <p class="p">This algorithm expresses the convolution as a direct convolution (e.g without
                                 implicitly or explicitly doing a matrix multiplication). 
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_CONVOLUTION_FWD_ALGO_FFT</samp></dt>
                           <dd class="dd">
                              <p class="p">This algorithm uses the Fast-Fourier Transform approach to compute the
                                 convolution. A significant memory workspace is needed to store intermediate
                                 results. 
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING</samp></dt>
                           <dd class="dd">
                              <p class="p">This algorithm uses the Fast-Fourier Transform approach but splits the inputs
                                 into tiles. A significant memory workspace is needed to store intermediate
                                 results but less than <samp class="ph codeph">CUDNN_CONVOLUTION_FWD_ALGO_FFT</samp> for
                                 large size images. 
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD</samp></dt>
                           <dd class="dd">
                              <p class="p">This algorithm uses the Winograd Transform approach to compute the
                                 convolution. A reasonably sized workspace is needed to store intermediate
                                 results. 
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_CONVOLUTION_FWD_ALGO_​WINOGRAD_NONFUSED</samp></dt>
                           <dd class="dd">
                              <p class="p">This algorithm uses the Winograd Transform approach to compute the
                                 convolution. Significant workspace may be needed to store intermediate
                                 results. 
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnConvolutionFwdAlgoPerf_t"><a name="cudnnConvolutionFwdAlgoPerf_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnConvolutionFwdAlgoPerf_t" name="cudnnConvolutionFwdAlgoPerf_t" shape="rect">3.15.&nbsp;cudnnConvolutionFwdAlgoPerf_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnConvolutionFwdAlgoPerf_t</samp> is a structure containing performance
                           results returned by <samp class="ph codeph">cudnnFindConvolutionForwardAlgorithm()</samp> or heuristic
                           results returned by <samp class="ph codeph">cudnnGetConvolutionForwardAlgorithm_v7()</samp>. 
                        </p>
                        <p class="p"><strong class="ph b">Data Members</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">cudnnConvolutionFwdAlgo_t algo</samp></dt>
                           <dd class="dd">
                              <p class="p">The algorithm run to obtain the associated performance metrics. </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">cudnnStatus_t status</samp></dt>
                           <dd class="dd">
                              <p class="p">If any error occurs during the workspace allocation or timing of
                                 <samp class="ph codeph">cudnnConvolutionForward()</samp>, this status will represent
                                 that error. Otherwise, this status will be the return status of
                                 <samp class="ph codeph">cudnnConvolutionForward()</samp>.
                              </p><a name="cudnnConvolutionFwdAlgoPerf_t__ul_xsg_trz_r1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnConvolutionFwdAlgoPerf_t__ul_xsg_trz_r1b">
                                 <li class="li"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp> if any error occured during
                                    workspace allocation or if provided workspace is insufficient.
                                 </li>
                                 <li class="li"><samp class="ph codeph">CUDNN_STATUS_INTERNAL_ERROR</samp> if any error occured during
                                    timing calculations or workspace deallocation.
                                 </li>
                                 <li class="li">Otherwise, this will be the return status of
                                    <samp class="ph codeph">cudnnConvolutionForward()</samp>.
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">float time</samp></dt>
                           <dd class="dd">
                              <p class="p">The execution time of <samp class="ph codeph">cudnnConvolutionForward()</samp> (in
                                 milliseconds). 
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">size_t memory</samp></dt>
                           <dd class="dd">
                              <p class="p">The workspace size (in bytes). </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">cudnnDeterminism_t determinism</samp></dt>
                           <dd class="dd">
                              <p class="p">The determinism of the algorithm. </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">cudnnMathType_t mathType</samp></dt>
                           <dd class="dd">
                              <p class="p">The math type provided to the algorithm. </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">int reserved[3]</samp></dt>
                           <dd class="dd">
                              <p class="p">Reserved space for future properties. </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnConvolutionFwdPreference_t"><a name="cudnnConvolutionFwdPreference_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnConvolutionFwdPreference_t" name="cudnnConvolutionFwdPreference_t" shape="rect">3.16.&nbsp;cudnnConvolutionFwdPreference_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnConvolutionFwdPreference_t</samp> is an enumerated type used by
                           <samp class="ph codeph">cudnnGetConvolutionForwardAlgorithm()</samp> to help the choice of the
                           algorithm used for the forward convolution. 
                        </p>
                        <p class="p"><strong class="ph b">Values</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_CONVOLUTION_FWD_NO_WORKSPACE</samp></dt>
                           <dd class="dd">
                              <p class="p">In this configuration, the routine
                                 <samp class="ph codeph">cudnnGetConvolutionForwardAlgorithm()</samp> is guaranteed to
                                 return an algorithm that does not require any extra workspace to be provided
                                 by the user. 
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_CONVOLUTION_FWD_PREFER_FASTEST</samp></dt>
                           <dd class="dd">
                              <p class="p">In this configuration, the routine
                                 <samp class="ph codeph">cudnnGetConvolutionForwardAlgorithm()</samp> will return the
                                 fastest algorithm regardless how much workspace is needed to execute it.
                                 
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_CONVOLUTION_FWD_SPECIFY_​WORKSPACE_LIMIT</samp></dt>
                           <dd class="dd">
                              <p class="p">In this configuration, the routine
                                 <samp class="ph codeph">cudnnGetConvolutionForwardAlgorithm()</samp> will return the
                                 fastest algorithm that fits within the memory limit that the user provided.
                                 
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnConvolutionMode_t"><a name="cudnnConvolutionMode_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnConvolutionMode_t" name="cudnnConvolutionMode_t" shape="rect">3.17.&nbsp;cudnnConvolutionMode_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnConvolutionMode_t</samp> is an enumerated type used by
                           <samp class="ph codeph">cudnnSetConvolutionDescriptor()</samp> to configure a convolution
                           descriptor. The filter used for the convolution can be applied in two different ways,
                           corresponding mathematically to a convolution or to a cross-correlation. (A
                           cross-correlation is equivalent to a convolution with its filter rotated by 180
                           degrees.)
                        </p>
                        <p class="p"><strong class="ph b">Values</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_CONVOLUTION</samp></dt>
                           <dd class="dd">
                              <p class="p">In this mode, a convolution operation will be done when applying the filter
                                 to the images. 
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_CROSS_CORRELATION</samp></dt>
                           <dd class="dd">
                              <p class="p">In this mode, a cross-correlation operation will be done when applying the
                                 filter to the images. 
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnCTCLossAlgo_t"><a name="cudnnCTCLossAlgo_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCTCLossAlgo_t" name="cudnnCTCLossAlgo_t" shape="rect">3.18.&nbsp;cudnnCTCLossAlgo_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnCTCLossAlgo_t</samp> is an enumerated type that exposes the different
                           algorithms available to execute the CTC loss operation.
                        </p>
                        <p class="p"><strong class="ph b">Values</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_CTC_LOSS_ALGO_DETERMINISTIC</samp></dt>
                           <dd class="dd">
                              <p class="p">Results are guaranteed to be reproducible</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_CTC_LOSS_ALGO_NON_DETERMINISTIC</samp></dt>
                           <dd class="dd">
                              <p class="p">Results are not guaranteed to be reproducible</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnCTCLossDescriptor_t"><a name="cudnnCTCLossDescriptor_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCTCLossDescriptor_t" name="cudnnCTCLossDescriptor_t" shape="rect">3.19.&nbsp;cudnnCTCLossDescriptor_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnCTCLossDescriptor_t</samp> is a pointer to an opaque structure holding the
                           description of a CTC loss operation. <samp class="ph codeph">cudnnCreateCTCLossDescriptor()</samp> is
                           used to create one instance, <samp class="ph codeph">cudnnSetCTCLossDescriptor()</samp> is be used to
                           initialize this instance, <samp class="ph codeph">cudnnDestroyCTCLossDescriptor()</samp> is be used to
                           destroy this instance. 
                        </p>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnDataType_t"><a name="cudnnDataType_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDataType_t" name="cudnnDataType_t" shape="rect">3.20.&nbsp;cudnnDataType_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnDataType_t</samp> is an enumerated type indicating the data type to which
                           a tensor descriptor or filter descriptor refers.
                        </p>
                        <p class="p"><strong class="ph b">Values</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_DATA_FLOAT</samp></dt>
                           <dd class="dd">
                              <p class="p">The data is 32-bit single-precision floating point
                                 (<samp class="ph codeph">float</samp>).
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_DATA_DOUBLE</samp></dt>
                           <dd class="dd">
                              <p class="p">The data is 64-bit double-precision floating point
                                 (<samp class="ph codeph">double</samp>).
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_DATA_HALF</samp></dt>
                           <dd class="dd">
                              <p class="p">The data is 16-bit floating point.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_DATA_INT8</samp></dt>
                           <dd class="dd">
                              <p class="p">The data is 8-bit signed integer.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_DATA_UINT8 (new for 7.1)</samp></dt>
                           <dd class="dd">
                              <p class="p">The data is 8-bit unsigned integer.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_DATA_INT32</samp></dt>
                           <dd class="dd">
                              <p class="p">The data is 32-bit signed integer.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_DATA_INT8x4</samp></dt>
                           <dd class="dd">
                              <p class="p"> The data is 32-bit elements each composed of 4 8-bit signed integer. This
                                 data type is only supported with tensor format CUDNN_TENSOR_NCHW_VECT_C.
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_DATA_INT8x32</samp></dt>
                           <dd class="dd">
                              <p class="p"> The data is 32-element vectors, each element being 8-bit signed integer.
                                 This data type is only supported with the tensor format
                                 CUDNN_TENSOR_NCHW_VECT_C. Moreover, this data type can only be used with
                                 “algo 1,” i.e., CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_​PRECOMP_GEMM. See <a class="xref" href="index.html#cudnnConvolutionFwdAlgo_t" shape="rect">cudnnConvolutionFwdAlgo_t.</a></p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_DATA_UINT8x4 (new for 7.1)</samp></dt>
                           <dd class="dd">
                              <p class="p"> The data is 32-bit elements each composed of 4 8-bit unsigned integer. This data type is only supported with tensor format
                                 CUDNN_TENSOR_NCHW_VECT_C.
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnDeterminism_t"><a name="cudnnDeterminism_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDeterminism_t" name="cudnnDeterminism_t" shape="rect">3.21.&nbsp;cudnnDeterminism_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnDeterminism_t</samp> is an enumerated type used to indicate if the
                           computed results are deterministic (reproducible). See section 2.5 (Reproducibility) for
                           more details on determinism.
                        </p>
                        <p class="p"><strong class="ph b">Values</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_NON_DETERMINISTIC</samp></dt>
                           <dd class="dd">
                              <p class="p">Results are not guaranteed to be reproducible</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_DETERMINISTIC</samp></dt>
                           <dd class="dd">
                              <p class="p">Results are guaranteed to be reproducible</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnDirectionMode_t"><a name="cudnnDirectionMode_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDirectionMode_t" name="cudnnDirectionMode_t" shape="rect">3.22.&nbsp;cudnnDirectionMode_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnDirectionMode_t</samp> is an enumerated type used to specify the
                           recurrence pattern in the <samp class="ph codeph">cudnnRNNForwardInference()</samp>,
                           <samp class="ph codeph">cudnnRNNForwardTraining()</samp>, <samp class="ph codeph">cudnnRNNBackwardData()</samp>
                           and <samp class="ph codeph">cudnnRNNBackwardWeights()</samp> routines. 
                        </p>
                        <p class="p"><strong class="ph b">Values</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp></dt>
                           <dd class="dd">The network iterates recurrently from the first input to the last.</dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp></dt>
                           <dd class="dd">Each layer of the the network iterates recurrently from the first input to the
                              last and separately from the last input to the first. The outputs of the two are
                              concatenated at each iteration giving the output of the layer.
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnDivNormMode_t"><a name="cudnnDivNormMode_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDivNormMode_t" name="cudnnDivNormMode_t" shape="rect">3.23.&nbsp;cudnnDivNormMode_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnDivNormMode_t</samp> is an enumerated type used to specify the mode of
                           operation in <samp class="ph codeph">cudnnDivisiveNormalizationForward()</samp> and
                           <samp class="ph codeph">cudnnDivisiveNormalizationBackward()</samp>. 
                        </p>
                        <p class="p"><strong class="ph b">Values</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_DIVNORM_PRECOMPUTED_MEANS</samp></dt>
                           <dd class="dd">
                              <p class="p">The means tensor data pointer is expected to contain means or other kernel
                                 convolution values precomputed by the user. The means pointer can also be
                                 NULL, in that case it's considered to be filled with zeroes. This is
                                 equivalent to spatial LRN. Note that in the backward pass the means are
                                 treated as independent inputs and the gradient over means is computed
                                 independently. In this mode to yield a net gradient over the entire LCN
                                 computational graph the destDiffMeans result should be backpropagated
                                 through the user's means layer (which can be impelemented using average
                                 pooling) and added to the destDiffData tensor produced by
                                 cudnnDivisiveNormalizationBackward. 
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnDropoutDescriptor_t"><a name="cudnnDropoutDescriptor_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDropoutDescriptor_t" name="cudnnDropoutDescriptor_t" shape="rect">3.24.&nbsp;cudnnDropoutDescriptor_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnDropoutDescriptor_t</samp> is a pointer to an opaque structure holding the
                           description of a dropout operation. <samp class="ph codeph">cudnnCreateDropoutDescriptor()</samp> is
                           used to create one instance, <samp class="ph codeph">cudnnSetDropoutDescriptor()</samp> is used to
                           initialize this instance, <samp class="ph codeph">cudnnDestroyDropoutDescriptor()</samp> is used to
                           destroy this instance, <samp class="ph codeph">cudnnGetDropoutDescriptor()</samp> is used to query
                           fields of a previously initialized instance,
                           <samp class="ph codeph">cudnnRestoreDropoutDescriptor()</samp> is used to restore an instance to a
                           previously saved off state. 
                        </p>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnErrQueryMode_t"><a name="cudnnErrQueryMode_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnErrQueryMode_t" name="cudnnErrQueryMode_t" shape="rect">3.25.&nbsp;cudnnErrQueryMode_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnErrQueryMode_t</samp> is an enumerated type passed to
                           <samp class="ph codeph">cudnnQueryRuntimeError()</samp> to select the remote kernel error query
                           mode. 
                        </p>
                        <p class="p"><strong class="ph b">Values</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_ERRQUERY_RAWCODE</samp></dt>
                           <dd class="dd">Read the error storage location regardless of the kernel completion status.</dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_ERRQUERY_NONBLOCKING</samp></dt>
                           <dd class="dd">Report if all tasks in the user stream of the cuDNN handle were completed. If
                              that is the case, report the remote kernel error code.
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_ERRQUERY_BLOCKING</samp></dt>
                           <dd class="dd">Wait for all tasks to complete in the user stream before reporting the remote
                              kernel error code.
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnFilterDescriptor_t"><a name="cudnnFilterDescriptor_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnFilterDescriptor_t" name="cudnnFilterDescriptor_t" shape="rect">3.26.&nbsp;cudnnFilterDescriptor_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnFilterDescriptor_t</samp> is a pointer to an opaque structure holding the
                           description of a filter dataset. <samp class="ph codeph">cudnnCreateFilterDescriptor()</samp> is used
                           to create one instance, and <samp class="ph codeph">cudnnSetFilter4dDescriptor()</samp> or
                           <samp class="ph codeph">cudnnSetFilterNdDescriptor()</samp> must be used to initialize this
                           instance. 
                        </p>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnFoldingDirection_t"><a name="cudnnFoldingDirection_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnFoldingDirection_t" name="cudnnFoldingDirection_t" shape="rect">3.27.&nbsp;cudnnFoldingDirection_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p dir="ltr" class="p" id="cudnnFoldingDirection_t__docs-internal-guid-665f44ae-7fff-510c-1872-0a114ae3575a"><a name="cudnnFoldingDirection_t__docs-internal-guid-665f44ae-7fff-510c-1872-0a114ae3575a" shape="rect">
                              <!-- --></a>cudnnFoldingDirection_t
                           			is an enumerated type used to select the folding direction. See also <a class="xref" href="index.html#cudnnTensorTransformDescriptor_t" shape="rect">cudnnTensorTransformDescriptor_t</a>.
                        </p>
                        <div class="tablenoborder"><a name="cudnnFoldingDirection_t__table_hpj_hcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnFoldingDirection_t__table_hpj_hcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="42.6056338028169%" rowspan="1" colspan="1"><strong class="ph b">Member</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="57.3943661971831%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="42.6056338028169%" rowspan="1" colspan="1">CUDNN_TRANSFORM_FOLD = 0U</td>
                                    <td class="entry" dir="ltr" valign="top" width="57.3943661971831%" rowspan="1" colspan="1">Selects folding.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="42.6056338028169%" rowspan="1" colspan="1">
                                       <p dir="ltr" class="p" id="cudnnFoldingDirection_t__docs-internal-guid-6b8b93a1-7fff-4d2a-1e35-23fa77dcdef2"><a name="cudnnFoldingDirection_t__docs-internal-guid-6b8b93a1-7fff-4d2a-1e35-23fa77dcdef2" shape="rect">
                                             <!-- --></a>CUDNN_TRANSFORM_UNFOLD = 1U
                                       </p>
                                    </td>
                                    <td class="entry" dir="ltr" valign="top" width="57.3943661971831%" rowspan="1" colspan="1">Selects unfolding.</td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnFusedOps_t"><a name="cudnnFusedOps_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnFusedOps_t" name="cudnnFusedOps_t" shape="rect">3.28.&nbsp;cudnnFusedOps_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p">The cudnnFusedOps_t type is an enumerated type to select a specific sequence of computations to
                           			perform in the fused operations. 
                        </p>
                        <div class="tablenoborder"><a name="cudnnFusedOps_t__table_hpj_hcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnFusedOps_t__table_hpj_hcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="57.98319327731092%" rowspan="1" colspan="1"><strong class="ph b">Member</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="42.016806722689076%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="57.98319327731092%" rowspan="1" colspan="1">
                                       <p class="p">CUDNN_FUSED_SCALE_BIAS_ACTIVATION_CONV_BNSTATS = 0 </p>
                                    </td>
                                    <td class="entry" valign="top" width="42.016806722689076%" rowspan="1" colspan="1">
                                       <p dir="ltr" class="p">On a per channel basis, performs these operations in this order:
                                          								scale, add bias, activation, convolution, and generate batchnorm statistics.
                                          							
                                       </p>
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" colspan="2" valign="top" rowspan="1">
                                       <div class="fig fignone" id="cudnnFusedOps_t__fig-fused-opcode0"><a name="cudnnFusedOps_t__fig-fused-opcode0" shape="rect">
                                             <!-- --></a><br clear="none"></br><div class="imagecenter">
                                             <embed class="image imagecenter" src="graphics/fused-op-block-diag-opcode0.svg" width="700"></embed>
                                          </div><br clear="none"></br></div>
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="57.98319327731092%" rowspan="1" colspan="1">
                                       <p class="p">CUDNN_FUSED_SCALE_BIAS_ACTIVATION_WGRAD = 1</p>
                                    </td>
                                    <td class="entry" valign="top" width="42.016806722689076%" rowspan="1" colspan="1">
                                       <p dir="ltr" class="p">On a per channel basis, performs these operations in this order:
                                          								scale, add bias, activation, convolution backward weights, and generate
                                          								batchnorm statistics. 
                                       </p>
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" colspan="2" valign="top" rowspan="1">
                                       <div class="fig fignone" id="cudnnFusedOps_t__fig-fused-opcode1"><a name="cudnnFusedOps_t__fig-fused-opcode1" shape="rect">
                                             <!-- --></a><br clear="none"></br><div class="imagecenter">
                                             <embed class="image imagecenter" src="graphics/fused-op-block-diag-opcode1.svg" width="600"></embed>
                                          </div><br clear="none"></br></div>
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="57.98319327731092%" rowspan="1" colspan="1">CUDNN_FUSED_BN_FINALIZE_STATISTICS_TRAINING = 2</td>
                                    <td class="entry" valign="top" width="42.016806722689076%" rowspan="1" colspan="1">
                                       <p dir="ltr" class="p">Computes the equivalent scale and bias from ySum, ySqSum and
                                          								learned scale, bias.
                                       </p>
                                       <p dir="ltr" class="p">Optionally update running statistics and generate saved stats</p>
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="57.98319327731092%" rowspan="1" colspan="1">CUDNN_FUSED_BN_FINALIZE_STATISTICS_INFERENCE = 3</td>
                                    <td class="entry" valign="top" width="42.016806722689076%" rowspan="1" colspan="1">
                                       <p dir="ltr" class="p"></p>
                                       <p dir="ltr" class="p">Computes the equivalent scale and bias from the learned running
                                          								statistics and the learned scale, bias.
                                       </p>
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="57.98319327731092%" rowspan="1" colspan="1">CUDNN_FUSED_CONV_SCALE_BIAS_ADD_ACTIVATION = 4</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.016806722689076%" rowspan="1" colspan="1">On a per channel basis, performs these operations in this order: convolution,
                                       							scale, add bias, element-wise addition with another tensor, and
                                       							activation.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="57.98319327731092%" rowspan="1" colspan="1">CUDNN_FUSED_SCALE_BIAS_ADD_ACTIVATION_GEN_BITMASK = 5</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.016806722689076%" rowspan="1" colspan="1">On a per channel basis, performs these operations in this order: scale and
                                       							bias on one tensor, scale and bias on a second tensor, element-wise addition of
                                       							these two  tensors, and on the resulting tensor perform activation, and
                                       							generate activation bit mask.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="57.98319327731092%" rowspan="1" colspan="1">CUDNN_FUSED_DACTIVATION_FORK_DBATCHNORM = 6</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.016806722689076%" rowspan="1" colspan="1">On a per channel basis, performs these operations in this order: backward
                                       							activation, fork (i.e., write out gradient for the residual branch), and
                                       							backward batch norm.
                                    </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnFusedOpsConstParamLabel_t"><a name="cudnnFusedOpsConstParamLabel_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnFusedOpsConstParamLabel_t" name="cudnnFusedOpsConstParamLabel_t" shape="rect">3.29.&nbsp;cudnnFusedOpsConstParamLabel_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p">The <samp class="ph codeph">cudnnFusedOpsConstParamLabel_t</samp> is an enumerated type for the selection of
                           			the type of the cudnnFusedOps descriptor. See also <a class="xref" href="index.html#cudnnSetFusedOpsConstParamPackAttribute" shape="rect">cudnnSetFusedOpsConstParamPackAttribute</a>. 
                        </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">typedef</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span> {
	CUDNN_PARAM_XDESC                          = 0,
	CUDNN_PARAM_XDATA_PLACEHOLDER              = 1,
	CUDNN_PARAM_BN_MODE                        = 2,
	CUDNN_PARAM_BN_EQSCALEBIAS_DESC            = 3,
	CUDNN_PARAM_BN_EQSCALE_PLACEHOLDER         = 4,
	CUDNN_PARAM_BN_EQBIAS_PLACEHOLDER          = 5,
	CUDNN_PARAM_ACTIVATION_DESC                = 6,
	CUDNN_PARAM_CONV_DESC                      = 7,
	CUDNN_PARAM_WDESC                          = 8,
	CUDNN_PARAM_WDATA_PLACEHOLDER              = 9,
	CUDNN_PARAM_DWDESC                         = 10,
	CUDNN_PARAM_DWDATA_PLACEHOLDER             = 11,
	CUDNN_PARAM_YDESC                          = 12,
	CUDNN_PARAM_YDATA_PLACEHOLDER              = 13,
	CUDNN_PARAM_DYDESC                         = 14,
	CUDNN_PARAM_DYDATA_PLACEHOLDER             = 15,
	CUDNN_PARAM_YSTATS_DESC                    = 16,
	CUDNN_PARAM_YSUM_PLACEHOLDER               = 17,
	CUDNN_PARAM_YSQSUM_PLACEHOLDER             = 18,
	CUDNN_PARAM_BN_SCALEBIAS_MEANVAR_DESC      = 19,
	CUDNN_PARAM_BN_SCALE_PLACEHOLDER           = 20,
	CUDNN_PARAM_BN_BIAS_PLACEHOLDER            = 21,
	CUDNN_PARAM_BN_SAVED_MEAN_PLACEHOLDER      = 22,
	CUDNN_PARAM_BN_SAVED_INVSTD_PLACEHOLDER    = 23,
	CUDNN_PARAM_BN_RUNNING_MEAN_PLACEHOLDER    = 24,
	CUDNN_PARAM_BN_RUNNING_VAR_PLACEHOLDER     = 25,
	CUDNN_PARAM_ZDESC                          = 26,
	CUDNN_PARAM_ZDATA_PLACEHOLDER              = 27,
	CUDNN_PARAM_BN_Z_EQSCALEBIAS_DESC          = 28,
	CUDNN_PARAM_BN_Z_EQSCALE_PLACEHOLDER       = 29,
	CUDNN_PARAM_BN_Z_EQBIAS_PLACEHOLDER        = 30,
	CUDNN_PARAM_ACTIVATION_BITMASK_DESC        = 31,
	CUDNN_PARAM_ACTIVATION_BITMASK_PLACEHOLDER = 32,
	CUDNN_PARAM_DXDESC                         = 33,
	CUDNN_PARAM_DXDATA_PLACEHOLDER             = 34,
	CUDNN_PARAM_DZDESC                         = 35,
	CUDNN_PARAM_DZDATA_PLACEHOLDER             = 36,
	CUDNN_PARAM_BN_DSCALE_PLACEHOLDER          = 37,
	CUDNN_PARAM_BN_DBIAS_PLACEHOLDER           = 38,
	} cudnnFusedOpsConstParamLabel_t;</pre><div class="p">
                           <div class="tablenoborder"><a name="cudnnFusedOpsConstParamLabel_t__table_xsy_1qs_vhb" shape="rect">
                                 <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnFusedOpsConstParamLabel_t__table_xsy_1qs_vhb" class="table" frame="border" border="1" rules="all">
                                 <caption><span class="tablecap">Table 2. Legend For Tables in This Section</span></caption>
                                 <thead class="thead" align="left">
                                    <tr class="row">
                                       <th class="entry" align="left" valign="top" width="50%" id="d54e6784" rowspan="1" colspan="1">Short-form used:</th>
                                       <th class="entry" align="left" valign="top" width="50%" id="d54e6787" rowspan="1" colspan="1">Stands for:</th>
                                    </tr>
                                 </thead>
                                 <tbody class="tbody">
                                    <tr class="row">
                                       <td class="entry" align="left" valign="top" width="50%" headers="d54e6784" rowspan="1" colspan="1">Setter</td>
                                       <td class="entry" align="left" valign="top" width="50%" headers="d54e6787" rowspan="1" colspan="1"><a class="xref" href="index.html#cudnnSetFusedOpsConstParamPackAttribute" shape="rect">cudnnSetFusedOpsConstParamPackAttribute</a></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" align="left" valign="top" width="50%" headers="d54e6784" rowspan="1" colspan="1">Getter</td>
                                       <td class="entry" align="left" valign="top" width="50%" headers="d54e6787" rowspan="1" colspan="1"><a class="xref" href="index.html#cudnnGetFusedOpsConstParamPackAttribute" shape="rect">cudnnGetFusedOpsConstParamPackAttribute</a></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" align="left" valign="top" width="50%" headers="d54e6784" rowspan="1" colspan="1">X_PointerPlaceHolder_t</td>
                                       <td class="entry" align="left" valign="top" width="50%" headers="d54e6787" rowspan="1" colspan="1"><a class="xref" href="index.html#cudnnFusedOpsPointerPlaceHolder_t" shape="rect">cudnnFusedOpsPointerPlaceHolder_t</a></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" align="left" valign="top" width="50%" headers="d54e6784" rowspan="1" colspan="1">"X_" prefix in the Attribute column</td>
                                       <td class="entry" align="left" valign="top" width="50%" headers="d54e6787" rowspan="1" colspan="1">Stands for "CUDNN_PARAM_" in the enumerator name</td>
                                    </tr>
                                 </tbody>
                              </table>
                           </div>
                        </div>
                        <div class="p">
                           <div class="tablenoborder"><a name="cudnnFusedOpsConstParamLabel_t__table_pxv_t3t_vhb" shape="rect">
                                 <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnFusedOpsConstParamLabel_t__table_pxv_t3t_vhb" class="table" frame="border" border="1" rules="all">
                                 <caption><span class="tablecap">Table 3. CUDNN_FUSED_SCALE_BIAS_ACTIVATION_CONV_BNSTATS</span></caption>
                                 <thead class="thead" align="left">
                                    <tr class="row">
                                       <th class="entry" colspan="4" align="left" valign="top" id="d54e6867" rowspan="1">For the attribute
                                          								CUDNN_FUSED_SCALE_BIAS_ACTIVATION_CONV_BNSTATS in cudnnFusedOp_t:
                                       </th>
                                    </tr>
                                    <tr class="row">
                                       <th class="entry" valign="top" width="30.839002267573694%" id="d54e6873" rowspan="1" colspan="1"><strong class="ph b">Attribute</strong></th>
                                       <th class="entry" valign="top" width="22.675736961451246%" id="d54e6877" rowspan="1" colspan="1"><strong class="ph b">Expected Descriptor Type Passed in, in the Setter</strong></th>
                                       <th class="entry" valign="top" width="23.80952380952381%" id="d54e6881" rowspan="1" colspan="1"><strong class="ph b">Description</strong></th>
                                       <th class="entry" valign="top" width="22.675736961451246%" id="d54e6885" rowspan="1" colspan="1">Default Value After Creation</th>
                                    </tr>
                                 </thead>
                                 <tbody class="tbody">
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="30.839002267573694%" headers="d54e6867 d54e6873" rowspan="1" colspan="1">X_XDESC</td>
                                       <td class="entry" dir="ltr" valign="top" width="22.675736961451246%" headers="d54e6867 d54e6877" rowspan="1" colspan="1">In the setter the <samp class="ph codeph">*param</samp> should be
                                          									<samp class="ph codeph">xDesc</samp>, a pointer to a previously initialized
                                          									<samp class="ph codeph">cudnnTensorDescriptor_t</samp>.
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e6867 d54e6881" rowspan="1" colspan="1">Tensor descriptor describing the size, layout and datatype of the x
                                          								(input) tensor
                                       </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e6867 d54e6885" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="30.839002267573694%" headers="d54e6867 d54e6873" rowspan="1" colspan="1">X_XDATA_PLACEHOLDER</td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e6867 d54e6877" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">In the setter the <samp class="ph codeph">*param</samp> should be a pointer
                                             									to a previously initialized X_PointerPlaceHolder_t*.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e6867 d54e6881" rowspan="1" colspan="1">Describes whether xData pointer in the VariantParamPack will be NULL, or
                                          								if not, user promised pointer alignment * 
                                       </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e6867 d54e6885" rowspan="1" colspan="1">CUDNN_PTR_NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="30.839002267573694%" headers="d54e6867 d54e6873" rowspan="1" colspan="1">X_BN_MODE </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e6867 d54e6877" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">In the setter the <samp class="ph codeph">*param</samp> should be a pointer
                                             									to a previously initialized <a class="xref" href="index.html#cudnnBatchNormMode_t" shape="rect">cudnnBatchNormMode_t*</a>.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e6867 d54e6881" rowspan="1" colspan="1">Describes the mode of operation for the scale, bias and the statistics.
                                          									
                                          <p class="p"></p>
                                          <p class="p">As of cuDNN 7.6.0, only “CUDNN_BATCHNORM_SPATIAL” and
                                             									“CUDNN_BATCHNORM_SPATIAL_PERSISTENT” are supported, i.e., scale, bias and
                                             									statistics are all per-channel.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e6867 d54e6885" rowspan="1" colspan="1">CUDNN_BATCHNORM_PER_ACTIVATION</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="30.839002267573694%" headers="d54e6867 d54e6873" rowspan="1" colspan="1">X_BN_EQSCALEBIAS_DESC </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e6867 d54e6877" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">In the setter the <samp class="ph codeph">*param</samp> should be a pointer
                                             									to a previously initialized <a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a>.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e6867 d54e6881" rowspan="1" colspan="1">Tensor descriptor describing the size, layout and datatype of the
                                          								batchNorm equivalent scale and bias tensors. The shapes must match the mode
                                          								specified in “CUDNN_PARAM_BN_MODE”. If set to NULL, both scale and bias
                                          								operation will become a NOP. 
                                       </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e6867 d54e6885" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="30.839002267573694%" headers="d54e6867 d54e6873" rowspan="1" colspan="1">X_BN_EQSCALE_PLACEHOLDER</td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e6867 d54e6877" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">In the setter the <samp class="ph codeph">*param</samp> should be a pointer
                                             									to a previously initialized X_PointerPlaceHolder_t*.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e6867 d54e6881" rowspan="1" colspan="1">
                                          <p class="p">Describes whether batchnorm equivalent scale pointer in the
                                             									VariantParamPack will be NULL, or if not, user promised pointer alignment
                                             									*.
                                          </p>
                                          <p class="p">If set to CUDNN_PTR_NULL, then the scale operation becomes a NOP.</p>
                                       </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e6867 d54e6885" rowspan="1" colspan="1">CUDNN_PTR_NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="30.839002267573694%" headers="d54e6867 d54e6873" rowspan="1" colspan="1">X_BN_EQBIAS_PLACEHOLDER </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e6867 d54e6877" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">In the setter the <samp class="ph codeph">*param</samp> should be a pointer
                                             									to a previously initialized X_PointerPlaceHolder_t*.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e6867 d54e6881" rowspan="1" colspan="1">Describes whether batchnorm equivalent bias pointer in the
                                          								VariantParamPack will be NULL, or if not, user promised pointer alignment
                                          									*.
                                          <p class="p"> If set to CUDNN_PTR_NULL, then the bias operation becomes a NOP.
                                             								
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e6867 d54e6885" rowspan="1" colspan="1">CUDNN_PTR_NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="30.839002267573694%" headers="d54e6867 d54e6873" rowspan="1" colspan="1">X_ACTIVATION_DESC </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e6867 d54e6877" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">In the setter the <samp class="ph codeph">*param</samp> should be a pointer
                                             									to a previously initialized <a class="xref" href="index.html#cudnnActivationDescriptor_t" shape="rect">cudnnActivationDescriptor_t*</a>.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e6867 d54e6881" rowspan="1" colspan="1"> Describes the activation operation. 
                                          <p class="p">As of 7.6.0, only activation
                                             									mode of “CUDNN_ACTIVATION_RELU” and “CUDNN_ACTIVATION_IDENTITY” is
                                             									supported. If set to NULL or if the activation mode is set to
                                             									“CUDNN_ACTIVATION_IDENTITY”, then the activation in the op sequence
                                             									becomes a NOP. 
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e6867 d54e6885" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="30.839002267573694%" headers="d54e6867 d54e6873" rowspan="1" colspan="1">X_CONV_DESC </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e6867 d54e6877" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">In the setter the <samp class="ph codeph">*param</samp> should be a pointer
                                             									to a previously initialized <a class="xref" href="index.html#cudnnConvolutionDescriptor_t" shape="rect">cudnnConvolutionDescriptor_t*</a>.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e6867 d54e6881" rowspan="1" colspan="1">Describes the convolution operation.</td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e6867 d54e6885" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="30.839002267573694%" headers="d54e6867 d54e6873" rowspan="1" colspan="1">X_WDESC</td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e6867 d54e6877" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">In the setter the <samp class="ph codeph">*param</samp> should be a pointer
                                             									to a previously initialized <a class="xref" href="index.html#cudnnFilterDescriptor_t" shape="rect">cudnnFilterDescriptor_t*</a>.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e6867 d54e6881" rowspan="1" colspan="1">Filter descriptor describing the size, layout and datatype of the w
                                          								(filter) tensor.
                                       </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e6867 d54e6885" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="30.839002267573694%" headers="d54e6867 d54e6873" rowspan="1" colspan="1">X_WDATA_PLACEHOLDER </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e6867 d54e6877" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">In the setter the <samp class="ph codeph">*param</samp> should be a pointer
                                             									to a previously initialized X_PointerPlaceHolder_t*.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e6867 d54e6881" rowspan="1" colspan="1"> Describes whether w (filter) tensor pointer in the VariantParamPack
                                          								will be NULL, or if not, user promised pointer alignment *.
                                       </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e6867 d54e6885" rowspan="1" colspan="1">CUDNN_PTR_NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="30.839002267573694%" headers="d54e6867 d54e6873" rowspan="1" colspan="1">X_YDESC </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e6867 d54e6877" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">In the setter the <samp class="ph codeph">*param</samp> should be a pointer
                                             									to a previously initialized <a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t*</a>.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e6867 d54e6881" rowspan="1" colspan="1"> Tensor descriptor describing the size, layout and datatype of the y
                                          								(output) tensor.
                                       </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e6867 d54e6885" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="30.839002267573694%" headers="d54e6867 d54e6873" rowspan="1" colspan="1">X_YDATA_PLACEHOLDER </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e6867 d54e6877" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">In the setter the <samp class="ph codeph">*param</samp> should be a pointer
                                             									to a previously initialized X_PointerPlaceHolder_t*.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e6867 d54e6881" rowspan="1" colspan="1"> Describes whether y (output) tensor pointer in the VariantParamPack
                                          								will be NULL, or if not, user promised pointer alignment *. 
                                       </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e6867 d54e6885" rowspan="1" colspan="1">CUDNN_PTR_NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="30.839002267573694%" headers="d54e6867 d54e6873" rowspan="1" colspan="1">X_YSTATS_DESC </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e6867 d54e6877" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">In the setter the <samp class="ph codeph">*param</samp> should be a pointer
                                             									to a previously initialized
                                             									<samp class="ph codeph">cudnnTensorDescriptor_t*</samp>.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e6867 d54e6881" rowspan="1" colspan="1"> Tensor descriptor describing the size, layout and datatype of the sum
                                          								of y and sum of y square tensors. The shapes need to match the mode
                                          								specified in “CUDNN_PARAM_BN_MODE”. 
                                          <p class="p">If set to NULL, the
                                             										<samp class="ph codeph">y</samp> statistics generation operation will be become a
                                             									NOP.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e6867 d54e6885" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="30.839002267573694%" headers="d54e6867 d54e6873" rowspan="1" colspan="1">X_YSUM_PLACEHOLDER</td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e6867 d54e6877" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">In the setter the <samp class="ph codeph">*param</samp> should be a pointer
                                             									to a previously initialized X_PointerPlaceHolder_t*.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e6867 d54e6881" rowspan="1" colspan="1"> Describes whether sum of <samp class="ph codeph">y</samp> pointer in the
                                          								VariantParamPack will be NULL, or if not, user promised pointer alignment
                                          									*.
                                          <p class="p"> If set to CUDNN_PTR_NULL, the y statistics generation operation
                                             									will be become a NOP 
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e6867 d54e6885" rowspan="1" colspan="1">CUDNN_PTR_NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="30.839002267573694%" headers="d54e6867 d54e6873" rowspan="1" colspan="1">X_YSQSUM_PLACEHOLDER </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e6867 d54e6877" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">In the setter the <samp class="ph codeph">*param</samp> should be a pointer
                                             									to a previously initialized X_PointerPlaceHolder_t*.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e6867 d54e6881" rowspan="1" colspan="1">Describes whether sum of <samp class="ph codeph">y</samp> square pointer in the
                                          								VariantParamPack will be NULL, or if not, user promised pointer alignment
                                          									*.
                                          <p class="p"> If set to CUDNN_PTR_NULL, the y statistics generation operation
                                             									will be become a NOP.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e6867 d54e6885" rowspan="1" colspan="1">CUDNN_PTR_NULL</td>
                                    </tr>
                                 </tbody>
                              </table>
                           </div>
                           <div class="note note"><span class="notetitle">Note:</span> If the corresponding pointer placeholder in ConstParamPack is set to
                              				“CUDNN_PTR_NULL”, then the device pointer in the VariantParamPack need to be NULL as
                              				well. 
                           </div>
                           <div class="note note"><span class="notetitle">Note:</span> If the corresponding pointer placeholder in ConstParamPack is set to
                              				“CUDNN_PTR_ELEM_ALIGNED” or “CUDNN_PTR_16B_ALIGNED”, then the device pointer in the
                              				VariantParamPack may not be NULL and need to be at least element-aligned or 16
                              				bytes-aligned, respectively. 
                           </div>
                        </div>
                        <div class="p">As of cuDNN 7.6.0, if the conditions in the <a class="xref" href="index.html#cudnnFusedOpsConstParamLabel_t__table-fully-fused-fast-path-fwd" shape="rect">Table 4</a> are met, then the
                           			fully fused fast path will be triggered. Otherwise a slower partially fused path will be
                           			triggered. 
                           
                           
                           <div class="tablenoborder"><a name="cudnnFusedOpsConstParamLabel_t__table-fully-fused-fast-path-fwd" shape="rect">
                                 <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnFusedOpsConstParamLabel_t__table-fully-fused-fast-path-fwd" class="table" frame="border" border="1" rules="all">
                                 <caption><span class="tablecap">Table 4. Conditions for Fully Fused Fast Path (Forward)</span></caption>
                                 <thead class="thead" align="left">
                                    <tr class="row">
                                       <th class="entry" valign="top" id="d54e7306" rowspan="1" colspan="1">Parameter</th>
                                       <th class="entry" valign="top" id="d54e7309" rowspan="1" colspan="1">Condition</th>
                                    </tr>
                                 </thead>
                                 <tbody class="tbody">
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" headers="d54e7306" rowspan="1" colspan="1">Device compute capability</td>
                                       <td class="entry" dir="ltr" valign="top" headers="d54e7309" rowspan="1" colspan="1">Need to be one of 7.0, 7.2 or 7.5</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" headers="d54e7306" rowspan="1" colspan="1">
                                          <p class="p">CUDNN_PARAM_XDESC</p>
                                          <p class="p">CUDNN_PARAM_XDATA_PLACEHOLDER</p>
                                       </td>
                                       <td class="entry" valign="top" headers="d54e7309" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">Tensor is 4 dimensional</p>
                                          <p class="p">Datatype is CUDNN_DATA_HALF</p>
                                          <p class="p">Layout is NHWC fully packed</p>
                                          <p dir="ltr" class="p">Alignment is CUDNN_PTR_16B_ALIGNED</p>
                                          <p dir="ltr" class="p">Tensor’s C dimension is a multiple of 8.</p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" headers="d54e7306" rowspan="1" colspan="1">
                                          <p class="p">CUDNN_PARAM_BN_EQSCALEBIAS_DESC</p>
                                          <p class="p">CUDNN_PARAM_BN_EQSCALE_PLACEHOLDER</p>
                                          <p class="p">CUDNN_PARAM_BN_EQBIAS_PLACEHOLDER</p>
                                       </td>
                                       <td class="entry" valign="top" headers="d54e7309" rowspan="1" colspan="1">
                                          <p class="p">If either one of scale and bias operation is not turned into a NOP:</p>
                                          <p class="p">Tensor is 4 dimensional with shape 1xCx1x1</p>
                                          <p class="p">Datatype is CUDNN_DATA_HALF</p>
                                          <p class="p">Layout is fully packed</p>
                                          <p dir="ltr" class="p">Alignment is CUDNN_PTR_16B_ALIGNED</p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" headers="d54e7306" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">CUDNN_PARAM_CONV_DESC</p>
                                          <p class="p">CUDNN_PARAM_WDESC</p>
                                          <p class="p">CUDNN_PARAM_WDATA_PLACEHOLDER</p>
                                       </td>
                                       <td class="entry" valign="top" headers="d54e7309" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">Convolution descriptor’s mode need to be
                                             									CUDNN_CROSS_CORRELATION
                                          </p>
                                          <p dir="ltr" class="p">Convolution descriptor’s dataType need to be
                                             									CUDNN_DATA_FLOAT
                                          </p>
                                          <p dir="ltr" class="p">Convolution descriptor’s dilationA is (1,1)</p>
                                          <p dir="ltr" class="p">Convolution descriptor’s group count need to be 1</p>
                                          <p dir="ltr" class="p">Convolution descriptor’s <samp class="ph codeph">mathType</samp> need to be
                                             									CUDNN_TENSOR_OP_MATH or CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION
                                          </p>
                                          <p dir="ltr" class="p">Filter is in NHWC layout</p>
                                          <p dir="ltr" class="p">Filter’s data type is CUDNN_DATA_HALF</p>
                                          <p dir="ltr" class="p">Filter’s K dimension is a multiple of 32.</p>
                                          <p dir="ltr" class="p">Filter size RxS is either 1x1 or 3x3</p>
                                          <p class="p">If filter size RxS is 1x1, convolution descriptor’s padA need to be (0,0)
                                             									and filterStrideA need to be (1,1)
                                          </p>
                                          <p class="p">Filter’s alignment is CUDNN_PTR_16B_ALIGNED</p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" headers="d54e7306" rowspan="1" colspan="1">
                                          <p class="p">CUDNN_PARAM_YDESC</p>
                                          <p class="p">CUDNN_PARAM_YDATA_PLACEHOLDER</p>
                                       </td>
                                       <td class="entry" valign="top" headers="d54e7309" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">Tensor is 4 dimensional</p>
                                          <p class="p">Datatype is CUDNN_DATA_HALF</p>
                                          <p class="p">Layout is NHWC fully packed</p>
                                          <p dir="ltr" class="p">Alignment is CUDNN_PTR_16B_ALIGNED</p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" headers="d54e7306" rowspan="1" colspan="1">
                                          <p class="p">CUDNN_PARAM_YSTATS_DESC</p>
                                          <p class="p">CUDNN_PARAM_YSUM_PLACEHOLDER</p>
                                          <p class="p">CUDNN_PARAM_YSQSUM_PLACEHOLDER</p>
                                       </td>
                                       <td class="entry" valign="top" headers="d54e7309" rowspan="1" colspan="1">
                                          <p class="p">If the generate statistics operation is not turned into a NOP:</p>
                                          <p class="p">Tensor is 4 dimensional with shape 1xKx1x1</p>
                                          <p class="p">Datatype is CUDNN_DATA_FLOAT</p>
                                          <p class="p">Layout is fully packed</p>
                                          <p dir="ltr" class="p">Alignment is CUDNN_PTR_16B_ALIGNED</p>
                                       </td>
                                    </tr>
                                 </tbody>
                              </table>
                           </div>
                        </div>
                        <div class="p">
                           <div class="tablenoborder"><a name="cudnnFusedOpsConstParamLabel_t__table_alv_s4s_vhb" shape="rect">
                                 <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnFusedOpsConstParamLabel_t__table_alv_s4s_vhb" class="table" frame="border" border="1" rules="all">
                                 <caption><span class="tablecap">Table 5. CUDNN_FUSED_SCALE_BIAS_ACTIVATION_WGRAD</span></caption>
                                 <thead class="thead" align="left">
                                    <tr class="row">
                                       <th class="entry" colspan="4" align="left" valign="top" id="d54e7529" rowspan="1">For the attribute
                                          								CUDNN_FUSED_SCALE_BIAS_ACTIVATION_WGRAD in cudnnFusedOp_t:
                                       </th>
                                    </tr>
                                    <tr class="row">
                                       <th class="entry" valign="top" width="30.839002267573694%" id="d54e7535" rowspan="1" colspan="1"><strong class="ph b">Attribute</strong></th>
                                       <th class="entry" valign="top" width="22.675736961451246%" id="d54e7539" rowspan="1" colspan="1"><strong class="ph b">Expected Descriptor Type Passed in, in the Setter</strong></th>
                                       <th class="entry" valign="top" width="23.80952380952381%" id="d54e7543" rowspan="1" colspan="1"><strong class="ph b">Description</strong></th>
                                       <th class="entry" valign="top" width="22.675736961451246%" id="d54e7547" rowspan="1" colspan="1">Default Value After Creation</th>
                                    </tr>
                                 </thead>
                                 <tbody class="tbody">
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="30.839002267573694%" headers="d54e7529 d54e7535" rowspan="1" colspan="1">X_XDESC</td>
                                       <td class="entry" dir="ltr" valign="top" width="22.675736961451246%" headers="d54e7529 d54e7539" rowspan="1" colspan="1">In the setter the <samp class="ph codeph">*param</samp> should be
                                          									<samp class="ph codeph">xDesc</samp>, a pointer to a previously initialized
                                          									<samp class="ph codeph">cudnnTensorDescriptor_t</samp>.
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e7529 d54e7543" rowspan="1" colspan="1">Tensor descriptor describing the size, layout and datatype of the x
                                          								(input) tensor
                                       </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e7529 d54e7547" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="30.839002267573694%" headers="d54e7529 d54e7535" rowspan="1" colspan="1">X_XDATA_PLACEHOLDER</td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e7529 d54e7539" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">In the setter the <samp class="ph codeph">*param</samp> should be a pointer
                                             									to a previously initialized X_PointerPlaceHolder_t*.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e7529 d54e7543" rowspan="1" colspan="1">Describes whether xData pointer in the VariantParamPack will be NULL, or
                                          								if not, user promised pointer alignment * 
                                       </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e7529 d54e7547" rowspan="1" colspan="1">CUDNN_PTR_NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="30.839002267573694%" headers="d54e7529 d54e7535" rowspan="1" colspan="1">X_BN_MODE </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e7529 d54e7539" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">In the setter the <samp class="ph codeph">*param</samp> should be a pointer
                                             									to a previously initialized <a class="xref" href="index.html#cudnnBatchNormMode_t" shape="rect">cudnnBatchNormMode_t*</a>.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e7529 d54e7543" rowspan="1" colspan="1">Describes the mode of operation for the scale, bias and the statistics.
                                          									
                                          <p class="p"></p>
                                          <p class="p">As of cuDNN 7.6.0, only “CUDNN_BATCHNORM_SPATIAL” and
                                             									“CUDNN_BATCHNORM_SPATIAL_PERSISTENT” are supported, i.e., scale, bias and
                                             									statistics are all per-channel.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e7529 d54e7547" rowspan="1" colspan="1">CUDNN_BATCHNORM_PER_ACTIVATION</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="30.839002267573694%" headers="d54e7529 d54e7535" rowspan="1" colspan="1">X_BN_EQSCALEBIAS_DESC </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e7529 d54e7539" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">In the setter the <samp class="ph codeph">*param</samp> should be a pointer
                                             									to a previously initialized <a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a>.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e7529 d54e7543" rowspan="1" colspan="1">Tensor descriptor describing the size, layout and datatype of the
                                          								batchNorm equivalent scale and bias tensors. The shapes must match the mode
                                          								specified in “CUDNN_PARAM_BN_MODE”. If set to NULL, both scale and bias
                                          								operation will become a NOP. 
                                       </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e7529 d54e7547" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="30.839002267573694%" headers="d54e7529 d54e7535" rowspan="1" colspan="1">X_BN_EQSCALE_PLACEHOLDER</td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e7529 d54e7539" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">In the setter the <samp class="ph codeph">*param</samp> should be a pointer
                                             									to a previously initialized X_PointerPlaceHolder_t*.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e7529 d54e7543" rowspan="1" colspan="1">
                                          <p class="p">Describes whether batchnorm equivalent scale pointer in the
                                             									VariantParamPack will be NULL, or if not, user promised pointer alignment
                                             									*.
                                          </p>
                                          <p class="p">If set to CUDNN_PTR_NULL, then the scale operation becomes a NOP.</p>
                                       </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e7529 d54e7547" rowspan="1" colspan="1">CUDNN_PTR_NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="30.839002267573694%" headers="d54e7529 d54e7535" rowspan="1" colspan="1">X_BN_EQBIAS_PLACEHOLDER </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e7529 d54e7539" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">In the setter the <samp class="ph codeph">*param</samp> should be a pointer
                                             									to a previously initialized X_PointerPlaceHolder_t*.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e7529 d54e7543" rowspan="1" colspan="1">Describes whether batchnorm equivalent bias pointer in the
                                          								VariantParamPack will be NULL, or if not, user promised pointer alignment
                                          									*.
                                          <p class="p"> If set to CUDNN_PTR_NULL, then the bias operation becomes a NOP.
                                             								
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e7529 d54e7547" rowspan="1" colspan="1">CUDNN_PTR_NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="30.839002267573694%" headers="d54e7529 d54e7535" rowspan="1" colspan="1">X_ACTIVATION_DESC </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e7529 d54e7539" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">In the setter the <samp class="ph codeph">*param</samp> should be a pointer
                                             									to a previously initialized <a class="xref" href="index.html#cudnnActivationDescriptor_t" shape="rect">cudnnActivationDescriptor_t*</a>.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e7529 d54e7543" rowspan="1" colspan="1"> Describes the activation operation. 
                                          <p class="p">As of 7.6.0, only activation
                                             									mode of “CUDNN_ACTIVATION_RELU” and “CUDNN_ACTIVATION_IDENTITY” is
                                             									supported. If set to NULL or if the activation mode is set to
                                             									“CUDNN_ACTIVATION_IDENTITY”, then the activation in the op sequence
                                             									becomes a NOP. 
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e7529 d54e7547" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="30.839002267573694%" headers="d54e7529 d54e7535" rowspan="1" colspan="1">X_CONV_DESC </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e7529 d54e7539" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">In the setter the <samp class="ph codeph">*param</samp> should be a pointer
                                             									to a previously initialized <a class="xref" href="index.html#cudnnConvolutionDescriptor_t" shape="rect">cudnnConvolutionDescriptor_t*</a>.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e7529 d54e7543" rowspan="1" colspan="1">Describes the convolution operation.</td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e7529 d54e7547" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="30.839002267573694%" headers="d54e7529 d54e7535" rowspan="1" colspan="1">X_DWDESC</td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e7529 d54e7539" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">In the setter the <samp class="ph codeph">*param</samp> should be a pointer
                                             									to a previously initialized <a class="xref" href="index.html#cudnnFilterDescriptor_t" shape="rect">cudnnFilterDescriptor_t*</a>.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e7529 d54e7543" rowspan="1" colspan="1">Filter descriptor describing the size, layout and datatype of the
                                          									<samp class="ph codeph">dw</samp> (filter gradient output) tensor.
                                       </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e7529 d54e7547" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="30.839002267573694%" headers="d54e7529 d54e7535" rowspan="1" colspan="1">X_DWDATA_PLACEHOLDER </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e7529 d54e7539" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">In the setter the <samp class="ph codeph">*param</samp> should be a pointer
                                             									to a previously initialized X_PointerPlaceHolder_t*.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e7529 d54e7543" rowspan="1" colspan="1"> Describes whether <samp class="ph codeph">dw</samp> (filter gradient output) tensor
                                          								pointer in the VariantParamPack will be NULL, or if not, user promised
                                          								pointer alignment *.
                                       </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e7529 d54e7547" rowspan="1" colspan="1">CUDNN_PTR_NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="30.839002267573694%" headers="d54e7529 d54e7535" rowspan="1" colspan="1">X_DYDESC </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e7529 d54e7539" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">In the setter the <samp class="ph codeph">*param</samp> should be a pointer
                                             									to a previously initialized <a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t*</a>.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e7529 d54e7543" rowspan="1" colspan="1"> Tensor descriptor describing the size, layout and datatype of the
                                          									<samp class="ph codeph">dy</samp> (gradient input) tensor.
                                       </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e7529 d54e7547" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="30.839002267573694%" headers="d54e7529 d54e7535" rowspan="1" colspan="1">X_DYDATA_PLACEHOLDER </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e7529 d54e7539" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">In the setter the <samp class="ph codeph">*param</samp> should be a pointer
                                             									to a previously initialized X_PointerPlaceHolder_t*.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e7529 d54e7543" rowspan="1" colspan="1"> Describes whether <samp class="ph codeph">dy</samp> (gradient input) tensor pointer
                                          								in the VariantParamPack will be NULL, or if not, user promised pointer
                                          								alignment *. 
                                       </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e7529 d54e7547" rowspan="1" colspan="1">CUDNN_PTR_NULL</td>
                                    </tr>
                                 </tbody>
                              </table>
                           </div>
                        </div>
                        <div class="p">
                           <div class="note note"><span class="notetitle">Note:</span> If the corresponding pointer placeholder in ConstParamPack is set to
                              				“CUDNN_PTR_NULL”, then the device pointer in the VariantParamPack need to be NULL as
                              				well. 
                           </div>
                           <div class="note note"><span class="notetitle">Note:</span> If the corresponding pointer placeholder in ConstParamPack is set to
                              				“CUDNN_PTR_ELEM_ALIGNED” or “CUDNN_PTR_16B_ALIGNED”, then the device pointer in the
                              				VariantParamPack may not be NULL and need to be at least element-aligned or 16
                              				bytes-aligned, respectively. 
                           </div>
                        </div>
                        <div class="p">As of cuDNN 7.6.0, if the conditions in the <a class="xref" href="index.html#cudnnFusedOpsConstParamLabel_t__table-fully-fused-fast-path-bwd" shape="rect">Table 6</a> are met, then the
                           			fully fused fast path will be triggered. Otherwise a slower partially fused path will be
                           			triggered. 
                           
                           
                           <div class="tablenoborder"><a name="cudnnFusedOpsConstParamLabel_t__table-fully-fused-fast-path-bwd" shape="rect">
                                 <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnFusedOpsConstParamLabel_t__table-fully-fused-fast-path-bwd" class="table" frame="border" border="1" rules="all">
                                 <caption><span class="tablecap">Table 6. Conditions for Fully Fused Fast Path (Backward)</span></caption>
                                 <thead class="thead" align="left">
                                    <tr class="row">
                                       <th class="entry" valign="top" id="d54e7900" rowspan="1" colspan="1">Parameter</th>
                                       <th class="entry" valign="top" id="d54e7903" rowspan="1" colspan="1">Condition</th>
                                    </tr>
                                 </thead>
                                 <tbody class="tbody">
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" headers="d54e7900" rowspan="1" colspan="1">Device compute capability</td>
                                       <td class="entry" dir="ltr" valign="top" headers="d54e7903" rowspan="1" colspan="1">Need to be one of 7.0, 7.2 or 7.5</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" headers="d54e7900" rowspan="1" colspan="1">
                                          <p class="p">CUDNN_PARAM_XDESC</p>
                                          <p class="p">CUDNN_PARAM_XDATA_PLACEHOLDER</p>
                                       </td>
                                       <td class="entry" valign="top" headers="d54e7903" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">Tensor is 4 dimensional</p>
                                          <p class="p">Datatype is CUDNN_DATA_HALF</p>
                                          <p class="p">Layout is NHWC fully packed</p>
                                          <p dir="ltr" class="p">Alignment is CUDNN_PTR_16B_ALIGNED</p>
                                          <p dir="ltr" class="p">Tensor’s C dimension is a multiple of 8.</p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" headers="d54e7900" rowspan="1" colspan="1">
                                          <p class="p">CUDNN_PARAM_BN_EQSCALEBIAS_DESC</p>
                                          <p class="p">CUDNN_PARAM_BN_EQSCALE_PLACEHOLDER</p>
                                          <p class="p">CUDNN_PARAM_BN_EQBIAS_PLACEHOLDER</p>
                                       </td>
                                       <td class="entry" valign="top" headers="d54e7903" rowspan="1" colspan="1">
                                          <p class="p">If either one of scale and bias operation is not turned into a NOP:</p>
                                          <p class="p">Tensor is 4 dimensional with shape 1xCx1x1</p>
                                          <p class="p">Datatype is CUDNN_DATA_HALF</p>
                                          <p class="p">Layout is fully packed</p>
                                          <p dir="ltr" class="p">Alignment is CUDNN_PTR_16B_ALIGNED</p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" headers="d54e7900" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">CUDNN_PARAM_CONV_DESC</p>
                                          <p class="p">CUDNN_PARAM_DWDESC</p>
                                          <p class="p">CUDNN_PARAM_DWDATA_PLACEHOLDER</p>
                                       </td>
                                       <td class="entry" valign="top" headers="d54e7903" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">Convolution descriptor’s mode need to be
                                             									CUDNN_CROSS_CORRELATION
                                          </p>
                                          <p dir="ltr" class="p">Convolution descriptor’s dataType need to be
                                             									CUDNN_DATA_FLOAT
                                          </p>
                                          <p dir="ltr" class="p">Convolution descriptor’s dilationA is (1,1)</p>
                                          <p dir="ltr" class="p">Convolution descriptor’s group count need to be 1</p>
                                          <p dir="ltr" class="p">Convolution descriptor’s mathType need to be
                                             									CUDNN_TENSOR_OP_MATH or CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION
                                          </p>
                                          <p dir="ltr" class="p">Filter gradient is in NHWC layout</p>
                                          <p dir="ltr" class="p">Filter gradient’s data type is CUDNN_DATA_HALF</p>
                                          <p dir="ltr" class="p">Filter gradient’s K dimension is a multiple of 32.</p>
                                          <p dir="ltr" class="p">Filter gradient size RxS is either 1x1 or 3x3</p>
                                          <p class="p">If filter gradient size RxS is 1x1, convolution descriptor’s padA need to
                                             									be (0,0) and filterStrideA need to be (1,1)
                                          </p>
                                          <p class="p">Filter gradient’s alignment is CUDNN_PTR_16B_ALIGNED</p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" headers="d54e7900" rowspan="1" colspan="1">
                                          <p class="p">CUDNN_PARAM_DYDESC</p>
                                          <p class="p">CUDNN_PARAM_DYDATA_PLACEHOLDER</p>
                                       </td>
                                       <td class="entry" valign="top" headers="d54e7903" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">Tensor is 4 dimensional</p>
                                          <p class="p">Datatype is CUDNN_DATA_HALF</p>
                                          <p class="p">Layout is NHWC fully packed</p>
                                          <p dir="ltr" class="p">Alignment is CUDNN_PTR_16B_ALIGNED</p>
                                       </td>
                                    </tr>
                                 </tbody>
                              </table>
                           </div>
                        </div>
                        <div class="p">
                           <div class="tablenoborder"><a name="cudnnFusedOpsConstParamLabel_t__table_vp3_ljt_vhb" shape="rect">
                                 <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnFusedOpsConstParamLabel_t__table_vp3_ljt_vhb" class="table" frame="border" border="1" rules="all">
                                 <caption><span class="tablecap">Table 7. CUDNN_FUSED_BN_FINALIZE_STATISTICS_TRAINING</span></caption>
                                 <thead class="thead" align="left">
                                    <tr class="row">
                                       <th class="entry" colspan="4" align="left" valign="top" id="d54e8085" rowspan="1">For the attribute
                                          								CUDNN_FUSED_BN_FINALIZE_STATISTICS_TRAINING in cudnnFusedOp_t:
                                       </th>
                                    </tr>
                                    <tr class="row">
                                       <th class="entry" valign="top" width="30.839002267573694%" id="d54e8091" rowspan="1" colspan="1"><strong class="ph b">Attribute</strong></th>
                                       <th class="entry" valign="top" width="22.675736961451246%" id="d54e8095" rowspan="1" colspan="1"><strong class="ph b">Expected Descriptor Type Passed in, in the Setter</strong></th>
                                       <th class="entry" valign="top" width="23.80952380952381%" id="d54e8099" rowspan="1" colspan="1"><strong class="ph b">Description</strong></th>
                                       <th class="entry" valign="top" width="22.675736961451246%" id="d54e8103" rowspan="1" colspan="1">Default Value After Creation</th>
                                    </tr>
                                 </thead>
                                 <tbody class="tbody">
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="30.839002267573694%" headers="d54e8085 d54e8091" rowspan="1" colspan="1">X_BN_MODE </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e8085 d54e8095" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">In the setter the <samp class="ph codeph">*param</samp> should be a pointer
                                             									to a previously initialized <a class="xref" href="index.html#cudnnBatchNormMode_t" shape="rect">cudnnBatchNormMode_t*</a>.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e8085 d54e8099" rowspan="1" colspan="1">Describes the mode of operation for the scale, bias and the statistics.
                                          									
                                          <p class="p"></p>
                                          <p class="p">As of cuDNN 7.6.0, only “CUDNN_BATCHNORM_SPATIAL” and
                                             									“CUDNN_BATCHNORM_SPATIAL_PERSISTENT” are supported, i.e., scale, bias and
                                             									statistics are all per-channel.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e8085 d54e8103" rowspan="1" colspan="1">CUDNN_BATCHNORM_PER_ACTIVATION</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="30.839002267573694%" headers="d54e8085 d54e8091" rowspan="1" colspan="1">X_YSTATS_DESC </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e8085 d54e8095" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">In the setter the <samp class="ph codeph">*param</samp> should be a pointer
                                             									to a previously initialized
                                             									<samp class="ph codeph">cudnnTensorDescriptor_t*</samp>.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e8085 d54e8099" rowspan="1" colspan="1"> Tensor descriptor describing the size, layout and datatype of the sum
                                          								of <samp class="ph codeph">y</samp> and sum of <samp class="ph codeph">y</samp> square tensors. The
                                          								shapes need to match the mode specified in “CUDNN_PARAM_BN_MODE”. 
                                       </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e8085 d54e8103" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="30.839002267573694%" headers="d54e8085 d54e8091" rowspan="1" colspan="1">X_YSUM_PLACEHOLDER</td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e8085 d54e8095" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">In the setter the <samp class="ph codeph">*param</samp> should be a pointer
                                             									to a previously initialized X_PointerPlaceHolder_t*.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e8085 d54e8099" rowspan="1" colspan="1"> Describes whether sum of <samp class="ph codeph">y</samp> pointer in the
                                          								VariantParamPack will be NULL, or if not, user promised pointer alignment
                                          								*.
                                       </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e8085 d54e8103" rowspan="1" colspan="1">CUDNN_PTR_NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="30.839002267573694%" headers="d54e8085 d54e8091" rowspan="1" colspan="1">X_YSQSUM_PLACEHOLDER </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e8085 d54e8095" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">In the setter the <samp class="ph codeph">*param</samp> should be a pointer
                                             									to a previously initialized X_PointerPlaceHolder_t*.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e8085 d54e8099" rowspan="1" colspan="1">Describes whether sum of <samp class="ph codeph">y</samp> square pointer in the
                                          								VariantParamPack will be NULL, or if not, user promised pointer alignment *. 
                                       </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e8085 d54e8103" rowspan="1" colspan="1">CUDNN_PTR_NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="30.839002267573694%" headers="d54e8085 d54e8091" rowspan="1" colspan="1"> X_BN_SCALEBIAS_MEANVAR_DESC </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e8085 d54e8095" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">In the setter the <samp class="ph codeph">*param</samp> should be a pointer
                                             									to a previously initialized <a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a>.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e8085 d54e8099" rowspan="1" colspan="1"> A common tensor descriptor describing the size, layout and datatype of
                                          								the batchNorm trained scale, bias and statistics tensors. The shapes need to
                                          								match the mode specified in “CUDNN_PARAM_BN_MODE” (similar to the
                                          									<samp class="ph codeph">bnScaleBiasMeanVarDesc</samp> field in the
                                          								cudnnBatchNormalization* API). 
                                       </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e8085 d54e8103" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="30.839002267573694%" headers="d54e8085 d54e8091" rowspan="1" colspan="1">X_BN_SCALE_PLACEHOLDER</td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e8085 d54e8095" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">In the setter the <samp class="ph codeph">*param</samp> should be a pointer
                                             									to a previously initialized X_PointerPlaceHolder_t*.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e8085 d54e8099" rowspan="1" colspan="1"> Describes whether the batchNorm trained scale pointer in the
                                          								VariantParamPack will be NULL, or if not, user promised pointer alignment *.
                                          									
                                          <p class="p">If the output of “BN_EQSCALE” is not needed, this is not needed and
                                             									may be NULL.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e8085 d54e8103" rowspan="1" colspan="1">CUDNN_PTR_NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="30.839002267573694%" headers="d54e8085 d54e8091" rowspan="1" colspan="1">X_BN_BIAS_PLACEHOLDER </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e8085 d54e8095" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">In the setter the <samp class="ph codeph">*param</samp> should be a pointer
                                             									to a previously initialized X_PointerPlaceHolder_t*.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e8085 d54e8099" rowspan="1" colspan="1"> Describes whether the batchNorm trained bias pointer in the
                                          								VariantParamPack will be NULL, or if not, user promised pointer alignment *.
                                          									
                                          <p class="p">If neither output of “BN_EQSCALE” or “BN_EQBIAS” is needed, this is
                                             									not needed and may be NULL.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e8085 d54e8103" rowspan="1" colspan="1">CUDNN_PTR_NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="30.839002267573694%" headers="d54e8085 d54e8091" rowspan="1" colspan="1"> X_BN_SAVED_MEAN_PLACEHOLDER </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e8085 d54e8095" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">In the setter the <samp class="ph codeph">*param</samp> should be a pointer
                                             									to a previously initialized X_PointerPlaceHolder_t*.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e8085 d54e8099" rowspan="1" colspan="1">Describes whether the batchNorm saved mean pointer in the
                                          								VariantParamPack will be NULL, or if not, user promised pointer alignment
                                          									*.
                                          <p class="p"> If set to CUDNN_PTR_NULL, then the computation for this output
                                             									becomes a NOP.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e8085 d54e8103" rowspan="1" colspan="1">CUDNN_PTR_NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="30.839002267573694%" headers="d54e8085 d54e8091" rowspan="1" colspan="1">X_BN_SAVED_INVSTD_PLACEHOLDER</td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e8085 d54e8095" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">In the setter the <samp class="ph codeph">*param</samp> should be a pointer
                                             									to a previously initialized X_PointerPlaceHolder_t*.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e8085 d54e8099" rowspan="1" colspan="1">Describes whether the batchNorm saved inverse standard deviation pointer
                                          								in the VariantParamPack will be NULL, or if not, user promised pointer
                                          								alignment *. 
                                          <p class="p">If set to CUDNN_PTR_NULL, then the computation for this
                                             									output becomes a NOP.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e8085 d54e8103" rowspan="1" colspan="1">CUDNN_PTR_NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="30.839002267573694%" headers="d54e8085 d54e8091" rowspan="1" colspan="1">X_BN_RUNNING_MEAN_PLACEHOLDER</td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e8085 d54e8095" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">In the setter the <samp class="ph codeph">*param</samp> should be a pointer
                                             									to a previously initialized X_PointerPlaceHolder_t*.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e8085 d54e8099" rowspan="1" colspan="1">Describes whether the batchNorm running mean pointer in the
                                          								VariantParamPack will be NULL, or if not, user promised pointer alignment *.
                                          									
                                          <p class="p">If set to CUDNN_PTR_NULL, then the computation for this output becomes
                                             									a NOP.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e8085 d54e8103" rowspan="1" colspan="1">CUDNN_PTR_NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="30.839002267573694%" headers="d54e8085 d54e8091" rowspan="1" colspan="1">X_BN_RUNNING_VAR_PLACEHOLDER </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e8085 d54e8095" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">In the setter the <samp class="ph codeph">*param</samp> should be a pointer
                                             									to a previously initialized X_PointerPlaceHolder_t*.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e8085 d54e8099" rowspan="1" colspan="1">Describes whether the batchNorm running variance pointer in the
                                          								VariantParamPack will be NULL, or if not, user promised pointer alignment *.
                                          									
                                          <p class="p">If set to CUDNN_PTR_NULL, then the computation for this output becomes
                                             									a NOP. 
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e8085 d54e8103" rowspan="1" colspan="1">CUDNN_PTR_NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="30.839002267573694%" headers="d54e8085 d54e8091" rowspan="1" colspan="1">X_BN_EQSCALEBIAS_DESC</td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e8085 d54e8095" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">In the setter the <samp class="ph codeph">*param</samp> should be a pointer
                                             									to a previously initialized <a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t*</a>.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e8085 d54e8099" rowspan="1" colspan="1">Tensor descriptor describing the size, layout and datatype of the
                                          								batchNorm equivalent scale and bias tensors. The shapes need to match the
                                          								mode specified in “CUDNN_PARAM_BN_MODE”. 
                                          <p class="p">If neither output of
                                             									“BN_EQSCALE” or “BN_EQBIAS” is needed, this is not needed and may be
                                             									NULL.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e8085 d54e8103" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="30.839002267573694%" headers="d54e8085 d54e8091" rowspan="1" colspan="1">X_BN_EQSCALE_PLACEHOLDER</td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e8085 d54e8095" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">In the setter the <samp class="ph codeph">*param</samp> should be a pointer
                                             									to a previously initialized X_PointerPlaceHolder_t*.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e8085 d54e8099" rowspan="1" colspan="1">Describes whether batchnorm equivalent scale pointer in the
                                          								VariantParamPack will be NULL, or if not, user promised pointer alignment
                                          									*.
                                          <p class="p"> If set to CUDNN_PTR_NULL, then the computation for this output
                                             									becomes a NOP.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e8085 d54e8103" rowspan="1" colspan="1">CUDNN_PTR_NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="30.839002267573694%" headers="d54e8085 d54e8091" rowspan="1" colspan="1">X_BN_EQBIAS_PLACEHOLDER</td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e8085 d54e8095" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">In the setter the <samp class="ph codeph">*param</samp> should be a pointer
                                             									to a previously initialized X_PointerPlaceHolder_t*.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e8085 d54e8099" rowspan="1" colspan="1">Describes whether batchnorm equivalent bias pointer in the
                                          								VariantParamPack will be NULL, or if not, user promised pointer alignment *.
                                          									
                                          <p class="p">If set to CUDNN_PTR_NULL, then the computation for this output becomes
                                             									a NOP.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e8085 d54e8103" rowspan="1" colspan="1">CUDNN_PTR_NULL</td>
                                    </tr>
                                 </tbody>
                              </table>
                           </div>
                        </div>
                        <div class="p">
                           <div class="tablenoborder"><a name="cudnnFusedOpsConstParamLabel_t__table_h3w_lnt_vhb" shape="rect">
                                 <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnFusedOpsConstParamLabel_t__table_h3w_lnt_vhb" class="table" frame="border" border="1" rules="all">
                                 <caption><span class="tablecap">Table 8. CUDNN_FUSED_BN_FINALIZE_STATISTICS_INFERENCE</span></caption>
                                 <thead class="thead" align="left">
                                    <tr class="row">
                                       <th class="entry" colspan="4" align="left" valign="top" id="d54e8493" rowspan="1">For the attribute
                                          								CUDNN_FUSED_BN_FINALIZE_STATISTICS_INFERENCE in cudnnFusedOp_t:
                                       </th>
                                    </tr>
                                    <tr class="row">
                                       <th class="entry" valign="top" width="30.839002267573694%" id="d54e8499" rowspan="1" colspan="1"><strong class="ph b">Attribute</strong></th>
                                       <th class="entry" valign="top" width="22.675736961451246%" id="d54e8503" rowspan="1" colspan="1"><strong class="ph b">Expected Descriptor Type Passed in, in the Setter</strong></th>
                                       <th class="entry" valign="top" width="23.80952380952381%" id="d54e8507" rowspan="1" colspan="1"><strong class="ph b">Description</strong></th>
                                       <th class="entry" valign="top" width="22.675736961451246%" id="d54e8511" rowspan="1" colspan="1">Default Value After Creation</th>
                                    </tr>
                                 </thead>
                                 <tbody class="tbody">
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="30.839002267573694%" headers="d54e8493 d54e8499" rowspan="1" colspan="1">X_BN_MODE </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e8493 d54e8503" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">In the setter the <samp class="ph codeph">*param</samp> should be a pointer
                                             									to a previously initialized <a class="xref" href="index.html#cudnnBatchNormMode_t" shape="rect">cudnnBatchNormMode_t*</a>.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e8493 d54e8507" rowspan="1" colspan="1">Describes the mode of operation for the scale, bias and the statistics.
                                          									
                                          <p class="p">As of cuDNN 7.6.0, only “CUDNN_BATCHNORM_SPATIAL” and
                                             									“CUDNN_BATCHNORM_SPATIAL_PERSISTENT” are supported, i.e., scale, bias and
                                             									statistics are all per-channel.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e8493 d54e8511" rowspan="1" colspan="1">CUDNN_BATCHNORM_PER_ACTIVATION</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="30.839002267573694%" headers="d54e8493 d54e8499" rowspan="1" colspan="1"> X_BN_SCALEBIAS_MEANVAR_DESC </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e8493 d54e8503" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">In the setter the <samp class="ph codeph">*param</samp> should be a pointer
                                             									to a previously initialized <a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a>.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e8493 d54e8507" rowspan="1" colspan="1"> A common tensor descriptor describing the size, layout and datatype of
                                          								the batchNorm trained scale, bias and statistics tensors. The shapes need to
                                          								match the mode specified in “CUDNN_PARAM_BN_MODE” (similar to the
                                          									<samp class="ph codeph">bnScaleBiasMeanVarDesc</samp> field in the
                                          								cudnnBatchNormalization* API). 
                                       </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e8493 d54e8511" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="30.839002267573694%" headers="d54e8493 d54e8499" rowspan="1" colspan="1">X_BN_SCALE_PLACEHOLDER</td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e8493 d54e8503" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">In the setter the <samp class="ph codeph">*param</samp> should be a pointer
                                             									to a previously initialized X_PointerPlaceHolder_t*.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e8493 d54e8507" rowspan="1" colspan="1"> Describes whether the batchNorm trained scale pointer in the
                                          								VariantParamPack will be NULL, or if not, user promised pointer alignment *.  
                                       </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e8493 d54e8511" rowspan="1" colspan="1">CUDNN_PTR_NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="30.839002267573694%" headers="d54e8493 d54e8499" rowspan="1" colspan="1">X_BN_BIAS_PLACEHOLDER </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e8493 d54e8503" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">In the setter the <samp class="ph codeph">*param</samp> should be a pointer
                                             									to a previously initialized X_PointerPlaceHolder_t*.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e8493 d54e8507" rowspan="1" colspan="1"> Describes whether the batchNorm trained bias pointer in the
                                          								VariantParamPack will be NULL, or if not, user promised pointer alignment *.  
                                       </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e8493 d54e8511" rowspan="1" colspan="1">CUDNN_PTR_NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="30.839002267573694%" headers="d54e8493 d54e8499" rowspan="1" colspan="1">X_BN_RUNNING_MEAN_PLACEHOLDER</td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e8493 d54e8503" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">In the setter the <samp class="ph codeph">*param</samp> should be a pointer
                                             									to a previously initialized X_PointerPlaceHolder_t*.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e8493 d54e8507" rowspan="1" colspan="1">Describes whether the batchNorm running mean pointer in the
                                          								VariantParamPack will be NULL, or if not, user promised pointer alignment *.  
                                       </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e8493 d54e8511" rowspan="1" colspan="1">CUDNN_PTR_NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="30.839002267573694%" headers="d54e8493 d54e8499" rowspan="1" colspan="1">X_BN_RUNNING_VAR_PLACEHOLDER </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e8493 d54e8503" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">In the setter the <samp class="ph codeph">*param</samp> should be a pointer
                                             									to a previously initialized X_PointerPlaceHolder_t*.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e8493 d54e8507" rowspan="1" colspan="1">Describes whether the batchNorm running variance pointer in the
                                          								VariantParamPack will be NULL, or if not, user promised pointer alignment *. 
                                       </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e8493 d54e8511" rowspan="1" colspan="1">CUDNN_PTR_NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="30.839002267573694%" headers="d54e8493 d54e8499" rowspan="1" colspan="1">X_BN_EQSCALEBIAS_DESC</td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e8493 d54e8503" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">In the setter the <samp class="ph codeph">*param</samp> should be a pointer
                                             									to a previously initialized <a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t*</a>.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e8493 d54e8507" rowspan="1" colspan="1">Tensor descriptor describing the size, layout and datatype of the
                                          								batchNorm equivalent scale and bias tensors. The shapes need to match the
                                          								mode specified in “CUDNN_PARAM_BN_MODE”.  
                                       </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e8493 d54e8511" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="30.839002267573694%" headers="d54e8493 d54e8499" rowspan="1" colspan="1">X_BN_EQSCALE_PLACEHOLDER</td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e8493 d54e8503" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">In the setter the <samp class="ph codeph">*param</samp> should be a pointer
                                             									to a previously initialized X_PointerPlaceHolder_t*.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e8493 d54e8507" rowspan="1" colspan="1">Describes whether batchnorm equivalent scale pointer in the
                                          								VariantParamPack will be NULL, or if not, user promised pointer alignment
                                          									*.
                                          <p class="p"> If set to CUDNN_PTR_NULL, then the computation for this output
                                             									becomes a NOP.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e8493 d54e8511" rowspan="1" colspan="1">CUDNN_PTR_NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="30.839002267573694%" headers="d54e8493 d54e8499" rowspan="1" colspan="1">X_BN_EQBIAS_PLACEHOLDER</td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e8493 d54e8503" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">In the setter the <samp class="ph codeph">*param</samp> should be a pointer
                                             									to a previously initialized X_PointerPlaceHolder_t*.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="23.80952380952381%" headers="d54e8493 d54e8507" rowspan="1" colspan="1">Describes whether batchnorm equivalent bias pointer in the
                                          								VariantParamPack will be NULL, or if not, user promised pointer alignment *.
                                          									
                                          <p class="p">If set to CUDNN_PTR_NULL, then the computation for this output becomes
                                             									a NOP.
                                          </p>
                                       </td>
                                       <td class="entry" valign="top" width="22.675736961451246%" headers="d54e8493 d54e8511" rowspan="1" colspan="1">CUDNN_PTR_NULL</td>
                                    </tr>
                                 </tbody>
                              </table>
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnFusedOpsConstParamPack_t"><a name="cudnnFusedOpsConstParamPack_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnFusedOpsConstParamPack_t" name="cudnnFusedOpsConstParamPack_t" shape="rect">3.30.&nbsp;cudnnFusedOpsConstParamPack_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnFusedOpsConstParamPack_t</samp> is a pointer to an opaque structure holding the
                           			description of the cudnnFusedOps constant parameters. Use the function <a class="xref" href="index.html#cudnnCreateFusedOpsConstParamPack" shape="rect">cudnnCreateFusedOpsConstParamPack</a> ​to create one instance of this structure,
                           			and the function <a class="xref" href="index.html#cudnnDestroyFusedOpsConstParamPack" shape="rect">cudnnDestroyFusedOpsConstParamPack</a> to destroy a
                           			previously-created descriptor. 
                        </p>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnFusedOpsPlan_t"><a name="cudnnFusedOpsPlan_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnFusedOpsPlan_t" name="cudnnFusedOpsPlan_t" shape="rect">3.31.&nbsp;cudnnFusedOpsPlan_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnFusedOpsPlan_t</samp> is a pointer to an opaque structure holding the
                           			description of the cudnnFusedOpsPlan. This descriptor contains the plan information,
                           			including the problem type and size, which kernels should be run, and the internal
                           			workspace partition. Use the function <a class="xref" href="index.html#cudnnCreateFusedOpsPlan" shape="rect">cudnnCreateFusedOpsPlan</a> to create
                           			one instance of this structure, and the function <a class="xref" href="index.html#cudnnDestroyFusedOpsPlan" shape="rect">cudnnDestroyFusedOpsPlan</a>
                           			to destroy a previously-created descriptor. 
                        </p>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnFusedOpsPointerPlaceHolder_t"><a name="cudnnFusedOpsPointerPlaceHolder_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnFusedOpsPointerPlaceHolder_t" name="cudnnFusedOpsPointerPlaceHolder_t" shape="rect">3.32.&nbsp;cudnnFusedOpsPointerPlaceHolder_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><span class="keyword apiname">cudnnFusedOpsPointerPlaceHolder_t</span> is an enumerated type used to select the
                           			alignment type of the cudnnFusedOps descriptor pointer. 
                        </p>
                        <div class="tablenoborder"><a name="cudnnFusedOpsPointerPlaceHolder_t__table_hpj_hcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnFusedOpsPointerPlaceHolder_t__table_hpj_hcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="51.690821256038646%" rowspan="1" colspan="1"><strong class="ph b">Member</strong></td>
                                    <td class="entry" dir="ltr" align="center" valign="top" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="51.690821256038646%" rowspan="1" colspan="1">CUDNN_PTR_NULL = 0</td>
                                    <td class="entry" dir="ltr" valign="top" width="48.30917874396135%" rowspan="1" colspan="1">Indicates that the pointer to the Tensor in the
                                       								<span class="keyword apiname">variantPack</span> will be NULL.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="51.690821256038646%" rowspan="1" colspan="1">CUDNN_PTR_ELEM_ALIGNED = 1</td>
                                    <td class="entry" dir="ltr" valign="top" width="48.30917874396135%" rowspan="1" colspan="1">Indicates that the pointer to the Tensor in the
                                       								<span class="keyword apiname">variantPack</span> will not be NULL, and will have element
                                       							alignment.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="51.690821256038646%" rowspan="1" colspan="1">CUDNN_PTR_16B_ALIGNED = 2</td>
                                    <td class="entry" dir="ltr" valign="top" width="48.30917874396135%" rowspan="1" colspan="1">Indicates that the pointer to the Tensor in the
                                       								<span class="keyword apiname">variantPack</span> will not be NULL, and will have 16 byte
                                       							alignment.
                                    </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnFusedOpsVariantParamLabel_t"><a name="cudnnFusedOpsVariantParamLabel_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnFusedOpsVariantParamLabel_t" name="cudnnFusedOpsVariantParamLabel_t" shape="rect">3.33.&nbsp;cudnnFusedOpsVariantParamLabel_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p">The <samp class="ph codeph">cudnnFusedOpsVariantParamLabel_t</samp> is an enumerated type that is used to set
                           			the buffer pointers. These buffer pointers can be changed in each iteration. 
                        </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">typedef</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span> {
	CUDNN_PTR_XDATA                              = 0,
	CUDNN_PTR_BN_EQSCALE                         = 1,
	CUDNN_PTR_BN_EQBIAS                          = 2,
	CUDNN_PTR_WDATA                              = 3,
	CUDNN_PTR_DWDATA                             = 4,
	CUDNN_PTR_YDATA                              = 5,
	CUDNN_PTR_DYDATA                             = 6,
	CUDNN_PTR_YSUM                               = 7,
	CUDNN_PTR_YSQSUM                             = 8,
	CUDNN_PTR_WORKSPACE                          = 9,
	CUDNN_PTR_BN_SCALE                           = 10,
	CUDNN_PTR_BN_BIAS                            = 11,
	CUDNN_PTR_BN_SAVED_MEAN                      = 12,
	CUDNN_PTR_BN_SAVED_INVSTD                    = 13,
	CUDNN_PTR_BN_RUNNING_MEAN                    = 14,
	CUDNN_PTR_BN_RUNNING_VAR                     = 15,
	CUDNN_PTR_ZDATA                              = 16,
	CUDNN_PTR_BN_Z_EQSCALE                       = 17,
	CUDNN_PTR_BN_Z_EQBIAS                        = 18,
	CUDNN_PTR_ACTIVATION_BITMASK                 = 19,
	CUDNN_PTR_DXDATA                             = 20,
	CUDNN_PTR_DZDATA                             = 21,
	CUDNN_PTR_BN_DSCALE                          = 22,
	CUDNN_PTR_BN_DBIAS                           = 23,
	CUDNN_SCALAR_SIZE_T_WORKSPACE_SIZE_IN_BYTES  = 100,
	CUDNN_SCALAR_INT64_T_BN_ACCUMULATION_COUNT   = 101,
	CUDNN_SCALAR_DOUBLE_BN_EXP_AVG_FACTOR        = 102,
	CUDNN_SCALAR_DOUBLE_BN_EPSILON               = 103,
	} cudnnFusedOpsVariantParamLabel_t;</pre><div class="p">
                           <div class="tablenoborder"><a name="cudnnFusedOpsVariantParamLabel_t__table_xsy_1qs_vhc" shape="rect">
                                 <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnFusedOpsVariantParamLabel_t__table_xsy_1qs_vhc" class="table" frame="border" border="1" rules="all">
                                 <caption><span class="tablecap">Table 9. Legend For Tables in This Section</span></caption>
                                 <thead class="thead" align="left">
                                    <tr class="row">
                                       <th class="entry" align="left" valign="top" width="50%" id="d54e8917" rowspan="1" colspan="1">Short-form used:</th>
                                       <th class="entry" align="left" valign="top" width="50%" id="d54e8920" rowspan="1" colspan="1">Stands for:</th>
                                    </tr>
                                 </thead>
                                 <tbody class="tbody">
                                    <tr class="row">
                                       <td class="entry" align="left" valign="top" width="50%" headers="d54e8917" rowspan="1" colspan="1">Setter</td>
                                       <td class="entry" align="left" valign="top" width="50%" headers="d54e8920" rowspan="1" colspan="1"><a class="xref" href="index.html#cudnnSetFusedOpsVariantParamPackAttribute" shape="rect">cudnnSetFusedOpsVariantParamPackAttribute</a></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" align="left" valign="top" width="50%" headers="d54e8917" rowspan="1" colspan="1">Getter</td>
                                       <td class="entry" align="left" valign="top" width="50%" headers="d54e8920" rowspan="1" colspan="1"><a class="xref" href="index.html#cudnnGetFusedOpsVariantParamPackAttribute" shape="rect">cudnnGetFusedOpsVariantParamPackAttribute</a></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" align="left" valign="top" width="50%" headers="d54e8917" rowspan="1" colspan="1">"X_" prefix in the Attribute column</td>
                                       <td class="entry" align="left" valign="top" width="50%" headers="d54e8920" rowspan="1" colspan="1">Stands for "CUDNN_PTR_" or "CUDNN_SCALAR_" in the enumerator
                                          								name
                                       </td>
                                    </tr>
                                 </tbody>
                              </table>
                           </div>
                        </div>
                        <div class="p">
                           <div class="tablenoborder"><a name="cudnnFusedOpsVariantParamLabel_t__table_wbr_fvt_vhb" shape="rect">
                                 <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnFusedOpsVariantParamLabel_t__table_wbr_fvt_vhb" class="table" frame="border" border="1" rules="all">
                                 <caption><span class="tablecap">Table 10. CUDNN_FUSED_SCALE_BIAS_ACTIVATION_CONV_BNSTATS</span></caption>
                                 <thead class="thead" align="left">
                                    <tr class="row">
                                       <th class="entry" colspan="5" valign="top" id="d54e8989" rowspan="1">For the attribute
                                          								CUDNN_FUSED_SCALE_BIAS_ACTIVATION_CONV_BNSTATS in cudnnFusedOp_t:
                                       </th>
                                    </tr>
                                    <tr class="row">
                                       <th class="entry" dir="ltr" valign="top" width="27.473958333333332%" id="d54e8995" rowspan="1" colspan="1">Attribute key</th>
                                       <th class="entry" valign="top" width="13.020833333333334%" id="d54e8998" rowspan="1" colspan="1">Expected Descriptor Type Passed in, in the Setter</th>
                                       <th class="entry" dir="ltr" valign="top" width="13.020833333333334%" id="d54e9001" rowspan="1" colspan="1">I/O Type</th>
                                       <th class="entry" dir="ltr" valign="top" width="33.46354166666667%" id="d54e9004" rowspan="1" colspan="1">Description</th>
                                       <th class="entry" dir="ltr" valign="top" width="13.020833333333334%" id="d54e9007" rowspan="1" colspan="1">Default Value</th>
                                    </tr>
                                 </thead>
                                 <tbody class="tbody">
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="27.473958333333332%" headers="d54e8989 d54e8995" rowspan="1" colspan="1">X_XDATA</td>
                                       <td class="entry" dir="ltr" valign="top" width="13.020833333333334%" headers="d54e8989 d54e8998" rowspan="1" colspan="1">void *</td>
                                       <td class="entry" dir="ltr" valign="top" width="13.020833333333334%" headers="d54e8989 d54e9001" rowspan="1" colspan="1">input</td>
                                       <td class="entry" dir="ltr" valign="top" width="33.46354166666667%" headers="d54e8989 d54e9004" rowspan="1" colspan="1">Pointer to x (input) Tensor on device, need to agree with
                                          								previously set CUDNN_PARAM_XDATA_PLACEHOLDER attribute *.
                                       </td>
                                       <td class="entry" dir="ltr" valign="top" width="13.020833333333334%" headers="d54e8989 d54e9007" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="27.473958333333332%" headers="d54e8989 d54e8995" rowspan="1" colspan="1">X_BN_EQSCALE</td>
                                       <td class="entry" dir="ltr" valign="top" width="13.020833333333334%" headers="d54e8989 d54e8998" rowspan="1" colspan="1">void *</td>
                                       <td class="entry" dir="ltr" valign="top" width="13.020833333333334%" headers="d54e8989 d54e9001" rowspan="1" colspan="1">input</td>
                                       <td class="entry" dir="ltr" valign="top" width="33.46354166666667%" headers="d54e8989 d54e9004" rowspan="1" colspan="1">Pointer to batchnorm equivalent scale tensor on device, need
                                          								to agree with previously set CUDNN_PARAM_BN_EQSCALE_PLACEHOLDER attribute
                                          								*.
                                       </td>
                                       <td class="entry" dir="ltr" valign="top" width="13.020833333333334%" headers="d54e8989 d54e9007" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="27.473958333333332%" headers="d54e8989 d54e8995" rowspan="1" colspan="1">X_BN_EQBIAS</td>
                                       <td class="entry" dir="ltr" valign="top" width="13.020833333333334%" headers="d54e8989 d54e8998" rowspan="1" colspan="1">void *</td>
                                       <td class="entry" dir="ltr" valign="top" width="13.020833333333334%" headers="d54e8989 d54e9001" rowspan="1" colspan="1">input</td>
                                       <td class="entry" dir="ltr" valign="top" width="33.46354166666667%" headers="d54e8989 d54e9004" rowspan="1" colspan="1">Pointer to batchnorm equivalent bias tensor on device, need to
                                          								agree with previously set CUDNN_PARAM_BN_EQBIAS_PLACEHOLDER attribute
                                          								*
                                       </td>
                                       <td class="entry" dir="ltr" valign="top" width="13.020833333333334%" headers="d54e8989 d54e9007" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="27.473958333333332%" headers="d54e8989 d54e8995" rowspan="1" colspan="1">X_WDATA</td>
                                       <td class="entry" dir="ltr" valign="top" width="13.020833333333334%" headers="d54e8989 d54e8998" rowspan="1" colspan="1">void *</td>
                                       <td class="entry" dir="ltr" valign="top" width="13.020833333333334%" headers="d54e8989 d54e9001" rowspan="1" colspan="1">input</td>
                                       <td class="entry" dir="ltr" valign="top" width="33.46354166666667%" headers="d54e8989 d54e9004" rowspan="1" colspan="1">Pointer to w (filter) tensor on device, need to agree with
                                          								previously set CUDNN_PARAM_WDATA_PLACEHOLDER attribute *
                                       </td>
                                       <td class="entry" dir="ltr" valign="top" width="13.020833333333334%" headers="d54e8989 d54e9007" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="27.473958333333332%" headers="d54e8989 d54e8995" rowspan="1" colspan="1">X_YDATA</td>
                                       <td class="entry" dir="ltr" valign="top" width="13.020833333333334%" headers="d54e8989 d54e8998" rowspan="1" colspan="1">void *</td>
                                       <td class="entry" dir="ltr" valign="top" width="13.020833333333334%" headers="d54e8989 d54e9001" rowspan="1" colspan="1">output</td>
                                       <td class="entry" dir="ltr" valign="top" width="33.46354166666667%" headers="d54e8989 d54e9004" rowspan="1" colspan="1">Pointer to y (output) tensor on device, need to agree with
                                          								previously set CUDNN_PARAM_YDATA_PLACEHOLDER attribute *
                                       </td>
                                       <td class="entry" dir="ltr" valign="top" width="13.020833333333334%" headers="d54e8989 d54e9007" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="27.473958333333332%" headers="d54e8989 d54e8995" rowspan="1" colspan="1">X_YSUM</td>
                                       <td class="entry" dir="ltr" valign="top" width="13.020833333333334%" headers="d54e8989 d54e8998" rowspan="1" colspan="1">void *</td>
                                       <td class="entry" dir="ltr" valign="top" width="13.020833333333334%" headers="d54e8989 d54e9001" rowspan="1" colspan="1">output</td>
                                       <td class="entry" dir="ltr" valign="top" width="33.46354166666667%" headers="d54e8989 d54e9004" rowspan="1" colspan="1">Pointer to sum of y tensor on device, need to agree with
                                          								previously set CUDNN_PARAM_YSUM_PLACEHOLDER attribute *
                                       </td>
                                       <td class="entry" dir="ltr" valign="top" width="13.020833333333334%" headers="d54e8989 d54e9007" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="27.473958333333332%" headers="d54e8989 d54e8995" rowspan="1" colspan="1">X_YSQSUM</td>
                                       <td class="entry" dir="ltr" valign="top" width="13.020833333333334%" headers="d54e8989 d54e8998" rowspan="1" colspan="1">void *</td>
                                       <td class="entry" dir="ltr" valign="top" width="13.020833333333334%" headers="d54e8989 d54e9001" rowspan="1" colspan="1">output</td>
                                       <td class="entry" dir="ltr" valign="top" width="33.46354166666667%" headers="d54e8989 d54e9004" rowspan="1" colspan="1">Pointer to sum of y square tensor on device, need to agree
                                          								with previously set CUDNN_PARAM_YSQSUM_PLACEHOLDER attribute *
                                       </td>
                                       <td class="entry" dir="ltr" valign="top" width="13.020833333333334%" headers="d54e8989 d54e9007" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="27.473958333333332%" headers="d54e8989 d54e8995" rowspan="1" colspan="1">X_WORKSPACE</td>
                                       <td class="entry" dir="ltr" valign="top" width="13.020833333333334%" headers="d54e8989 d54e8998" rowspan="1" colspan="1">void *</td>
                                       <td class="entry" dir="ltr" valign="top" width="13.020833333333334%" headers="d54e8989 d54e9001" rowspan="1" colspan="1">input</td>
                                       <td class="entry" dir="ltr" valign="top" width="33.46354166666667%" headers="d54e8989 d54e9004" rowspan="1" colspan="1">Pointer to user allocated workspace on device. Can be NULL if
                                          								the workspace size requested is 0.
                                       </td>
                                       <td class="entry" dir="ltr" valign="top" width="13.020833333333334%" headers="d54e8989 d54e9007" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="27.473958333333332%" headers="d54e8989 d54e8995" rowspan="1" colspan="1">X_SIZE_T_WORKSPACE_SIZE_IN_BYTES</td>
                                       <td class="entry" dir="ltr" valign="top" width="13.020833333333334%" headers="d54e8989 d54e8998" rowspan="1" colspan="1">size_t *</td>
                                       <td class="entry" dir="ltr" valign="top" width="13.020833333333334%" headers="d54e8989 d54e9001" rowspan="1" colspan="1">input</td>
                                       <td class="entry" dir="ltr" valign="top" width="33.46354166666667%" headers="d54e8989 d54e9004" rowspan="1" colspan="1">Pointer to a size_t value in host memory describing the user
                                          								allocated workspace size in bytes. The amount need to be equal or larger
                                          								than the amount requested in cudnnMakeFusedOpsPlan
                                       </td>
                                       <td class="entry" dir="ltr" valign="top" width="13.020833333333334%" headers="d54e8989 d54e9007" rowspan="1" colspan="1">0</td>
                                    </tr>
                                 </tbody>
                              </table>
                           </div>
                           <div class="note note"><span class="notetitle">Note:</span> If the corresponding pointer placeholder in ConstParamPack is set to
                              				“CUDNN_PTR_NULL”, then the device pointer in the VariantParamPack need to be NULL as
                              				well. 
                           </div>
                           <div class="note note"><span class="notetitle">Note:</span> If the corresponding pointer placeholder in ConstParamPack is set to
                              				“CUDNN_PTR_ELEM_ALIGNED” or “CUDNN_PTR_16B_ALIGNED”, then the device pointer in the
                              				VariantParamPack may not be NULL and need to be at least element-aligned or 16
                              				bytes-aligned, respectively. 
                           </div>
                        </div>
                        <div class="p">
                           <div class="tablenoborder"><a name="cudnnFusedOpsVariantParamLabel_t__table_fdr_dwt_vhb" shape="rect">
                                 <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnFusedOpsVariantParamLabel_t__table_fdr_dwt_vhb" class="table" frame="border" border="1" rules="all">
                                 <caption><span class="tablecap">Table 11. CUDNN_FUSED_SCALE_BIAS_ACTIVATION_WGRAD </span></caption>
                                 <thead class="thead" align="left">
                                    <tr class="row">
                                       <th class="entry" colspan="5" valign="top" id="d54e9210" rowspan="1">For the attribute
                                          								CUDNN_FUSED_SCALE_BIAS_ACTIVATION_WGRAD in cudnnFusedOp_t:
                                       </th>
                                    </tr>
                                    <tr class="row">
                                       <th class="entry" dir="ltr" valign="top" width="34.592680047225514%" id="d54e9216" rowspan="1" colspan="1">Attribute key</th>
                                       <th class="entry" valign="top" width="11.806375442739082%" id="d54e9219" rowspan="1" colspan="1">Expected Descriptor Type Passed in, in the Setter</th>
                                       <th class="entry" dir="ltr" valign="top" width="11.806375442739082%" id="d54e9222" rowspan="1" colspan="1">I/O Type</th>
                                       <th class="entry" dir="ltr" valign="top" width="29.988193624557262%" id="d54e9225" rowspan="1" colspan="1">Description</th>
                                       <th class="entry" dir="ltr" valign="top" width="11.806375442739082%" id="d54e9228" rowspan="1" colspan="1">Default Value</th>
                                    </tr>
                                 </thead>
                                 <tbody class="tbody">
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="34.592680047225514%" headers="d54e9210 d54e9216" rowspan="1" colspan="1">X_XDATA</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.806375442739082%" headers="d54e9210 d54e9219" rowspan="1" colspan="1">void *</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.806375442739082%" headers="d54e9210 d54e9222" rowspan="1" colspan="1">input</td>
                                       <td class="entry" dir="ltr" valign="top" width="29.988193624557262%" headers="d54e9210 d54e9225" rowspan="1" colspan="1">Pointer to x (input) tensor on device, need to agree with
                                          								previously set CUDNN_PARAM_XDATA_PLACEHOLDER attribute *
                                       </td>
                                       <td class="entry" dir="ltr" valign="top" width="11.806375442739082%" headers="d54e9210 d54e9228" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="34.592680047225514%" headers="d54e9210 d54e9216" rowspan="1" colspan="1">X_BN_EQSCALE</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.806375442739082%" headers="d54e9210 d54e9219" rowspan="1" colspan="1">void *</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.806375442739082%" headers="d54e9210 d54e9222" rowspan="1" colspan="1">input</td>
                                       <td class="entry" dir="ltr" valign="top" width="29.988193624557262%" headers="d54e9210 d54e9225" rowspan="1" colspan="1">Pointer to batchnorm equivalent scale tensor on device, need
                                          								to agree with previously set CUDNN_PARAM_BN_EQSCALE_PLACEHOLDER attribute
                                          								*
                                       </td>
                                       <td class="entry" dir="ltr" valign="top" width="11.806375442739082%" headers="d54e9210 d54e9228" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="34.592680047225514%" headers="d54e9210 d54e9216" rowspan="1" colspan="1">X_BN_EQBIAS</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.806375442739082%" headers="d54e9210 d54e9219" rowspan="1" colspan="1">void *</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.806375442739082%" headers="d54e9210 d54e9222" rowspan="1" colspan="1">input</td>
                                       <td class="entry" dir="ltr" valign="top" width="29.988193624557262%" headers="d54e9210 d54e9225" rowspan="1" colspan="1">Pointer to batchnorm equivalent bias tensor on device, need to
                                          								agree with previously set CUDNN_PARAM_BN_EQBIAS_PLACEHOLDER attribute
                                          								*
                                       </td>
                                       <td class="entry" dir="ltr" valign="top" width="11.806375442739082%" headers="d54e9210 d54e9228" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="34.592680047225514%" headers="d54e9210 d54e9216" rowspan="1" colspan="1">X_DWDATA</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.806375442739082%" headers="d54e9210 d54e9219" rowspan="1" colspan="1">void *</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.806375442739082%" headers="d54e9210 d54e9222" rowspan="1" colspan="1">output</td>
                                       <td class="entry" dir="ltr" valign="top" width="29.988193624557262%" headers="d54e9210 d54e9225" rowspan="1" colspan="1">Pointer to dw (filter gradient output) tensor on device, need
                                          								to agree with previously set CUDNN_PARAM_WDATA_PLACEHOLDER attribute
                                          								*
                                       </td>
                                       <td class="entry" dir="ltr" valign="top" width="11.806375442739082%" headers="d54e9210 d54e9228" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="34.592680047225514%" headers="d54e9210 d54e9216" rowspan="1" colspan="1">X_DYDATA</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.806375442739082%" headers="d54e9210 d54e9219" rowspan="1" colspan="1">void *</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.806375442739082%" headers="d54e9210 d54e9222" rowspan="1" colspan="1">input</td>
                                       <td class="entry" dir="ltr" valign="top" width="29.988193624557262%" headers="d54e9210 d54e9225" rowspan="1" colspan="1">Pointer to dy (gradient input) tensor on device, need to agree
                                          								with previously set CUDNN_PARAM_YDATA_PLACEHOLDER attribute *
                                       </td>
                                       <td class="entry" dir="ltr" valign="top" width="11.806375442739082%" headers="d54e9210 d54e9228" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="34.592680047225514%" headers="d54e9210 d54e9216" rowspan="1" colspan="1">X_WORKSPACE</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.806375442739082%" headers="d54e9210 d54e9219" rowspan="1" colspan="1">void *</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.806375442739082%" headers="d54e9210 d54e9222" rowspan="1" colspan="1">input</td>
                                       <td class="entry" dir="ltr" valign="top" width="29.988193624557262%" headers="d54e9210 d54e9225" rowspan="1" colspan="1">Pointer to user allocated workspace on device. Can be NULL if
                                          								the workspace size requested is 0.
                                       </td>
                                       <td class="entry" dir="ltr" valign="top" width="11.806375442739082%" headers="d54e9210 d54e9228" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="34.592680047225514%" headers="d54e9210 d54e9216" rowspan="1" colspan="1">X_SIZE_T_WORKSPACE_SIZE_IN_BYTES</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.806375442739082%" headers="d54e9210 d54e9219" rowspan="1" colspan="1">size_t *</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.806375442739082%" headers="d54e9210 d54e9222" rowspan="1" colspan="1">input</td>
                                       <td class="entry" dir="ltr" valign="top" width="29.988193624557262%" headers="d54e9210 d54e9225" rowspan="1" colspan="1">Pointer to a size_t value in host memory describing the user
                                          								allocated workspace size in bytes. The amount need to be equal or larger
                                          								than the amount requested in <samp class="ph codeph">cudnnMakeFusedOpsPlan</samp></td>
                                       <td class="entry" dir="ltr" valign="top" width="11.806375442739082%" headers="d54e9210 d54e9228" rowspan="1" colspan="1">0</td>
                                    </tr>
                                 </tbody>
                              </table>
                           </div>
                        </div>
                        <div class="p">
                           <div class="note note"><span class="notetitle">Note:</span> If the corresponding pointer placeholder in ConstParamPack is set to
                              				“CUDNN_PTR_NULL”, then the device pointer in the VariantParamPack need to be NULL as
                              				well. 
                           </div>
                           <div class="note note"><span class="notetitle">Note:</span> If the corresponding pointer placeholder in ConstParamPack is set to
                              				“CUDNN_PTR_ELEM_ALIGNED” or “CUDNN_PTR_16B_ALIGNED”, then the device pointer in the
                              				VariantParamPack may not be NULL and need to be at least element-aligned or 16
                              				bytes-aligned, respectively. 
                           </div>
                        </div>
                        <div class="p">
                           <div class="tablenoborder"><a name="cudnnFusedOpsVariantParamLabel_t__table_jtz_dxt_vhb" shape="rect">
                                 <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnFusedOpsVariantParamLabel_t__table_jtz_dxt_vhb" class="table" frame="border" border="1" rules="all">
                                 <caption><span class="tablecap">Table 12. CUDNN_FUSED_BN_FINALIZE_STATISTICS_TRAINING </span></caption>
                                 <thead class="thead" align="left">
                                    <tr class="row">
                                       <th class="entry" colspan="5" valign="top" id="d54e9401" rowspan="1">For the attribute
                                          								CUDNN_FUSED_BN_FINALIZE_STATISTICS_TRAINING in cudnnFusedOp_t:
                                       </th>
                                    </tr>
                                    <tr class="row">
                                       <th class="entry" dir="ltr" valign="top" width="33.84785005512679%" id="d54e9407" rowspan="1" colspan="1">Attribute key</th>
                                       <th class="entry" valign="top" width="11.025358324145534%" id="d54e9410" rowspan="1" colspan="1">Expected Descriptor Type Passed in, in the Setter</th>
                                       <th class="entry" dir="ltr" valign="top" width="11.025358324145534%" id="d54e9413" rowspan="1" colspan="1">I/O Type</th>
                                       <th class="entry" dir="ltr" valign="top" width="33.0760749724366%" id="d54e9416" rowspan="1" colspan="1">Description</th>
                                       <th class="entry" dir="ltr" valign="top" width="11.025358324145534%" id="d54e9419" rowspan="1" colspan="1">Default Value</th>
                                    </tr>
                                 </thead>
                                 <tbody class="tbody">
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="33.84785005512679%" headers="d54e9401 d54e9407" rowspan="1" colspan="1">X_YSUM</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.025358324145534%" headers="d54e9401 d54e9410" rowspan="1" colspan="1">void *</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.025358324145534%" headers="d54e9401 d54e9413" rowspan="1" colspan="1">input</td>
                                       <td class="entry" dir="ltr" valign="top" width="33.0760749724366%" headers="d54e9401 d54e9416" rowspan="1" colspan="1">Pointer to sum of y tensor on device, need to agree with
                                          								previously set CUDNN_PARAM_YSUM_PLACEHOLDER attribute *
                                       </td>
                                       <td class="entry" dir="ltr" valign="top" width="11.025358324145534%" headers="d54e9401 d54e9419" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="33.84785005512679%" headers="d54e9401 d54e9407" rowspan="1" colspan="1">X_YSQSUM</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.025358324145534%" headers="d54e9401 d54e9410" rowspan="1" colspan="1">void *</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.025358324145534%" headers="d54e9401 d54e9413" rowspan="1" colspan="1">input</td>
                                       <td class="entry" dir="ltr" valign="top" width="33.0760749724366%" headers="d54e9401 d54e9416" rowspan="1" colspan="1">Pointer to sum of y square tensor on device, need to agree
                                          								with previously set CUDNN_PARAM_YSQSUM_PLACEHOLDER attribute *
                                       </td>
                                       <td class="entry" dir="ltr" valign="top" width="11.025358324145534%" headers="d54e9401 d54e9419" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="33.84785005512679%" headers="d54e9401 d54e9407" rowspan="1" colspan="1">X_BN_SCALE</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.025358324145534%" headers="d54e9401 d54e9410" rowspan="1" colspan="1">void *</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.025358324145534%" headers="d54e9401 d54e9413" rowspan="1" colspan="1">input</td>
                                       <td class="entry" dir="ltr" valign="top" width="33.0760749724366%" headers="d54e9401 d54e9416" rowspan="1" colspan="1">Pointer to sum of y square tensor on device, need to agree
                                          								with previously set CUDNN_PARAM_BN_SCALE_PLACEHOLDER attribute *
                                       </td>
                                       <td class="entry" dir="ltr" valign="top" width="11.025358324145534%" headers="d54e9401 d54e9419" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="33.84785005512679%" headers="d54e9401 d54e9407" rowspan="1" colspan="1">X_BN_BIAS</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.025358324145534%" headers="d54e9401 d54e9410" rowspan="1" colspan="1">void *</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.025358324145534%" headers="d54e9401 d54e9413" rowspan="1" colspan="1">input</td>
                                       <td class="entry" dir="ltr" valign="top" width="33.0760749724366%" headers="d54e9401 d54e9416" rowspan="1" colspan="1">Pointer to sum of y square tensor on device, need to agree
                                          								with previously set CUDNN_PARAM_BN_BIAS_PLACEHOLDER attribute *
                                       </td>
                                       <td class="entry" dir="ltr" valign="top" width="11.025358324145534%" headers="d54e9401 d54e9419" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="33.84785005512679%" headers="d54e9401 d54e9407" rowspan="1" colspan="1">X_BN_SAVED_MEAN</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.025358324145534%" headers="d54e9401 d54e9410" rowspan="1" colspan="1">void *</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.025358324145534%" headers="d54e9401 d54e9413" rowspan="1" colspan="1">output</td>
                                       <td class="entry" dir="ltr" valign="top" width="33.0760749724366%" headers="d54e9401 d54e9416" rowspan="1" colspan="1">Pointer to sum of y square tensor on device, need to agree
                                          								with previously set CUDNN_PARAM_BN_SAVED_MEAN_PLACEHOLDER attribute
                                          								*
                                       </td>
                                       <td class="entry" dir="ltr" valign="top" width="11.025358324145534%" headers="d54e9401 d54e9419" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="33.84785005512679%" headers="d54e9401 d54e9407" rowspan="1" colspan="1">X_BN_SAVED_INVSTD</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.025358324145534%" headers="d54e9401 d54e9410" rowspan="1" colspan="1">void *</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.025358324145534%" headers="d54e9401 d54e9413" rowspan="1" colspan="1">output</td>
                                       <td class="entry" dir="ltr" valign="top" width="33.0760749724366%" headers="d54e9401 d54e9416" rowspan="1" colspan="1">Pointer to sum of y square tensor on device, need to agree
                                          								with previously set CUDNN_PARAM_BN_SAVED_INVSTD_PLACEHOLDER attribute
                                          								*
                                       </td>
                                       <td class="entry" dir="ltr" valign="top" width="11.025358324145534%" headers="d54e9401 d54e9419" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="33.84785005512679%" headers="d54e9401 d54e9407" rowspan="1" colspan="1">X_BN_RUNNING_MEAN</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.025358324145534%" headers="d54e9401 d54e9410" rowspan="1" colspan="1">void *</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.025358324145534%" headers="d54e9401 d54e9413" rowspan="1" colspan="1">input/output</td>
                                       <td class="entry" dir="ltr" valign="top" width="33.0760749724366%" headers="d54e9401 d54e9416" rowspan="1" colspan="1">Pointer to sum of y square tensor on device, need to agree
                                          								with previously set CUDNN_PARAM_BN_RUNNING_MEAN_PLACEHOLDER attribute
                                          								*
                                       </td>
                                       <td class="entry" dir="ltr" valign="top" width="11.025358324145534%" headers="d54e9401 d54e9419" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="33.84785005512679%" headers="d54e9401 d54e9407" rowspan="1" colspan="1">X_BN_RUNNING_VAR</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.025358324145534%" headers="d54e9401 d54e9410" rowspan="1" colspan="1">void *</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.025358324145534%" headers="d54e9401 d54e9413" rowspan="1" colspan="1">input/output</td>
                                       <td class="entry" dir="ltr" valign="top" width="33.0760749724366%" headers="d54e9401 d54e9416" rowspan="1" colspan="1">Pointer to sum of y square tensor on device, need to agree
                                          								with previously set CUDNN_PARAM_BN_RUNNING_VAR_PLACEHOLDER attribute
                                          								*
                                       </td>
                                       <td class="entry" dir="ltr" valign="top" width="11.025358324145534%" headers="d54e9401 d54e9419" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="33.84785005512679%" headers="d54e9401 d54e9407" rowspan="1" colspan="1">X_BN_EQSCALE</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.025358324145534%" headers="d54e9401 d54e9410" rowspan="1" colspan="1">void *</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.025358324145534%" headers="d54e9401 d54e9413" rowspan="1" colspan="1">output</td>
                                       <td class="entry" dir="ltr" valign="top" width="33.0760749724366%" headers="d54e9401 d54e9416" rowspan="1" colspan="1">Pointer to batchnorm equivalent scale tensor on device, need
                                          								to agree with previously set CUDNN_PARAM_BN_EQSCALE_PLACEHOLDER attribute
                                          								*
                                       </td>
                                       <td class="entry" dir="ltr" valign="top" width="11.025358324145534%" headers="d54e9401 d54e9419" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="33.84785005512679%" headers="d54e9401 d54e9407" rowspan="1" colspan="1">X_BN_EQBIAS</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.025358324145534%" headers="d54e9401 d54e9410" rowspan="1" colspan="1">void *</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.025358324145534%" headers="d54e9401 d54e9413" rowspan="1" colspan="1">output</td>
                                       <td class="entry" dir="ltr" valign="top" width="33.0760749724366%" headers="d54e9401 d54e9416" rowspan="1" colspan="1">Pointer to batchnorm equivalent bias tensor on device, need to
                                          								agree with previously set CUDNN_PARAM_BN_EQBIAS_PLACEHOLDER attribute
                                          								*
                                       </td>
                                       <td class="entry" dir="ltr" valign="top" width="11.025358324145534%" headers="d54e9401 d54e9419" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="33.84785005512679%" headers="d54e9401 d54e9407" rowspan="1" colspan="1">X_INT64_T_BN_ACCUMULATION_COUNT</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.025358324145534%" headers="d54e9401 d54e9410" rowspan="1" colspan="1">int64_t *</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.025358324145534%" headers="d54e9401 d54e9413" rowspan="1" colspan="1">input</td>
                                       <td class="entry" valign="top" width="33.0760749724366%" headers="d54e9401 d54e9416" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">Pointer to a scalar value in int64_t on host memory.</p>
                                          <p dir="ltr" class="p">This value should describe the number of tensor elements
                                             									accumulated in the sum of y and sum of y square tensors.
                                          </p>
                                          <p dir="ltr" class="p">For example:</p>
                                          <p dir="ltr" class="p">In the single GPU use case, and if the mode is
                                             									CUDNN_BATCHNORM_SPATIAL or CUDNN_BATCHNORM_SPATIAL_PERSISTENT, the value
                                             									should be equal to N*H*W of the tensor from which the statistics are
                                             									calculated.
                                          </p>
                                          <p dir="ltr" class="p">In multi-GPU use case, if all-reduce has been performed on the
                                             									sum of y and sum of y square tensors, this value should be the sum of the
                                             									single GPU accumulation count on each of the GPUs.
                                          </p>
                                       </td>
                                       <td class="entry" dir="ltr" valign="top" width="11.025358324145534%" headers="d54e9401 d54e9419" rowspan="1" colspan="1">0</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="33.84785005512679%" headers="d54e9401 d54e9407" rowspan="1" colspan="1">X_DOUBLE_BN_EXP_AVG_FACTOR</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.025358324145534%" headers="d54e9401 d54e9410" rowspan="1" colspan="1">double *</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.025358324145534%" headers="d54e9401 d54e9413" rowspan="1" colspan="1">input</td>
                                       <td class="entry" valign="top" width="33.0760749724366%" headers="d54e9401 d54e9416" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">Pointer to a scalar value in double on host memory.</p>
                                          <p dir="ltr" class="p">Factor used in the moving average computation. See
                                             									“exponentialAverageFactor” in cudnnBatchNormalization* APIs
                                          </p>
                                       </td>
                                       <td class="entry" dir="ltr" valign="top" width="11.025358324145534%" headers="d54e9401 d54e9419" rowspan="1" colspan="1">0.0</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="33.84785005512679%" headers="d54e9401 d54e9407" rowspan="1" colspan="1">X_DOUBLE_BN_EPSILON</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.025358324145534%" headers="d54e9401 d54e9410" rowspan="1" colspan="1">double *</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.025358324145534%" headers="d54e9401 d54e9413" rowspan="1" colspan="1">input</td>
                                       <td class="entry" valign="top" width="33.0760749724366%" headers="d54e9401 d54e9416" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">Pointer to a scalar value in double on host memory.</p>
                                          <p dir="ltr" class="p">A conditioning constant used in the batch normalization
                                             									formula. Its value should be equal to or greater than the value defined
                                             									for CUDNN_BN_MIN_EPSILON in cudnn.h
                                          </p>
                                          <p dir="ltr" class="p">See “exponentialAverageFactor” in cudnnBatchNormalization*
                                             									APIs
                                          </p>
                                       </td>
                                       <td class="entry" dir="ltr" valign="top" width="11.025358324145534%" headers="d54e9401 d54e9419" rowspan="1" colspan="1">0.0</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="33.84785005512679%" headers="d54e9401 d54e9407" rowspan="1" colspan="1">X_WORKSPACE</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.025358324145534%" headers="d54e9401 d54e9410" rowspan="1" colspan="1">void *</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.025358324145534%" headers="d54e9401 d54e9413" rowspan="1" colspan="1">input</td>
                                       <td class="entry" dir="ltr" valign="top" width="33.0760749724366%" headers="d54e9401 d54e9416" rowspan="1" colspan="1">Pointer to user allocated workspace on device. Can be NULL if
                                          								the workspace size requested is 0.
                                       </td>
                                       <td class="entry" dir="ltr" valign="top" width="11.025358324145534%" headers="d54e9401 d54e9419" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="33.84785005512679%" headers="d54e9401 d54e9407" rowspan="1" colspan="1">X_SIZE_T_WORKSPACE_SIZE_IN_BYTES</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.025358324145534%" headers="d54e9401 d54e9410" rowspan="1" colspan="1">size_t *</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.025358324145534%" headers="d54e9401 d54e9413" rowspan="1" colspan="1">input</td>
                                       <td class="entry" dir="ltr" valign="top" width="33.0760749724366%" headers="d54e9401 d54e9416" rowspan="1" colspan="1">Pointer to a size_t value in host memory describing the user
                                          								allocated workspace size in bytes. The amount need to be equal or larger
                                          								than the amount requested in <samp class="ph codeph">cudnnMakeFusedOpsPlan</samp>.
                                       </td>
                                       <td class="entry" dir="ltr" valign="top" width="11.025358324145534%" headers="d54e9401 d54e9419" rowspan="1" colspan="1">0</td>
                                    </tr>
                                 </tbody>
                              </table>
                           </div>
                        </div>
                        <div class="p">
                           <div class="note note"><span class="notetitle">Note:</span> If the corresponding pointer placeholder in ConstParamPack is set to
                              				“CUDNN_PTR_NULL”, then the device pointer in the VariantParamPack need to be NULL as
                              				well. 
                           </div>
                           <div class="note note"><span class="notetitle">Note:</span> If the corresponding pointer placeholder in ConstParamPack is set to
                              				“CUDNN_PTR_ELEM_ALIGNED” or “CUDNN_PTR_16B_ALIGNED”, then the device pointer in the
                              				VariantParamPack may not be NULL and need to be at least element-aligned or 16
                              				bytes-aligned, respectively. 
                           </div>
                        </div>
                        <div class="p">
                           <div class="tablenoborder"><a name="cudnnFusedOpsVariantParamLabel_t__table_b3t_xxt_vhb" shape="rect">
                                 <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnFusedOpsVariantParamLabel_t__table_b3t_xxt_vhb" class="table" frame="border" border="1" rules="all">
                                 <caption><span class="tablecap">Table 13. CUDNN_FUSED_BN_FINALIZE_STATISTICS_INFERENCE </span></caption>
                                 <thead class="thead" align="left">
                                    <tr class="row">
                                       <th class="entry" colspan="5" valign="top" id="d54e9767" rowspan="1">For the attribute
                                          								CUDNN_FUSED_BN_FINALIZE_STATISTICS_INFERENCE in cudnnFusedOp_t:
                                       </th>
                                    </tr>
                                    <tr class="row">
                                       <th class="entry" dir="ltr" valign="top" width="32.88439955106622%" id="d54e9773" rowspan="1" colspan="1">Attribute key</th>
                                       <th class="entry" valign="top" width="11.22334455667789%" id="d54e9776" rowspan="1" colspan="1">Expected Descriptor Type Passed in, in the Setter</th>
                                       <th class="entry" dir="ltr" valign="top" width="11.22334455667789%" id="d54e9779" rowspan="1" colspan="1">I/O Type</th>
                                       <th class="entry" dir="ltr" valign="top" width="33.44556677890011%" id="d54e9782" rowspan="1" colspan="1">Description</th>
                                       <th class="entry" dir="ltr" valign="top" width="11.22334455667789%" id="d54e9785" rowspan="1" colspan="1">Default Value</th>
                                    </tr>
                                 </thead>
                                 <tbody class="tbody">
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="32.88439955106622%" headers="d54e9767 d54e9773" rowspan="1" colspan="1">X_BN_SCALE</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.22334455667789%" headers="d54e9767 d54e9776" rowspan="1" colspan="1">void *</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.22334455667789%" headers="d54e9767 d54e9779" rowspan="1" colspan="1">input</td>
                                       <td class="entry" dir="ltr" valign="top" width="33.44556677890011%" headers="d54e9767 d54e9782" rowspan="1" colspan="1">Pointer to sum of y square tensor on device, need to agree
                                          								with previously set CUDNN_PARAM_BN_SCALE_PLACEHOLDER attribute *
                                       </td>
                                       <td class="entry" dir="ltr" valign="top" width="11.22334455667789%" headers="d54e9767 d54e9785" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="32.88439955106622%" headers="d54e9767 d54e9773" rowspan="1" colspan="1">X_BN_BIAS</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.22334455667789%" headers="d54e9767 d54e9776" rowspan="1" colspan="1">void *</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.22334455667789%" headers="d54e9767 d54e9779" rowspan="1" colspan="1">input</td>
                                       <td class="entry" dir="ltr" valign="top" width="33.44556677890011%" headers="d54e9767 d54e9782" rowspan="1" colspan="1">Pointer to sum of y square tensor on device, need to agree
                                          								with previously set CUDNN_PARAM_BN_BIAS_PLACEHOLDER attribute *
                                       </td>
                                       <td class="entry" dir="ltr" valign="top" width="11.22334455667789%" headers="d54e9767 d54e9785" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="32.88439955106622%" headers="d54e9767 d54e9773" rowspan="1" colspan="1">X_BN_RUNNING_MEAN</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.22334455667789%" headers="d54e9767 d54e9776" rowspan="1" colspan="1">void *</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.22334455667789%" headers="d54e9767 d54e9779" rowspan="1" colspan="1">input/output</td>
                                       <td class="entry" dir="ltr" valign="top" width="33.44556677890011%" headers="d54e9767 d54e9782" rowspan="1" colspan="1">Pointer to sum of y square tensor on device, need to agree
                                          								with previously set CUDNN_PARAM_BN_RUNNING_MEAN_PLACEHOLDER attribute
                                          								*
                                       </td>
                                       <td class="entry" dir="ltr" valign="top" width="11.22334455667789%" headers="d54e9767 d54e9785" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="32.88439955106622%" headers="d54e9767 d54e9773" rowspan="1" colspan="1">X_BN_RUNNING_VAR</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.22334455667789%" headers="d54e9767 d54e9776" rowspan="1" colspan="1">void *</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.22334455667789%" headers="d54e9767 d54e9779" rowspan="1" colspan="1">input/output</td>
                                       <td class="entry" dir="ltr" valign="top" width="33.44556677890011%" headers="d54e9767 d54e9782" rowspan="1" colspan="1">Pointer to sum of y square tensor on device, need to agree
                                          								with previously set CUDNN_PARAM_BN_RUNNING_VAR_PLACEHOLDER attribute
                                          								*
                                       </td>
                                       <td class="entry" dir="ltr" valign="top" width="11.22334455667789%" headers="d54e9767 d54e9785" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="32.88439955106622%" headers="d54e9767 d54e9773" rowspan="1" colspan="1">X_BN_EQSCALE</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.22334455667789%" headers="d54e9767 d54e9776" rowspan="1" colspan="1">void *</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.22334455667789%" headers="d54e9767 d54e9779" rowspan="1" colspan="1">output</td>
                                       <td class="entry" dir="ltr" valign="top" width="33.44556677890011%" headers="d54e9767 d54e9782" rowspan="1" colspan="1">Pointer to batchnorm equivalent scale tensor on device, need
                                          								to agree with previously set CUDNN_PARAM_BN_EQSCALE_PLACEHOLDER attribute
                                          								*
                                       </td>
                                       <td class="entry" dir="ltr" valign="top" width="11.22334455667789%" headers="d54e9767 d54e9785" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="32.88439955106622%" headers="d54e9767 d54e9773" rowspan="1" colspan="1">X_BN_EQBIAS</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.22334455667789%" headers="d54e9767 d54e9776" rowspan="1" colspan="1">void *</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.22334455667789%" headers="d54e9767 d54e9779" rowspan="1" colspan="1">output</td>
                                       <td class="entry" dir="ltr" valign="top" width="33.44556677890011%" headers="d54e9767 d54e9782" rowspan="1" colspan="1">Pointer to batchnorm equivalent bias tensor on device, need to
                                          								agree with previously set CUDNN_PARAM_BN_EQBIAS_PLACEHOLDER attribute
                                          								*
                                       </td>
                                       <td class="entry" dir="ltr" valign="top" width="11.22334455667789%" headers="d54e9767 d54e9785" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="32.88439955106622%" headers="d54e9767 d54e9773" rowspan="1" colspan="1">X_DOUBLE_BN_EPSILON</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.22334455667789%" headers="d54e9767 d54e9776" rowspan="1" colspan="1">double *</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.22334455667789%" headers="d54e9767 d54e9779" rowspan="1" colspan="1">input</td>
                                       <td class="entry" valign="top" width="33.44556677890011%" headers="d54e9767 d54e9782" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">Pointer to a scalar value in double on host memory.</p>
                                          <p dir="ltr" class="p">A conditioning constant used in the batch normalization
                                             									formula. Its value should be equal to or greater than the value defined
                                             									for CUDNN_BN_MIN_EPSILON in cudnn.h
                                          </p>
                                          <p dir="ltr" class="p">See “exponentialAverageFactor” in cudnnBatchNormalization*
                                             									APIs
                                          </p>
                                       </td>
                                       <td class="entry" dir="ltr" valign="top" width="11.22334455667789%" headers="d54e9767 d54e9785" rowspan="1" colspan="1">0.0</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="32.88439955106622%" headers="d54e9767 d54e9773" rowspan="1" colspan="1">X_WORKSPACE</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.22334455667789%" headers="d54e9767 d54e9776" rowspan="1" colspan="1">void *</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.22334455667789%" headers="d54e9767 d54e9779" rowspan="1" colspan="1">input</td>
                                       <td class="entry" dir="ltr" valign="top" width="33.44556677890011%" headers="d54e9767 d54e9782" rowspan="1" colspan="1">Pointer to user allocated workspace on device. Can be NULL if
                                          								the workspace size requested is 0.
                                       </td>
                                       <td class="entry" dir="ltr" valign="top" width="11.22334455667789%" headers="d54e9767 d54e9785" rowspan="1" colspan="1">NULL</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="32.88439955106622%" headers="d54e9767 d54e9773" rowspan="1" colspan="1">X_SIZE_T_WORKSPACE_SIZE_IN_BYTES</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.22334455667789%" headers="d54e9767 d54e9776" rowspan="1" colspan="1">size_t *</td>
                                       <td class="entry" dir="ltr" valign="top" width="11.22334455667789%" headers="d54e9767 d54e9779" rowspan="1" colspan="1">input</td>
                                       <td class="entry" dir="ltr" valign="top" width="33.44556677890011%" headers="d54e9767 d54e9782" rowspan="1" colspan="1">Pointer to a size_t value in host memory describing the user allocated
                                          								workspace size in bytes. The amount need to be equal or larger than the
                                          								amount requested in <samp class="ph codeph">cudnnMakeFusedOpsPlan</samp>.
                                       </td>
                                       <td class="entry" dir="ltr" valign="top" width="11.22334455667789%" headers="d54e9767 d54e9785" rowspan="1" colspan="1">0</td>
                                    </tr>
                                 </tbody>
                              </table>
                           </div>
                        </div>
                        <div class="p">
                           <div class="note note"><span class="notetitle">Note:</span> If the corresponding pointer placeholder in ConstParamPack is set to
                              				“CUDNN_PTR_NULL”, then the device pointer in the VariantParamPack need to be NULL as
                              				well. 
                           </div>
                           <div class="note note"><span class="notetitle">Note:</span> If the corresponding pointer placeholder in ConstParamPack is set to
                              				“CUDNN_PTR_ELEM_ALIGNED” or “CUDNN_PTR_16B_ALIGNED”, then the device pointer in the
                              				VariantParamPack may not be NULL and need to be at least element-aligned or 16
                              				bytes-aligned, respectively. 
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnFusedOpsVariantParamPack_t"><a name="cudnnFusedOpsVariantParamPack_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnFusedOpsVariantParamPack_t" name="cudnnFusedOpsVariantParamPack_t" shape="rect">3.34.&nbsp;cudnnFusedOpsVariantParamPack_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnFusedOpsVariantParamPack_t</samp> is a pointer to an opaque structure holding
                           			the description of the cudnnFusedOps variant parameters. Use the function <a class="xref" href="index.html#cudnnCreateFusedOpsVariantParamPack" shape="rect">cudnnCreateFusedOpsVariantParamPack</a> to create one instance of this structure,
                           			and the function <a class="xref" href="index.html#cudnnDestroyFusedOpsVariantParamPack" shape="rect">cudnnDestroyFusedOpsVariantParamPack</a> to destroy a
                           			previously-created descriptor. 
                        </p>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnHandle_t"><a name="cudnnHandle_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnHandle_t" name="cudnnHandle_t" shape="rect">3.35.&nbsp;cudnnHandle_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnHandle_t</samp> is a pointer to an opaque structure holding the cuDNN
                           library context. The cuDNN library context must be created using
                           <samp class="ph codeph">cudnnCreate()</samp> and the returned handle must be passed to all
                           subsequent library function calls. The context should be destroyed at the end using
                           <samp class="ph codeph">cudnnDestroy()</samp>. The context is associated with only one GPU device,
                           the current device at the time of the call to <samp class="ph codeph">cudnnCreate()</samp>. However
                           multiple contexts can be created on the same GPU device. 
                        </p>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnIndicesType_t"><a name="cudnnIndicesType_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnIndicesType_t" name="cudnnIndicesType_t" shape="rect">3.36.&nbsp;cudnnIndicesType_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnIndicesType_t</samp> is an enumerated type used to indicate the data type
                           for the indices to be computed by the <samp class="ph codeph">cudnnReduceTensor()</samp> routine. This
                           enumerated type is used as a field for the
                           <samp class="ph codeph">cudnnReduceTensorDescriptor_t</samp> descriptor.
                        </p>
                        <p class="p"><strong class="ph b">Values</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_32BIT_INDICES</samp></dt>
                           <dd class="dd">
                              <p class="p"> Compute unsigned int indices </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_64BIT_INDICES</samp></dt>
                           <dd class="dd">
                              <p class="p"> Compute unsigned long long indices </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_16BIT_INDICES</samp></dt>
                           <dd class="dd">
                              <p class="p"> Compute unsigned short indices </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_8BIT_INDICES</samp></dt>
                           <dd class="dd">
                              <p class="p"> Compute unsigned char indices </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnLossNormalizationMode_t"><a name="cudnnLossNormalizationMode_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnLossNormalizationMode_t" name="cudnnLossNormalizationMode_t" shape="rect">3.37.&nbsp;cudnnLossNormalizationMode_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnLossNormalizationMode_t</samp> is an enumerated type that controls the input
                           			normalization mode for a   loss function. This type can be used with <a class="xref" href="index.html#cudnnSetCTCLossDescriptorEx" shape="rect">cudnnSetCTCLossDescriptorEx</a>.
                        </p>
                        <p class="p"><strong class="ph b">Values</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_LOSS_NORMALIZATION_NONE</samp></dt>
                           <dd class="dd">
                              <p class="p">The input <samp class="ph codeph">probs</samp> of <a class="xref" href="index.html#cudnnCTCLoss" shape="rect">cudnnCTCLoss</a> function is
                                 						expected to be the normalized probabilty, and the output
                                 							<samp class="ph codeph">gradients</samp> is the gradient of loss with respect to the
                                 						unnormalized probability.
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_LOSS_NORMALIZATION_SOFTMAX</samp></dt>
                           <dd class="dd">
                              <p class="p">The input <samp class="ph codeph">probs</samp> of <a class="xref" href="index.html#cudnnCTCLoss" shape="rect">cudnnCTCLoss</a> function is
                                 						expected to be the unnormalized activation from the previous layer, and the output
                                 							<samp class="ph codeph">gradients</samp> is the gradient with respect to the activation.
                                 						Internally the probability is computed by softmax normalization. 
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnLRNMode_t"><a name="cudnnLRNMode_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnLRNMode_t" name="cudnnLRNMode_t" shape="rect">3.38.&nbsp;cudnnLRNMode_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnLRNMode_t</samp> is an enumerated type used to specify the mode of
                           operation in <samp class="ph codeph">cudnnLRNCrossChannelForward()</samp> and
                           <samp class="ph codeph">cudnnLRNCrossChannelBackward()</samp>. 
                        </p>
                        <p class="p"><strong class="ph b">Values</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_LRN_CROSS_CHANNEL_DIM1</samp></dt>
                           <dd class="dd">
                              <p class="p">LRN computation is performed across tensor's dimension dimA[1].</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnMathType_t"><a name="cudnnMathType_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnMathType_t" name="cudnnMathType_t" shape="rect">3.39.&nbsp;cudnnMathType_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnMathType_t</samp> is an enumerated type used to indicate if the use of
                           Tensor Core Operations is permitted a given library routine.
                        </p>
                        <p class="p"><strong class="ph b">Values</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_DEFAULT_MATH</samp></dt>
                           <dd class="dd">
                              <p class="p"> Tensor Core Operations are not used.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_TENSOR_OP_MATH</samp></dt>
                           <dd class="dd">
                              <p class="p"> The use of Tensor Core Operations is permitted. </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION</samp></dt>
                           <dd class="dd">
                              <p class="p">  Enables the use of FP32 tensors for both input and output.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnMultiHeadAttnWeightKind_t"><a name="cudnnMultiHeadAttnWeightKind_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnMultiHeadAttnWeightKind_t" name="cudnnMultiHeadAttnWeightKind_t" shape="rect">3.40.&nbsp;cudnnMultiHeadAttnWeightKind_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p">cudnnMultiHeadAttnWeightKind_t is an enumerated type to specify the multi-head weight
                           			group. 
                        </p>
                        <div class="tablenoborder"><a name="cudnnMultiHeadAttnWeightKind_t__table_hpj_hcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnMultiHeadAttnWeightKind_t__table_hpj_hcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="42.6056338028169%" rowspan="1" colspan="1"><strong class="ph b">Member</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="57.3943661971831%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="42.6056338028169%" rowspan="1" colspan="1">CUDNN_ATTN_Q_WEIGHTS = 0</td>
                                    <td class="entry" dir="ltr" valign="top" width="57.3943661971831%" rowspan="1" colspan="1">Selects the multi-head query weight group. </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="42.6056338028169%" rowspan="1" colspan="1">CUDNN_ATTN_K_WEIGHTS = 1</td>
                                    <td class="entry" dir="ltr" valign="top" width="57.3943661971831%" rowspan="1" colspan="1">Selects the multi-head key weight group. </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="42.6056338028169%" rowspan="1" colspan="1">CUDNN_ATTN_V_WEIGHTS = 2</td>
                                    <td class="entry" dir="ltr" valign="top" width="57.3943661971831%" rowspan="1" colspan="1">Selects the multi-head value weight group. </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="42.6056338028169%" rowspan="1" colspan="1">CUDNN_ATTN_O_WEIGHTS = 3</td>
                                    <td class="entry" dir="ltr" valign="top" width="57.3943661971831%" rowspan="1" colspan="1">Selects the multi-head output weight group. </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnNanPropagation_t"><a name="cudnnNanPropagation_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnNanPropagation_t" name="cudnnNanPropagation_t" shape="rect">3.41.&nbsp;cudnnNanPropagation_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnNanPropagation_t</samp> is an enumerated type used to indicate if a given
                           routine should propagate <samp class="ph codeph">Nan</samp> numbers. This enumerated type is used as a
                           field for the <samp class="ph codeph">cudnnActivationDescriptor_t</samp> descriptor and
                           <samp class="ph codeph">cudnnPoolingDescriptor_t</samp> descriptor.
                        </p>
                        <p class="p"><strong class="ph b">Values</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_NOT_PROPAGATE_NAN</samp></dt>
                           <dd class="dd">
                              <p class="p"><samp class="ph codeph">Nan</samp> numbers are not propagated
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_PROPAGATE_NAN</samp></dt>
                           <dd class="dd">
                              <p class="p"><samp class="ph codeph">Nan</samp> numbers are propagated
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnOpTensorDescriptor_t"><a name="cudnnOpTensorDescriptor_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnOpTensorDescriptor_t" name="cudnnOpTensorDescriptor_t" shape="rect">3.42.&nbsp;cudnnOpTensorDescriptor_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnOpTensorDescriptor_t</samp> is a pointer to an opaque structure holding
                           the description of a Tensor Ccore Operation, used as a parameter to
                           <samp class="ph codeph">cudnnOpTensor()</samp>. <samp class="ph codeph">cudnnCreateOpTensorDescriptor()</samp>
                           is used to create one instance, and <samp class="ph codeph">cudnnSetOpTensorDescriptor()</samp> must
                           be used to initialize this instance. 
                        </p>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnOpTensorOp_t"><a name="cudnnOpTensorOp_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnOpTensorOp_t" name="cudnnOpTensorOp_t" shape="rect">3.43.&nbsp;cudnnOpTensorOp_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnOpTensorOp_t</samp> is an enumerated type used to indicate the Tensor Core
                           Operation to be used by the <samp class="ph codeph">cudnnOpTensor()</samp> routine. This enumerated
                           type is used as a field for the <samp class="ph codeph">cudnnOpTensorDescriptor_t</samp>
                           descriptor.
                        </p>
                        <p class="p"><strong class="ph b">Values</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_OP_TENSOR_ADD</samp></dt>
                           <dd class="dd">
                              <p class="p"> The operation to be performed is addition </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_OP_TENSOR_MUL</samp></dt>
                           <dd class="dd">
                              <p class="p"> The operation to be performed is multiplication </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_OP_TENSOR_MIN</samp></dt>
                           <dd class="dd">
                              <p class="p"> The operation to be performed is a minimum comparison </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_OP_TENSOR_MAX</samp></dt>
                           <dd class="dd">
                              <p class="p"> The operation to be performed is a maximum comparison </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_OP_TENSOR_SQRT</samp></dt>
                           <dd class="dd">
                              <p class="p"> The operation to be performed is square root, performed on only the A tensor
                                 
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_OP_TENSOR_NOT</samp></dt>
                           <dd class="dd">
                              <p class="p"> The operation to be performed is negation, performed on only the A tensor
                                 
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnPersistentRNNPlan_t"><a name="cudnnPersistentRNNPlan_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnPersistentRNNPlan_t" name="cudnnPersistentRNNPlan_t" shape="rect">3.44.&nbsp;cudnnPersistentRNNPlan_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnPersistentRNNPlan_t</samp> is a pointer to an opaque structure holding a
                           plan to execute a dynamic persistent RNN.
                           <samp class="ph codeph">cudnnCreatePersistentRNNPlan()</samp> is used to create and initialize one
                           instance. 
                        </p>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnPoolingDescriptor_t"><a name="cudnnPoolingDescriptor_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnPoolingDescriptor_t" name="cudnnPoolingDescriptor_t" shape="rect">3.45.&nbsp;cudnnPoolingDescriptor_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnPoolingDescriptor_t</samp> is a pointer to an opaque structure holding the
                           description of a pooling operation. <samp class="ph codeph">cudnnCreatePoolingDescriptor()</samp> is
                           used to create one instance, and <samp class="ph codeph">cudnnSetPoolingNdDescriptor()</samp> or
                           <samp class="ph codeph">cudnnSetPooling2dDescriptor()</samp> must be used to initialize this
                           instance. 
                        </p>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnPoolingMode_t"><a name="cudnnPoolingMode_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnPoolingMode_t" name="cudnnPoolingMode_t" shape="rect">3.46.&nbsp;cudnnPoolingMode_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnPoolingMode_t</samp> is an enumerated type passed to
                           <samp class="ph codeph">cudnnSetPoolingDescriptor()</samp> to select the pooling method to be used
                           by <samp class="ph codeph">cudnnPoolingForward()</samp> and
                           <samp class="ph codeph">cudnnPoolingBackward()</samp>.
                        </p>
                        <p class="p"><strong class="ph b">Values</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_POOLING_MAX</samp></dt>
                           <dd class="dd">
                              <p class="p">The maximum value inside the pooling window is used.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_POOLING_AVERAGE_COUNT_INCLUDE_PADDING</samp></dt>
                           <dd class="dd">
                              <p class="p"> Values inside the pooling window are averaged. The number of elements used
                                 to calculate the average includes spatial locations falling in the padding
                                 region. 
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING</samp></dt>
                           <dd class="dd">
                              <p class="p"> Values inside the pooling window are averaged. The number of elements used
                                 to calculate the average excludes spatial locations falling in the padding
                                 region.
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_POOLING_MAX_DETERMINISTIC</samp></dt>
                           <dd class="dd">
                              <p class="p">The maximum value inside the pooling window is used. The algorithm used is
                                 deterministic.
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnReduceTensorDescriptor_t"><a name="cudnnReduceTensorDescriptor_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnReduceTensorDescriptor_t" name="cudnnReduceTensorDescriptor_t" shape="rect">3.47.&nbsp;cudnnReduceTensorDescriptor_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnReduceTensorDescriptor_t</samp> is a pointer to an opaque structure
                           holding the description of a tensor reduction operation, used as a parameter to
                           <samp class="ph codeph">cudnnReduceTensor()</samp>.
                           <samp class="ph codeph">cudnnCreateReduceTensorDescriptor()</samp> is used to create one instance,
                           and <samp class="ph codeph">cudnnSetReduceTensorDescriptor()</samp> must be used to initialize this
                           instance. 
                        </p>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="unique_274979723"><a name="unique_274979723" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#unique_274979723" name="unique_274979723" shape="rect">cudnnReduceTensorIndices_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnReduceTensorIndices_t</samp> is an enumerated type used to indicate
                           whether indices are to be computed by the <samp class="ph codeph">cudnnReduceTensor()</samp> routine.
                           This enumerated type is used as a field for the
                           <samp class="ph codeph">cudnnReduceTensorDescriptor_t</samp> descriptor.
                        </p>
                        <p class="p"><strong class="ph b">Values</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_REDUCE_TENSOR_NO_INDICES</samp></dt>
                           <dd class="dd">
                              <p class="p"> Do not compute indices </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_REDUCE_TENSOR_FLATTENED_INDICES</samp></dt>
                           <dd class="dd">
                              <p class="p"> Compute indices. The resulting indices are relative, and flattened. </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnReduceTensorOp_t"><a name="cudnnReduceTensorOp_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnReduceTensorOp_t" name="cudnnReduceTensorOp_t" shape="rect">3.49.&nbsp;cudnnReduceTensorOp_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnReduceTensorOp_t</samp> is an enumerated type used to indicate the Tensor
                           Core Operation to be used by the <samp class="ph codeph">cudnnReduceTensor()</samp> routine. This
                           enumerated type is used as a field for the
                           <samp class="ph codeph">cudnnReduceTensorDescriptor_t</samp> descriptor.
                        </p>
                        <p class="p"><strong class="ph b">Values</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_REDUCE_TENSOR_ADD</samp></dt>
                           <dd class="dd">
                              <p class="p"> The operation to be performed is addition </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_REDUCE_TENSOR_MUL</samp></dt>
                           <dd class="dd">
                              <p class="p"> The operation to be performed is multiplication </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_REDUCE_TENSOR_MIN</samp></dt>
                           <dd class="dd">
                              <p class="p"> The operation to be performed is a minimum comparison </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_REDUCE_TENSOR_MAX</samp></dt>
                           <dd class="dd">
                              <p class="p"> The operation to be performed is a maximum comparison </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_REDUCE_TENSOR_AMAX</samp></dt>
                           <dd class="dd">
                              <p class="p"> The operation to be performed is a maximum comparison of absolute values
                                 
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_REDUCE_TENSOR_AVG</samp></dt>
                           <dd class="dd">
                              <p class="p"> The operation to be performed is averaging </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_REDUCE_TENSOR_NORM1</samp></dt>
                           <dd class="dd">
                              <p class="p"> The operation to be performed is addition of absolute values </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_REDUCE_TENSOR_NORM2</samp></dt>
                           <dd class="dd">
                              <p class="p"> The operation to be performed is a square root of sum of squares </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_REDUCE_TENSOR_MUL_NO_ZEROS</samp></dt>
                           <dd class="dd">
                              <p class="p"> The operation to be performed is multiplication, not including elements of
                                 value zero 
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnReorderType_t"><a name="cudnnReorderType_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnReorderType_t" name="cudnnReorderType_t" shape="rect">3.50.&nbsp;cudnnReorderType_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">typedef</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span> {
	CUDNN_DEFAULT_REORDER = 0,
	CUDNN_NO_REORDER      = 1,
	} cudnnReorderType_t;		</pre><p dir="ltr" class="p" id="cudnnReorderType_t__docs-internal-guid-0eaa8c2b-7fff-7d3b-da2a-c0eee8303faf"><a name="cudnnReorderType_t__docs-internal-guid-0eaa8c2b-7fff-7d3b-da2a-c0eee8303faf" shape="rect">
                              <!-- --></a><samp class="ph codeph">cudnnReorderType_t</samp> is an enumerated type to set the convolution
                           			reordering type. The reordering type can be set by <a class="xref" href="index.html#cudnnSetConvolutionReorderType" shape="rect">cudnnSetConvolutionReorderType</a> and its status can be read by <a class="xref" href="index.html#cudnnGetConvolutionReorderType" shape="rect">cudnnGetConvolutionReorderType</a>. 
                        </p>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnRNNAlgo_t"><a name="cudnnRNNAlgo_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnRNNAlgo_t" name="cudnnRNNAlgo_t" shape="rect">3.51.&nbsp;cudnnRNNAlgo_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnRNNAlgo_t</samp> is an enumerated type used to specify the algorithm used
                           in the <samp class="ph codeph">cudnnRNNForwardInference()</samp>,
                           <samp class="ph codeph">cudnnRNNForwardTraining()</samp>, <samp class="ph codeph">cudnnRNNBackwardData()</samp>
                           and <samp class="ph codeph">cudnnRNNBackwardWeights()</samp> routines. 
                        </p>
                        <p class="p"><strong class="ph b">Values</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_RNN_ALGO_STANDARD</samp></dt>
                           <dd class="dd">Each RNN layer is executed as a sequence of operations. This algorithm is
                              expected to have robust performance across a wide range of network
                              parameters.
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_STATIC</samp></dt>
                           <dd class="dd">
                              <p class="p">The recurrent parts of the network are executed using a <em class="ph i">persistent
                                    kernel</em> approach. This method is expected to be fast when the first
                                 dimension of the input tensor is small (ie. a small minibatch). 
                              </p>
                              <p class="p"><samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_STATIC</samp> is only supported on devices
                                 with compute capability &gt;= 6.0. 
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_DYNAMIC</samp></dt>
                           <dd class="dd">
                              <p class="p">The recurrent parts of the network are executed using a <em class="ph i">persistent
                                    kernel</em> approach. This method is expected to be fast when the first
                                 dimension of the input tensor is small (ie. a small minibatch). When using
                                 <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_DYNAMIC</samp> persistent kernels are
                                 prepared at runtime and are able to optimized using the specific parameters
                                 of the network and active GPU. As such, when using
                                 <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_DYNAMIC</samp> a one-time plan
                                 preparation stage must be executed. These plans can then be reused in
                                 repeated calls with the same model parameters. 
                              </p>
                              <p class="p">The limits on the maximum number of hidden units supported when using
                                 <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_DYNAMIC</samp> are significantly higher
                                 than the limits when using <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_STATIC</samp>,
                                 however throughput is likely to significantly reduce when exceeding the
                                 maximums supported by <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_STATIC</samp>. In
                                 this regime this method will still outperform
                                 <samp class="ph codeph">CUDNN_RNN_ALGO_STANDARD</samp> for some cases. 
                              </p>
                              <p class="p"><samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_DYNAMIC</samp> is only supported on devices
                                 with compute capability &gt;= 6.0 on Linux machines. 
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnRNNBiasMode_t"><a name="cudnnRNNBiasMode_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnRNNBiasMode_t" name="cudnnRNNBiasMode_t" shape="rect">3.52.&nbsp;cudnnRNNBiasMode_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnRNNBiasMode_t </samp>is an enumerated type used to specify the number of bias
                           			vectors for RNN functions. See the description of the <a class="xref" href="index.html#cudnnRNNMode_t" shape="rect">cudnnRNNMode_t</a> enumerated type for the equations for each cell type based on the
                           			bias mode.
                        </p>
                        <p class="p"><strong class="ph b">Values</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_RNN_NO_BIAS</samp></dt>
                           <dd class="dd">
                              <p class="p"> Applies RNN cell formulas that do not use biases.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_RNN_SINGLE_INP_BIAS</samp></dt>
                           <dd class="dd">
                              <p class="p">Applies RNN cell formulas that use one input bias vector in the input GEMM.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_RNN_DOUBLE_BIAS</samp></dt>
                           <dd class="dd">
                              <p class="p">Applies RNN cell formulas that use two bias vectors.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_RNN_SINGLE_REC_BIAS</samp></dt>
                           <dd class="dd">
                              <p class="p">Applies RNN cell formulas that use one recurrent bias vector in the recurrent GEMM.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnRNNClipMode_t"><a name="cudnnRNNClipMode_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnRNNClipMode_t" name="cudnnRNNClipMode_t" shape="rect">3.53.&nbsp;cudnnRNNClipMode_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnRNNClipMode_t</samp> is an enumerated type used to select the LSTM cell
                           clipping mode. It is used with <samp class="ph codeph">cudnnRNNSetClip()</samp>,
                           <samp class="ph codeph">cudnnRNNGetClip()</samp> functions, and internally within LSTM cells. 
                        </p>
                        <p class="p"><strong class="ph b">Values</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_RNN_CLIP_NONE</samp></dt>
                           <dd class="dd">
                              <p class="p">Disables LSTM cell clipping.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_RNN_CLIP_MINMAX</samp></dt>
                           <dd class="dd">
                              <p class="p">Enables LSTM cell clipping.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnRNNDataDescriptor_t"><a name="cudnnRNNDataDescriptor_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnRNNDataDescriptor_t" name="cudnnRNNDataDescriptor_t" shape="rect">3.54.&nbsp;cudnnRNNDataDescriptor_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnRNNDataDescriptor_t</samp> is a pointer to an opaque structure holding the
                           description of a RNN data set. The function
                           <samp class="ph codeph">cudnnCreateRNNDataDescriptor()</samp> is used to create one instance, and
                           <samp class="ph codeph">cudnnSetRNNDataDescriptor()</samp> must be used to initialize this
                           instance. 
                        </p>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnRNNDataLayout_t"><a name="cudnnRNNDataLayout_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnRNNDataLayout_t" name="cudnnRNNDataLayout_t" shape="rect">3.55.&nbsp;cudnnRNNDataLayout_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnRNNDataLayout_t</samp> is an enumerated type used to select the RNN data
                           			layout. It is used used in the API calls <a class="xref" href="index.html#cudnnGetRNNDataDescriptor" shape="rect">cudnnGetRNNDataDescriptor</a>   and
                           				<a class="xref" href="index.html#cudnnSetRNNDataDescriptor" shape="rect">cudnnSetRNNDataDescriptor</a>. 
                        </p>
                        <p class="p"><strong class="ph b">Values</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_RNN_DATA_LAYOUT_SEQ_MAJOR_UNPACKED</samp></dt>
                           <dd class="dd">
                              <p class="p">Data layout is padded, with outer stride from one time-step to the next.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_RNN_DATA_LAYOUT_SEQ_MAJOR_PACKED</samp></dt>
                           <dd class="dd">
                              <p class="p">The sequence length is sorted and packed as in basic RNN API.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_RNN_DATA_LAYOUT_BATCH_MAJOR_UNPACKED</samp></dt>
                           <dd class="dd">
                              <p class="p">Data layout is padded, with outer stride from one batch to the next.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnRNNDescriptor_t"><a name="cudnnRNNDescriptor_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnRNNDescriptor_t" name="cudnnRNNDescriptor_t" shape="rect">3.56.&nbsp;cudnnRNNDescriptor_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnRNNDescriptor_t</samp> is a pointer to an opaque structure holding the
                           description of an RNN operation. <samp class="ph codeph">cudnnCreateRNNDescriptor()</samp> is used to
                           create one instance, and <samp class="ph codeph">cudnnSetRNNDescriptor()</samp> must be used to
                           initialize this instance. 
                        </p>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnRNNInputMode_t"><a name="cudnnRNNInputMode_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnRNNInputMode_t" name="cudnnRNNInputMode_t" shape="rect">3.57.&nbsp;cudnnRNNInputMode_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnRNNInputMode_t</samp> is an enumerated type used to specify the behavior
                           of the first layer in the <samp class="ph codeph">cudnnRNNForwardInference()</samp>,
                           <samp class="ph codeph">cudnnRNNForwardTraining()</samp>, <samp class="ph codeph">cudnnRNNBackwardData()</samp>
                           and <samp class="ph codeph">cudnnRNNBackwardWeights()</samp> routines. 
                        </p>
                        <p class="p"><strong class="ph b">Values</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_LINEAR_INPUT</samp></dt>
                           <dd class="dd">A biased matrix multiplication is performed at the input of the first recurrent
                              layer.
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_SKIP_INPUT</samp></dt>
                           <dd class="dd">No operation is performed at the input of the first recurrent layer. If
                              <samp class="ph codeph">CUDNN_SKIP_INPUT</samp> is used the leading dimension of the input
                              tensor must be equal to the hidden state size of the network.
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnRNNMode_t"><a name="cudnnRNNMode_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnRNNMode_t" name="cudnnRNNMode_t" shape="rect">3.58.&nbsp;cudnnRNNMode_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnRNNMode_t</samp> is an enumerated type used to specify the type of network
                           			used in the <a class="xref" href="index.html#cudnnRNNForwardInference" shape="rect">cudnnRNNForwardInference()</a>,
                           				<a class="xref" href="index.html#cudnnRNNForwardTraining" shape="rect">cudnnRNNForwardTraining()</a>, <a class="xref" href="index.html#cudnnRNNBackwardData" shape="rect">cudnnRNNBackwardData()</a> and <a class="xref" href="index.html#cudnnRNNBackwardWeights" shape="rect">cudnnRNNBackwardWeights()</a> routines. 
                        </p>
                        <p class="p"><strong class="ph b">Values</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_RNN_RELU</samp></dt>
                           <dd class="dd">
                              <p class="p">A single-gate recurrent neural network with a ReLU activation function.</p>
                              <p class="p">In the forward pass, the output <samp class="ph codeph">h<sub class="ph sub">t</sub></samp> for a given
                                 						iteration can be computed from the recurrent input <samp class="ph codeph">h<sub class="ph sub">t-1</sub></samp> and
                                 						the previous layer input <samp class="ph codeph">x<sub class="ph sub">t</sub></samp>, given the matrices <samp class="ph codeph">W,
                                    							R</samp> and the bias vectors, where <strong class="ph b"><samp class="ph codeph">ReLU(x) = max(x,
                                       						0)</samp></strong>.
                              </p>
                              <p class="p">If <strong class="ph b"><samp class="ph codeph">cudnnRNNBiasMode_t biasMode</samp></strong> in
                                 							<strong class="ph b"><samp class="ph codeph">rnnDesc</samp></strong> is <strong class="ph b"><samp class="ph codeph">CUDNN_RNN_DOUBLE_BIAS</samp></strong>
                                 						(default mode), then the following equation with
                                 							biases<strong class="ph b"><samp class="ph codeph">b<sub class="ph sub">W</sub></samp></strong> and <strong class="ph b"><samp class="ph codeph">b<sub class="ph sub">R</sub></samp></strong>
                                 						applies:
                              </p>
                              <p class="p">h<sub class="ph sub">t</sub> = ReLU(W<sub class="ph sub">i</sub>x<sub class="ph sub">t</sub> + R<sub class="ph sub">i</sub>h<sub class="ph sub">t-1</sub> +
                                 							b<sub class="ph sub">Wi</sub> + b<sub class="ph sub">Ri</sub>)
                              </p>
                              <p class="p"></p>
                              <p class="p">If <strong class="ph b"><samp class="ph codeph">cudnnRNNBiasMode_t biasMode</samp></strong> in
                                 							<strong class="ph b"><samp class="ph codeph">rnnDesc</samp></strong> is <strong class="ph b"><samp class="ph codeph">CUDNN_RNN_SINGLE_INP_BIAS</samp></strong>
                                 						or <strong class="ph b"><samp class="ph codeph">CUDNN_RNN_SINGLE_REC_BIAS,</samp></strong>then the following equation with
                                 						bias <strong class="ph b"><samp class="ph codeph">b</samp></strong> applies:
                              </p>
                              <p class="p">h<sub class="ph sub">t</sub> = ReLU(W<sub class="ph sub">i</sub>x<sub class="ph sub">t</sub> + R<sub class="ph sub">i</sub>h<sub class="ph sub">t-1</sub> +
                                 							b<sub class="ph sub">i</sub>)
                              </p>
                              <p class="p"></p>
                              <p class="p">If <strong class="ph b"><samp class="ph codeph">cudnnRNNBiasMode_t biasMode</samp></strong> in
                                 							<strong class="ph b"><samp class="ph codeph">rnnDesc</samp></strong> is <strong class="ph b"><samp class="ph codeph">CUDNN_RNN_NO_BIAS,</samp></strong>then the
                                 						following equation applies:
                              </p>
                              <p class="p">h<sub class="ph sub">t</sub> = ReLU(W<sub class="ph sub">i</sub>x<sub class="ph sub">t</sub> + R<sub class="ph sub">i</sub>h<sub class="ph sub">t-1</sub>)
                              </p>
                              <p class="p"></p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_RNN_TANH</samp></dt>
                           <dd class="dd">
                              <p class="p">A single-gate recurrent neural network with a <samp class="ph codeph">tanh</samp> activation
                                 						function.
                              </p>
                              <p class="p">In the forward pass, the output <samp class="ph codeph">h<sub class="ph sub">t</sub></samp> for a given iteration
                                 						can be computed from the recurrent input <samp class="ph codeph">h<sub class="ph sub">t-1</sub></samp> and the
                                 						previous layer input <samp class="ph codeph">x<sub class="ph sub">t</sub></samp>, given the matrices <samp class="ph codeph">W,
                                    							R</samp> and the bias vectors, and where <strong class="ph b"><samp class="ph codeph">tanh</samp></strong> is the
                                 						hyperbolic tangent function. 
                              </p>
                              <p class="p">If <strong class="ph b"><samp class="ph codeph">cudnnRNNBiasMode_t biasMode</samp></strong> in
                                 							<strong class="ph b"><samp class="ph codeph">rnnDesc</samp></strong> is <strong class="ph b"><samp class="ph codeph">CUDNN_RNN_DOUBLE_BIAS</samp></strong>
                                 						(default mode), then the following equation with
                                 							biases<strong class="ph b"><samp class="ph codeph">b<sub class="ph sub">W</sub></samp></strong> and <strong class="ph b"><samp class="ph codeph">b<sub class="ph sub">R</sub></samp></strong>
                                 						applies:
                              </p>
                              <div class="p"><pre xml:space="preserve">h<sub class="ph sub">t</sub> = tanh(W<sub class="ph sub">i</sub>x<sub class="ph sub">t</sub> + R<sub class="ph sub">i</sub>h<sub class="ph sub">t-1</sub> + b<sub class="ph sub">Wi</sub> + b<sub class="ph sub">Ri</sub>)</pre></div>
                              <p class="p">If <strong class="ph b"><samp class="ph codeph">cudnnRNNBiasMode_t biasMode</samp></strong> in
                                 							<strong class="ph b"><samp class="ph codeph">rnnDesc</samp></strong> is <strong class="ph b"><samp class="ph codeph">CUDNN_RNN_SINGLE_INP_BIAS</samp></strong>
                                 						or <strong class="ph b"><samp class="ph codeph">CUDNN_RNN_SINGLE_REC_BIAS,</samp></strong>then the following equation with
                                 						bias <strong class="ph b"><samp class="ph codeph">b</samp></strong> applies:
                              </p>
                              <div class="p"><pre xml:space="preserve">h<sub class="ph sub">t</sub> = tanh(W<sub class="ph sub">i</sub>x<sub class="ph sub">t</sub> + R<sub class="ph sub">i</sub>h<sub class="ph sub">t-1</sub> + b<sub class="ph sub">i</sub>)</pre></div>
                              <p class="p"></p>
                              <p class="p">If <strong class="ph b"><samp class="ph codeph">cudnnRNNBiasMode_t biasMode</samp></strong> in
                                 							<strong class="ph b"><samp class="ph codeph">rnnDesc</samp></strong> is <strong class="ph b"><samp class="ph codeph">CUDNN_RNN_NO_BIAS,</samp></strong>then the
                                 						following equation applies:
                              </p>
                              <div class="p"><pre xml:space="preserve">h<sub class="ph sub">t</sub> = tanh(W<sub class="ph sub">i</sub>x<sub class="ph sub">t</sub> + R<sub class="ph sub">i</sub>h<sub class="ph sub">t-1</sub>)</pre></div>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_LSTM</samp></dt>
                           <dd class="dd">
                              <p class="p">A four-gate Long Short-Term Memory network with no peephole connections.</p>
                              <p class="p">In the forward pass, the output <samp class="ph codeph">h<sub class="ph sub">t</sub></samp> and cell
                                 						output <samp class="ph codeph">c<sub class="ph sub">t</sub></samp> for a given iteration can be computed from the
                                 						recurrent input <samp class="ph codeph">h<sub class="ph sub">t-1</sub></samp>, the cell input
                                 							<samp class="ph codeph">c<sub class="ph sub">t-1</sub></samp> and the previous layer input
                                 							<samp class="ph codeph">x<sub class="ph sub">t</sub></samp>, given the matrices <samp class="ph codeph">W, R</samp> and the bias
                                 						vectors.  
                              </p>
                              <div class="p">In addition, the following applies:<a name="cudnnRNNMode_t__ul_ybz_jhb_nhb" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnRNNMode_t__ul_ybz_jhb_nhb">
                                    <li class="li liexpand"><samp class="ph codeph">σ</samp> is the sigmoid operator such that:
                                       									<samp class="ph codeph">σ(x) = 1 / (1 + e<sup class="ph sup">-x</sup>)</samp>,
                                    </li>
                                    <li class="li liexpand"><samp class="ph codeph">◦</samp> represents a point-wise multiplication, 
                                    </li>
                                    <li class="li liexpand"><samp class="ph codeph">tanh</samp> is the hyperbolic tangent function, and
                                    </li>
                                    <li class="li liexpand"><samp class="ph codeph">i<sub class="ph sub">t</sub>, f<sub class="ph sub">t</sub>, o<sub class="ph sub">t</sub>,
                                          									c'<sub class="ph sub">t</sub></samp> represent the input, forget, output and new gates
                                       								respectively. 
                                    </li>
                                 </ul>
                              </div>
                              <p class="p">If <strong class="ph b"><samp class="ph codeph">cudnnRNNBiasMode_t biasMode</samp></strong> in
                                 							<strong class="ph b"><samp class="ph codeph">rnnDesc</samp></strong> is <strong class="ph b"><samp class="ph codeph">CUDNN_RNN_DOUBLE_BIAS</samp></strong>
                                 						(default mode), then the following equations with
                                 								biases<strong class="ph b"><samp class="ph codeph">b<sub class="ph sub">W</sub></samp></strong> and
                                 							<strong class="ph b"><samp class="ph codeph">b<sub class="ph sub">R</sub></samp></strong> apply:
                              </p><pre xml:space="preserve">i<sub class="ph sub">t</sub> = σ(W<sub class="ph sub">i</sub>x<sub class="ph sub">t</sub> + R<sub class="ph sub">i</sub>h<sub class="ph sub">t-1</sub> + b<sub class="ph sub">Wi</sub> + b<sub class="ph sub">Ri</sub>)
f<sub class="ph sub">t</sub> = σ(W<sub class="ph sub">f</sub>x<sub class="ph sub">t</sub> + R<sub class="ph sub">f</sub>h<sub class="ph sub">t-1</sub> + b<sub class="ph sub">Wf</sub> + b<sub class="ph sub">Rf</sub>)
o<sub class="ph sub">t</sub> = σ(W<sub class="ph sub">o</sub>x<sub class="ph sub">t</sub> + R<sub class="ph sub">o</sub>h<sub class="ph sub">t-1</sub> + b<sub class="ph sub">Wo</sub> + b<sub class="ph sub">Ro</sub>)
c'<sub class="ph sub">t</sub> = tanh(W<sub class="ph sub">c</sub>x<sub class="ph sub">t</sub> + R<sub class="ph sub">c</sub>h<sub class="ph sub">t-1</sub> + b<sub class="ph sub">Wc</sub> + b<sub class="ph sub">Rc</sub>)
c<sub class="ph sub">t</sub> = f<sub class="ph sub">t</sub> ◦ c<sub class="ph sub">t-1</sub> + i<sub class="ph sub">t</sub> ◦ c'<sub class="ph sub">t</sub>
h<sub class="ph sub">t</sub> = o<sub class="ph sub">t</sub> ◦ tanh(c<sub class="ph sub">t</sub>)</pre><p class="p"></p>
                              <p class="p">If <strong class="ph b"><samp class="ph codeph">cudnnRNNBiasMode_t biasMode</samp></strong> in
                                 							<strong class="ph b"><samp class="ph codeph">rnnDesc</samp></strong> is <strong class="ph b"><samp class="ph codeph">CUDNN_RNN_SINGLE_INP_BIAS</samp></strong>
                                 						or <strong class="ph b"><samp class="ph codeph">CUDNN_RNN_SINGLE_REC_BIAS,</samp></strong>then the following equations with
                                 						bias <strong class="ph b"><samp class="ph codeph">b</samp></strong> apply:
                              </p><pre xml:space="preserve">i<sub class="ph sub">t</sub> = σ(W<sub class="ph sub">i</sub>x<sub class="ph sub">t</sub> + R<sub class="ph sub">i</sub>h<sub class="ph sub">t-1</sub> + b<sub class="ph sub">i</sub>)
f<sub class="ph sub">t</sub> = σ(W<sub class="ph sub">f</sub>x<sub class="ph sub">t</sub> + R<sub class="ph sub">f</sub>h<sub class="ph sub">t-1</sub> + b<sub class="ph sub">f</sub>)
o<sub class="ph sub">t</sub> = σ(W<sub class="ph sub">o</sub>x<sub class="ph sub">t</sub> + R<sub class="ph sub">o</sub>h<sub class="ph sub">t-1</sub> + b<sub class="ph sub">o</sub>)
c'<sub class="ph sub">t</sub> = tanh(W<sub class="ph sub">c</sub>x<sub class="ph sub">t</sub> + R<sub class="ph sub">c</sub>h<sub class="ph sub">t-1</sub> + b<sub class="ph sub">c</sub>)
c<sub class="ph sub">t</sub> = f<sub class="ph sub">t </sub>◦ c<sub class="ph sub">t-1</sub> + i<sub class="ph sub">t</sub> ◦ c'<sub class="ph sub">t</sub>
h<sub class="ph sub">t</sub> = o<sub class="ph sub">t</sub> ◦ tanh(c<sub class="ph sub">t</sub>)</pre><p class="p"></p>
                              <p class="p"></p>
                              <p class="p">If <strong class="ph b"><samp class="ph codeph">cudnnRNNBiasMode_t biasMode</samp></strong> in
                                 							<strong class="ph b"><samp class="ph codeph">rnnDesc</samp></strong> is <strong class="ph b"><samp class="ph codeph">CUDNN_RNN_NO_BIAS,</samp></strong>then the
                                 						following equations apply:
                              </p><pre xml:space="preserve">i<sub class="ph sub">t</sub> = σ(W<sub class="ph sub">i</sub>x<sub class="ph sub">t</sub> + R<sub class="ph sub">i</sub>h<sub class="ph sub">t-1</sub>)
f<sub class="ph sub">t</sub> = σ(W<sub class="ph sub">f</sub>x<sub class="ph sub">t</sub> + R<sub class="ph sub">f</sub>h<sub class="ph sub">t-1</sub>)
o<sub class="ph sub">t</sub> = σ(W<sub class="ph sub">o</sub>x<sub class="ph sub">t</sub> + R<sub class="ph sub">o</sub>h<sub class="ph sub">t-1</sub>)
c'<sub class="ph sub">t</sub> = tanh(W<sub class="ph sub">c</sub>x<sub class="ph sub">t</sub> + R<sub class="ph sub">c</sub>h<sub class="ph sub">t-1</sub>)
c<sub class="ph sub">t</sub> = f<sub class="ph sub">t</sub> ◦ c<sub class="ph sub">t-1</sub> + i<sub class="ph sub">t </sub>◦ c'<sub class="ph sub">t</sub>
h<sub class="ph sub">t</sub> = o<sub class="ph sub">t</sub>◦tanh(c<sub class="ph sub">t</sub>)</pre><p class="p"></p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_GRU</samp></dt>
                           <dd class="dd">
                              <p class="p">A three-gate network consisting of Gated Recurrent Units.</p>
                              <p class="p">In the forward pass, the output <samp class="ph codeph">h<sub class="ph sub">t</sub></samp> for a given iteration
                                 						can be computed from the recurrent input <samp class="ph codeph">h<sub class="ph sub">t-1</sub></samp> and the
                                 						previous layer input <samp class="ph codeph">x<sub class="ph sub">t</sub></samp> given matrices <samp class="ph codeph">W, R</samp>
                                 						and the bias vectors. 
                              </p>
                              <p class="p">In addition, <samp class="ph codeph">σ</samp> is the sigmoid operator: <samp class="ph codeph">σ(x) = 1 /
                                    							(1 + e<sup class="ph sup">-x</sup>)</samp>, <samp class="ph codeph">◦</samp> represents a point-wise
                                 						multiplication and <samp class="ph codeph">tanh</samp> is the hyperbolic tangent function.
                                 								<samp class="ph codeph">i<sub class="ph sub">t</sub>, r<sub class="ph sub">t</sub>, h'<sub class="ph sub">t</sub></samp> represent the input,
                                 						reset, new gates respectively. 
                              </p>
                              
                              If <strong class="ph b"><samp class="ph codeph">cudnnRNNBiasMode_t
                                    						biasMode</samp></strong> in <strong class="ph b"><samp class="ph codeph">rnnDesc</samp></strong> is
                              							<strong class="ph b"><samp class="ph codeph">CUDNN_RNN_DOUBLE_BIAS</samp></strong> (default mode), then the following
                              					equations with biases<strong class="ph b"><samp class="ph codeph">b<sub class="ph sub">W</sub></samp></strong> and
                              							<strong class="ph b"><samp class="ph codeph">b<sub class="ph sub">R</sub></samp></strong> apply:<pre xml:space="preserve">i<sub class="ph sub">t</sub> = σ(W<sub class="ph sub">i</sub>x<sub class="ph sub">t</sub> + R<sub class="ph sub">i</sub>h<sub class="ph sub">t-1</sub> + b<sub class="ph sub">Wi</sub> + b<sub class="ph sub">Ru</sub>)
r<sub class="ph sub">t</sub> = σ(W<sub class="ph sub">r</sub>x<sub class="ph sub">t</sub> + R<sub class="ph sub">r</sub>h<sub class="ph sub">t-1</sub> + b<sub class="ph sub">Wr</sub> + b<sub class="ph sub">Rr</sub>)
h'<sub class="ph sub">t</sub> = tanh(W<sub class="ph sub">h</sub>x<sub class="ph sub">t</sub> + r<sub class="ph sub">t</sub>◦(R<sub class="ph sub">h</sub>h<sub class="ph sub">t-1</sub> + b<sub class="ph sub">Rh</sub>) + b<sub class="ph sub">Wh</sub>)
h<sub class="ph sub">t</sub> = (1 - i<sub class="ph sub">t</sub>) ◦ h'<sub class="ph sub">t</sub> + i<sub class="ph sub">t</sub> ◦ h<sub class="ph sub">t-1</sub></pre><p class="p"></p>
                              <p class="p">If <strong class="ph b"><samp class="ph codeph">cudnnRNNBiasMode_t biasMode</samp></strong> in
                                 							<strong class="ph b"><samp class="ph codeph">rnnDesc</samp></strong> is
                                 						<strong class="ph b"><samp class="ph codeph">CUDNN_RNN_SINGLE_INP_BIAS,</samp></strong>then the following equations with bias
                                 								<strong class="ph b"><samp class="ph codeph">b</samp></strong> apply:
                              </p><pre xml:space="preserve">i<sub class="ph sub">t</sub> = σ(W<sub class="ph sub">i</sub>x<sub class="ph sub">t</sub> + R<sub class="ph sub">i</sub>h<sub class="ph sub">t-1</sub> + b<sub class="ph sub">i</sub>)
r<sub class="ph sub">t</sub> = σ(W<sub class="ph sub">r</sub>x<sub class="ph sub">t</sub> + R<sub class="ph sub">r</sub>h<sub class="ph sub">t-1</sub> + b<sub class="ph sub">r</sub>)
h'<sub class="ph sub">t</sub> = tanh(W<sub class="ph sub">h</sub>x<sub class="ph sub">t</sub> + r<sub class="ph sub">t</sub> ◦ (R<sub class="ph sub">h</sub>h<sub class="ph sub">t-1</sub>) + b<sub class="ph sub">Wh</sub>)
h<sub class="ph sub">t</sub> = (1 - i<sub class="ph sub">t</sub>) ◦ h'<sub class="ph sub">t</sub> + i<sub class="ph sub">t</sub> ◦ h<sub class="ph sub">t-1</sub></pre><div class="p">If <strong class="ph b"><samp class="ph codeph">cudnnRNNBiasMode_t biasMode</samp></strong> in <strong class="ph b"><samp class="ph codeph">rnnDesc</samp></strong> is
                                 								<strong class="ph b"><samp class="ph codeph">CUDNN_RNN_SINGLE_REC_BIAS,</samp></strong>then the following
                                 						equations with bias <strong class="ph b"><samp class="ph codeph">b</samp></strong>
                                 						apply:<pre xml:space="preserve">i<sub class="ph sub">t</sub> = σ(W<sub class="ph sub">i</sub>x<sub class="ph sub">t</sub> + R<sub class="ph sub">i</sub>h<sub class="ph sub">t-1</sub> + b<sub class="ph sub">i</sub>)
r<sub class="ph sub">t</sub> = σ(W<sub class="ph sub">r</sub>x<sub class="ph sub">t</sub> + R<sub class="ph sub">r</sub>h<sub class="ph sub">t-1</sub> + b<sub class="ph sub">r</sub>)
h'<sub class="ph sub">t</sub> = tanh(W<sub class="ph sub">h</sub>x<sub class="ph sub">t</sub> + r<sub class="ph sub">t</sub> ◦ (R<sub class="ph sub">h</sub>h<sub class="ph sub">t-1</sub> + b<sub class="ph sub">Rh</sub>))
h<sub class="ph sub">t</sub> = (1 - i<sub class="ph sub">t</sub>) ◦ h'<sub class="ph sub">t</sub> + i<sub class="ph sub">t</sub> ◦ h<sub class="ph sub">t-1</sub></pre></div>
                           </dd>
                           <dd class="dd">
                              <p class="p"></p>
                              <p class="p">If <strong class="ph b"><samp class="ph codeph">cudnnRNNBiasMode_t biasMode</samp></strong> in
                                 							<strong class="ph b"><samp class="ph codeph">rnnDesc</samp></strong> is <strong class="ph b"><samp class="ph codeph">CUDNN_RNN_NO_BIAS,</samp></strong>then the
                                 						following equations apply:
                              </p>
                              <div class="p"><pre xml:space="preserve">i<sub class="ph sub">t</sub> = σ(W<sub class="ph sub">i</sub>x<sub class="ph sub">t</sub> + R<sub class="ph sub">i</sub>h<sub class="ph sub">t-1</sub>)
r<sub class="ph sub">t</sub> = σ(W<sub class="ph sub">r</sub>x<sub class="ph sub">t</sub> + R<sub class="ph sub">r</sub>h<sub class="ph sub">t-1</sub>)
h'<sub class="ph sub">t</sub> = tanh(W<sub class="ph sub">h</sub>x<sub class="ph sub">t</sub> + r<sub class="ph sub">t</sub> ◦ (R<sub class="ph sub">h</sub>h<sub class="ph sub">t-1</sub>))
h<sub class="ph sub">t</sub> = (1 - i<sub class="ph sub">t</sub>) ◦ h'<sub class="ph sub">t</sub> + i<sub class="ph sub">t </sub>◦ h<sub class="ph sub">t-1</sub></pre></div>
                              <p class="p"></p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnRNNPaddingMode_t"><a name="cudnnRNNPaddingMode_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnRNNPaddingMode_t" name="cudnnRNNPaddingMode_t" shape="rect">3.59.&nbsp;cudnnRNNPaddingMode_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnRNNPaddingMode_t</samp> is an enumerated type used to enable or disable
                           the padded input/output.  
                        </p>
                        <p class="p"><strong class="ph b">Values</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_RNN_PADDED_IO_DISABLED</samp></dt>
                           <dd class="dd">Disables the padded input/output. </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_RNN_PADDED_IO_ENABLED </samp></dt>
                           <dd class="dd">Enables the padded input/output.</dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSamplerType_t"><a name="cudnnSamplerType_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSamplerType_t" name="cudnnSamplerType_t" shape="rect">3.60.&nbsp;cudnnSamplerType_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnSamplerType_t</samp> is an enumerated type passed to
                           <samp class="ph codeph">cudnnSetSpatialTransformerNdDescriptor()</samp> to select the sampler type
                           to be used by <samp class="ph codeph">cudnnSpatialTfSamplerForward()</samp> and
                           <samp class="ph codeph">cudnnSpatialTfSamplerBackward()</samp>. 
                        </p>
                        <p class="p"><strong class="ph b">Values</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_SAMPLER_BILINEAR</samp></dt>
                           <dd class="dd">Selects the bilinear sampler.</dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSeqDataAxis_t"><a name="cudnnSeqDataAxis_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSeqDataAxis_t" name="cudnnSeqDataAxis_t" shape="rect">3.61.&nbsp;cudnnSeqDataAxis_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p dir="ltr" class="p" id="cudnnSeqDataAxis_t__docs-internal-guid-dc00d1a4-7fff-7749-0dd8-3e19ca56cd06"><a name="cudnnSeqDataAxis_t__docs-internal-guid-dc00d1a4-7fff-7749-0dd8-3e19ca56cd06" shape="rect">
                              <!-- --></a>cudnnSeqDataAxis_t
                           			is an enumerated type to specify each supported sequence data axis. 
                        </p>
                        <p dir="ltr" class="p">For continued API compatibility, the user is recommended to use these enumerated
                           			labels when fetching and storing axes-arrays such as <samp class="ph codeph">dimA</samp>, and
                           				<samp class="ph codeph">axes</samp>. 
                        </p>
                        <div class="p">User should: <a name="cudnnSeqDataAxis_t__ul_b3y_3xn_5gb" shape="rect">
                              <!-- --></a><ol class="ol" id="cudnnSeqDataAxis_t__ul_b3y_3xn_5gb">
                              <li class="li liexpand">Specify the dimension of sequence data buffer as follows:
                                 					<pre xml:space="preserve">int dimA[CUDNN_SEQDATA_DIM_COUNT]; 
dimA[CUDNN_SEQDATA_TIME_DIM] = n_timesteps; 
dimA[CUDNN_SEQDATA_BATCH_DIM] = n_batch; 
dimA[CUDNN_SEQDATA_BEAM_DIM]] = beam_size; 
dimA[CUDNN_SEQDATA_VECT_DIM]] = hidden_size; </pre></li>
                              <li class="li liexpand">Specify the axes order as follows:
                                 					<pre xml:space="preserve">cudnnSeqDataAxis_t axes[CUDNN_SEQDATA_DIM_COUNT] = 
	{CUDNN_SEQDATA_TIME_DIM, 
	 CUDNN_SEQDATA_BATCH_DIM, 
	 CUDNN_SEQDATA_BEAM_DIM, 
	 CUDNN_SEQDATA_VECT_DIM}; </pre>The
                                 					CUDNN_SEQDATA_DIM_COUNT defines the number of supported dimensions or axes for
                                 					sequential data. This value is currently set to 4.<div class="note note"><span class="notetitle">Note:</span> The user is advised against
                                    						using the equivalent integer values for the enumerated labels. 
                                 </div>
                              </li>
                           </ol>
                        </div>
                        <div class="tablenoborder"><a name="cudnnSeqDataAxis_t__table_hpj_hcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnSeqDataAxis_t__table_hpj_hcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="42.6056338028169%" rowspan="1" colspan="1"><strong class="ph b">Member</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="57.3943661971831%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="42.6056338028169%" rowspan="1" colspan="1">CUDNN_SEQDATA_TIME_DIM = 0</td>
                                    <td class="entry" dir="ltr" valign="top" width="57.3943661971831%" rowspan="1" colspan="1">Time step index.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="42.6056338028169%" rowspan="1" colspan="1">CUDNN_SEQDATA_BATCH_DIM = 1</td>
                                    <td class="entry" dir="ltr" valign="top" width="57.3943661971831%" rowspan="1" colspan="1">Batch index.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="42.6056338028169%" rowspan="1" colspan="1">CUDNN_SEQDATA_BEAM_DIM = 2</td>
                                    <td class="entry" dir="ltr" valign="top" width="57.3943661971831%" rowspan="1" colspan="1">Beam index.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="42.6056338028169%" rowspan="1" colspan="1">CUDNN_SEQDATA_VECT_DIM = 3</td>
                                    <td class="entry" dir="ltr" valign="top" width="57.3943661971831%" rowspan="1" colspan="1">Hidden vector index.</td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSeqDataDescriptor_t"><a name="cudnnSeqDataDescriptor_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSeqDataDescriptor_t" name="cudnnSeqDataDescriptor_t" shape="rect">3.62.&nbsp;cudnnSeqDataDescriptor_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p">cudnnSeqDataDescriptor_t is a pointer to an opaque structure holding the description of
                           			sequence data. Use the function <a class="xref" href="index.html#cudnnCreateSeqDataDescriptor" shape="rect">cudnnCreateSeqDataDescriptor</a> to create one instance, and
                           			<a class="xref" href="index.html#cudnnDestroySeqDataDescriptor" shape="rect">cudnnDestroySeqDataDescriptor</a> to destroy a previously created descriptor. 
                        </p>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSoftmaxAlgorithm_t"><a name="cudnnSoftmaxAlgorithm_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSoftmaxAlgorithm_t" name="cudnnSoftmaxAlgorithm_t" shape="rect">3.63.&nbsp;cudnnSoftmaxAlgorithm_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnSoftmaxAlgorithm_t</samp> is used to select an implementation of the
                           softmax function used in <samp class="ph codeph">cudnnSoftmaxForward()</samp> and
                           <samp class="ph codeph">cudnnSoftmaxBackward()</samp>. 
                        </p>
                        <p class="p"><strong class="ph b">Values</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_SOFTMAX_FAST</samp></dt>
                           <dd class="dd">
                              <p class="p">This implementation applies the straightforward softmax operation.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_SOFTMAX_ACCURATE</samp></dt>
                           <dd class="dd">
                              <p class="p">This implementation scales each point of the softmax input domain by its
                                 maximum value to avoid potential floating point overflows in the softmax
                                 evaluation.
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_SOFTMAX_LOG</samp></dt>
                           <dd class="dd">
                              <p class="p">This entry performs the Log softmax operation, avoiding overflows by scaling
                                 each point in the input domain as in
                                 <samp class="ph codeph">CUDNN_SOFTMAX_ACCURATE</samp></p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSoftmaxMode_t"><a name="cudnnSoftmaxMode_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSoftmaxMode_t" name="cudnnSoftmaxMode_t" shape="rect">3.64.&nbsp;cudnnSoftmaxMode_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnSoftmaxMode_t</samp> is used to select over which data the
                           <samp class="ph codeph">cudnnSoftmaxForward()</samp> and <samp class="ph codeph">cudnnSoftmaxBackward()</samp>
                           are computing their results. 
                        </p>
                        <p class="p"><strong class="ph b">Values</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_SOFTMAX_MODE_INSTANCE</samp></dt>
                           <dd class="dd">
                              <p class="p">The softmax operation is computed per image (N) across the dimensions
                                 C,H,W.
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_SOFTMAX_MODE_CHANNEL</samp></dt>
                           <dd class="dd">
                              <p class="p">The softmax operation is computed per spatial location (H,W) per image (N)
                                 across the dimension C.
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSpatialTransformerDescriptor_t"><a name="cudnnSpatialTransformerDescriptor_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSpatialTransformerDescriptor_t" name="cudnnSpatialTransformerDescriptor_t" shape="rect">3.65.&nbsp;cudnnSpatialTransformerDescriptor_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnSpatialTransformerDescriptor_t</samp> is a pointer to an opaque structure
                           holding the description of a spatial transformation operation.
                           <samp class="ph codeph">cudnnCreateSpatialTransformerDescriptor()</samp> is used to create one
                           instance, <samp class="ph codeph">cudnnSetSpatialTransformerNdDescriptor()</samp> is used to
                           initialize this instance, <samp class="ph codeph">cudnnDestroySpatialTransformerDescriptor()</samp> is
                           used to destroy this instance. 
                        </p>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnStatus_t"><a name="cudnnStatus_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnStatus_t" name="cudnnStatus_t" shape="rect">3.66.&nbsp;cudnnStatus_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnStatus_t</samp> is an enumerated type used for function status returns.
                           All cuDNN library functions return their status, which can be one of the following
                           values:
                        </p>
                        <p class="p"><strong class="ph b">Values</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The operation completed successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_INITIALIZED</samp></dt>
                           <dd class="dd">
                              <p class="p">The cuDNN library was not initialized properly. This error is usually
                                 returned when a call to <samp class="ph codeph">cudnnCreate()</samp> fails or when
                                 <samp class="ph codeph">cudnnCreate()</samp> has not been called prior to calling
                                 another cuDNN routine. In the former case, it is usually due to an error in
                                 the CUDA Runtime API called by <samp class="ph codeph">cudnnCreate()</samp> or by an error
                                 in the hardware setup.
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">Resource allocation failed inside the cuDNN library. This is usually caused
                                 by an internal <samp class="ph codeph">cudaMalloc()</samp> failure.
                              </p>
                              <p class="p">To correct: prior to the function call, deallocate previously allocated
                                 memory as much as possible.
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">An incorrect value or parameter was passed to the function.</p>
                              <p class="p">To correct: ensure that all the parameters being passed have valid
                                 values.
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_ARCH_MISMATCH</samp></dt>
                           <dd class="dd">
                              <p class="p">The function requires a feature absent from the current GPU device. Note that
                                 cuDNN only supports devices with compute capabilities greater than or equal
                                 to 3.0.
                              </p>
                              <p class="p">To correct: compile and run the application on a device with appropriate
                                 compute capability.
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_MAPPING_ERROR</samp></dt>
                           <dd class="dd">
                              <p class="p">An access to GPU memory space failed, which is usually caused by a failure to
                                 bind a texture.
                              </p>
                              <p class="p">To correct: prior to the function call, unbind any previously bound
                                 textures.
                              </p>
                              <p class="p">Otherwise, this may indicate an internal error/bug in the library.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The GPU program failed to execute. This is usually caused by a failure to
                                 launch some cuDNN kernel on the GPU, which can occur for multiple
                                 reasons.
                              </p>
                              <p class="p">To correct: check that the hardware, an appropriate version of the driver,
                                 and the cuDNN library are correctly installed.
                              </p>
                              <p class="p">Otherwise, this may indicate a internal error/bug in the library.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_INTERNAL_ERROR</samp></dt>
                           <dd class="dd">
                              <p class="p">An internal cuDNN operation
                                 failed.
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The functionality requested is not presently supported by cuDNN.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_LICENSE_ERROR</samp></dt>
                           <dd class="dd">
                              <p class="p">The functionality requested requires some license and an error was detected
                                 when trying to check the current licensing. This error can happen if the
                                 license is not present or is expired or if the environment variable
                                 NVIDIA_LICENSE_FILE is not set properly. 
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_RUNTIME_PREREQUISITE_MISSING</samp></dt>
                           <dd class="dd">
                              <p class="p">Runtime library required by RNN calls (libcuda.so or nvcuda.dll) cannot be
                                 found in predefined search paths. 
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_RUNTIME_IN_PROGRESS</samp></dt>
                           <dd class="dd">
                              <p class="p">Some tasks in the user stream are not completed. </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_RUNTIME_FP_OVERFLOW</samp></dt>
                           <dd class="dd">
                              <p class="p">Numerical overflow occurred during the GPU kernel execution. </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnTensorDescriptor_t"><a name="cudnnTensorDescriptor_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnTensorDescriptor_t" name="cudnnTensorDescriptor_t" shape="rect">3.67.&nbsp;cudnnTensorDescriptor_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnCreateTensorDescriptor_t</samp> is a pointer to an opaque structure
                           holding the description of a generic n-D dataset.
                           <samp class="ph codeph">cudnnCreateTensorDescriptor()</samp> is used to create one instance, and
                           one of the routrines <samp class="ph codeph">cudnnSetTensorNdDescriptor()</samp>,
                           <samp class="ph codeph">cudnnSetTensor4dDescriptor()</samp> or
                           <samp class="ph codeph">cudnnSetTensor4dDescriptorEx()</samp> must be used to initialize this
                           instance. 
                        </p>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnTensorFormat_t"><a name="cudnnTensorFormat_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnTensorFormat_t" name="cudnnTensorFormat_t" shape="rect">3.68.&nbsp;cudnnTensorFormat_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnTensorFormat_t</samp> is an enumerated type used by
                           				<samp class="ph codeph">cudnnSetTensor4dDescriptor()</samp> to create a tensor with a pre-defined
                           			layout. For a detailed explanation of how these Tensors are arranged in memory, see <a class="xref" href="index.html#data-layout-formats" shape="rect">Data Layout Formats</a>.
                        </p>
                        <p class="p"><strong class="ph b">Values</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_TENSOR_NCHW</samp></dt>
                           <dd class="dd">
                              <p class="p">This tensor format specifies that the data is laid out in the following
                                 order: batch size, feature maps, rows, columns. The strides are implicitly
                                 defined in such a way that the data are contiguous in memory with no padding
                                 between images, feature maps, rows, and columns; the columns are the inner
                                 dimension and the images are the outermost dimension. 
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_TENSOR_NHWC</samp></dt>
                           <dd class="dd">
                              <p class="p">This tensor format specifies that the data is laid out in the following
                                 order: batch size, rows, columns, feature maps. The strides are implicitly
                                 defined in such a way that the data are contiguous in memory with no padding
                                 between images, rows, columns, and feature maps; the feature maps are the
                                 inner dimension and the images are the outermost dimension. 
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_TENSOR_NCHW_VECT_C</samp></dt>
                           <dd class="dd">
                              <p class="p">This tensor format specifies that the data is laid out in the following
                                 order: batch size, feature maps, rows, columns. However, each element of the
                                 tensor is a vector of multiple feature maps. The length of the vector is
                                 carried by the data type of the tensor. The strides are implicitly defined
                                 in such a way that the data are contiguous in memory with no padding between
                                 images, feature maps, rows, and columns; the columns are the inner dimension
                                 and the images are the outermost dimension. This format is only supported
                                 with tensor data types CUDNN_DATA_INT8x4, CUDNN_DATA_INT8x32, and
                                 CUDNN_DATA_UINT8x4. 
                              </p>
                              <p class="p">The CUDNN_TENSOR_NCHW_VECT_C can also be interpreted in the following way: The
                                 						NCHW INT8x32 format is really N x (C/32) x H x W x 32 (32 Cs for every W), just as
                                 						the NCHW INT8x4 format is N x (C/4) x H x W x 4 (4 Cs for every W). Hence the
                                 						"VECT_C" name - each W is a vector (4 or 32) of Cs. 
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnTensorTransformDescriptor_t"><a name="cudnnTensorTransformDescriptor_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnTensorTransformDescriptor_t" name="cudnnTensorTransformDescriptor_t" shape="rect">3.69.&nbsp;cudnnTensorTransformDescriptor_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p"><samp class="ph codeph">cudnnTensorTransformDescriptor_t</samp> is an opaque structure containing the
                           			description of the Tensor transform. Use the
                           				<a class="xref" href="index.html#cudnnCreateTensorTransformDescriptor" shape="rect">cudnnCreateTensorTransformDescriptor</a> function to create an instance
                           			of this descriptor, and <a class="xref" href="index.html#cudnnDestroyTensorTransformDescriptor" shape="rect">cudnnDestroyTensorTransformDescriptor</a> function
                           			to destroy a previously created instance. 
                        </p>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnWgradMode_t"><a name="cudnnWgradMode_t" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnWgradMode_t" name="cudnnWgradMode_t" shape="rect">3.70.&nbsp;cudnnWgradMode_t</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <p class="p">cudnnWgradMode_t is an enumerated type to select how the weight gradient output buffers should
                           			be updated with the partial gradients.
                        </p>
                        <div class="p">
                           <div class="tablenoborder"><a name="cudnnWgradMode_t__table_pkh_v34_5gb" shape="rect">
                                 <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnWgradMode_t__table_pkh_v34_5gb" class="table" frame="border" border="1" rules="all">
                                 <tbody class="tbody">
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="39.0625%" rowspan="1" colspan="1"><strong class="ph b">Member</strong></td>
                                       <td class="entry" dir="ltr" valign="top" width="60.9375%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="39.0625%" rowspan="1" colspan="1">CUDNN_WGRAD_MODE_ADD = 0</td>
                                       <td class="entry" dir="ltr" valign="top" width="60.9375%" rowspan="1" colspan="1">Adds the partial gradients to the weight gradient output
                                          								buffers (i.e., weight gradient output buffers = weight gradient output
                                          								buffers + partial gradients).
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" valign="top" width="39.0625%" rowspan="1" colspan="1">CUDNN_WGRAD_MODE_ADD = 1</td>
                                       <td class="entry" dir="ltr" valign="top" width="60.9375%" rowspan="1" colspan="1">Replaces the weight gradient output buffer values with the
                                          								partial gradients (i.e., weight gradient output buffers = partial
                                          								gradients).
                                       </td>
                                    </tr>
                                 </tbody>
                              </table>
                           </div>
                        </div>
                     </div>
                  </div>
               </div>
               <div class="topic concept nested0" id="api-introduction"><a name="api-introduction" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#api-introduction" name="api-introduction" shape="rect">4.&nbsp;cuDNN API Reference</a></h2>
                  <div class="body conbody">
                     <div class="abstract"><span class="shortdesc"></span></div>
                     <p class="p">This chapter describes the API of all the routines of the cuDNN library. </p>
                  </div>
                  <div class="topic concept nested1" id="cudnnActivationBackward"><a name="cudnnActivationBackward" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnActivationBackward" name="cudnnActivationBackward" shape="rect">4.1.&nbsp;cudnnActivationBackward</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnActivationBackward(
    cudnnHandle_t                    handle,
    cudnnActivationDescriptor_t      activationDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *alpha,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *y,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    dyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *dy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *beta,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    dxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *dx)</pre><p class="p">This routine computes the gradient of a neuron activation function.</p>
                        <div class="note note"><span class="notetitle">Note:</span> In-place operation is allowed for this routine; i.e. <samp class="ph codeph">dy</samp> and
                           <samp class="ph codeph">dx</samp> pointers may be equal. However, this requires the corresponding
                           tensor descriptors to be identical (particularly, the strides of the input and output
                           must match for in-place operation to be allowed).
                        </div>
                        <div class="note note"><span class="notetitle">Note:</span> All tensor formats are supported for 4 and 5 dimensions, however best performance is
                           obtained when the strides of <samp class="ph codeph">yDesc</samp> and <samp class="ph codeph">xDesc</samp> are equal
                           and <samp class="ph codeph">HW-packed</samp>. For more than 5 dimensions the tensors must have their
                           spatial dimensions packed.
                        </div>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context. See <a class="xref" href="index.html#cudnnHandle_t" shape="rect">cudnnHandle_t.</a></p>
                           </dd>
                           <dt class="dt dlterm">activationDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Activation descriptor. See <a class="xref" href="index.html#cudnnActivationDescriptor_t" shape="rect">cudnnActivationDescriptor_t.</a></p>
                           </dd>
                           <dt class="dt dlterm">alpha, beta </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointers to scaling factors (in host memory) used to blend the
                                 computation result with prior value in the output layer as follows: dstValue
                                 = alpha[0]*result + beta[0]*priorDstValue. <a class="xref" href="index.html#general-description" shape="rect">Refer to this
                                    section for additional details.</a></p>
                           </dd>
                           <dt class="dt dlterm">yDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized input tensor descriptor.
                                 See <a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t.</a></p>
                           </dd>
                           <dt class="dt dlterm">y </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">yDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dyDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized input differential tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dy </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">dyDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">xDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized output tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">x </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the output tensor
                                 descriptor <samp class="ph codeph">xDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dxDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized output differential tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dx </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the output tensor
                                 descriptor <samp class="ph codeph">dxDesc</samp>.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The function launched successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnActivationBackward__ul_p1s_hzh_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnActivationBackward__ul_p1s_hzh_s1b">
                                 <li class="li">The strides <samp class="ph codeph">nStride, cStride, hStride, wStride</samp> of the
                                    input differential tensor and output differential tensors differ and
                                    in-place operation is used.
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function does not support the provided configuration. See the following
                                 for some examples of non-supported configurations:
                              </p><a name="cudnnActivationBackward__ul_w1s_hzh_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnActivationBackward__ul_w1s_hzh_s1b">
                                 <li class="li">The dimensions <samp class="ph codeph">n,c,h,w</samp> of the input tensor and output
                                    tensors differ.
                                 </li>
                                 <li class="li">The <samp class="ph codeph">datatype</samp> of the input tensor and output tensors
                                    differs.
                                 </li>
                                 <li class="li">The strides <samp class="ph codeph">nStride, cStride, hStride, wStride</samp> of the
                                    input tensor and the input differential tensor differ.
                                 </li>
                                 <li class="li">The strides <samp class="ph codeph">nStride, cStride, hStride, wStride</samp> of the
                                    output tensor and the output differential tensor differ.
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function failed to launch on the GPU.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnActivationForward"><a name="cudnnActivationForward" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnActivationForward" name="cudnnActivationForward" shape="rect">4.2.&nbsp;cudnnActivationForward</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnActivationForward(
    cudnnHandle_t handle,
    cudnnActivationDescriptor_t     activationDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *alpha,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *beta,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *y)</pre><p class="p">This routine applies a specified neuron activation function element-wise over each input
                           value.
                        </p>
                        <div class="note note"><span class="notetitle">Note:</span> In-place operation is allowed for this routine; i.e., <samp class="ph codeph">xData</samp> and
                           <samp class="ph codeph">yData</samp> pointers may be equal. However, this requires
                           <samp class="ph codeph">xDesc</samp> and <samp class="ph codeph">yDesc</samp> descriptors to be identical
                           (particularly, the strides of the input and output must match for in-place operation to
                           be allowed).
                        </div>
                        <div class="note note"><span class="notetitle">Note:</span> All tensor formats are supported for 4 and 5 dimensions, however best performance is
                           obtained when the strides of <samp class="ph codeph">xDesc</samp> and <samp class="ph codeph">yDesc</samp> are equal
                           and <samp class="ph codeph">HW-packed</samp>. For more than 5 dimensions the tensors must have their
                           spatial dimensions packed.
                        </div>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context. See <a class="xref" href="index.html#cudnnHandle_t" shape="rect">cudnnHandle_t</a>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">activationDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Activation descriptor. See <a class="xref" href="index.html#cudnnActivationDescriptor_t" shape="rect">cudnnActivationDescriptor_t</a>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">alpha, beta </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointers to scaling factors (in host memory) used to blend the
                                 computation result with prior value in the output layer as follows: dstValue
                                 = alpha[0]*result + beta[0]*priorDstValue. <a class="xref" href="index.html#general-description" shape="rect">Please refer to this
                                    section for additional details.</a></p>
                           </dd>
                           <dt class="dt dlterm">xDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized input tensor descriptor.
                                 See <a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">x </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">xDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">yDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized output tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">y </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the output tensor
                                 descriptor <samp class="ph codeph">yDesc</samp>.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The function launched successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function does not support the provided configuration.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnActivationForward__ul_j53_2zh_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnActivationForward__ul_j53_2zh_s1b">
                                 <li class="li">The parameter <samp class="ph codeph">mode</samp> has an invalid enumerant value.
                                 </li>
                                 <li class="li">The dimensions <samp class="ph codeph">n,c,h,w</samp> of the input tensor and output
                                    tensors differ.
                                 </li>
                                 <li class="li">The <samp class="ph codeph">datatype</samp> of the input tensor and output tensors
                                    differs.
                                 </li>
                                 <li class="li">The strides <samp class="ph codeph">nStride,cStride,hStride,wStride</samp> of the
                                    input tensor and output tensors differ and in-place operation is used
                                    (i.e., <samp class="ph codeph">x</samp> and <samp class="ph codeph">y</samp> pointers are
                                    equal).
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function failed to launch on the GPU.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnAddTensor"><a name="cudnnAddTensor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnAddTensor" name="cudnnAddTensor" shape="rect">4.3.&nbsp;cudnnAddTensor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnAddTensor(
    cudnnHandle_t                     handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *alpha,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t     aDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *A,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *beta,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t     cDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                             *C)</pre><p class="p">This function adds the scaled values of a bias tensor to another tensor. Each dimension
                           of the bias tensor <samp class="ph codeph">A</samp> must match the corresponding dimension of the
                           destination tensor <samp class="ph codeph">C</samp> or must be equal to 1. In the latter case, the
                           same value from the bias tensor for those dimensions will be used to blend into the
                           <samp class="ph codeph">C</samp> tensor.
                        </p>
                        <div class="note note"><span class="notetitle">Note:</span> Up to dimension 5, all tensor formats are supported. Beyond those dimensions, this
                           routine is not supported
                        </div>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context. See <a class="xref" href="index.html#cudnnHandle_t" shape="rect">cudnnHandle_t.</a></p>
                           </dd>
                           <dt class="dt dlterm">alpha, beta </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointers to scaling factors (in host memory) used to blend the
                                 source value with prior value in the destination tensor as follows: dstValue
                                 = alpha[0]*srcValue + beta[0]*priorDstValue. <a class="xref" href="index.html#general-description" shape="rect">Refer to this
                                    section for additional details.</a></p>
                           </dd>
                           <dt class="dt dlterm">aDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor. See <a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t.</a></p>
                           </dd>
                           <dt class="dt dlterm">A </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointer to data of the tensor described by the
                                 <samp class="ph codeph">aDesc</samp> descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">cDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">C </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input/Output</em>. Pointer to data of the tensor described by the
                                 <samp class="ph codeph">cDesc</samp> descriptor.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The function executed successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function does not support the provided configuration.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">The dimensions of the bias tensor refer to an amount of data that is
                                 incompatible the output tensor dimensions or the <samp class="ph codeph">dataType</samp>
                                 of the two tensor descriptors are different.
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function failed to launch on the GPU.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnBatchNormalizationBackward"><a name="cudnnBatchNormalizationBackward" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnBatchNormalizationBackward" name="cudnnBatchNormalizationBackward" shape="rect">4.4.&nbsp;cudnnBatchNormalizationBackward</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnBatchNormalizationBackward(
      cudnnHandle_t                    handle,
      cudnnBatchNormMode_t             mode,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *alphaDataDiff,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *betaDataDiff,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *alphaParamDiff,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *betaParamDiff,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    xDesc,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *x,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    dyDesc,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *dy,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    dxDesc,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *dx,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    bnScaleBiasDiffDesc,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *bnScale,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *resultBnScaleDiff,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *resultBnBiasDiff,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>                           epsilon,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *savedMean,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *savedInvVariance)</pre><p class="p">This function performs the backward batch normalization layer computation. This layer is
                           based on the paper <a class="xref" href="https://arxiv.org/abs/1502.03167" target="_blank" shape="rect"><em class="ph i"><u class="ph u">Batch Normalization: Accelerating Deep Network Training by
                                    Reducing Internal Covariate Shift,</u></em><u class="ph u"> S. Ioffe, C. Szegedy, 2015.
                                 </u></a></p>
                        <div class="p">
                           <div class="note note"><span class="notetitle">Note:</span> See <samp class="ph codeph"><a class="xref" href="index.html#cudnnDeriveBNTensorDescriptor" shape="rect">cudnnDeriveBNTensorDescriptor</a></samp> for the secondary tensor
                              descriptor generation for the parameters using in this function.
                           </div>
                        </div>
                        <div class="note note"><span class="notetitle">Note:</span> Only 4D and 5D tensors are supported.
                        </div>
                        <div class="note note"><span class="notetitle">Note:</span> The <samp class="ph codeph">epsilon</samp> value has to be the same during training, backpropagation
                           and inference.
                        </div>
                        <div class="note note"><span class="notetitle">Note:</span> Higher performance can be obtained when HW-packed tensors are used for all of
                           <samp class="ph codeph">x, dy, dx</samp>.
                        </div>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN library descriptor. See
                                 <a class="xref" href="index.html#cudnnHandle_t" shape="rect">cudnnHandle_t.</a></p>
                           </dd>
                           <dt class="dt dlterm">mode</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Mode of operation (spatial or per-activation). See <a class="xref" href="index.html#datatypes-reference" shape="rect">cudnnBatchNormMode_t.</a></p>
                           </dd>
                           <dt class="dt dlterm">*alphaDataDiff, *betaDataDiff </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Inputs</em>. Pointers to scaling factors (in host memory) used to blend the
                                 gradient output <samp class="ph codeph">dx</samp> with a prior value in the destination
                                 tensor as follows: 
                              </p>
                              <p class="p"><samp class="ph codeph">dstValue = alphaDataDiff[0]*resultValue +
                                    betaDataDiff[0]*priorDstValue. </samp><a class="xref" href="index.html#scaling-parameters" shape="rect"> Refer to this
                                    section for additional details. </a></p>
                           </dd>
                           <dt class="dt dlterm">*alphaParamDiff, *betaParamDiff </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Inputs</em>. Pointers to scaling factors (in host memory) used to blend the
                                 gradient outputs <samp class="ph codeph">resultBnScaleDiff</samp> and
                                 <samp class="ph codeph">resultBnBiasDiff</samp> with prior values in the destination
                                 tensor as follows: 
                              </p>
                              <p class="p"><samp class="ph codeph">dstValue = alphaParamDiff[0]*resultValue +
                                    betaParamDiff[0]*priorDstValue. </samp><a class="xref" href="index.html#scaling-parameters" shape="rect"> Refer to this
                                    section for additional details. </a></p>
                           </dd>
                           <dt class="dt dlterm">xDesc, dxDesc, dyDesc </dt>
                           <dd class="dd">
                              <p dir="ltr" class="p" id="cudnnBatchNormalizationBackward__docs-internal-guid-55a7d5da-7fff-69f3-5961-0db485bd08ce"><a name="cudnnBatchNormalizationBackward__docs-internal-guid-55a7d5da-7fff-69f3-5961-0db485bd08ce" shape="rect">
                                    <!-- --></a><em class="ph i">Inputs</em>. Handles to the previously initialized tensor
                                 descriptors.
                              </p>
                           </dd>
                           <dt class="dt dlterm">*x</dt>
                           <dd class="dd">
                              <p dir="ltr" class="p" id="cudnnBatchNormalizationBackward__docs-internal-guid-55a7d5da-7fff-69f3-5961-0db485bd08cf"><a name="cudnnBatchNormalizationBackward__docs-internal-guid-55a7d5da-7fff-69f3-5961-0db485bd08cf" shape="rect">
                                    <!-- --></a><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">xDesc</samp>, for the layer’s <samp class="ph codeph">x</samp>
                                 data.
                              </p>
                           </dd>
                           <dt class="dt dlterm">*dy</dt>
                           <dd class="dd">
                              <p dir="ltr" class="p" id="cudnnBatchNormalizationBackward__docs-internal-guid-55a7d5da-7fff-69f3-5961-0db485bd08ca"><a name="cudnnBatchNormalizationBackward__docs-internal-guid-55a7d5da-7fff-69f3-5961-0db485bd08ca" shape="rect">
                                    <!-- --></a><em class="ph i">Inputs</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">dyDesc</samp>, for the backpropagated differential
                                 <samp class="ph codeph">dy</samp> input.
                              </p>
                           </dd>
                           <dt class="dt dlterm">*dx</dt>
                           <dd class="dd">
                              <p dir="ltr" class="p" id="cudnnBatchNormalizationBackward__docs-internal-guid-55a7d5da-7fff-69f3-5961-0db485bd08cc"><a name="cudnnBatchNormalizationBackward__docs-internal-guid-55a7d5da-7fff-69f3-5961-0db485bd08cc" shape="rect">
                                    <!-- --></a><em class="ph i">Inputs</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">dxDesc</samp>, for the resulting differential output
                                 with respect to <samp class="ph codeph">x</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">bnScaleBiasDiffDesc </dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. Shared tensor descriptor for the following five tensors:
                                 <samp class="ph codeph">bnScale, resultBnScaleDiff, resultBnBiasDiff, savedMean,
                                    savedInvVariance</samp>. The dimensions for this tensor descriptor are
                                 dependent on normalization mode. See <a class="xref" href="index.html#cudnnDeriveBNTensorDescriptor" shape="rect">cudnnDeriveBNTensorDescriptor</a>.
                                 <div class="note note"><span class="notetitle">Note:</span> The data type of this
                                    tensor descriptor must be 'float' for FP16 and FP32 input tensors, and
                                    'double' for FP64 input tensors.
                                 </div>
                              </div>
                           </dd>
                           <dt class="dt dlterm">*bnScale</dt>
                           <dd class="dd"><em class="ph i">Input</em>. Pointer in the device memory for the batch normalization
                              <samp class="ph codeph">scale</samp> parameter (in original paper the quantity
                              <samp class="ph codeph">scale</samp> is referred to as gamma). 
                              <div class="note note"><span class="notetitle">Note:</span> The
                                 <samp class="ph codeph">bnBias</samp> parameter is not needed for this layer's
                                 computation.
                              </div>
                           </dd>
                           <dt class="dt dlterm">resultBnScaleDiff, resultBnBiasDiff</dt>
                           <dd class="dd"><em class="ph i">Outputs</em>. Pointers in device memory for the resulting scale and bias
                              differentials computed by this routine. Note that these scale and bias gradients
                              are weight gradients specific to this batch normalization operation, and by
                              definition are not backpropagated.  
                           </dd>
                           <dt class="dt dlterm">epsilon </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Epsilon value used in batch normalization formula. Its value
                                 						should be equal to or greater than the value defined for CUDNN_BN_MIN_EPSILON in
                                 						cudnn.h.  Same <samp class="ph codeph">epsilon</samp> value should be used in forward and
                                 						backward functions.
                              </p>
                           </dd>
                           <dt class="dt dlterm">*savedMean, *savedInvVariance</dt>
                           <dd class="dd"><em class="ph i">Inputs</em>. Optional cache parameters containing saved intermediate results
                              that were computed during the forward pass. For this to work correctly, the
                              layer's <samp class="ph codeph">x</samp> and <samp class="ph codeph">bnScale</samp> data has to remain
                              unchanged until this backward function is called. 
                              <div class="note note"><span class="notetitle">Note:</span> Both these parameters
                                 can be NULL but only at the same time. It is recommended to use this cache
                                 since the memory overhead is relatively small. 
                              </div>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The computation was performed successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function does not support the provided configuration.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnBatchNormalizationBackward__ul_gx5_kph_jt" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnBatchNormalizationBackward__ul_gx5_kph_jt">
                                 <li class="li">Any of the pointers <samp class="ph codeph">alpha, beta, x, dy, dx, bnScale,
                                       resultBnScaleDiff, resultBnBiasDiff</samp> is NULL.
                                 </li>
                                 <li class="li">Number of <samp class="ph codeph">xDesc</samp> or <samp class="ph codeph">yDesc</samp> or
                                    <samp class="ph codeph">dxDesc</samp> tensor descriptor dimensions is not within
                                    the range of [4,5] (only 4D and 5D tensors are supported.)
                                 </li>
                                 <li class="li"><samp class="ph codeph">bnScaleBiasDiffDesc</samp>  dimensions are not 1xCx1x1 for 4D
                                    and 1xCx1x1x1 for 5D for spatial, and are not 1xCxHxW for 4D and
                                    1xCxDxHxW for 5D for per-activation mode.
                                 </li>
                                 <li class="li">Exactly one of <samp class="ph codeph">savedMean</samp>,
                                    <samp class="ph codeph">savedInvVariance</samp> pointers is NULL.
                                 </li>
                                 <li class="li"><samp class="ph codeph">epsilon</samp> value is less than CUDNN_BN_MIN_EPSILON.
                                 </li>
                                 <li class="li">Dimensions or data types mismatch for any pair of <samp class="ph codeph">xDesc, dyDesc,
                                       dxDesc.</samp></li>
                              </ul>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnBatchNormalizationBackwardEx"><a name="cudnnBatchNormalizationBackwardEx" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnBatchNormalizationBackwardEx" name="cudnnBatchNormalizationBackwardEx" shape="rect">4.5.&nbsp;cudnnBatchNormalizationBackwardEx</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnBatchNormalizationBackwardEx (
    cudnnHandle_t                       handle,
    cudnnBatchNormMode_t                mode,
    cudnnBatchNormOps_t                 bnOps,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                          *alphaDataDiff,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                          *betaDataDiff,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                          *alphaParamDiff,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                          *betaParamDiff,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                          *xData,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                          *yData,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       dyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                          *dyData,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       dzDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *dzData,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       dxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *dxData,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       dBnScaleBiasDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                          *bnScaleData,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                          *bnBiasData,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *dBnScaleData,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *dBnBiasData,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>                              epsilon,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                          *savedMean,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                          *savedInvVariance,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnActivationDescriptor_t   activationDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *workspace,
    size_t                              workSpaceSizeInBytes
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *reserveSpace
    size_t                              reserveSpaceSizeInBytes);</pre><p dir="ltr" class="p" id="cudnnBatchNormalizationBackwardEx__docs-internal-guid-12cc3e4e-7fff-da71-b317-47db9b82284a"><a name="cudnnBatchNormalizationBackwardEx__docs-internal-guid-12cc3e4e-7fff-da71-b317-47db9b82284a" shape="rect">
                              <!-- --></a>This function is
                           an extension of the <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormalizationBackward" shape="rect">cudnnBatchNormalizationBackward()</a></samp> for performing the backward
                           batch normalization layer computation with a fast NHWC semi-persistent kernel. This API
                           will trigger the new semi-persistent NHWC kernel when the below conditions are true:
                        </p><a name="cudnnBatchNormalizationBackwardEx__ul_dk3_1w4_sfb" shape="rect">
                           <!-- --></a><ul class="ul" id="cudnnBatchNormalizationBackwardEx__ul_dk3_1w4_sfb">
                           <li dir="ltr" class="li">
                              <p dir="ltr" class="p">All tensors, namely, <samp class="ph codeph">x, y, dz, dy, dx</samp> must be
                                 NHWC-fully packed, and must be of the type CUDNN_DATA_HALF. 
                              </p>
                           </li>
                           <li dir="ltr" class="li">
                              <p dir="ltr" class="p">The tensor C dimension should be a multiple of 4.</p>
                           </li>
                           <li dir="ltr" class="li">
                              <p dir="ltr" class="p">The input parameter <samp class="ph codeph">mode </samp>must be set to
                                 CUDNN_BATCHNORM_SPATIAL_PERSISTENT.
                              </p>
                           </li>
                           <li dir="ltr" class="li">
                              <p dir="ltr" class="p"><samp class="ph codeph">workspace </samp>is not NULL.
                              </p>
                           </li>
                           <li dir="ltr" class="li">
                              <p dir="ltr" class="p"><samp class="ph codeph">workSpaceSizeInBytes </samp>is equal or larger than the
                                 amount required by cudnnGetBatchNormalizationBackwardExWorkspaceSize(). 
                              </p>
                           </li>
                           <li dir="ltr" class="li">
                              <p dir="ltr" class="p"><samp class="ph codeph">reserveSpaceSizeInBytes </samp>is equal or larger than
                                 the amount required by
                                 cudnnGetBatchNormalizationTrainingExReserveSpaceSize().
                              </p>
                           </li>
                           <li dir="ltr" class="li">
                              <p dir="ltr" class="p">The content in <samp class="ph codeph">reserveSpace</samp> stored by <a class="xref" href="index.html#cudnnBatchNormalizationForwardTrainingEx" shape="rect">cudnnBatchNormalizationForwardTrainingEx()</a> must be preserved.
                              </p>
                           </li>
                        </ul>
                        <p dir="ltr" class="p">If <samp class="ph codeph">workspace</samp> is NULL and <samp class="ph codeph">workSpaceSizeInBytes</samp>
                           of zero is passed in, this API will function exactly like the non-extended function
                           <samp class="ph codeph">cudnnBatchNormalizationBackward</samp>.
                        </p>
                        <p dir="ltr" class="p">This workspace is not required to be clean. Moreover, the workspace does not
                           have to remain unchanged between the forward and backward pass, as it is not used for
                           passing any information.
                        </p>
                        <p dir="ltr" class="p">This extended function can accept a <samp class="ph codeph">*workspace </samp>pointer to the
                           GPU workspace, and <samp class="ph codeph">workSpaceSizeInBytes, </samp>the size of the workspace,
                           from the user.
                        </p>
                        <p dir="ltr" class="p">The <samp class="ph codeph">bnOps </samp>input can be used to set this function to perform
                           either only the batch normalization, or batch normalization followed by activation, or
                           batch normalization followed by element-wise addition and then activation. 
                        </p>
                        <p dir="ltr" class="p">Only 4D and 5D tensors are supported. The <samp class="ph codeph">epsilon</samp> value has to
                           be the same during the training, the backpropagation and the inference.
                        </p>
                        <p class="p">When the tensor layout is NCHW, higher performance can be obtained when HW-packed tensors
                           are used for <samp class="ph codeph">x, dy, dx</samp>.
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p dir="ltr" class="p" id="cudnnBatchNormalizationBackwardEx__docs-internal-guid-f8a203ce-7fff-2534-2441-0f5efa63bac6"><a name="cudnnBatchNormalizationBackwardEx__docs-internal-guid-f8a203ce-7fff-2534-2441-0f5efa63bac6" shape="rect">
                                    <!-- --></a><em class="ph i">Input</em>. Handle to a previously created cuDNN library descriptor.
                                 See <a class="xref" href="index.html#cudnnHandle_t" shape="rect">cudnnHandle_t.</a></p>
                           </dd>
                           <dt class="dt dlterm">mode</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Mode of operation (spatial or per-activation). See <a class="xref" href="index.html#datatypes-reference" shape="rect">cudnnBatchNormMode_t.</a></p>
                           </dd>
                           <dt class="dt dlterm">bnOps</dt>
                           <dd class="dd"><em class="ph i">Input</em>. Mode of operation for the fast NHWC kernel. See <a class="xref" href="index.html#datatypes-reference" shape="rect">cudnnBatchNormOps_t.</a>. This input can be used to set this function to
                              perform either only the batch normalization, or batch normalization followed by
                              activation, or batch normalization followed by element-wise addition and then
                              activation. 
                           </dd>
                           <dt class="dt dlterm">*alphaDataDiff, *betaDataDiff </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Inputs</em>. Pointers to scaling factors (in host memory) used to blend the
                                 gradient output <samp class="ph codeph">dx</samp> with a prior value in the destination
                                 tensor as follows: 
                              </p>
                              <p class="p"><samp class="ph codeph">dstValue = alpha[0]*resultValue + beta[0]*priorDstValue.
                                    </samp><a class="xref" href="index.html#general-description" shape="rect"> Refer
                                    to this section for additional details. </a></p>
                           </dd>
                           <dt class="dt dlterm">*alphaParamDiff, *betaParamDiff </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Inputs</em>. Pointers to scaling factors (in host memory) used to blend the
                                 gradient outputs <samp class="ph codeph">dBnScaleData</samp> and
                                 <samp class="ph codeph">dBnBiasData</samp> with prior values in the destination tensor
                                 as follows: 
                              </p>
                              <p class="p"><samp class="ph codeph">dstValue = alpha[0]*resultValue + beta[0]*priorDstValue.
                                    </samp><a class="xref" href="index.html#general-description" shape="rect"> Refer
                                    to this section for additional details. </a></p>
                           </dd>
                           <dt class="dt dlterm">xDesc, *x,yDesc, *yData, dyDesc, *dyData, dzDesc, *dzData, dxDesc, *dx/dt</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Inputs</em>. Tensor descriptors and pointers in the device memory for the
                                 layer's <samp class="ph codeph">x</samp> data, back propagated differential
                                 <samp class="ph codeph">dy</samp> (inputs), the optional <samp class="ph codeph">y</samp> input
                                 data, the optional <samp class="ph codeph">dz</samp> output, and the <samp class="ph codeph">dx</samp>
                                 output, which is the resulting differential with respect to
                                 <samp class="ph codeph">x.</samp> See <a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t.</a></p>
                           </dd>
                           <dt class="dt dlterm">dBnScaleBiasDesc</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Shared tensor descriptor for the following six tensors:
                                 <samp class="ph codeph">bnScaleData, bnBiasData, dBnScaleData, dBnBiasData, savedMean,
                                    and savedInvVariance. </samp>See <a class="xref" href="index.html#cudnnDeriveBNTensorDescriptor" shape="rect">cudnnDeriveBNTensorDescriptor</a>.
                              </p>
                              <div class="p">The dimensions for this tensor descriptor are dependent on normalization
                                 mode. 
                                 <div class="note note"><span class="notetitle">Note:</span> Note: The data type of this tensor descriptor must be 'float'
                                    for FP16 and FP32 input tensors, and 'double' for FP64 input tensors.
                                    
                                 </div>
                                 
                                 See <a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t.</a></div>
                           </dd>
                           <dt class="dt dlterm">*bnScaleData </dt>
                           <dd class="dd">
                              <p dir="ltr" class="p" id="cudnnBatchNormalizationBackwardEx__docs-internal-guid-63df85d3-7fff-42fb-0b19-8013173beee8"><a name="cudnnBatchNormalizationBackwardEx__docs-internal-guid-63df85d3-7fff-42fb-0b19-8013173beee8" shape="rect">
                                    <!-- --></a><em class="ph i">Input</em>. Pointer in the device memory for the batch normalization
                                 scale parameter (in the <a class="xref" href="https://arxiv.org/abs/1502.03167" target="_blank" shape="rect">original paper</a> the quantity scale
                                 is referred to as gamma).
                              </p>
                           </dd>
                           <dt class="dt dlterm">*bnBiasData</dt>
                           <dd class="dd"><em class="ph i">Input</em>. Pointers in the device memory for the batch normalization bias
                              parameter (in the <a class="xref" href="https://arxiv.org/abs/1502.03167" target="_blank" shape="rect">original paper</a> bias is referred to as beta). This
                              parameter is used only when activation should be performed. 
                           </dd>
                           <dt class="dt dlterm"><strong class="ph b">*dBnScaleData, <strong class="ph b">dBnBiasData</strong></strong></dt>
                           <dd class="dd"><em class="ph i">Inputs</em>. Pointers in the device memory for the gradients of
                              <samp class="ph codeph">bnScaleData</samp> and <samp class="ph codeph">bnBiasData</samp>, respectively.  
                           </dd>
                           <dt class="dt dlterm">epsilon </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Epsilon value used in batch normalization formula. Its value
                                 						should be equal to or greater than the value defined for CUDNN_BN_MIN_EPSILON in
                                 						cudnn.h. Same epsilon value should be used in forward and backward functions.
                              </p>
                           </dd>
                           <dt class="dt dlterm">*savedMean, *savedInvVariance</dt>
                           <dd class="dd"><em class="ph i">Inputs</em>. Optional cache parameters containing saved intermediate results
                              computed during the forward pass. For this to work correctly, the layer's
                              <samp class="ph codeph">x</samp> and <samp class="ph codeph">bnScaleData</samp>,
                              <samp class="ph codeph">bnBiasData</samp> data has to remain unchanged until this backward
                              function is called. Note that both these parameters can be NULL but only at the
                              same time. It is recommended to use this cache since the memory overhead is
                              relatively small. 
                           </dd>
                           <dt class="dt dlterm">activationDesc</dt>
                           <dd class="dd"><em class="ph i">Input</em>. Tensor descriptor for the activation operation.
                           </dd>
                           <dt class="dt dlterm">workspace</dt>
                           <dd class="dd"><em class="ph i">Input</em>. Pointer to the GPU workspace. If <samp class="ph codeph">workspace</samp> is
                              NULL and <samp class="ph codeph">workSpaceSizeInBytes</samp> of zero is passed in, then this
                              API will function exactly like the non-extended function <a class="xref" href="index.html#cudnnBatchNormalizationBackward" shape="rect">cudnnBatchNormalizationBackward()</a>.
                           </dd>
                           <dt class="dt dlterm">workSpaceSizeInBytes</dt>
                           <dd class="dd"><em class="ph i">Input</em>. The size of the workspace. Must be large enough to trigger the
                              fast NHWC semi-persistent kernel by this function. 
                           </dd>
                           <dt class="dt dlterm">*reserveSpace</dt>
                           <dd class="dd"><em class="ph i">Input</em>. Pointer to the GPU workspace for the
                              <samp class="ph codeph">reserveSpace</samp>.
                           </dd>
                           <dt class="dt dlterm">reserveSpaceSizeInBytes</dt>
                           <dd class="dd"><em class="ph i">Input</em>. The size of the <samp class="ph codeph">reserveSpace</samp>. Must be equal or
                              larger than the amount required by
                              <samp class="ph codeph">cudnnGetBatchNormalizationTrainingExReserveSpaceSize()</samp>.
                              
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The computation was performed successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function does not support the provided configuration.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnBatchNormalizationBackwardEx__ul_gx5_kph_jt" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnBatchNormalizationBackwardEx__ul_gx5_kph_jt">
                                 <li class="li">Any of the pointers <samp class="ph codeph">alphaDataDiff, betaDataDiff, alphaParamDiff,
                                       betaParamDiff, x, dy, dx, bnScale, resultBnScaleDiff,
                                       resultBnBiasDiff </samp> is NULL.
                                 </li>
                                 <li class="li">Number of <samp class="ph codeph">xDesc</samp> or <samp class="ph codeph">yDesc</samp> or
                                    <samp class="ph codeph">dxDesc</samp> tensor descriptor dimensions is not within
                                    the range of [4,5] (only 4D and 5D tensors are supported.)
                                 </li>
                                 <li class="li"><samp class="ph codeph">dBnScaleBiasDesc</samp> dimensions not 1xCx1x1 for 4D and
                                    1xCx1x1x1 for 5D for spatial, and are not 1xCxHxW for 4D and 1xCxDxHxW
                                    for 5D for per-activation mode. .
                                 </li>
                                 <li class="li">Exactly one of <samp class="ph codeph">savedMean</samp>,
                                    <samp class="ph codeph">savedInvVariance</samp> pointers is NULL.
                                 </li>
                                 <li class="li"><samp class="ph codeph">epsilon</samp> value is less than CUDNN_BN_MIN_EPSILON.
                                 </li>
                                 <li class="li">Dimensions or data types mismatch for any pair of
                                    <samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">dyDesc</samp>,
                                    <samp class="ph codeph">dxDesc</samp>.
                                 </li>
                              </ul>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnBatchNormalizationForwardInference"><a name="cudnnBatchNormalizationForwardInference" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnBatchNormalizationForwardInference" name="cudnnBatchNormalizationForwardInference" shape="rect">4.6.&nbsp;cudnnBatchNormalizationForwardInference</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve"> cudnnStatus_t cudnnBatchNormalizationForwardInference(
      cudnnHandle_t                    handle,
      cudnnBatchNormMode_t             mode,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *alpha,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *beta,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    xDesc,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *x,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    yDesc,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *y,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    bnScaleBiasMeanVarDesc,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *bnScale,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *bnBias,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *estimatedMean,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *estimatedVariance,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>                           epsilon)</pre><p class="p">This function performs the forward batch normalization layer computation for the
                           inference phase. This layer is based on the paper <a class="xref" href="https://arxiv.org/abs/1502.03167" target="_blank" shape="rect"><em class="ph i">Batch
                                 Normalization: Accelerating Deep Network Training by Reducing Internal Covariate
                                 Shift</em>, S. Ioffe, C. Szegedy, 2015</a>.
                        </p>
                        <div class="note note"><span class="notetitle">Note:</span> See <samp class="ph codeph"><a class="xref" href="index.html#cudnnDeriveBNTensorDescriptor" shape="rect">cudnnDeriveBNTensorDescriptor</a></samp> for the secondary tensor
                           descriptor generation for the parameters using in this function.
                        </div>
                        <div class="note note"><span class="notetitle">Note:</span> Only 4D and 5D tensors are supported.
                        </div>
                        <div class="note note"><span class="notetitle">Note:</span> The input transformation performed by this function is defined as: 
                           <p class="p"></p><samp class="ph codeph">y =
                              beta*y + alpha *[bnBias + (bnScale * (x-estimatedMean)/sqrt(epsilon +
                              estimatedVariance)] </samp></div>
                        <div class="note note"><span class="notetitle">Note:</span> The <samp class="ph codeph">epsilon</samp> value has to be the same during training, backpropagation
                           and inference.
                        </div>
                        <div class="note note"><span class="notetitle">Note:</span> For training phase use <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormalizationForwardTraining" shape="rect">cudnnBatchNormalizationForwardTraining</a></samp>.
                        </div>
                        <div class="note note"><span class="notetitle">Note:</span> Higher performance can be obtained when HW-packed tensors are used for all of
                           <samp class="ph codeph">x</samp> and <samp class="ph codeph">dx</samp>.
                        </div>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN library descriptor. See
                                 <a class="xref" href="index.html#cudnnHandle_t" shape="rect">cudnnHandle_t.</a></p>
                           </dd>
                           <dt class="dt dlterm">mode </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Mode of operation (spatial or per-activation). See <a class="xref" href="index.html#datatypes-reference" shape="rect">cudnnBatchNormMode_t.</a></p>
                           </dd>
                           <dt class="dt dlterm">alpha, beta </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Inputs</em>. Pointers to scaling factors (in host memory) used to blend the
                                 layer output value with prior value in the destination tensor as follows: 
                              </p>
                              <p class="p"><samp class="ph codeph">dstValue = alpha[0]*resultValue + beta[0]*priorDstValue.</samp><a class="xref" href="index.html#general-description" shape="rect"> Refer to this
                                    section for additional details. </a></p>
                           </dd>
                           <dt class="dt dlterm">xDesc, yDesc</dt>
                           <dd class="dd">
                              <p dir="ltr" class="p" id="cudnnBatchNormalizationForwardInference__docs-internal-guid-c79bc280-7fff-4710-67ed-6165bb5c74f2"><a name="cudnnBatchNormalizationForwardInference__docs-internal-guid-c79bc280-7fff-4710-67ed-6165bb5c74f2" shape="rect">
                                    <!-- --></a><em class="ph i">Input</em>. Handles to the previously initialized tensor
                                 descriptors.
                              </p>
                           </dd>
                           <dt class="dt dlterm">*x</dt>
                           <dd class="dd">
                              <p dir="ltr" class="p" id="cudnnBatchNormalizationForwardInference__docs-internal-guid-c79bc280-7fff-4710-67ed-6165bb5c74f3"><a name="cudnnBatchNormalizationForwardInference__docs-internal-guid-c79bc280-7fff-4710-67ed-6165bb5c74f3" shape="rect">
                                    <!-- --></a><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">xDesc</samp>, for the layer’s <samp class="ph codeph">x</samp> input
                                 data.
                              </p>
                           </dd>
                           <dt class="dt dlterm">*y</dt>
                           <dd class="dd">
                              <p dir="ltr" class="p" id="cudnnBatchNormalizationForwardInference__docs-internal-guid-c79bc280-7fff-4710-67ed-6165bb5c74f4"><a name="cudnnBatchNormalizationForwardInference__docs-internal-guid-c79bc280-7fff-4710-67ed-6165bb5c74f4" shape="rect">
                                    <!-- --></a><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">yDesc</samp>, for the <samp class="ph codeph">y</samp>output of the
                                 batch normalization layer.
                              </p>
                           </dd>
                           <dt class="dt dlterm">bnScaleBiasMeanVarDesc, bnScale, bnBias </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Inputs</em>. Tensor descriptor and pointers in device memory for the batch
                                 normalization scale and bias parameters (in the <a class="xref" href="https://arxiv.org/abs/1502.03167" target="_blank" shape="rect">original paper</a> bias is referred to as beta and scale as
                                 gamma).
                              </p>
                           </dd>
                           <dt class="dt dlterm">estimatedMean, estimatedVariance </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Inputs</em>. Mean and variance tensors (these have the same descriptor as
                                 the bias and scale). The  <samp class="ph codeph">resultRunningMean</samp> and
                                 <samp class="ph codeph">resultRunningVariance</samp>, accumulated during the training
                                 phase from the <samp class="ph codeph">cudnnBatchNormalizationForwardTraining()</samp>
                                 call, should be passed as inputs here.
                              </p>
                           </dd>
                           <dt class="dt dlterm">epsilon </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Epsilon value used in the batch normalization formula. Its
                                 						value should be equal to or greater than the value defined for
                                 						CUDNN_BN_MIN_EPSILON in cudnn.h. 
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The computation was performed successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function does not support the provided configuration.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnBatchNormalizationForwardInference__ul_wv1_blg_jt" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnBatchNormalizationForwardInference__ul_wv1_blg_jt">
                                 <li class="li">One of the pointers <samp class="ph codeph">alpha, beta, x, y, bnScale, bnBias,
                                       estimatedMean, estimatedInvVariance</samp> is NULL.
                                 </li>
                                 <li class="li">Number of <samp class="ph codeph">xDesc</samp> or <samp class="ph codeph">yDesc</samp> tensor
                                    descriptor dimensions is not within the range of [4,5] (only 4D and 5D
                                    tensors are supported.)
                                 </li>
                                 <li class="li"><samp class="ph codeph">bnScaleBiasMeanVarDesc</samp> dimensions are not 1xCx1x1 for
                                    4D and 1xCx1x1x1 for 5D for spatial, and are not 1xCxHxW for 4D and
                                    1xCxDxHxW for 5D for per-activation mode.
                                 </li>
                                 <li class="li"><samp class="ph codeph">epsilon</samp> value is less than CUDNN_BN_MIN_EPSILON.
                                 </li>
                                 <li class="li">Dimensions or data types mismatch for <samp class="ph codeph">xDesc</samp>,
                                    <samp class="ph codeph">yDesc.</samp></li>
                              </ul>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnBatchNormalizationForwardTraining"><a name="cudnnBatchNormalizationForwardTraining" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnBatchNormalizationForwardTraining" name="cudnnBatchNormalizationForwardTraining" shape="rect">4.7.&nbsp;cudnnBatchNormalizationForwardTraining</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve"> cudnnStatus_t cudnnBatchNormalizationForwardTraining(
      cudnnHandle_t                    handle,
      cudnnBatchNormMode_t             mode,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *alpha,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *beta,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    xDesc,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *x,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    yDesc,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *y,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    bnScaleBiasMeanVarDesc,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *bnScale,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *bnBias,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>                           exponentialAverageFactor,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *resultRunningMean,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *resultRunningVariance,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>                           epsilon,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *resultSaveMean,
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *resultSaveInvVariance)</pre><p class="p">This function performs the forward batch normalization layer computation for the training
                           phase. This layer is based on the paper <a class="xref" href="https://arxiv.org/abs/1502.03167" target="_blank" shape="rect"><em class="ph i">Batch Normalization: Accelerating Deep Network
                                 Training by Reducing Internal Covariate Shift</em>, S. Ioffe, C. Szegedy,
                              2015</a>.
                        </p>
                        <div class="note note"><span class="notetitle">Note:</span> See <samp class="ph codeph"><a class="xref" href="index.html#cudnnDeriveBNTensorDescriptor" shape="rect">cudnnDeriveBNTensorDescriptor</a></samp> for the secondary tensor
                           descriptor generation for the parameters using in this function.
                        </div>
                        <div class="note note"><span class="notetitle">Note:</span> Only 4D and 5D tensors are supported.
                        </div>
                        <div class="note note"><span class="notetitle">Note:</span> The <span class="keyword apiname">epsilon</span> value has to be the same during training,
                           backpropagation and inference.
                        </div>
                        <div class="note note"><span class="notetitle">Note:</span> For inference phase use
                           <span class="keyword apiname">cudnnBatchNormalizationForwardInference</span>.
                        </div>
                        <div class="note note"><span class="notetitle">Note:</span> Higher performance can be obtained when HW-packed tensors are used for both
                           <span class="keyword apiname">x</span> and <span class="keyword apiname">y.</span></div>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p">Handle to a previously created cuDNN library descriptor. See <a class="xref" href="index.html#cudnnHandle_t" shape="rect">cudnnHandle_t.</a></p>
                           </dd>
                           <dt class="dt dlterm">mode </dt>
                           <dd class="dd">
                              <p class="p">Mode of operation (spatial or per-activation). See <a class="xref" href="index.html#datatypes-reference" shape="rect">cudnnBatchNormMode_t.</a></p>
                           </dd>
                           <dt class="dt dlterm">alpha, beta </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Inputs</em>. Pointers to scaling factors (in host memory) used to blend the
                                 layer output value with prior value in the destination tensor as follows: 
                              </p>
                              <p class="p"><samp class="ph codeph">dstValue = alpha[0]*resultValue + beta[0]*priorDstValue.
                                    </samp><a class="xref" href="index.html#scaling-parameters" shape="rect"> Refer
                                    to this section for additional details. </a></p>
                           </dd>
                           <dt class="dt dlterm">xDesc, yDesc</dt>
                           <dd class="dd">
                              <p class="p">Tensor descriptors and pointers in device memory for the layer's
                                 <samp class="ph codeph">x</samp> and <samp class="ph codeph">y</samp> data. See <a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t.</a></p>
                           </dd>
                           <dt class="dt dlterm">*x</dt>
                           <dd class="dd">
                              <p dir="ltr" class="p" id="cudnnBatchNormalizationForwardTraining__docs-internal-guid-c79bc280-7fff-4710-67ed-6165bb5c74f3"><a name="cudnnBatchNormalizationForwardTraining__docs-internal-guid-c79bc280-7fff-4710-67ed-6165bb5c74f3" shape="rect">
                                    <!-- --></a><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">xDesc</samp>, for the layer’s <samp class="ph codeph">x</samp> input
                                 data.
                              </p>
                           </dd>
                           <dt class="dt dlterm">*y</dt>
                           <dd class="dd">
                              <p dir="ltr" class="p" id="cudnnBatchNormalizationForwardTraining__docs-internal-guid-c79bc280-7fff-4710-67ed-6165bb5c74f4"><a name="cudnnBatchNormalizationForwardTraining__docs-internal-guid-c79bc280-7fff-4710-67ed-6165bb5c74f4" shape="rect">
                                    <!-- --></a><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">yDesc</samp>, for the <samp class="ph codeph">y</samp>output of the
                                 batch normalization layer.
                              </p>
                           </dd>
                           <dt class="dt dlterm">bnScaleBiasMeanVarDesc </dt>
                           <dd class="dd">
                              <p class="p">Shared tensor descriptor desc for the secondary tensor that was derived by
                                 <a class="xref" href="index.html#cudnnDeriveBNTensorDescriptor" shape="rect">cudnnDeriveBNTensorDescriptor</a>. The dimensions for this
                                 tensor descriptor are dependent on the normalization mode.
                              </p>
                           </dd>
                           <dt class="dt dlterm">bnScale, bnBias</dt>
                           <dd class="dd"><em class="ph i">Inputs</em>. Pointers in device memory for the batch normalization scale and
                              bias parameters (in the <a class="xref" href="https://arxiv.org/abs/1502.03167" target="_blank" shape="rect">original paper</a> bias is referred to as
                              beta and scale as gamma). Note that <samp class="ph codeph">bnBias</samp> parameter can
                              replace the previous layer's bias parameter for improved efficiency.
                           </dd>
                           <dt class="dt dlterm">exponentialAverageFactor</dt>
                           <dd class="dd"><em class="ph i">Input</em>. Factor used in the moving average computation as
                              follows:
                              <p class="p"></p><samp class="ph codeph">runningMean = runningMean*(1-factor) +
                                 newMean*factor</samp><p class="p"></p>
                              
                              Use a <samp class="ph codeph">factor=1/(1+n)</samp> at
                              <samp class="ph codeph">N</samp>-th call to the function to get Cumulative Moving Average
                              (CMA) behavior such that:
                              <p class="p"></p><samp class="ph codeph">CMA[n] = (x[1]+...+x[n])/n</samp>. This
                              is proved below:
                              <p class="p"></p>
                              
                              Writing <samp class="ph codeph">CMA[n+1] =
                                 (n*CMA[n]+x[n+1])/(n+1)</samp><p class="p"></p><samp class="ph codeph">= ((n+1)*CMA[n]-CMA[n])/(n+1) +
                                 x[n+1]/(n+1) </samp><p class="p"></p><samp class="ph codeph">= CMA[n]*(1-1/(n+1))+x[n+1]*1/(n+1)
                                 </samp><p class="p"></p><samp class="ph codeph">= CMA[n]*(1-factor) + x(n+1)*factor.</samp></dd>
                           <dt class="dt dlterm">resultRunningMean, resultRunningVariance </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Inputs/Outputs</em>. Running mean and variance tensors (these have the same
                                 						descriptor as the bias and scale). Both of these pointers can be NULL but
                                 						only at the same time. The value stored in
                                 							<samp class="ph codeph">resultRunningVariance</samp> (or passed as an input in
                                 						inference mode) is the sample variance, and is the moving average of
                                 						variance[x] where variance is computed either over batch or spatial+batch
                                 						dimensions depending on the mode. If these pointers are not NULL, the
                                 						tensors should be initialized to some reasonable values or to 0.
                              </p>
                           </dd>
                           <dt class="dt dlterm">epsilon </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Epsilon value used in the batch normalization formula. Its
                                 						value should be equal to or greater than the value defined for
                                 						CUDNN_BN_MIN_EPSILON in cudnn.h. Same <samp class="ph codeph">epsilon</samp> value should be
                                 						used in forward and backward functions.
                              </p>
                           </dd>
                           <dt class="dt dlterm">resultSaveMean, resultSaveInvVariance</dt>
                           <dd class="dd"><em class="ph i">Outputs</em>. Optional cache to save intermediate results computed during the
                              forward pass. These buffers can be used to speed up the backward pass when
                              supplied to the <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormalizationBackward" shape="rect">cudnnBatchNormalizationBackward()</a></samp> function. The
                              intermediate results stored in <samp class="ph codeph">resultSaveMean</samp> and
                              <samp class="ph codeph">resultSaveInvVariance</samp> buffers should not be used directly
                              by the user. Depending on the batch normalization mode, the results stored in
                              <samp class="ph codeph">resultSaveInvVariance</samp> may vary. For the cache to work
                              correctly, the input layer data must remain unchanged until the backward
                              function is called. Note that both parameters can be NULL but only at the same
                              time. In such a case intermediate statistics will not be saved, and
                              <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormalizationBackward" shape="rect">cudnnBatchNormalizationBackward()</a></samp> will have to
                              re-compute them. It is recommended to use this cache as the memory overhead is
                              relatively small because these tensors have a much lower product of dimensions
                              than the data tensors. 
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The computation was performed successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function does not support the provided configuration.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnBatchNormalizationForwardTraining__ul_qnn_k4g_jt" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnBatchNormalizationForwardTraining__ul_qnn_k4g_jt">
                                 <li class="li">One of the pointers <samp class="ph codeph">alpha, beta, x, y, bnScale, bnBias</samp>
                                    is NULL.
                                 </li>
                                 <li class="li">Number of <samp class="ph codeph">xDesc</samp> or <samp class="ph codeph">yDesc</samp> tensor
                                    descriptor dimensions is not within the range of [4,5] (only 4D and 5D
                                    tensors are supported.)
                                 </li>
                                 <li class="li"><samp class="ph codeph">bnScaleBiasMeanVarDesc</samp> dimensions are not 1xCx1x1 for
                                    4D and 1xCx1x1x1 for 5D for spatial, and are not 1xCxHxW for 4D and
                                    1xCxDxHxW for 5D for per-activation mode.
                                 </li>
                                 <li class="li">Exactly one of <samp class="ph codeph">resultSaveMean</samp>,
                                    <samp class="ph codeph">resultSaveInvVariance</samp> pointers is NULL.
                                 </li>
                                 <li class="li">Exactly one of <samp class="ph codeph">resultRunningMean</samp>,
                                    <samp class="ph codeph">resultRunningInvVariance</samp> pointers is NULL.
                                 </li>
                                 <li class="li"><samp class="ph codeph">epsilon</samp> value is less than CUDNN_BN_MIN_EPSILON.
                                 </li>
                                 <li class="li">Dimensions or data types mismatch for <samp class="ph codeph">xDesc</samp>,
                                    <samp class="ph codeph">yDesc</samp></li>
                              </ul>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnBatchNormalizationForwardTrainingEx"><a name="cudnnBatchNormalizationForwardTrainingEx" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnBatchNormalizationForwardTrainingEx" name="cudnnBatchNormalizationForwardTrainingEx" shape="rect">4.8.&nbsp;cudnnBatchNormalizationForwardTrainingEx</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve"> cudnnStatus_t cudnnBatchNormalizationForwardTrainingEx(
    cudnnHandle_t                       handle,
    cudnnBatchNormMode_t                mode,
    cudnnBatchNormOps_t                 bnOps,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                          *alpha,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                          *beta,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                          *xData,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       zDesc, 
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                          *zData, 
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *yData,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       bnScaleBiasMeanVarDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                          *bnScaleData,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                          *bnBiasData, 
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>                              exponentialAverageFactor,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *resultRunningMeanData,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *resultRunningVarianceData,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>                              epsilon,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *saveMean,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *saveInvVariance,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnActivationDescriptor_t   activationDesc, 
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *workspace,
    size_t                              workSpaceSizeInBytes
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *reserveSpace
    size_t                              reserveSpaceSizeInBytes);</pre><p class="p">This function is an extension of the
                           <samp class="ph codeph">cudnnBatchNormalizationForwardTraining()</samp> for performing the forward
                           batch normalization layer computation. 
                        </p>
                        <p dir="ltr" class="p" id="cudnnBatchNormalizationForwardTrainingEx__docs-internal-guid-12cc3e4e-7fff-da71-b317-47db9b82284a"><a name="cudnnBatchNormalizationForwardTrainingEx__docs-internal-guid-12cc3e4e-7fff-da71-b317-47db9b82284a" shape="rect">
                              <!-- --></a>This API will
                           trigger the new semi-persistent NHWC kernel when the below conditions are true:
                        </p><a name="cudnnBatchNormalizationForwardTrainingEx__ul_dk3_1w4_sfb" shape="rect">
                           <!-- --></a><ul class="ul" id="cudnnBatchNormalizationForwardTrainingEx__ul_dk3_1w4_sfb">
                           <li dir="ltr" class="li">
                              <p dir="ltr" class="p">All tensors, namely, <samp class="ph codeph">x, y, dz, dy, dx</samp> must be
                                 NHWC-fully packed, and must be of the type CUDNN_DATA_HALF. 
                              </p>
                           </li>
                           <li dir="ltr" class="li">
                              <p dir="ltr" class="p">The tensor C dimension should be a multiple of 4.</p>
                           </li>
                           <li dir="ltr" class="li">
                              <p dir="ltr" class="p">The input parameter <samp class="ph codeph">mode </samp>must be set to
                                 CUDNN_BATCHNORM_SPATIAL_PERSISTENT.
                              </p>
                           </li>
                           <li dir="ltr" class="li">
                              <p dir="ltr" class="p"><samp class="ph codeph">workspace </samp>is not NULL.
                              </p>
                           </li>
                           <li dir="ltr" class="li">
                              <p dir="ltr" class="p"><samp class="ph codeph">workSpaceSizeInBytes </samp>is equal or larger than the
                                 amount required by
                                 <samp class="ph codeph">cudnnGetBatchNormalizationForwardTrainingExWorkspaceSize</samp>().
                                 
                              </p>
                           </li>
                           <li dir="ltr" class="li">
                              <p dir="ltr" class="p"><samp class="ph codeph">reserveSpaceSizeInBytes </samp>is equal or larger than the
                                 amount required by
                                 <samp class="ph codeph">cudnnGetBatchNormalizationTrainingExReserveSpaceSize()</samp>.
                              </p>
                           </li>
                           <li dir="ltr" class="li">
                              <p dir="ltr" class="p">The content in <samp class="ph codeph">reserveSpace</samp> stored by <a class="xref" href="index.html#cudnnBatchNormalizationForwardTrainingEx" shape="rect">cudnnBatchNormalizationForwardTrainingEx()</a> must be preserved.
                              </p>
                           </li>
                        </ul>
                        <p dir="ltr" class="p">If <samp class="ph codeph">workspace</samp> is NULL and <samp class="ph codeph">workSpaceSizeInBytes</samp>
                           of zero is passed in, this API will function exactly like the non-extended function
                           <samp class="ph codeph">cudnnBatchNormalizationForwardTraining()</samp>.
                        </p>
                        <p dir="ltr" class="p">This workspace is not required to be clean. Moreover, the workspace does not
                           have to remain unchanged between the forward and backward pass, as it is not used for
                           passing any information.
                        </p>
                        <p dir="ltr" class="p">This extended function can accept a <samp class="ph codeph">*workspace </samp>pointer to the
                           GPU workspace, and <samp class="ph codeph">workSpaceSizeInBytes, </samp>the size of the workspace,
                           from the user.
                        </p>
                        <p dir="ltr" class="p">The <samp class="ph codeph">bnOps </samp>input can be used to set this function to perform
                           either only the batch normalization, or batch normalization followed by activation, or
                           batch normalization followed by element-wise addition and then activation. 
                        </p>
                        <p dir="ltr" class="p">Only 4D and 5D tensors are supported. The <samp class="ph codeph">epsilon</samp> value has to
                           be the same during the training, the backpropagation and the inference.
                        </p>
                        <p class="p">When the tensor layout is NCHW, higher performance can be obtained when HW-packed tensors
                           are used for <samp class="ph codeph">x, dy, dx</samp>.
                        </p>
                        <p class="p"></p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN library descriptor. See
                                 <a class="xref" href="index.html#cudnnHandle_t" shape="rect">cudnnHandle_t.</a></p>
                           </dd>
                           <dt class="dt dlterm">mode </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Mode of operation (spatial or per-activation). See <a class="xref" href="index.html#datatypes-reference" shape="rect">cudnnBatchNormMode_t.</a></p>
                           </dd>
                           <dt class="dt dlterm">bnOps</dt>
                           <dd class="dd"><em class="ph i">Input</em>. Mode of operation for the fast NHWC kernel. See <a class="xref" href="index.html#datatypes-reference" shape="rect">cudnnBatchNormOps_t.</a>. This input can be used to set this function to
                              perform either only the batch normalization, or batch normalization followed by
                              activation, or batch normalization followed by element-wise addition and then
                              activation. 
                           </dd>
                           <dt class="dt dlterm">*alpha, *beta </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Inputs</em>. Pointers to scaling factors (in host memory) used to blend the
                                 layer output value with prior value in the destination tensor as follows: 
                              </p>
                              <p class="p"><samp class="ph codeph">dstValue = alpha[0]*resultValue + beta[0]*priorDstValue.</samp><a class="xref" href="index.html#general-description" shape="rect"> Refer to this
                                    section for additional details. </a></p>
                           </dd>
                           <dt class="dt dlterm">xDesc, *xData, zDesc, *zData, yDesc, *yData</dt>
                           <dd class="dd">
                              <p class="p">Tensor descriptors and pointers in device memory for the layer's
                                 <samp class="ph codeph">x</samp> and <samp class="ph codeph">y</samp> data, and for the optional
                                 <samp class="ph codeph">z</samp> tensor input for residual addition to the result of
                                 the batch normalization operation, prior to the activation. The optional
                                 tensor input <samp class="ph codeph">z</samp> should be exact the same size as
                                 <samp class="ph codeph">x</samp> and the final output <samp class="ph codeph">y</samp>. This
                                 <samp class="ph codeph">z</samp> input is element-wise added to the output of batch
                                 normalization. This addition optionally happens after batch normalization
                                 and before the activation. See <a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t.</a></p>
                           </dd>
                           <dt class="dt dlterm">bnScaleBiasMeanVarDesc </dt>
                           <dd class="dd">
                              <p class="p">Shared tensor descriptor desc for the secondary tensor that was derived by
                                 <a class="xref" href="index.html#cudnnDeriveBNTensorDescriptor" shape="rect">cudnnDeriveBNTensorDescriptor()</a>. The dimensions for this tensor
                                 descriptor are dependent on the normalization mode. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">*bnScaleData, *bnBiasData</dt>
                           <dd class="dd"><em class="ph i">Inputs</em>. Pointers in the device memory for the for the batch normalization
                              scale and bias data. In the <a class="xref" href="https://arxiv.org/abs/1502.03167" target="_blank" shape="rect">original paper</a> bias is referred to as
                              beta and scale as gamma. Note that <samp class="ph codeph">bnBiasData</samp> parameter can
                              replace the previous operation’s bias parameter for improved efficiency. 
                           </dd>
                           <dt class="dt dlterm">exponentialAverageFactor</dt>
                           <dd class="dd"><em class="ph i">Input</em>. Factor used in the moving average computation as
                              follows:
                              <p class="p"></p><samp class="ph codeph">runningMean = runningMean*(1-factor) +
                                 newMean*factor</samp><p class="p"></p>
                              
                              Use a <samp class="ph codeph">factor=1/(1+n)</samp> at
                              <samp class="ph codeph">N</samp>-th call to the function to get Cumulative Moving Average
                              (CMA) behavior such that:
                              <p class="p"></p><samp class="ph codeph">CMA[n] = (x[1]+...+x[n])/n</samp>. This
                              is proved below:
                              <p class="p"></p>
                              
                              Writing <samp class="ph codeph">CMA[n+1] =
                                 (n*CMA[n]+x[n+1])/(n+1)</samp><p class="p"></p><samp class="ph codeph">= ((n+1)*CMA[n]-CMA[n])/(n+1) +
                                 x[n+1]/(n+1) </samp><p class="p"></p><samp class="ph codeph">= CMA[n]*(1-1/(n+1))+x[n+1]*1/(n+1)
                                 </samp><p class="p"></p><samp class="ph codeph">= CMA[n]*(1-factor) + x(n+1)*factor.</samp></dd>
                           <dt class="dt dlterm">*resultRunningMeanData, *resultRunningVarianceData </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Inputs/Outputs</em>. Pointers to the running mean and running variance
                                 data. Both these pointers can be NULL but only at the same time. The value
                                 stored in <samp class="ph codeph">resultRunningVarianceData</samp> (or passed as an input
                                 in inference mode) is the sample variance, and is the moving average of
                                 variance[x] where variance is computed either over batch or spatial+batch
                                 dimensions depending on the mode. If these pointers are not NULL, the
                                 tensors should be initialized to some reasonable values or to 0. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">epsilon </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Epsilon value used in the batch normalization formula. Its
                                 						value should be equal to or greater than the value defined for
                                 						CUDNN_BN_MIN_EPSILON in cudnn.h. Same <samp class="ph codeph">epsilon</samp> value should be
                                 						used in forward and backward functions.
                              </p>
                           </dd>
                           <dt class="dt dlterm">*saveMean, *saveInvVariance</dt>
                           <dd class="dd"><em class="ph i">Outputs</em>. Optional cache parameters containing saved intermediate results
                              					computed during the forward pass. For this to work correctly, the layer's
                              						<samp class="ph codeph">x</samp> and <samp class="ph codeph">bnScaleData</samp>, <samp class="ph codeph">bnBiasData</samp>
                              					data has to remain unchanged until this backward function is called. Note that both
                              					these parameters can be NULL but only at the same time. It is recommended to use this
                              					cache since the memory overhead is relatively small. 
                           </dd>
                           <dt class="dt dlterm">activationDesc</dt>
                           <dd class="dd"><em class="ph i">Input</em>. Tensor descriptor for the activation operation. When the
                              <samp class="ph codeph">bnOps</samp> input is set to either
                              CUDNN_BATCHNORM_OPS_BN_ACTIVATION or CUDNN_BATCHNORM_OPS_BN_ADD_ACTIVATION then
                              this activation is used. 
                           </dd>
                           <dt class="dt dlterm">*workspace, workSpaceSizeInBytes</dt>
                           <dd class="dd"><em class="ph i">Inputs</em>. <samp class="ph codeph">*workspace</samp> is a pointer to the GPU workspace,
                              and <samp class="ph codeph">workSpaceSizeInBytes</samp> is the size of the workspace. When the
                              <samp class="ph codeph">*workspace</samp> is not NULL and
                              <samp class="ph codeph">*workSpaceSizeInBytes</samp> is large enough, and the tensor
                              layout is NHWC and the data type configuration is supported, then this function
                              will trigger a new semi-persistent NHWC kernel for batch normalization. The
                              workspace is not required to be clean. Also, the workspace does not need to
                              remain unchanged between the forward and backward passes. 
                           </dd>
                           <dt class="dt dlterm">*reserveSpace</dt>
                           <dd class="dd"><em class="ph i">Input</em>. Pointer to the GPU workspace for the
                              <samp class="ph codeph">reserveSpace</samp>.
                           </dd>
                           <dt class="dt dlterm">reserveSpaceSizeInBytes</dt>
                           <dd class="dd"><em class="ph i">Input</em>. The size of the <samp class="ph codeph">reserveSpace</samp>. Must be equal or
                              larger than the amount required by
                              <samp class="ph codeph">cudnnGetBatchNormalizationTrainingExReserveSpaceSize()</samp>.
                              
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The computation was performed successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function does not support the provided configuration.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnBatchNormalizationForwardTrainingEx__ul_qnn_k4g_jt" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnBatchNormalizationForwardTrainingEx__ul_qnn_k4g_jt">
                                 <li class="li">One of the pointers <samp class="ph codeph">alpha, beta, x, y, bnScaleData,
                                       bnBiasData</samp> is NULL.
                                 </li>
                                 <li class="li">Number of <samp class="ph codeph">xDesc</samp> or <samp class="ph codeph">yDesc</samp> tensor
                                    descriptor dimensions is not within the [4,5] range (only 4D and 5D
                                    tensors are supported.).
                                 </li>
                                 <li class="li"><samp class="ph codeph">bnScaleBiasMeanVarDesc</samp> dimensions are not 1xCx1x1 for
                                    4D and 1xCx1x1x1 for 5D for spatial, and are not 1xCxHxW for 4D and
                                    1xCxDxHxW for 5D for per-activation mode. 
                                 </li>
                                 <li class="li">Exactly one of <samp class="ph codeph">saveMean</samp>,
                                    <samp class="ph codeph">saveInvVariance</samp>  pointers is NULL.
                                 </li>
                                 <li class="li">Exactly one of <samp class="ph codeph">resultRunningMeanData</samp>,
                                    <samp class="ph codeph">resultRunningInvVarianceData</samp> pointers is NULL.
                                 </li>
                                 <li class="li"><samp class="ph codeph">epsilon</samp> value is less than CUDNN_BN_MIN_EPSILON.
                                 </li>
                                 <li class="li">Dimensions or data types mismatch for <samp class="ph codeph">xDesc</samp>,
                                    <samp class="ph codeph">yDesc</samp></li>
                              </ul>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnConvolutionBackwardBias"><a name="cudnnConvolutionBackwardBias" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnConvolutionBackwardBias" name="cudnnConvolutionBackwardBias" shape="rect">4.9.&nbsp;cudnnConvolutionBackwardBias</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnConvolutionBackwardBias(
    cudnnHandle_t                    handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *alpha,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    dyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *dy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *beta,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    dbDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *db)</pre><p class="p">This function computes the convolution function gradient with respect to the bias, which
                           is the sum of every element belonging to the same feature map across all of the images
                           of the input tensor. Therefore, the number of elements produced is equal to the number
                           of features maps of the input tensor. 
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context. See <a class="xref" href="index.html#cudnnHandle_t" shape="rect">cudnnHandle_t.</a></p>
                           </dd>
                           <dt class="dt dlterm">alpha, beta </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointers to scaling factors (in host memory) used to blend the
                                 computation result with prior value in the output layer as follows: dstValue
                                 = alpha[0]*result + beta[0]*priorDstValue. <a class="xref" href="index.html#general-description" shape="rect">Refer to this
                                    section for additional details.</a></p>
                           </dd>
                           <dt class="dt dlterm">dyDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized input tensor
                                 descriptor. See <a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t.</a></p>
                           </dd>
                           <dt class="dt dlterm">dy </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">dyDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dbDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized output tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">db </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the output tensor
                                 descriptor <samp class="ph codeph">dbDesc</samp>.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The operation was launched successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function does not support the provided configuration.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnConvolutionBackwardBias__ul_o4f_c3b_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnConvolutionBackwardBias__ul_o4f_c3b_s1b">
                                 <li class="li">One of the parameters <samp class="ph codeph">n,height,width</samp> of the output
                                    tensor is not 1.
                                 </li>
                                 <li class="li">The numbers of feature maps of the input tensor and output tensor
                                    differ.
                                 </li>
                                 <li class="li">The <samp class="ph codeph">dataType</samp> of the two tensor descriptors are
                                    different.
                                 </li>
                              </ul>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnConvolutionBackwardData"><a name="cudnnConvolutionBackwardData" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnConvolutionBackwardData" name="cudnnConvolutionBackwardData" shape="rect">4.10.&nbsp;cudnnConvolutionBackwardData</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnConvolutionBackwardData(
    cudnnHandle_t                       handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                         *alpha,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t       wDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                         *w,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       dyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                         *dy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnConvolutionDescriptor_t  convDesc,
    cudnnConvolutionBwdDataAlgo_t       algo,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                               *workSpace,
    size_t                              workSpaceSizeInBytes,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                         *beta,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       dxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                               *dx)</pre><p class="p">This function computes the convolution data gradient of the tensor <samp class="ph codeph">dy</samp>,
                           			where <samp class="ph codeph">y</samp> is the output of the forward convolution in
                           				<samp class="ph codeph">cudnnConvolutionForward()</samp>. It uses the specified
                           				<samp class="ph codeph">algo</samp>, and returns the results in the output tensor
                           				<samp class="ph codeph">dx</samp>. Scaling factors <samp class="ph codeph">alpha</samp> and
                           				<samp class="ph codeph">beta</samp> can be used to scale the computed result or accumulate with
                           			the current <samp class="ph codeph">dx</samp>.
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context. See <a class="xref" href="index.html#cudnnHandle_t" shape="rect">cudnnHandle_t.</a></p>
                           </dd>
                           <dt class="dt dlterm">alpha, beta </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointers to scaling factors (in host memory) used to blend the
                                 computation result with prior value in the output layer as follows: dstValue
                                 = alpha[0]*result + beta[0]*priorDstValue. <a class="xref" href="index.html#scaling-parameters" shape="rect">Refer to this
                                    section for additional details.</a></p>
                           </dd>
                           <dt class="dt dlterm">wDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor. See <a class="xref" href="index.html#cudnnFilterDescriptor_t" shape="rect">cudnnFilterDescriptor_t</a>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">w </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the filter
                                 descriptor <samp class="ph codeph">wDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dyDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized input differential tensor
                                 	descriptor. See <a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t.</a></p>
                           </dd>
                           <dt class="dt dlterm">dy </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the input
                                 differential tensor descriptor <samp class="ph codeph">dyDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">convDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Previously initialized convolution descriptor. See <a class="xref" href="index.html#cudnnConvolutionDescriptor_t" shape="rect">cudnnConvolutionDescriptor_t</a>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">algo </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Enumerant that specifies which backward data convolution
                                 						algorithm shoud be used to compute the results. See <a class="xref" href="index.html#cudnnConvolutionBwdDataAlgo_t" shape="rect">cudnnConvolutionBwdDataAlgo_t</a>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">workSpace </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory to a workspace needed to able to
                                 execute the specified algorithm. If no workspace is needed for a particular
                                 algorithm, that pointer can be nil.
                              </p>
                           </dd>
                           <dt class="dt dlterm">workSpaceSizeInBytes </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                 <samp class="ph codeph">workSpace</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dxDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized output tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dx </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input/Output</em>. Data pointer to GPU memory associated with the output
                                 tensor descriptor <samp class="ph codeph">dxDesc</samp> that carries the result.
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">TABLE OF THE SUPPORTED CONFIGURATIONS</strong></p>
                        <p class="p">This function supports the following combinations of data types for
                           				<samp class="ph codeph">wDesc</samp>, <samp class="ph codeph">dyDesc</samp>, <samp class="ph codeph">convDesc</samp>, and
                           				<samp class="ph codeph">dxDesc</samp>. See the following table for a list of the supported
                           			configurations.
                        </p>
                        <div class="tablenoborder"><a name="cudnnConvolutionBackwardData__table_izw_3kb_s1b" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnConvolutionBackwardData__table_izw_3kb_s1b" class="table" frame="border" border="1" rules="all">
                              <thead class="thead" align="left">
                                 <tr class="row">
                                    <th class="entry" valign="top" width="30.087527352297595%" id="d54e17289" rowspan="1" colspan="1">Data Type Configurations</th>
                                    <th class="entry" valign="top" width="34.9562363238512%" id="d54e17292" rowspan="1" colspan="1"><samp class="ph codeph">wDesc</samp>'s, <samp class="ph codeph">dyDesc</samp>'s and
                                       <samp class="ph codeph">dxDesc</samp>'s Data Type
                                    </th>
                                    <th class="entry" valign="top" width="34.9562363238512%" id="d54e17303" rowspan="1" colspan="1"><samp class="ph codeph">convDesc</samp>'s Data Type
                                    </th>
                                 </tr>
                              </thead>
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" valign="top" width="30.087527352297595%" headers="d54e17289" rowspan="1" colspan="1">TRUE_HALF_CONFIG (only supported on architectures with true fp16
                                       							support, i.e., compute capability 5.3 and later). 
                                    </td>
                                    <td class="entry" valign="top" width="34.9562363238512%" headers="d54e17292" rowspan="1" colspan="1">CUDNN_DATA_HALF</td>
                                    <td class="entry" valign="top" width="34.9562363238512%" headers="d54e17303" rowspan="1" colspan="1">CUDNN_DATA_HALF</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="30.087527352297595%" headers="d54e17289" rowspan="1" colspan="1">PSEUDO_HALF_CONFIG</td>
                                    <td class="entry" valign="top" width="34.9562363238512%" headers="d54e17292" rowspan="1" colspan="1">CUDNN_DATA_HALF</td>
                                    <td class="entry" valign="top" width="34.9562363238512%" headers="d54e17303" rowspan="1" colspan="1">CUDNN_DATA_FLOAT</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="30.087527352297595%" headers="d54e17289" rowspan="1" colspan="1">FLOAT_CONFIG</td>
                                    <td class="entry" valign="top" width="34.9562363238512%" headers="d54e17292" rowspan="1" colspan="1">CUDNN_DATA_FLOAT</td>
                                    <td class="entry" valign="top" width="34.9562363238512%" headers="d54e17303" rowspan="1" colspan="1">CUDNN_DATA_FLOAT</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="30.087527352297595%" headers="d54e17289" rowspan="1" colspan="1">DOUBLE_CONFIG</td>
                                    <td class="entry" valign="top" width="34.9562363238512%" headers="d54e17292" rowspan="1" colspan="1">CUDNN_DATA_DOUBLE</td>
                                    <td class="entry" valign="top" width="34.9562363238512%" headers="d54e17303" rowspan="1" colspan="1">CUDNN_DATA_DOUBLE</td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                        <div class="note note"><span class="notetitle">Note:</span><p class="p">Specifying a separate algorithm can cause changes in performance, support and
                              				computation determinism. See the following for a list of algorithm options, and
                              				their respective supported parameters and deterministic behavior.
                           </p>
                        </div>
                        <p class="p"><strong class="ph b">TABLE OF THE SUPPORTED ALGORITHMS</strong></p>
                        <p class="p">The table below shows the list of the supported 2D and 3D convolutions. The 2D
                           			convolutions are described first, followed by the 3D convolutions. 
                        </p>
                        <p class="p">For the following terms, the short-form versions shown in the paranthesis are used in the
                           			table below, for brevity: 
                        </p>
                        <div class="p"><a name="cudnnConvolutionBackwardData__ul_tkp_2w5_y2b" shape="rect">
                              <!-- --></a><ul class="ul" id="cudnnConvolutionBackwardData__ul_tkp_2w5_y2b">
                              <li class="li">CUDNN_CONVOLUTION_BWD_DATA_ALGO_0 <strong class="ph b">(_ALGO_0)</strong></li>
                              <li class="li">CUDNN_CONVOLUTION_BWD_DATA_ALGO_1 <strong class="ph b">(_ALGO_1)</strong></li>
                              <li class="li">CUDNN_CONVOLUTION_BWD_DATA_ALGO_FFT <strong class="ph b">(_FFT)</strong></li>
                              <li class="li">CUDNN_CONVOLUTION_BWD_DATA_ALGO_FFT_TILING <strong class="ph b">(_FFT_TILING)</strong></li>
                              <li class="li">CUDNN_CONVOLUTION_BWD_DATA_ALGO_WINOGRAD <strong class="ph b">(_WINOGRAD)</strong></li>
                              <li class="li">CUDNN_CONVOLUTION_BWD_DATA_ALGO_WINOGRAD_NONFUSED
                                 					<strong class="ph b">(_WINOGRAD_NONFUSED)</strong></li>
                              <li class="li">CUDNN_TENSOR_NCHW <strong class="ph b">(_NCHW)</strong></li>
                              <li class="li">CUDNN_TENSOR_NHWC <strong class="ph b">(_NHWC)</strong></li>
                              <li class="li">CUDNN_TENSOR_NCHW_VECT_C <strong class="ph b">(_NCHW_VECT_C)</strong></li>
                           </ul>
                        </div>
                        <p class="p"><strong class="ph b">FOR 2D CONVOLUTIONS.</strong></p>
                        <div class="p">
                           <div class="tablenoborder"><a name="cudnnConvolutionBackwardData__table_ipg_rzt_y2b" shape="rect">
                                 <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnConvolutionBackwardData__table_ipg_rzt_y2b" class="table" frame="border" border="1" rules="all">
                                 <tbody class="tbody">
                                    <tr class="row">
                                       <td class="entry" colspan="6" align="left" valign="top" rowspan="1">
                                          <p dir="ltr" class="p"><strong class="ph b">Filter descriptor </strong><samp class="ph codeph"><strong class="ph b">wDesc:
                                                   										</strong></samp><samp class="ph codeph">_<strong class="ph b">NHWC</strong></samp>. See <a class="xref" href="index.html#cudnnTensorFormat_t" shape="rect">cudnnTensorFormat_t</a>.
                                          </p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" align="left" valign="top" width="19.54787234042553%" rowspan="1" colspan="1"><strong class="ph b">Algo Name</strong><p class="p">(see below for 3D Convolutions)</p>
                                       </td>
                                       <td class="entry" align="left" valign="top" width="13.297872340425531%" rowspan="1" colspan="1"><strong class="ph b">Deterministic (Yes or No)</strong></td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="13.297872340425531%" rowspan="1" colspan="1"><strong class="ph b">Tensor Formats Supported for
                                             									<samp class="ph codeph">dyDesc</samp></strong></td>
                                       <td class="entry" align="left" valign="top" width="13.297872340425531%" rowspan="1" colspan="1"><strong class="ph b">Tensor Formats Supported for
                                             								<samp class="ph codeph">dxDesc</samp></strong></td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="20.212765957446805%" rowspan="1" colspan="1"><strong class="ph b">Data Type Configurations Supported</strong></td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="20.345744680851062%" rowspan="1" colspan="1"><strong class="ph b">Important</strong></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" align="left" valign="top" width="19.54787234042553%" rowspan="1" colspan="1"><strong class="ph b">_ALGO_1</strong></td>
                                       <td class="entry" align="left" valign="top" width="13.297872340425531%" rowspan="1" colspan="1">&nbsp;</td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="13.297872340425531%" rowspan="1" colspan="1">NHWC HWC-packed </td>
                                       <td class="entry" align="left" valign="top" width="13.297872340425531%" rowspan="1" colspan="1">NHWC HWC-packed </td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="20.212765957446805%" rowspan="1" colspan="1">
                                          <p class="p">- TRUE_HALF_CONFIG, </p>
                                          <p class="p">- PSEUDO_HALF_CONFIG, and </p>
                                          <p class="p">- FLOAT_CONFIG</p>
                                       </td>
                                       <td class="entry" align="left" valign="top" width="20.345744680851062%" rowspan="1" colspan="1">&nbsp;</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" colspan="6" align="left" valign="top" rowspan="1">
                                          <p dir="ltr" class="p"><strong class="ph b">Filter descriptor </strong><samp class="ph codeph"><strong class="ph b">wDesc:
                                                   										</strong></samp><samp class="ph codeph">_<strong class="ph b">NCHW</strong></samp>.
                                          </p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" align="left" valign="top" width="19.54787234042553%" rowspan="1" colspan="1"><strong class="ph b">Algo Name </strong></td>
                                       <td class="entry" align="left" valign="top" width="13.297872340425531%" rowspan="1" colspan="1"><strong class="ph b">Deterministic (Yes or No)</strong></td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="13.297872340425531%" rowspan="1" colspan="1"><strong class="ph b">Tensor Formats Supported for
                                             									<samp class="ph codeph">dyDesc</samp></strong></td>
                                       <td class="entry" align="left" valign="top" width="13.297872340425531%" rowspan="1" colspan="1"><strong class="ph b">Tensor Formats Supported for
                                             								<samp class="ph codeph">dxDesc</samp></strong></td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="20.212765957446805%" rowspan="1" colspan="1"><strong class="ph b">Data Type Configurations Supported</strong></td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="20.345744680851062%" rowspan="1" colspan="1"><strong class="ph b">Important</strong></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" align="left" valign="top" width="19.54787234042553%" rowspan="1" colspan="1"><strong class="ph b">_ALGO_0</strong></td>
                                       <td class="entry" align="left" valign="top" width="13.297872340425531%" rowspan="1" colspan="1">No</td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="13.297872340425531%" rowspan="1" colspan="1">NCHW CHW-packed</td>
                                       <td class="entry" align="left" valign="top" width="13.297872340425531%" rowspan="1" colspan="1">
                                          <p class="p"> All except <samp class="ph codeph">_NCHW_VECT_C</samp>.  
                                          </p>
                                       </td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="20.212765957446805%" rowspan="1" colspan="1">
                                          <p class="p">- PSEUDO_HALF_CONFIG,</p>
                                          <p class="p">- FLOAT_CONFIG, and</p>
                                          <p class="p">- DOUBLE_CONFIG</p>
                                       </td>
                                       <td class="entry" align="left" valign="top" width="20.345744680851062%" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">- <strong class="ph b">Dilation</strong>: greater than 0 for all
                                             									dimensions
                                          </p>
                                          <p class="p">- <samp class="ph codeph">convDesc</samp> Group Count Support: Greater than 0.
                                             								
                                          </p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" align="left" valign="top" width="19.54787234042553%" rowspan="1" colspan="1"><strong class="ph b">_ALGO_1</strong></td>
                                       <td class="entry" align="left" valign="top" width="13.297872340425531%" rowspan="1" colspan="1">Yes</td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="13.297872340425531%" rowspan="1" colspan="1">NCHW CHW-packed</td>
                                       <td class="entry" align="left" valign="top" width="13.297872340425531%" rowspan="1" colspan="1">
                                          <p class="p"> _All except <samp class="ph codeph">_NCHW_VECT_C</samp>.  
                                          </p>
                                       </td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="20.212765957446805%" rowspan="1" colspan="1">
                                          <p class="p">- TRUE_HALF_CONFIG,</p>
                                          <p class="p">- PSEUDO_HALF_CONFIG, </p>
                                          <p class="p">- FLOAT_CONFIG, and</p>
                                          <p class="p">- DOUBLE_CONFIG</p>
                                       </td>
                                       <td class="entry" align="left" valign="top" width="20.345744680851062%" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">- <strong class="ph b">Dilation</strong>: 1 for all dimensions
                                          </p>
                                          <p class="p">- <samp class="ph codeph">convDesc</samp> Group Count Support: Greater than 0.
                                             								
                                          </p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" align="left" valign="top" width="19.54787234042553%" rowspan="1" colspan="1"><strong class="ph b">_FFT</strong></td>
                                       <td class="entry" align="left" valign="top" width="13.297872340425531%" rowspan="1" colspan="1">Yes</td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="13.297872340425531%" rowspan="1" colspan="1">NCHW CHW-packed</td>
                                       <td class="entry" align="left" valign="top" width="13.297872340425531%" rowspan="1" colspan="1">
                                          <p class="p"> NCHW HW-packed</p>
                                       </td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="20.212765957446805%" rowspan="1" colspan="1">
                                          <p class="p">- PSEUDO_HALF_CONFIG, and</p>
                                          <p class="p">- FLOAT_CONFIG</p>
                                       </td>
                                       <td class="entry" align="left" valign="top" width="20.345744680851062%" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">- <strong class="ph b">Dilation</strong>: 1 for all dimensions
                                          </p>
                                          <p class="p">- <samp class="ph codeph">convDesc</samp> Group Count Support: Greater than 0. 
                                          </p>
                                          <p class="p">- <samp class="ph codeph">dxDesc</samp>'s feature map height + 2 *
                                             										<samp class="ph codeph">convDesc</samp>'s zero-padding height must equal
                                             									256 or less 
                                          </p>
                                          <p class="p">- <samp class="ph codeph">dxDesc</samp>'s feature map width + 2 *
                                             										<samp class="ph codeph">convDesc</samp>'s zero-padding width must equal
                                             									256 or less 
                                          </p>
                                          <p class="p">- <samp class="ph codeph">convDesc</samp>'s vertical and horizontal filter
                                             									stride must equal 1 
                                          </p>
                                          <p class="p">- <samp class="ph codeph">wDesc</samp>'s filter height must be greater than
                                             										<samp class="ph codeph">convDesc</samp>'s zero-padding height 
                                          </p>
                                          <p class="p">- <samp class="ph codeph">wDesc</samp>'s filter width must be greater than
                                             										<samp class="ph codeph">convDesc</samp>'s zero-padding width 
                                          </p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" align="left" valign="top" width="19.54787234042553%" rowspan="1" colspan="1"><strong class="ph b">_FFT_TILING</strong></td>
                                       <td class="entry" align="left" valign="top" width="13.297872340425531%" rowspan="1" colspan="1">Yes</td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="13.297872340425531%" rowspan="1" colspan="1">NCHW CHW-packed</td>
                                       <td class="entry" align="left" valign="top" width="13.297872340425531%" rowspan="1" colspan="1">
                                          <p class="p"> NCHW HW-packed</p>
                                       </td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="20.212765957446805%" rowspan="1" colspan="1">
                                          <p class="p">- PSEUDO_HALF_CONFIG, and </p>
                                          <p class="p">- FLOAT_CONFIG</p>
                                          <p class="p">- DOUBLE_CONFIG is also supported when the task can be handled by
                                             									1D FFT, ie, one of the filter dimension, width or height is 1.
                                             								
                                          </p>
                                       </td>
                                       <td class="entry" align="left" valign="top" width="20.345744680851062%" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">- <strong class="ph b">Dilation</strong>: 1 for all dimensions
                                          </p>
                                          <p class="p">- <samp class="ph codeph">convDesc</samp> Group Count Support: Greater than 0. 
                                          </p>
                                          <p class="p">- When neither of <samp class="ph codeph">wDesc</samp>'s filter dimension is 1,
                                             									the filter width and height must not be larger than 32 
                                          </p>
                                          <p class="p">- When either of <samp class="ph codeph">wDesc</samp>'s filter dimension is 1,
                                             									the largest filter dimension should not exceed 256 
                                          </p>
                                          <p class="p">- <samp class="ph codeph">convDesc</samp>'s vertical and horizontal filter stride must equal 1 when
                                             									either the filter width or filter height is 1, otherwise the
                                             									stride can be 1 or 2
                                          </p>
                                          <p class="p">- <samp class="ph codeph">wDesc</samp>'s filter height must be greater than
                                             										<samp class="ph codeph">convDesc</samp>'s zero-padding height 
                                          </p>
                                          <p class="p">- <samp class="ph codeph">wDesc</samp>'s filter width must be greater than
                                             										<samp class="ph codeph">convDesc</samp>'s zero-padding width 
                                          </p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" align="left" valign="top" width="19.54787234042553%" rowspan="1" colspan="1"><strong class="ph b">_WINOGRAD</strong></td>
                                       <td class="entry" align="left" valign="top" width="13.297872340425531%" rowspan="1" colspan="1">Yes</td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="13.297872340425531%" rowspan="1" colspan="1">NCHW CHW-packed</td>
                                       <td class="entry" align="left" valign="top" width="13.297872340425531%" rowspan="1" colspan="1">
                                          <p class="p">All except <samp class="ph codeph">_NCHW_VECT_C</samp>.  
                                          </p>
                                       </td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="20.212765957446805%" rowspan="1" colspan="1">
                                          <p class="p"> - PSEUDO_HALF_CONFIG, and</p>
                                          <p class="p">- FLOAT_CONFIG</p>
                                       </td>
                                       <td class="entry" align="left" valign="top" width="20.345744680851062%" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">- <strong class="ph b">Dilation</strong>: 1 for all dimensions
                                          </p>
                                          <p class="p">- <samp class="ph codeph">convDesc</samp> Group Count Support: Greater than 0. 
                                          </p>
                                          <p class="p">- <samp class="ph codeph">convDesc</samp>'s vertical and horizontal filter
                                             									stride must equal 1 
                                          </p>
                                          <p class="p">- <samp class="ph codeph">wDesc</samp>'s filter height must be 3 
                                          </p>
                                          <p class="p">- <samp class="ph codeph">wDesc</samp>'s filter width must be 3 
                                          </p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" align="left" valign="top" width="19.54787234042553%" rowspan="1" colspan="1"><strong class="ph b">_WINOGRAD_NONFUSED</strong></td>
                                       <td class="entry" align="left" valign="top" width="13.297872340425531%" rowspan="1" colspan="1">Yes</td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="13.297872340425531%" rowspan="1" colspan="1">NCHW CHW-packed</td>
                                       <td class="entry" align="left" valign="top" width="13.297872340425531%" rowspan="1" colspan="1">
                                          <p class="p"> All except <samp class="ph codeph">_NCHW_VECT_C</samp>.  
                                          </p>
                                       </td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="20.212765957446805%" rowspan="1" colspan="1">
                                          <p class="p">- TRUE_HALF_CONFIG,</p>
                                          <p class="p">- PSEUDO_HALF_CONFIG, and </p>
                                          <p class="p">- FLOAT_CONFIG</p>
                                       </td>
                                       <td class="entry" align="left" valign="top" width="20.345744680851062%" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">- <strong class="ph b">Dilation</strong>: 1 for all dimensions
                                          </p>
                                          <p class="p">- <samp class="ph codeph">convDesc</samp> Group Count Support: Greater than 0. 
                                          </p>
                                          <p class="p">- <samp class="ph codeph">convDesc</samp>'s vertical and horizontal filter
                                             									stride must equal 1 
                                          </p>
                                          <p class="p">- <samp class="ph codeph">wDesc</samp>'s filter (height, width) must be (3,3)
                                             									or (5,5) 
                                          </p>
                                          <p class="p">- If <samp class="ph codeph">wDesc</samp>'s filter (height, width) is (5,5)
                                             									then the data type config TRUE_HALF_CONFIG is not supported 
                                          </p>
                                       </td>
                                    </tr>
                                 </tbody>
                              </table>
                           </div>
                        </div>
                        <p class="p"><strong class="ph b">FOR 3D CONVOLUTIONS.</strong></p>
                        <div class="p">
                           <div class="tablenoborder"><a name="cudnnConvolutionBackwardData__table_ipg_rzt_y3b" shape="rect">
                                 <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnConvolutionBackwardData__table_ipg_rzt_y3b" class="table" frame="border" border="1" rules="all">
                                 <tbody class="tbody">
                                    <tr class="row">
                                       <td class="entry" colspan="6" align="left" valign="top" rowspan="1">
                                          <p dir="ltr" class="p"><strong class="ph b">Filter descriptor </strong><samp class="ph codeph"><strong class="ph b">wDesc:
                                                   										</strong></samp><samp class="ph codeph">_<strong class="ph b">NCHW</strong></samp></p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" align="left" valign="top" width="19.54787234042553%" rowspan="1" colspan="1"><strong class="ph b">Algo Name (3D Convolutions)</strong></td>
                                       <td class="entry" align="left" valign="top" width="13.297872340425531%" rowspan="1" colspan="1"><strong class="ph b">Deterministic (Yes or No)</strong></td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="13.297872340425531%" rowspan="1" colspan="1"><strong class="ph b">Tensor Formats Supported for
                                             									<samp class="ph codeph">dyDesc</samp></strong></td>
                                       <td class="entry" align="left" valign="top" width="13.297872340425531%" rowspan="1" colspan="1"><strong class="ph b">Tensor Formats Supported for
                                             								<samp class="ph codeph">dxDesc</samp></strong></td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="20.212765957446805%" rowspan="1" colspan="1"><strong class="ph b">Data Type Configurations Support</strong></td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="20.345744680851062%" rowspan="1" colspan="1"><strong class="ph b">Important</strong></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" align="left" valign="top" width="19.54787234042553%" rowspan="1" colspan="1"><strong class="ph b">_ALGO_0</strong></td>
                                       <td class="entry" align="left" valign="top" width="13.297872340425531%" rowspan="1" colspan="1">Yes</td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="13.297872340425531%" rowspan="1" colspan="1">NCDHW CDHW-packed</td>
                                       <td class="entry" align="left" valign="top" width="13.297872340425531%" rowspan="1" colspan="1">
                                          <p class="p"> All except <samp class="ph codeph">_NCDHW_VECT_C</samp>.  
                                          </p>
                                       </td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="20.212765957446805%" rowspan="1" colspan="1">
                                          <p class="p">- PSEUDO_HALF_CONFIG,</p>
                                          <p class="p">- FLOAT_CONFIG, and</p>
                                          <p class="p">- DOUBLE_CONFIG.</p>
                                       </td>
                                       <td class="entry" align="left" valign="top" width="20.345744680851062%" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">- <strong class="ph b">Dilation</strong>: greater than 0 for all
                                             									dimensions
                                          </p>
                                          <p class="p">- <samp class="ph codeph">convDesc</samp> Group Count Support: Greater than 0.
                                             								
                                          </p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" align="left" valign="top" width="19.54787234042553%" rowspan="1" colspan="1"><strong class="ph b">_ALGO_1</strong></td>
                                       <td class="entry" align="left" valign="top" width="13.297872340425531%" rowspan="1" colspan="1">Yes</td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="13.297872340425531%" rowspan="1" colspan="1">NCDHW-fully-packed</td>
                                       <td class="entry" align="left" valign="top" width="13.297872340425531%" rowspan="1" colspan="1">
                                          <p class="p"> NCDHW-fully-packed</p>
                                       </td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="20.212765957446805%" rowspan="1" colspan="1">
                                          <p class="p">- TRUE_HALF_CONFIG,</p>
                                          <p class="p">- PSEUDO_HALF_CONFIG,</p>
                                          <p class="p">- FLOAT_CONFIG, and</p>
                                          <p class="p">- DOUBLE_CONFIG.</p>
                                       </td>
                                       <td class="entry" align="left" valign="top" width="20.345744680851062%" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">- <strong class="ph b">Dilation</strong>: 1 for all dimensions
                                          </p>
                                          <p class="p">- <samp class="ph codeph">convDesc</samp> Group Count Support: Greater than 0.
                                             								
                                          </p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" align="left" valign="top" width="19.54787234042553%" rowspan="1" colspan="1"><strong class="ph b">_FFT_TILING</strong></td>
                                       <td class="entry" align="left" valign="top" width="13.297872340425531%" rowspan="1" colspan="1">Yes</td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="13.297872340425531%" rowspan="1" colspan="1">NCDHW CDHW-packed</td>
                                       <td class="entry" align="left" valign="top" width="13.297872340425531%" rowspan="1" colspan="1">
                                          <p class="p"> NCDHW DHW-packed</p>
                                       </td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="20.212765957446805%" rowspan="1" colspan="1">
                                          <p class="p">- PSEUDO_HALF_CONFIG,</p>
                                          <p class="p">- FLOAT_CONFIG, and</p>
                                          <p class="p">- DOUBLE_CONFIG.</p>
                                       </td>
                                       <td class="entry" align="left" valign="top" width="20.345744680851062%" rowspan="1" colspan="1">
                                          <p dir="ltr" class="p">- <strong class="ph b">Dilation</strong>: 1 for all dimensions
                                          </p>
                                          <p class="p">- <samp class="ph codeph">convDesc</samp> Group Count Support: Greater than 0. 
                                          </p>
                                          <p class="p">- <samp class="ph codeph">wDesc</samp>'s filter height must equal 16 or less 
                                          </p>
                                          <p class="p">- <samp class="ph codeph">wDesc</samp>'s filter width must equal 16 or less 
                                          </p>
                                          <p class="p">- <samp class="ph codeph">wDesc</samp>'s filter depth must equal 16 or less 
                                          </p>
                                          <p class="p">- <samp class="ph codeph">convDesc</samp>'s must have all filter strides equal
                                             									to 1 
                                          </p>
                                          <p class="p">- <samp class="ph codeph">wDesc</samp>'s filter height must be greater than
                                             										<samp class="ph codeph">convDesc</samp>'s zero-padding height 
                                          </p>
                                          <p class="p">- <samp class="ph codeph">wDesc</samp>'s filter width must be greater than
                                             										<samp class="ph codeph">convDesc</samp>'s zero-padding width 
                                          </p>
                                          <p class="p">- <samp class="ph codeph">wDesc</samp>'s filter depth must be greater than
                                             										<samp class="ph codeph">convDesc</samp>'s zero-padding width 
                                          </p>
                                       </td>
                                    </tr>
                                 </tbody>
                              </table>
                           </div>
                        </div>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The operation was launched successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnConvolutionBackwardData__ul_ibx_3kb_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnConvolutionBackwardData__ul_ibx_3kb_s1b">
                                 <li class="li">At least one of the following is NULL: <samp class="ph codeph">handle</samp>,
                                    <samp class="ph codeph">dyDesc</samp>, <samp class="ph codeph">wDesc</samp>,
                                    <samp class="ph codeph">convDesc</samp>, <samp class="ph codeph">dxDesc</samp>,
                                    <samp class="ph codeph">dy</samp>, <samp class="ph codeph">w</samp>, <samp class="ph codeph">dx</samp>,
                                    <samp class="ph codeph">alpha</samp>, <samp class="ph codeph">beta</samp></li>
                                 <li class="li"><samp class="ph codeph">wDesc</samp> and <samp class="ph codeph">dyDesc</samp> have a non-matching
                                    number of dimensions
                                 </li>
                                 <li class="li"><samp class="ph codeph">wDesc</samp> and <samp class="ph codeph">dxDesc</samp> have a non-matching
                                    number of dimensions
                                 </li>
                                 <li class="li"><samp class="ph codeph">wDesc</samp> has fewer than three number of dimensions
                                 </li>
                                 <li class="li"><samp class="ph codeph">wDesc</samp>, <samp class="ph codeph">dxDesc</samp> and
                                    <samp class="ph codeph">dyDesc</samp> have a non-matching data type.
                                 </li>
                                 <li class="li"><samp class="ph codeph">wDesc</samp> and <samp class="ph codeph">dxDesc</samp> have a non-matching
                                    number of input feature maps per image (or group in case of Grouped
                                    Convolutions).
                                 </li>
                                 <li class="li"><samp class="ph codeph">dyDescs's</samp> spatial sizes do not match with the expected
                                    size as determined by
                                    <samp class="ph codeph">cudnnGetConvolutionNdForwardOutputDim</samp></li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">At least one of the following conditions are met: <a name="cudnnConvolutionBackwardData__ul_mbx_3kb_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnConvolutionBackwardData__ul_mbx_3kb_s1b">
                                 <li class="li"><samp class="ph codeph">dyDesc</samp> or <samp class="ph codeph">dxDesc</samp> have negative tensor
                                    striding
                                 </li>
                                 <li class="li"><samp class="ph codeph">dyDesc</samp>, <samp class="ph codeph">wDesc</samp> or
                                    <samp class="ph codeph">dxDesc</samp> has a number of dimensions that is not 4 or
                                    5
                                 </li>
                                 <li class="li">The chosen algo does not support the parameters provided; see above for
                                    exhaustive list of parameter support for each algo
                                 </li>
                                 <li class="li"><samp class="ph codeph">dyDesc</samp> or <samp class="ph codeph">wDesc</samp> indicate an output
                                    channel count that isn't a multiple of group count (if group count has
                                    been set in convDesc).
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_MAPPING_ERROR</samp></dt>
                           <dd class="dd">
                              <p class="p">An error occurs during the texture binding of the filter data or the input
                                 differential tensor data
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function failed to launch on the GPU.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnConvolutionBackwardFilter"><a name="cudnnConvolutionBackwardFilter" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnConvolutionBackwardFilter" name="cudnnConvolutionBackwardFilter" shape="rect">4.11.&nbsp;cudnnConvolutionBackwardFilter</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnConvolutionBackwardFilter(
    cudnnHandle_t                       handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                         *alpha,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                         *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       dyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                         *dy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnConvolutionDescriptor_t  convDesc,
    cudnnConvolutionBwdFilterAlgo_t     algo,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                               *workSpace,
    size_t                              workSpaceSizeInBytes,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                         *beta,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t       dwDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                               *dw)</pre><p class="p">This function computes the convolution weight (filter) gradient of the tensor
                           <samp class="ph codeph">dy</samp>, where <samp class="ph codeph">y</samp> is the output of the forward
                           convolution in <samp class="ph codeph">cudnnConvolutionForward()</samp>. It uses the specified
                           <samp class="ph codeph">algo</samp>, and returns the results in the output tensor
                           <samp class="ph codeph">dw</samp>. Scaling factors <samp class="ph codeph">alpha</samp> and
                           <samp class="ph codeph">beta</samp> can be used to scale the computed result or accumulate with
                           the current <samp class="ph codeph">dw</samp>.
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context. See <a class="xref" href="index.html#cudnnHandle_t" shape="rect">cudnnHandle_t.</a></p>
                           </dd>
                           <dt class="dt dlterm">alpha, beta </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointers to scaling factors (in host memory) used to blend the
                                 computation result with prior value in the output layer as follows: dstValue
                                 = alpha[0]*result + beta[0]*priorDstValue. <a class="xref" href="index.html#scaling-parameters" shape="rect">Refer to this
                                    section for additional details.</a></p>
                           </dd>
                           <dt class="dt dlterm">xDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor. See <a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t.</a></p>
                           </dd>
                           <dt class="dt dlterm">x </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">xDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dyDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized input differential tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dy </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the backpropagation
                                 gradient tensor descriptor <samp class="ph codeph">dyDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">convDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Previously initialized convolution descriptor. See <a class="xref" href="index.html#cudnnConvolutionDescriptor_t" shape="rect">cudnnConvolutionDescriptor_t</a>.
                                 
                              </p>
                           </dd>
                           <dt class="dt dlterm">algo </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Enumerant that specifies which convolution algorithm shoud be
                                 used to compute the results. See <a class="xref" href="index.html#cudnnConvolutionBwdFilterAlgo_t" shape="rect">cudnnConvolutionBwdFilterAlgo_t</a>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">workSpace </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory to a workspace needed to able to
                                 execute the specified algorithm. If no workspace is needed for a particular
                                 algorithm, that pointer can be nil.
                              </p>
                           </dd>
                           <dt class="dt dlterm">workSpaceSizeInBytes </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                 <samp class="ph codeph">workSpace</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dwDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized filter gradient descriptor.
                                 See <a class="xref" href="index.html#cudnnFilterDescriptor_t" shape="rect">cudnnFilterDescriptor_t</a>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dw </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input/Output</em>. Data pointer to GPU memory associated with the filter
                                 gradient descriptor <samp class="ph codeph">dwDesc</samp> that carries the result.
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">TABLE OF THE SUPPORTED CONFIGURATIONS</strong></p>
                        <p class="p">This function supports the following combinations of data types for
                           				<samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">dyDesc</samp>, <samp class="ph codeph">convDesc</samp>, and
                           				<samp class="ph codeph">dwDesc</samp>. See the following table for a list of the supported
                           			configurations.
                        </p>
                        <div class="tablenoborder"><a name="cudnnConvolutionBackwardFilter__table_atf_hjb_s1b" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnConvolutionBackwardFilter__table_atf_hjb_s1b" class="table" frame="border" border="1" rules="all">
                              <thead class="thead" align="left">
                                 <tr class="row">
                                    <th class="entry" valign="top" width="30.087527352297595%" id="d54e18774" rowspan="1" colspan="1">Data Type Configurations</th>
                                    <th class="entry" valign="top" width="34.9562363238512%" id="d54e18777" rowspan="1" colspan="1"><samp class="ph codeph">xDesc</samp>'s, <samp class="ph codeph">dyDesc</samp>'s and
                                       <samp class="ph codeph">dwDesc</samp>'s Data Type
                                    </th>
                                    <th class="entry" valign="top" width="34.9562363238512%" id="d54e18788" rowspan="1" colspan="1"><samp class="ph codeph">convDesc</samp>'s Data Type
                                    </th>
                                 </tr>
                              </thead>
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" valign="top" width="30.087527352297595%" headers="d54e18774" rowspan="1" colspan="1">TRUE_HALF_CONFIG (only supported on architectures with true fp16
                                       support, i.e., compute capability 5.3 and later). 
                                    </td>
                                    <td class="entry" valign="top" width="34.9562363238512%" headers="d54e18777" rowspan="1" colspan="1">CUDNN_DATA_HALF</td>
                                    <td class="entry" valign="top" width="34.9562363238512%" headers="d54e18788" rowspan="1" colspan="1">CUDNN_DATA_HALF</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="30.087527352297595%" headers="d54e18774" rowspan="1" colspan="1">PSEUDO_HALF_CONFIG</td>
                                    <td class="entry" valign="top" width="34.9562363238512%" headers="d54e18777" rowspan="1" colspan="1">CUDNN_DATA_HALF</td>
                                    <td class="entry" valign="top" width="34.9562363238512%" headers="d54e18788" rowspan="1" colspan="1">CUDNN_DATA_FLOAT</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="30.087527352297595%" headers="d54e18774" rowspan="1" colspan="1">FLOAT_CONFIG</td>
                                    <td class="entry" valign="top" width="34.9562363238512%" headers="d54e18777" rowspan="1" colspan="1">CUDNN_DATA_FLOAT</td>
                                    <td class="entry" valign="top" width="34.9562363238512%" headers="d54e18788" rowspan="1" colspan="1">CUDNN_DATA_FLOAT</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="30.087527352297595%" headers="d54e18774" rowspan="1" colspan="1">DOUBLE_CONFIG</td>
                                    <td class="entry" valign="top" width="34.9562363238512%" headers="d54e18777" rowspan="1" colspan="1">CUDNN_DATA_DOUBLE</td>
                                    <td class="entry" valign="top" width="34.9562363238512%" headers="d54e18788" rowspan="1" colspan="1">CUDNN_DATA_DOUBLE</td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                        <div class="note note"><span class="notetitle">Note:</span><p class="p">Specifying a separate algorithm can cause changes in performance, support and
                              				computation determinism. See the following for an exhaustive list of algorithm
                              				options and their respective supported parameters and deterministic behavior.
                           </p>
                        </div>
                        <p class="p"><strong class="ph b">TABLE OF THE SUPPORTED ALGORITHMS</strong></p>
                        <p class="p">The table below shows the list of the supported 2D and 3D convolutions. The 2D
                           			convolutions are described first, followed by the 3D convolutions. 
                        </p>
                        <p class="p">For the following terms, the short-form versions shown in the paranthesis are used in the
                           			table below, for brevity: 
                        </p>
                        <div class="p"><a name="cudnnConvolutionBackwardFilter__ul_tkp_2w5_y2b" shape="rect">
                              <!-- --></a><ul class="ul" id="cudnnConvolutionBackwardFilter__ul_tkp_2w5_y2b">
                              <li class="li">CUDNN_CONVOLUTION_BWD_FILTER_ALGO_0 <strong class="ph b">(_ALGO_0)</strong></li>
                              <li class="li">CUDNN_CONVOLUTION_BWD_FILTER_ALGO_1 <strong class="ph b">(_ALGO_1)</strong></li>
                              <li class="li">CUDNN_CONVOLUTION_BWD_FILTER_ALGO_3 <strong class="ph b">(_ALGO_3)</strong></li>
                              <li class="li">CUDNN_CONVOLUTION_BWD_FILTER_ALGO_FFT <strong class="ph b">(_FFT)</strong></li>
                              <li class="li">CUDNN_CONVOLUTION_BWD_FILTER_ALGO_FFT_TILING <strong class="ph b">(_FFT_TILING)</strong></li>
                              <li class="li">CUDNN_CONVOLUTION_BWD_FILTER_ALGO_WINOGRAD_NONFUSED
                                 					<strong class="ph b">(_WINOGRAD_NONFUSED)</strong></li>
                              <li class="li">CUDNN_TENSOR_NCHW <strong class="ph b">(_NCHW)</strong></li>
                              <li class="li">CUDNN_TENSOR_NHWC <strong class="ph b">(_NHWC)</strong></li>
                              <li class="li">CUDNN_TENSOR_NCHW_VECT_C <strong class="ph b">(_NCHW_VECT_C)</strong></li>
                           </ul>
                        </div>
                        <p class="p"><strong class="ph b">FOR 2D CONVOLUTIONS.</strong></p>
                        <div class="tablenoborder"><a name="cudnnConvolutionBackwardFilter__table_ipg_rzt_y2b" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnConvolutionBackwardFilter__table_ipg_rzt_y2b" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" colspan="6" align="left" valign="top" rowspan="1">
                                       <p dir="ltr" class="p"><strong class="ph b">Filter descriptor </strong><samp class="ph codeph"><strong class="ph b">dwDesc:
                                                </strong></samp><samp class="ph codeph">_<strong class="ph b">NHWC</strong></samp>. See <a class="xref" href="index.html#cudnnTensorFormat_t" shape="rect">cudnnTensorFormat_t</a>.
                                       </p>
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" align="left" valign="top" width="21.207658321060386%" rowspan="1" colspan="1"><strong class="ph b">Algo Name </strong><p class="p">(see below for 3D Convolutions)</p>
                                    </td>
                                    <td class="entry" align="left" valign="top" width="14.72754050073638%" rowspan="1" colspan="1"><strong class="ph b">Deterministic (Yes or No)</strong></td>
                                    <td class="entry" dir="ltr" align="left" valign="top" width="12.51840942562592%" rowspan="1" colspan="1"><strong class="ph b">Tensor Formats Supported for
                                          <samp class="ph codeph">xDesc</samp></strong></td>
                                    <td class="entry" align="left" valign="top" width="14.72754050073638%" rowspan="1" colspan="1"><strong class="ph b">Tensor Formats Supported for  <samp class="ph codeph">dyDesc</samp></strong></td>
                                    <td class="entry" dir="ltr" align="left" valign="top" width="16.936671575846834%" rowspan="1" colspan="1"><strong class="ph b">Data Type Configurations Supported</strong></td>
                                    <td class="entry" dir="ltr" align="left" valign="top" width="19.882179675994113%" rowspan="1" colspan="1"><strong class="ph b">Important</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" align="left" valign="top" width="21.207658321060386%" rowspan="1" colspan="1"><strong class="ph b">_ALGO_0</strong>, and <strong class="ph b">_ALGO_1</strong></td>
                                    <td class="entry" align="left" valign="top" width="14.72754050073638%" rowspan="1" colspan="1">&nbsp;</td>
                                    <td class="entry" dir="ltr" align="left" valign="top" width="12.51840942562592%" rowspan="1" colspan="1">NHWC HWC-packed </td>
                                    <td class="entry" align="left" valign="top" width="14.72754050073638%" rowspan="1" colspan="1">NHWC HWC-packed </td>
                                    <td class="entry" dir="ltr" align="left" valign="top" width="16.936671575846834%" rowspan="1" colspan="1">
                                       <p class="p">- PSEUDO_HALF_CONFIG, and</p>
                                       <p class="p">- FLOAT_CONFIG</p>
                                    </td>
                                    <td class="entry" align="left" valign="top" width="19.882179675994113%" rowspan="1" colspan="1">&nbsp;</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" colspan="6" align="left" valign="top" rowspan="1">
                                       <p class="p"></p>
                                       <p dir="ltr" class="p"><strong class="ph b">Filter descriptor </strong><samp class="ph codeph"><strong class="ph b">wDesc:
                                                </strong></samp><samp class="ph codeph">_<strong class="ph b">NCHW</strong></samp>.
                                       </p>
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" align="left" valign="top" width="21.207658321060386%" rowspan="1" colspan="1"><strong class="ph b">Algo Name </strong></td>
                                    <td class="entry" align="left" valign="top" width="14.72754050073638%" rowspan="1" colspan="1"><strong class="ph b">Deterministic (Yes or No)</strong></td>
                                    <td class="entry" dir="ltr" align="left" valign="top" width="12.51840942562592%" rowspan="1" colspan="1"><strong class="ph b">Tensor Formats Supported for
                                          <samp class="ph codeph">xDesc</samp></strong></td>
                                    <td class="entry" align="left" valign="top" width="14.72754050073638%" rowspan="1" colspan="1"><strong class="ph b">Tensor Formats Supported for  <samp class="ph codeph">dyDesc</samp></strong></td>
                                    <td class="entry" dir="ltr" align="left" valign="top" width="16.936671575846834%" rowspan="1" colspan="1"><strong class="ph b">Data Type Configurations Supported</strong></td>
                                    <td class="entry" dir="ltr" align="left" valign="top" width="19.882179675994113%" rowspan="1" colspan="1"><strong class="ph b">Important</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" align="left" valign="top" width="21.207658321060386%" rowspan="1" colspan="1"><strong class="ph b">_ALGO_0</strong></td>
                                    <td class="entry" align="left" valign="top" width="14.72754050073638%" rowspan="1" colspan="1">No</td>
                                    <td class="entry" dir="ltr" align="left" valign="top" width="12.51840942562592%" rowspan="1" colspan="1">
                                       <p class="p"> All except <samp class="ph codeph">_NCHW_VECT_C</samp>.  
                                       </p>
                                    </td>
                                    <td class="entry" align="left" valign="top" width="14.72754050073638%" rowspan="1" colspan="1">
                                       <p class="p"> NCHW CHW-packed</p>
                                    </td>
                                    <td class="entry" dir="ltr" align="left" valign="top" width="16.936671575846834%" rowspan="1" colspan="1">
                                       <p class="p">- PSEUDO_HALF_CONFIG,</p>
                                       <p class="p">- FLOAT_CONFIG, and</p>
                                       <p class="p">- DOUBLE_CONFIG</p>
                                    </td>
                                    <td class="entry" align="left" valign="top" width="19.882179675994113%" rowspan="1" colspan="1">
                                       <p dir="ltr" class="p">- <strong class="ph b">Dilation</strong>: greater than 0 for all dimensions
                                       </p>
                                       <p class="p">- <samp class="ph codeph">convDesc</samp> Group Count Support: Greater than 0. 
                                       </p>
                                       <p class="p">- This algo is not supported if output is of type
                                          <samp class="ph codeph">CUDNN_DATA_HALF</samp> and the number of elements in
                                          <samp class="ph codeph">dw</samp> is odd. 
                                       </p>
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" align="left" valign="top" width="21.207658321060386%" rowspan="1" colspan="1"><strong class="ph b">_ALGO_1</strong></td>
                                    <td class="entry" align="left" valign="top" width="14.72754050073638%" rowspan="1" colspan="1">Yes</td>
                                    <td class="entry" dir="ltr" align="left" valign="top" width="12.51840942562592%" rowspan="1" colspan="1">
                                       <p class="p"> _NCHW or _NHWC </p>
                                    </td>
                                    <td class="entry" align="left" valign="top" width="14.72754050073638%" rowspan="1" colspan="1">
                                       <p class="p"> NCHW CHW-packed</p>
                                    </td>
                                    <td class="entry" dir="ltr" align="left" valign="top" width="16.936671575846834%" rowspan="1" colspan="1">
                                       <p class="p">- TRUE_HALF_CONFIG,</p>
                                       <p class="p">-  PSEUDO_HALF_CONFIG,</p>
                                       <p class="p">- FLOAT_CONFIG, and</p>
                                       <p class="p">- DOUBLE_CONFIG</p>
                                    </td>
                                    <td class="entry" align="left" valign="top" width="19.882179675994113%" rowspan="1" colspan="1">
                                       <p dir="ltr" class="p">- <strong class="ph b">Dilation</strong>: 1 for all dimensions
                                       </p>
                                       <p class="p">- <samp class="ph codeph">convDesc</samp> Group Count Support: Greater than 0. 
                                       </p>
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" align="left" valign="top" width="21.207658321060386%" rowspan="1" colspan="1"><strong class="ph b">_FFT</strong></td>
                                    <td class="entry" align="left" valign="top" width="14.72754050073638%" rowspan="1" colspan="1">Yes</td>
                                    <td class="entry" dir="ltr" align="left" valign="top" width="12.51840942562592%" rowspan="1" colspan="1">
                                       <p class="p"> NCHW CHW-packed</p>
                                    </td>
                                    <td class="entry" align="left" valign="top" width="14.72754050073638%" rowspan="1" colspan="1">
                                       <p class="p"> NCHW CHW-packed</p>
                                    </td>
                                    <td class="entry" dir="ltr" align="left" valign="top" width="16.936671575846834%" rowspan="1" colspan="1">
                                       <p class="p"> - PSEUDO_HALF_CONFIG, and</p>
                                       <p class="p">- FLOAT_CONFIG</p>
                                    </td>
                                    <td class="entry" align="left" valign="top" width="19.882179675994113%" rowspan="1" colspan="1">
                                       <p dir="ltr" class="p">- <strong class="ph b">Dilation</strong>: 1 for all dimensions
                                       </p>
                                       <p class="p">- <samp class="ph codeph">convDesc</samp> Group Count Support: Greater than 0. 
                                       </p>
                                       <p class="p">- <samp class="ph codeph">xDesc</samp>'s feature map height + 2 *
                                          <samp class="ph codeph">convDesc</samp>'s zero-padding height must equal 256
                                          or less 
                                       </p>
                                       <p class="p">- <samp class="ph codeph">xDesc</samp>'s feature map width + 2 *
                                          <samp class="ph codeph">convDesc</samp>'s zero-padding width must equal 256 or
                                          less 
                                       </p>
                                       <p class="p">- <samp class="ph codeph">convDesc</samp>'s vertical and horizontal filter stride
                                          must equal 1 
                                       </p>
                                       <p class="p">- <samp class="ph codeph">dwDesc</samp>'s filter height must be greater than
                                          <samp class="ph codeph">convDesc</samp>'s zero-padding height 
                                       </p>
                                       <p class="p">- <samp class="ph codeph">dwDesc</samp>'s filter width must be greater than
                                          <samp class="ph codeph">convDesc</samp>'s zero-padding width 
                                       </p>
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" align="left" valign="top" width="21.207658321060386%" rowspan="1" colspan="1"><strong class="ph b">_ALGO_3</strong></td>
                                    <td class="entry" align="left" valign="top" width="14.72754050073638%" rowspan="1" colspan="1">Yes</td>
                                    <td class="entry" dir="ltr" align="left" valign="top" width="12.51840942562592%" rowspan="1" colspan="1">
                                       <p class="p"> All except <samp class="ph codeph">_NCHW_VECT_C</samp>.  
                                       </p>
                                    </td>
                                    <td class="entry" align="left" valign="top" width="14.72754050073638%" rowspan="1" colspan="1">
                                       <p class="p"> NCHW CHW-packed</p>
                                    </td>
                                    <td class="entry" dir="ltr" align="left" valign="top" width="16.936671575846834%" rowspan="1" colspan="1">
                                       <p class="p">-  PSEUDO_HALF_CONFIG,</p>
                                       <p class="p">- FLOAT_CONFIG, and</p>
                                       <p class="p">- DOUBLE_CONFIG</p>
                                    </td>
                                    <td class="entry" align="left" valign="top" width="19.882179675994113%" rowspan="1" colspan="1">
                                       <p dir="ltr" class="p">- <strong class="ph b">Dilation</strong>: 1 for all dimensions
                                       </p>
                                       <p class="p">- <samp class="ph codeph">convDesc</samp> Group Count Support: Greater than 0. 
                                       </p>
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" align="left" valign="top" width="21.207658321060386%" rowspan="1" colspan="1"><strong class="ph b">_<strong class="ph b">WINOGRAD_NONFUSED</strong></strong></td>
                                    <td class="entry" align="left" valign="top" width="14.72754050073638%" rowspan="1" colspan="1">Yes</td>
                                    <td class="entry" dir="ltr" align="left" valign="top" width="12.51840942562592%" rowspan="1" colspan="1">
                                       <p class="p">All except <samp class="ph codeph">_NCHW_VECT_C</samp>.  
                                       </p>
                                    </td>
                                    <td class="entry" align="left" valign="top" width="14.72754050073638%" rowspan="1" colspan="1">
                                       <p class="p"> NCHW CHW-packed</p>
                                    </td>
                                    <td class="entry" dir="ltr" align="left" valign="top" width="16.936671575846834%" rowspan="1" colspan="1">
                                       <p class="p">- TRUE_HALF_CONFIG, </p>
                                       <p class="p">- PSEUDO_HALF_CONFIG, and </p>
                                       <p class="p">- FLOAT_CONFIG</p>
                                    </td>
                                    <td class="entry" align="left" valign="top" width="19.882179675994113%" rowspan="1" colspan="1">
                                       <p dir="ltr" class="p">- <strong class="ph b">Dilation</strong>: 1 for all dimensions
                                       </p>
                                       <p class="p">- <samp class="ph codeph">convDesc</samp> Group Count Support: Greater than 0. 
                                       </p>
                                       <p class="p">- <samp class="ph codeph">convDesc</samp>'s vertical and horizontal filter stride
                                          must equal 1 
                                       </p>
                                       <p class="p">- <samp class="ph codeph">wDesc</samp>'s filter (height, width) must be (3,3) or
                                          (5,5)
                                       </p>
                                       <p class="p">- If <samp class="ph codeph">wDesc</samp>'s filter (height, width) is (5,5), then
                                          the data type config TRUE_HALF_CONFIG is not supported. 
                                       </p>
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" align="left" valign="top" width="21.207658321060386%" rowspan="1" colspan="1"><strong class="ph b">_FFT_TILING</strong></td>
                                    <td class="entry" align="left" valign="top" width="14.72754050073638%" rowspan="1" colspan="1">Yes</td>
                                    <td class="entry" dir="ltr" align="left" valign="top" width="12.51840942562592%" rowspan="1" colspan="1">
                                       <p class="p"> NCHW CHW-packed</p>
                                    </td>
                                    <td class="entry" align="left" valign="top" width="14.72754050073638%" rowspan="1" colspan="1">
                                       <p class="p"> NCHW CHW-packed</p>
                                    </td>
                                    <td class="entry" dir="ltr" align="left" valign="top" width="16.936671575846834%" rowspan="1" colspan="1">
                                       <p class="p">- PSEUDO_HALF_CONFIG,</p>
                                       <p class="p">- FLOAT_CONFIG, and</p>
                                       <p class="p">- DOUBLE_CONFIG</p>
                                    </td>
                                    <td class="entry" align="left" valign="top" width="19.882179675994113%" rowspan="1" colspan="1">
                                       <p dir="ltr" class="p">- <strong class="ph b">Dilation</strong>: 1 for all dimensions
                                       </p>
                                       <p class="p">- <samp class="ph codeph">convDesc</samp> Group Count Support: Greater than 0. 
                                       </p>
                                       <p class="p">- <samp class="ph codeph">xDesc</samp>'s width or height must equal 1 
                                       </p>
                                       <p class="p">- <samp class="ph codeph">dyDesc</samp>'s width or height must equal 1 (the same
                                          dimension as in <samp class="ph codeph">xDesc</samp>.) The other dimension must be
                                          less than or equal to 256, i.e., the largest 1D tile size currently
                                          supported. 
                                       </p>
                                       <p class="p">- <samp class="ph codeph">convDesc</samp>'s vertical and horizontal filter stride
                                          must equal 1 
                                       </p>
                                       <p class="p">- <samp class="ph codeph">dwDesc</samp>'s filter height must be greater than
                                          <samp class="ph codeph">convDesc</samp>'s zero-padding height. 
                                       </p>
                                       <p class="p">- <samp class="ph codeph">dwDesc</samp>'s filter width must be greater than
                                          <samp class="ph codeph">convDesc</samp>'s zero-padding width. 
                                       </p>
                                    </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                        <p class="p"><strong class="ph b">FOR 3D CONVOLUTIONS.</strong></p>
                        <div class="tablenoborder"><a name="cudnnConvolutionBackwardFilter__table_ipg_rzt_y3b" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnConvolutionBackwardFilter__table_ipg_rzt_y3b" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" colspan="6" align="left" valign="top" rowspan="1">
                                       <p dir="ltr" class="p"><strong class="ph b">Filter descriptor </strong><samp class="ph codeph"><strong class="ph b">wDesc:
                                                </strong></samp><samp class="ph codeph">_<strong class="ph b">NCHW</strong></samp></p>
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" align="left" valign="top" width="21.207658321060386%" rowspan="1" colspan="1"><strong class="ph b">Algo Name </strong></td>
                                    <td class="entry" align="left" valign="top" width="14.72754050073638%" rowspan="1" colspan="1"><strong class="ph b">Deterministic (Yes or No)</strong></td>
                                    <td class="entry" dir="ltr" align="left" valign="top" width="12.51840942562592%" rowspan="1" colspan="1"><strong class="ph b">Tensor Formats Supported for
                                          <samp class="ph codeph">xDesc</samp></strong></td>
                                    <td class="entry" align="left" valign="top" width="14.72754050073638%" rowspan="1" colspan="1"><strong class="ph b">Tensor Formats Supported for  <samp class="ph codeph">dyDesc</samp></strong></td>
                                    <td class="entry" dir="ltr" align="left" valign="top" width="16.936671575846834%" rowspan="1" colspan="1"><strong class="ph b">Data Type Configurations Support</strong></td>
                                    <td class="entry" dir="ltr" align="left" valign="top" width="19.882179675994113%" rowspan="1" colspan="1"><strong class="ph b">Important</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" align="left" valign="top" width="21.207658321060386%" rowspan="1" colspan="1"><strong class="ph b">_ALGO_0</strong></td>
                                    <td class="entry" align="left" valign="top" width="14.72754050073638%" rowspan="1" colspan="1">No</td>
                                    <td class="entry" dir="ltr" align="left" valign="top" width="12.51840942562592%" rowspan="1" colspan="1">
                                       <p class="p"> All except <samp class="ph codeph">_NCDHW_VECT_C</samp>.  
                                       </p>
                                    </td>
                                    <td class="entry" align="left" valign="top" width="14.72754050073638%" rowspan="1" colspan="1">
                                       <p class="p"> NCDHW CDHW-packed</p>
                                    </td>
                                    <td class="entry" dir="ltr" align="left" valign="top" width="16.936671575846834%" rowspan="1" colspan="1">
                                       <p class="p">- PSEUDO_HALF_CONFIG,</p>
                                       <p class="p">- FLOAT_CONFIG, and</p>
                                       <p class="p">- DOUBLE_CONFIG.</p>
                                    </td>
                                    <td class="entry" align="left" valign="top" width="19.882179675994113%" rowspan="1" colspan="1">
                                       <p dir="ltr" class="p">- <strong class="ph b">Dilation</strong>: greater than 0 for all dimensions
                                       </p>
                                       <p class="p">- <samp class="ph codeph">convDesc</samp> Group Count Support: Greater than 0. 
                                       </p>
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" align="left" valign="top" width="21.207658321060386%" rowspan="1" colspan="1"><strong class="ph b">_ALGO_3</strong></td>
                                    <td class="entry" align="left" valign="top" width="14.72754050073638%" rowspan="1" colspan="1">No</td>
                                    <td class="entry" dir="ltr" align="left" valign="top" width="12.51840942562592%" rowspan="1" colspan="1">
                                       <p class="p"> NCDHW-fully-packed</p>
                                    </td>
                                    <td class="entry" align="left" valign="top" width="14.72754050073638%" rowspan="1" colspan="1">
                                       <p class="p"> NCDHW-fully-packed</p>
                                    </td>
                                    <td class="entry" dir="ltr" align="left" valign="top" width="16.936671575846834%" rowspan="1" colspan="1">
                                       <p class="p">- PSEUDO_HALF_CONFIG,</p>
                                       <p class="p">- FLOAT_CONFIG, and</p>
                                       <p class="p">- DOUBLE_CONFIG.</p>
                                    </td>
                                    <td class="entry" align="left" valign="top" width="19.882179675994113%" rowspan="1" colspan="1">
                                       <p dir="ltr" class="p">- <strong class="ph b">Dilation</strong>: 1 for all dimensions
                                       </p>
                                       <p class="p">- <samp class="ph codeph">convDesc</samp> Group Count Support: Greater than 0. 
                                       </p>
                                    </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The operation was launched successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnConvolutionBackwardFilter__ul_y5f_hjb_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnConvolutionBackwardFilter__ul_y5f_hjb_s1b">
                                 <li class="li">At least one of the following is NULL: <samp class="ph codeph">handle</samp>,
                                    <samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">dyDesc</samp>,
                                    <samp class="ph codeph">convDesc</samp>, <samp class="ph codeph">dwDesc</samp>,
                                    <samp class="ph codeph">xData</samp>, <samp class="ph codeph">dyData</samp>,
                                    <samp class="ph codeph">dwData</samp>, <samp class="ph codeph">alpha</samp>,
                                    <samp class="ph codeph">beta</samp></li>
                                 <li class="li"><samp class="ph codeph">xDesc</samp> and <samp class="ph codeph">dyDesc</samp> have a non-matching
                                    number of dimensions
                                 </li>
                                 <li class="li"><samp class="ph codeph">xDesc</samp> and <samp class="ph codeph">dwDesc</samp> have a non-matching
                                    number of dimensions
                                 </li>
                                 <li class="li"><samp class="ph codeph">xDesc</samp> has fewer than three number of dimensions
                                 </li>
                                 <li class="li"><samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">dyDesc</samp> and
                                    <samp class="ph codeph">dwDesc</samp> have a non-matching data type.
                                 </li>
                                 <li class="li"><samp class="ph codeph">xDesc</samp> and <samp class="ph codeph">dwDesc</samp> have a non-matching
                                    number of input feature maps per image (or group in case of Grouped
                                    Convolutions).
                                 </li>
                                 <li class="li"><samp class="ph codeph">yDesc</samp> or <samp class="ph codeph">wDesc</samp> indicate an output
                                    channel count that isn't a multiple of group count (if group count has
                                    been set in convDesc).
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">At least one of the following conditions are met: <a name="cudnnConvolutionBackwardFilter__ul_dvf_hjb_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnConvolutionBackwardFilter__ul_dvf_hjb_s1b">
                                 <li class="li"><samp class="ph codeph">xDesc</samp> or <samp class="ph codeph">dyDesc</samp> have negative tensor
                                    striding
                                 </li>
                                 <li class="li"><samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">dyDesc</samp> or
                                    <samp class="ph codeph">dwDesc</samp> has a number of dimensions that is not 4 or
                                    5
                                 </li>
                                 <li class="li">The chosen algo does not support the parameters provided; see above for
                                    exhaustive list of parameter support for each algo
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_MAPPING_ERROR</samp></dt>
                           <dd class="dd">
                              <p class="p">An error occurs during the texture binding of the filter data.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function failed to launch on the GPU.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnConvolutionBiasActivationForward"><a name="cudnnConvolutionBiasActivationForward" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnConvolutionBiasActivationForward" name="cudnnConvolutionBiasActivationForward" shape="rect">4.12.&nbsp;cudnnConvolutionBiasActivationForward</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnConvolutionBiasActivationForward(
    cudnnHandle_t                       handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                         *alpha1,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                         *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t       wDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                         *w,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnConvolutionDescriptor_t  convDesc,
    cudnnConvolutionFwdAlgo_t           algo,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                               *workSpace,
    size_t                              workSpaceSizeInBytes,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                         *alpha2,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       zDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                         *z,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       biasDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                         *bias,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnActivationDescriptor_t   activationDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                               *y)</pre><p class="p">This function applies a bias and then an activation to the convolutions or
                           cross-correlations of cudnnConvolutionForward(), returning results in
                           <samp class="ph codeph">y</samp>. The full computation follows the equation <samp class="ph codeph">y = act ( alpha1 *
                              conv(x) + alpha2 * z + bias )</samp>.
                        </p>
                        <div class="note note"><span class="notetitle">Note:</span> The routine <samp class="ph codeph">cudnnGetConvolution2dForwardOutputDim</samp> or
                           <samp class="ph codeph">cudnnGetConvolutionNdForwardOutputDim</samp> can be used to determine the
                           proper dimensions of the output tensor descriptor <samp class="ph codeph">yDesc</samp> with respect to
                           <samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">convDesc</samp> and <samp class="ph codeph">wDesc</samp>. 
                        </div>
                        <div class="note note"><span class="notetitle">Note:</span>  Only the CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_​PRECOMP_GEMM algo is enabled with
                           CUDNN_ACTIVATION_IDENTITY. In other words, in the
                           <samp class="ph codeph">cudnnActivationDescriptor_t</samp> structure of the input
                           <samp class="ph codeph">activationDesc</samp>, if the mode of the
                           <samp class="ph codeph">cudnnActivationMode_t</samp> field is set to the enum value
                           CUDNN_ACTIVATION_IDENTITY, then the input <samp class="ph codeph">cudnnConvolutionFwdAlgo_t</samp> of
                           this function <samp class="ph codeph">cudnnConvolutionBiasActivationForward()</samp> must be set to
                           the enum value CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_​PRECOMP_GEMM. See also the
                           documentation for the function <samp class="ph codeph">cudnnSetActivationDescriptor()</samp>. 
                        </div>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context. See <a class="xref" href="index.html#cudnnHandle_t" shape="rect">cudnnHandle_t.</a></p>
                           </dd>
                           <dt class="dt dlterm">alpha1, alpha2 </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointers to scaling factors (in host memory) used to blend the
                                 computation result with prior value in the output layer as described by the
                                 above equation. <a class="xref" href="index.html#general-description" shape="rect">Please refer to this section for additional details.</a></p>
                           </dd>
                           <dt class="dt dlterm">xDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor. See <a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t.</a></p>
                           </dd>
                           <dt class="dt dlterm">x </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">xDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">wDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor. See <a class="xref" href="index.html#cudnnFilterDescriptor_t" shape="rect">cudnnFilterDescriptor_t</a>.
                                 
                              </p>
                           </dd>
                           <dt class="dt dlterm">w </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the filter
                                 descriptor <samp class="ph codeph">wDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">convDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Previously initialized convolution descriptor. See <a class="xref" href="index.html#cudnnConvolutionDescriptor_t" shape="rect">cudnnConvolutionDescriptor_t</a>.
                                 
                              </p>
                           </dd>
                           <dt class="dt dlterm">algo </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Enumerant that specifies which convolution algorithm should be
                                 used to compute the results. See <a class="xref" href="index.html#cudnnConvolutionFwdAlgo_t" shape="rect">cudnnConvolutionFwdAlgo_t</a>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">workSpace </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory to a workspace needed to able to
                                 execute the specified algorithm. If no workspace is needed for a particular
                                 algorithm, that pointer can be nil.
                              </p>
                           </dd>
                           <dt class="dt dlterm">workSpaceSizeInBytes </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                 <samp class="ph codeph">workSpace</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">zDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">z </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">zDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">biasDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">bias </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">biasDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">activationDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized activation descriptor. See
                                 <a class="xref" href="index.html#cudnnActivationDescriptor_t" shape="rect">cudnnActivationDescriptor_t</a>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">yDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">y </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input/Output</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">yDesc</samp> that carries the result of the
                                 convolution.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">For the convolution step, this function supports the specific combinations of data types
                           for <samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">wDesc</samp>, <samp class="ph codeph">convDesc</samp> and
                           <samp class="ph codeph">yDesc</samp> as listed in the documentation of cudnnConvolutionForward().
                           The following table specifies the supported combinations of data types for
                           <samp class="ph codeph">x</samp>, <samp class="ph codeph">y</samp>, <samp class="ph codeph">z</samp>, <samp class="ph codeph">bias</samp>,
                           and <samp class="ph codeph">alpha1/alpha2</samp>.
                        </p>
                        <p class="p">Table Key: X = CUDNN_DATA</p>
                        <div class="tablenoborder"><a name="cudnnConvolutionBiasActivationForward__table_vmm_yhb_s1b" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnConvolutionBiasActivationForward__table_vmm_yhb_s1b" class="table" frame="border" border="1" rules="all">
                              <thead class="thead" align="left">
                                 <tr class="row">
                                    <th class="entry" valign="top" width="20%" id="d54e20292" rowspan="1" colspan="1">x</th>
                                    <th class="entry" valign="top" width="20%" id="d54e20295" rowspan="1" colspan="1">w</th>
                                    <th class="entry" valign="top" width="20%" id="d54e20298" rowspan="1" colspan="1">y and z</th>
                                    <th class="entry" valign="top" width="20%" id="d54e20301" rowspan="1" colspan="1">bias</th>
                                    <th class="entry" valign="top" width="20%" id="d54e20304" rowspan="1" colspan="1">alpha1/alpha2</th>
                                 </tr>
                              </thead>
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" valign="top" width="20%" headers="d54e20292" rowspan="1" colspan="1">X_DOUBLE</td>
                                    <td class="entry" valign="top" width="20%" headers="d54e20295" rowspan="1" colspan="1">X_DOUBLE</td>
                                    <td class="entry" valign="top" width="20%" headers="d54e20298" rowspan="1" colspan="1">X_DOUBLE</td>
                                    <td class="entry" valign="top" width="20%" headers="d54e20301" rowspan="1" colspan="1">X_DOUBLE</td>
                                    <td class="entry" valign="top" width="20%" headers="d54e20304" rowspan="1" colspan="1">X_DOUBLE</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="20%" headers="d54e20292" rowspan="1" colspan="1">X_FLOAT</td>
                                    <td class="entry" valign="top" width="20%" headers="d54e20295" rowspan="1" colspan="1">X_FLOAT</td>
                                    <td class="entry" valign="top" width="20%" headers="d54e20298" rowspan="1" colspan="1">X_FLOAT</td>
                                    <td class="entry" valign="top" width="20%" headers="d54e20301" rowspan="1" colspan="1">X_FLOAT</td>
                                    <td class="entry" valign="top" width="20%" headers="d54e20304" rowspan="1" colspan="1">X_FLOAT</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="20%" headers="d54e20292" rowspan="1" colspan="1">X_HALF</td>
                                    <td class="entry" valign="top" width="20%" headers="d54e20295" rowspan="1" colspan="1">X_HALF</td>
                                    <td class="entry" valign="top" width="20%" headers="d54e20298" rowspan="1" colspan="1">X_HALF</td>
                                    <td class="entry" valign="top" width="20%" headers="d54e20301" rowspan="1" colspan="1">X_HALF</td>
                                    <td class="entry" valign="top" width="20%" headers="d54e20304" rowspan="1" colspan="1">X_FLOAT</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="20%" headers="d54e20292" rowspan="1" colspan="1">X_INT8</td>
                                    <td class="entry" valign="top" width="20%" headers="d54e20295" rowspan="1" colspan="1">X_INT8</td>
                                    <td class="entry" valign="top" width="20%" headers="d54e20298" rowspan="1" colspan="1">X_INT8</td>
                                    <td class="entry" valign="top" width="20%" headers="d54e20301" rowspan="1" colspan="1">X_FLOAT</td>
                                    <td class="entry" valign="top" width="20%" headers="d54e20304" rowspan="1" colspan="1">X_FLOAT</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="20%" headers="d54e20292" rowspan="1" colspan="1">X_INT8</td>
                                    <td class="entry" valign="top" width="20%" headers="d54e20295" rowspan="1" colspan="1">X_INT8</td>
                                    <td class="entry" valign="top" width="20%" headers="d54e20298" rowspan="1" colspan="1">X_FLOAT</td>
                                    <td class="entry" valign="top" width="20%" headers="d54e20301" rowspan="1" colspan="1">X_FLOAT</td>
                                    <td class="entry" valign="top" width="20%" headers="d54e20304" rowspan="1" colspan="1">X_FLOAT</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="20%" headers="d54e20292" rowspan="1" colspan="1">X_INT8x4</td>
                                    <td class="entry" valign="top" width="20%" headers="d54e20295" rowspan="1" colspan="1">X_INT8x4</td>
                                    <td class="entry" valign="top" width="20%" headers="d54e20298" rowspan="1" colspan="1">X_INT8x4</td>
                                    <td class="entry" valign="top" width="20%" headers="d54e20301" rowspan="1" colspan="1">X_FLOAT</td>
                                    <td class="entry" valign="top" width="20%" headers="d54e20304" rowspan="1" colspan="1">X_FLOAT</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="20%" headers="d54e20292" rowspan="1" colspan="1">X_INT8x4</td>
                                    <td class="entry" valign="top" width="20%" headers="d54e20295" rowspan="1" colspan="1">X_INT8x4</td>
                                    <td class="entry" valign="top" width="20%" headers="d54e20298" rowspan="1" colspan="1">X_FLOAT</td>
                                    <td class="entry" valign="top" width="20%" headers="d54e20301" rowspan="1" colspan="1">X_FLOAT</td>
                                    <td class="entry" valign="top" width="20%" headers="d54e20304" rowspan="1" colspan="1">X_FLOAT</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="20%" headers="d54e20292" rowspan="1" colspan="1">X_UINT8</td>
                                    <td class="entry" valign="top" width="20%" headers="d54e20295" rowspan="1" colspan="1">X_INT8</td>
                                    <td class="entry" valign="top" width="20%" headers="d54e20298" rowspan="1" colspan="1">X_INT8</td>
                                    <td class="entry" valign="top" width="20%" headers="d54e20301" rowspan="1" colspan="1">X_FLOAT</td>
                                    <td class="entry" valign="top" width="20%" headers="d54e20304" rowspan="1" colspan="1">X_FLOAT</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="20%" headers="d54e20292" rowspan="1" colspan="1">X_UINT8</td>
                                    <td class="entry" valign="top" width="20%" headers="d54e20295" rowspan="1" colspan="1">X_INT8</td>
                                    <td class="entry" valign="top" width="20%" headers="d54e20298" rowspan="1" colspan="1">X_FLOAT</td>
                                    <td class="entry" valign="top" width="20%" headers="d54e20301" rowspan="1" colspan="1">X_FLOAT</td>
                                    <td class="entry" valign="top" width="20%" headers="d54e20304" rowspan="1" colspan="1">X_FLOAT</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="20%" headers="d54e20292" rowspan="1" colspan="1">X_UINT8x4</td>
                                    <td class="entry" valign="top" width="20%" headers="d54e20295" rowspan="1" colspan="1">X_INT8x4</td>
                                    <td class="entry" valign="top" width="20%" headers="d54e20298" rowspan="1" colspan="1">X_INT8x4</td>
                                    <td class="entry" valign="top" width="20%" headers="d54e20301" rowspan="1" colspan="1">X_FLOAT</td>
                                    <td class="entry" valign="top" width="20%" headers="d54e20304" rowspan="1" colspan="1">X_FLOAT</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="20%" headers="d54e20292" rowspan="1" colspan="1">X_UINT8x4</td>
                                    <td class="entry" valign="top" width="20%" headers="d54e20295" rowspan="1" colspan="1">X_INT8x4</td>
                                    <td class="entry" valign="top" width="20%" headers="d54e20298" rowspan="1" colspan="1">X_FLOAT</td>
                                    <td class="entry" valign="top" width="20%" headers="d54e20301" rowspan="1" colspan="1">X_FLOAT</td>
                                    <td class="entry" valign="top" width="20%" headers="d54e20304" rowspan="1" colspan="1">X_FLOAT</td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                        <p class="p">In addition to the error values listed by the documentation of cudnnConvolutionForward(),
                           the possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The operation was launched successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">At least one of the following conditions are met: <a name="cudnnConvolutionBiasActivationForward__ul_dnm_yhb_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnConvolutionBiasActivationForward__ul_dnm_yhb_s1b">
                                 <li class="li">At least one of the following is NULL: <samp class="ph codeph">zDesc</samp>,
                                    <samp class="ph codeph">zData</samp>, <samp class="ph codeph">biasDesc</samp>,
                                    <samp class="ph codeph">bias</samp>, <samp class="ph codeph">activationDesc</samp>.
                                 </li>
                                 <li class="li">The second dimension of <samp class="ph codeph">biasDesc</samp> and the first
                                    dimension of <samp class="ph codeph">filterDesc</samp> are not equal.
                                 </li>
                                 <li class="li"><samp class="ph codeph">zDesc</samp> and <samp class="ph codeph">destDesc</samp> do not match.
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">The function does not support the provided configuration. See the following for
                              some examples of non-supported configurations: <a name="cudnnConvolutionBiasActivationForward__ul_fnm_yhb_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnConvolutionBiasActivationForward__ul_fnm_yhb_s1b">
                                 <li class="li">The <samp class="ph codeph">mode</samp> of <samp class="ph codeph">activationDesc</samp> is neither <samp class="ph codeph">CUDNN_ACTIVATION_RELU</samp> or <samp class="ph codeph">CUDNN_ACTIVATION_IDENTITY</samp>.
                                 </li>
                                 <li class="li">The <samp class="ph codeph">reluNanOpt</samp> of <samp class="ph codeph">activationDesc</samp> is not <samp class="ph codeph">CUDNN_NOT_PROPAGATE_NAN</samp>.
                                 </li>
                                 <li class="li">The second stride of <samp class="ph codeph">biasDesc</samp> is not equal to one.
                                 </li>
                                 <li class="li">The data type of <samp class="ph codeph">biasDesc</samp> does not correspond to the data type of <samp class="ph codeph">yDesc</samp> as listed in the above data types table.
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function failed to launch on the GPU.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnConvolutionForward"><a name="cudnnConvolutionForward" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnConvolutionForward" name="cudnnConvolutionForward" shape="rect">4.13.&nbsp;cudnnConvolutionForward</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnConvolutionForward(
    cudnnHandle_t                       handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                         *alpha,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                         *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t       wDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                         *w,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnConvolutionDescriptor_t  convDesc,
    cudnnConvolutionFwdAlgo_t           algo,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                               *workSpace,
    size_t                              workSpaceSizeInBytes,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                         *beta,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                               *y)</pre><p class="p">This function executes convolutions or cross-correlations over <samp class="ph codeph">x</samp> using
                           			filters specified with <samp class="ph codeph">w</samp>, returning results in <samp class="ph codeph">y</samp>.
                           			Scaling factors <samp class="ph codeph">alpha</samp> and <samp class="ph codeph">beta</samp> can be used to scale
                           			the input tensor and the output tensor respectively.
                        </p>
                        <div class="note note"><span class="notetitle">Note:</span> The routine <samp class="ph codeph">cudnnGetConvolution2dForwardOutputDim</samp> or
                           				<samp class="ph codeph">cudnnGetConvolutionNdForwardOutputDim</samp> can be used to determine the
                           			proper dimensions of the output tensor descriptor <samp class="ph codeph">yDesc</samp> with respect to
                           				<samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">convDesc</samp> and <samp class="ph codeph">wDesc</samp>. 
                        </div>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context. See <a class="xref" href="index.html#cudnnHandle_t" shape="rect">cudnnHandle_t.</a></p>
                           </dd>
                           <dt class="dt dlterm">alpha, beta </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointers to scaling factors (in host memory) used to blend the computation
                                 						result with prior value in the output layer as follows: dstValue =
                                 						alpha[0]*result + beta[0]*priorDstValue. <a class="xref" href="index.html#scaling-parameters" shape="rect">Refer to this section for additional details.</a></p>
                           </dd>
                           <dt class="dt dlterm">xDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor. See <a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t.</a></p>
                           </dd>
                           <dt class="dt dlterm">x </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 						descriptor <samp class="ph codeph">xDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">wDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor. See <a class="xref" href="index.html#cudnnFilterDescriptor_t" shape="rect">cudnnFilterDescriptor_t</a>.
                                 					
                              </p>
                           </dd>
                           <dt class="dt dlterm">w </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the filter
                                 						descriptor <samp class="ph codeph">wDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">convDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Previously initialized convolution descriptor. See <a class="xref" href="index.html#cudnnConvolutionDescriptor_t" shape="rect">cudnnConvolutionDescriptor_t</a>.
                                 					
                              </p>
                           </dd>
                           <dt class="dt dlterm">algo </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Enumerant that specifies which convolution algorithm shoud be
                                 						used to compute the results. See <a class="xref" href="index.html#cudnnConvolutionFwdAlgo_t" shape="rect">cudnnConvolutionFwdAlgo_t</a>.
                                 					
                              </p>
                           </dd>
                           <dt class="dt dlterm">workSpace </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory to a workspace needed to able to
                                 						execute the specified algorithm. If no workspace is needed for a particular
                                 						algorithm, that pointer can be nil.
                              </p>
                           </dd>
                           <dt class="dt dlterm">workSpaceSizeInBytes </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                 							<samp class="ph codeph">workSpace</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">yDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">y </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input/Output</em>. Data pointer to GPU memory associated with the tensor
                                 						descriptor <samp class="ph codeph">yDesc</samp> that carries the result of the
                                 						convolution.
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">TABLE OF THE SUPPORTED CONFIGURATIONS</strong></p>
                        <p class="p">This function supports the following  combinations of data types for <samp class="ph codeph">xDesc</samp>,
                           				<samp class="ph codeph">wDesc</samp>, <samp class="ph codeph">convDesc</samp>, and <samp class="ph codeph">yDesc</samp>. See
                           			the following table for a list of the supported configurations.
                        </p>
                        <div class="tablenoborder"><a name="cudnnConvolutionForward__table_wst_5hb_s1b" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnConvolutionForward__table_wst_5hb_s1b" class="table" frame="border" border="1" rules="all">
                              <thead class="thead" align="left">
                                 <tr class="row">
                                    <th class="entry" valign="top" width="22.29428455614106%" id="d54e20966" rowspan="1" colspan="1">Data Type Configurations</th>
                                    <th class="entry" valign="top" width="25.90190514795298%" id="d54e20969" rowspan="1" colspan="1"><samp class="ph codeph">xDesc</samp> and <samp class="ph codeph">wDesc</samp></th>
                                    <th class="entry" valign="top" width="25.90190514795298%" id="d54e20977" rowspan="1" colspan="1"><samp class="ph codeph">convDesc</samp></th>
                                    <th class="entry" valign="top" width="25.90190514795298%" id="d54e20981" rowspan="1" colspan="1"><samp class="ph codeph">yDesc</samp></th>
                                 </tr>
                              </thead>
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" valign="top" width="22.29428455614106%" headers="d54e20966" rowspan="1" colspan="1">TRUE_HALF_CONFIG (only supported on architectures with true fp16 support, i.e., compute
                                       							capability 5.3 and later).
                                    </td>
                                    <td class="entry" valign="top" width="25.90190514795298%" headers="d54e20969" rowspan="1" colspan="1">CUDNN_DATA_HALF</td>
                                    <td class="entry" valign="top" width="25.90190514795298%" headers="d54e20977" rowspan="1" colspan="1">CUDNN_DATA_HALF</td>
                                    <td class="entry" valign="top" width="25.90190514795298%" headers="d54e20981" rowspan="1" colspan="1">CUDNN_DATA_HALF</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="22.29428455614106%" headers="d54e20966" rowspan="1" colspan="1">PSEUDO_HALF_CONFIG</td>
                                    <td class="entry" valign="top" width="25.90190514795298%" headers="d54e20969" rowspan="1" colspan="1">CUDNN_DATA_HALF</td>
                                    <td class="entry" valign="top" width="25.90190514795298%" headers="d54e20977" rowspan="1" colspan="1">CUDNN_DATA_FLOAT</td>
                                    <td class="entry" valign="top" width="25.90190514795298%" headers="d54e20981" rowspan="1" colspan="1">CUDNN_DATA_HALF</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="22.29428455614106%" headers="d54e20966" rowspan="1" colspan="1">FLOAT_CONFIG</td>
                                    <td class="entry" valign="top" width="25.90190514795298%" headers="d54e20969" rowspan="1" colspan="1">CUDNN_DATA_FLOAT</td>
                                    <td class="entry" valign="top" width="25.90190514795298%" headers="d54e20977" rowspan="1" colspan="1">CUDNN_DATA_FLOAT</td>
                                    <td class="entry" valign="top" width="25.90190514795298%" headers="d54e20981" rowspan="1" colspan="1">CUDNN_DATA_FLOAT</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="22.29428455614106%" headers="d54e20966" rowspan="1" colspan="1">DOUBLE_CONFIG</td>
                                    <td class="entry" valign="top" width="25.90190514795298%" headers="d54e20969" rowspan="1" colspan="1">CUDNN_DATA_DOUBLE</td>
                                    <td class="entry" valign="top" width="25.90190514795298%" headers="d54e20977" rowspan="1" colspan="1">CUDNN_DATA_DOUBLE</td>
                                    <td class="entry" valign="top" width="25.90190514795298%" headers="d54e20981" rowspan="1" colspan="1">CUDNN_DATA_DOUBLE</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="22.29428455614106%" headers="d54e20966" rowspan="1" colspan="1">INT8_CONFIG (only supported on architectures with DP4A support, i.e.,
                                       							compute capability 6.1 and later).
                                    </td>
                                    <td class="entry" valign="top" width="25.90190514795298%" headers="d54e20969" rowspan="1" colspan="1">CUDNN_DATA_INT8</td>
                                    <td class="entry" valign="top" width="25.90190514795298%" headers="d54e20977" rowspan="1" colspan="1">CUDNN_DATA_INT32</td>
                                    <td class="entry" valign="top" width="25.90190514795298%" headers="d54e20981" rowspan="1" colspan="1">CUDNN_DATA_INT8</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="22.29428455614106%" headers="d54e20966" rowspan="1" colspan="1">INT8_EXT_CONFIG (only supported on architectures with DP4A support,
                                       							i.e., compute capability 6.1 and later).
                                    </td>
                                    <td class="entry" valign="top" width="25.90190514795298%" headers="d54e20969" rowspan="1" colspan="1">CUDNN_DATA_INT8</td>
                                    <td class="entry" valign="top" width="25.90190514795298%" headers="d54e20977" rowspan="1" colspan="1">CUDNN_DATA_INT32</td>
                                    <td class="entry" valign="top" width="25.90190514795298%" headers="d54e20981" rowspan="1" colspan="1">CUDNN_DATA_FLOAT</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="22.29428455614106%" headers="d54e20966" rowspan="1" colspan="1">INT8x4_CONFIG (only supported on architectures with DP4A support,
                                       							i.e., compute capability 6.1 and later).
                                    </td>
                                    <td class="entry" valign="top" width="25.90190514795298%" headers="d54e20969" rowspan="1" colspan="1">CUDNN_DATA_INT8x4</td>
                                    <td class="entry" valign="top" width="25.90190514795298%" headers="d54e20977" rowspan="1" colspan="1">CUDNN_DATA_INT32</td>
                                    <td class="entry" valign="top" width="25.90190514795298%" headers="d54e20981" rowspan="1" colspan="1">CUDNN_DATA_INT8x4</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="22.29428455614106%" headers="d54e20966" rowspan="1" colspan="1">INT8x4_EXT_CONFIG (only supported on architectures with DP4A support,
                                       							i.e., compute capability 6.1 and later).
                                    </td>
                                    <td class="entry" valign="top" width="25.90190514795298%" headers="d54e20969" rowspan="1" colspan="1">CUDNN_DATA_INT8x4</td>
                                    <td class="entry" valign="top" width="25.90190514795298%" headers="d54e20977" rowspan="1" colspan="1">CUDNN_DATA_INT32</td>
                                    <td class="entry" valign="top" width="25.90190514795298%" headers="d54e20981" rowspan="1" colspan="1">CUDNN_DATA_FLOAT</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="22.29428455614106%" headers="d54e20966" rowspan="1" colspan="1">UINT8x4_CONFIG (new for 7.1) (only supported on architectures with
                                       							DP4A support, i.e., compute capability 6.1 and later).
                                    </td>
                                    <td class="entry" valign="top" width="25.90190514795298%" headers="d54e20969" rowspan="1" colspan="1">CUDNN_DATA_UINT8x4</td>
                                    <td class="entry" valign="top" width="25.90190514795298%" headers="d54e20977" rowspan="1" colspan="1">CUDNN_DATA_INT32</td>
                                    <td class="entry" valign="top" width="25.90190514795298%" headers="d54e20981" rowspan="1" colspan="1">CUDNN_DATA_UINT8x4</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="22.29428455614106%" headers="d54e20966" rowspan="1" colspan="1">UINT8x4_EXT_CONFIG (new for 7.1) (only supported on architectures
                                       							with DP4A support, i.e., compute capability 6.1 and later).
                                    </td>
                                    <td class="entry" valign="top" width="25.90190514795298%" headers="d54e20969" rowspan="1" colspan="1">CUDNN_DATA_UINT8x4</td>
                                    <td class="entry" valign="top" width="25.90190514795298%" headers="d54e20977" rowspan="1" colspan="1">CUDNN_DATA_INT32</td>
                                    <td class="entry" valign="top" width="25.90190514795298%" headers="d54e20981" rowspan="1" colspan="1">CUDNN_DATA_FLOAT</td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                        <div class="p">
                           <div class="note note"><span class="notetitle">Note:</span> For this function, all algorithms perform deterministic computations. Specifying a
                              				separate algorithm can cause changes in performance and support. 
                           </div>
                        </div>
                        <p class="p"><strong class="ph b">TABLE OF THE SUPPORTED ALGORITHMS</strong></p>
                        <p class="p">The table below shows the list of the supported 2D and 3D convolutions. The 2D convolutions are
                           			described first, followed by the 3D convolutions. 
                        </p>
                        <p class="p">For the following terms, the short-form versions shown in the paranthesis are used in the table
                           			below, for brevity: 
                        </p>
                        <div class="p"><a name="cudnnConvolutionForward__ul_tkp_2w5_y2b" shape="rect">
                              <!-- --></a><ul class="ul" id="cudnnConvolutionForward__ul_tkp_2w5_y2b">
                              <li class="li">CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM <strong class="ph b">(_IMPLICIT_GEMM)</strong></li>
                              <li class="li">CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM <strong class="ph b">(_IMPLICIT_PRECOMP_GEMM)</strong></li>
                              <li class="li">CUDNN_CONVOLUTION_FWD_ALGO_GEMM <strong class="ph b">(_GEMM)</strong></li>
                              <li class="li">CUDNN_CONVOLUTION_FWD_ALGO_DIRECT <strong class="ph b">(_DIRECT)</strong></li>
                              <li class="li">CUDNN_CONVOLUTION_FWD_ALGO_FFT <strong class="ph b">(_FFT)</strong></li>
                              <li class="li">CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING <strong class="ph b">(_FFT_TILING)</strong></li>
                              <li class="li">CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD <strong class="ph b">(_WINOGRAD)</strong></li>
                              <li class="li">CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED <strong class="ph b">(_WINOGRAD_NONFUSED)</strong></li>
                              <li class="li">CUDNN_TENSOR_NCHW <strong class="ph b">(_NCHW)</strong></li>
                              <li class="li">CUDNN_TENSOR_NHWC <strong class="ph b">(_NHWC)</strong></li>
                              <li class="li">CUDNN_TENSOR_NCHW_VECT_C <strong class="ph b">(_NCHW_VECT_C)</strong></li>
                           </ul>
                        </div>
                        <p class="p"><strong class="ph b">FOR 2D CONVOLUTIONS.</strong></p>
                        <div class="p">
                           <div class="tablenoborder"><a name="cudnnConvolutionForward__table_ipg_rzt_y2b" shape="rect">
                                 <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnConvolutionForward__table_ipg_rzt_y2b" class="table" frame="border" border="1" rules="all">
                                 <tbody class="tbody">
                                    <tr class="row">
                                       <td class="entry" colspan="5" align="left" valign="top" rowspan="1">
                                          <p class="p"></p>
                                          <p dir="ltr" class="p"><strong class="ph b">Filter descriptor </strong><samp class="ph codeph"><strong class="ph b">wDesc:
                                                   										</strong></samp><samp class="ph codeph">_<strong class="ph b">NCHW</strong></samp>. See <a class="xref" href="index.html#cudnnTensorFormat_t" shape="rect">cudnnTensorFormat_t</a>.
                                          </p>
                                          <p class="p"><samp class="ph codeph">convDesc</samp> Group count support: Greater than 0,
                                             									for all algos.
                                          </p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" align="left" valign="top" width="24.870466321243526%" rowspan="1" colspan="1"><strong class="ph b">Algo Name </strong><p class="p">(see below for 3D Convolutions)</p>
                                       </td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="14.680483592400693%" rowspan="1" colspan="1"><strong class="ph b">Tensor Formats Supported for
                                             									<samp class="ph codeph">xDesc</samp></strong></td>
                                       <td class="entry" align="left" valign="top" width="17.271157167530227%" rowspan="1" colspan="1"><strong class="ph b">Tensor Formats Supported for
                                             								<samp class="ph codeph">yDesc</samp></strong></td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="19.86183074265976%" rowspan="1" colspan="1"><strong class="ph b">Data Type Configurations Supported</strong></td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="23.316062176165808%" rowspan="1" colspan="1"><strong class="ph b">Important</strong></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" align="left" valign="top" width="24.870466321243526%" rowspan="1" colspan="1"><strong class="ph b">_IMPLICIT_GEMM</strong></td>
                                       <td class="entry" dir="ltr" rowspan="3" align="left" valign="top" width="14.680483592400693%" colspan="1">All except <samp class="ph codeph">_NCHW_VECT_C</samp>.  
                                       </td>
                                       <td class="entry" rowspan="3" align="left" valign="top" width="17.271157167530227%" colspan="1">All except <samp class="ph codeph">_NCHW_VECT_C</samp>.   
                                       </td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="19.86183074265976%" rowspan="1" colspan="1">
                                          <p class="p">- PSEUDO_HALF_CONFIG,</p>
                                          <p class="p">- FLOAT_CONFIG, and</p>
                                          <p class="p">- DOUBLE_CONFIG</p>
                                       </td>
                                       <td class="entry" align="left" valign="top" width="23.316062176165808%" rowspan="1" colspan="1">
                                          <p class="p"><strong class="ph b">Dilation</strong>: Greater than 0 for all dimensions. 
                                          </p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" align="left" valign="top" width="24.870466321243526%" rowspan="1" colspan="1"><strong class="ph b">_IMPLICIT_PRECOMP_GEMM</strong></td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="19.86183074265976%" rowspan="1" colspan="1">
                                          <p class="p">- TRUE_HALF_CONFIG,</p>
                                          <p class="p">- PSEUDO_HALF_CONFIG,</p>
                                          <p class="p">- FLOAT_CONFIG, and</p>
                                          <p class="p"> - DOUBLE_CONFIG.</p>
                                       </td>
                                       <td class="entry" align="left" valign="top" width="23.316062176165808%" rowspan="1" colspan="1">
                                          <p class="p"><strong class="ph b">Dilation</strong>: 1 for all dimensions. 
                                          </p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" align="left" valign="top" width="24.870466321243526%" rowspan="1" colspan="1"><strong class="ph b">_GEMM</strong></td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="19.86183074265976%" rowspan="1" colspan="1">
                                          <p class="p">- PSEUDO_HALF_CONFIG,</p>
                                          <p class="p">- FLOAT_CONFIG, and</p>
                                          <p class="p">- DOUBLE_CONFIG</p>
                                       </td>
                                       <td class="entry" align="left" valign="top" width="23.316062176165808%" rowspan="1" colspan="1">
                                          <p class="p"><strong class="ph b">Dilation</strong>: 1 for all dimensions. 
                                          </p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" align="left" valign="top" width="24.870466321243526%" rowspan="1" colspan="1"><strong class="ph b">_FFT</strong></td>
                                       <td class="entry" dir="ltr" rowspan="2" align="left" valign="top" width="14.680483592400693%" colspan="1">NCHW HW-packed</td>
                                       <td class="entry" rowspan="2" align="left" valign="top" width="17.271157167530227%" colspan="1">NCHW HW-packed</td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="19.86183074265976%" rowspan="1" colspan="1">
                                          <p class="p">- PSEUDO_HALF_CONFIG, and</p>
                                          <p class="p">- FLOAT_CONFIG</p>
                                       </td>
                                       <td class="entry" align="left" valign="top" width="23.316062176165808%" rowspan="1" colspan="1">
                                          <p class="p"><strong class="ph b">Dilation</strong>: 1 for all dimensions. 
                                          </p>
                                          <p dir="ltr" class="p">- xDesc's feature map <strong class="ph b">height </strong>+ 2 * convDesc's
                                             									zero-padding height must equal 256 or less
                                          </p>
                                          <p dir="ltr" class="p">- xDesc's feature map <strong class="ph b">width </strong>+ 2 * convDesc's
                                             									zero-padding width must equal 256 or less
                                          </p>
                                          <p dir="ltr" class="p">- convDesc's vertical and horizontal filter stride must
                                             									equal 1
                                          </p>
                                          <p dir="ltr" class="p">- wDesc's filter height must be greater than convDesc's
                                             									zero-padding <strong class="ph b">height</strong></p>
                                          <p dir="ltr" class="p">- wDesc's filter width must be greater than convDesc's
                                             									zero-padding <strong class="ph b">width</strong></p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" align="left" valign="top" width="24.870466321243526%" rowspan="1" colspan="1"><strong class="ph b">_FFT_TILING</strong></td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="19.86183074265976%" rowspan="1" colspan="1">
                                          <p class="p">- PSEUDO_HALF_CONFIG, and</p>
                                          <p class="p">- FLOAT_CONFIG
                                             								
                                          </p>
                                          <p class="p"></p>
                                          
                                          DOUBLE_CONFIG is also supported when the task can be handled
                                          								by 1D FFT, i.e., one of the filter dimension, width or height is 1. 
                                       </td>
                                       <td class="entry" align="left" valign="top" width="23.316062176165808%" rowspan="1" colspan="1">
                                          <p class="p"><strong class="ph b">Dilation</strong>: 1 for all dimensions. 
                                          </p>
                                          <p class="p">- When <strong class="ph b">neither </strong>of wDesc's filter dimension is 1, the
                                             									filter width and height must not be larger than 32
                                          </p>
                                          <p class="p">- When <strong class="ph b">either </strong>of wDesc's filter dimension is 1, the
                                             									largest filter dimension should not exceed 256
                                          </p>
                                          <p class="p">- convDesc's vertical and horizontal filter stride must equal 1 when either the filter
                                             									width or filter height is 1, otherwise the stride can be 1 or
                                             									2
                                          </p>
                                          <p class="p">- wDesc's filter height must be greater than convDesc's
                                             									zero-padding height
                                          </p>
                                          <p class="p">- wDesc's filter width must be greater than convDesc's
                                             									zero-padding width
                                          </p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" align="left" valign="top" width="24.870466321243526%" rowspan="1" colspan="1"><strong class="ph b">_WINOGRAD</strong></td>
                                       <td class="entry" dir="ltr" rowspan="2" align="left" valign="top" width="14.680483592400693%" colspan="1">All <strong class="ph b">except:
                                             								</strong><p class="p"></p>
                                          
                                          _NCHW_VECT_C
                                       </td>
                                       <td class="entry" rowspan="2" align="left" valign="top" width="17.271157167530227%" colspan="1">All <strong class="ph b">except: </strong><p class="p"></p>
                                          
                                          _NCHW_VECT_C
                                       </td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="19.86183074265976%" rowspan="1" colspan="1">
                                          <p class="p">- PSEUDO_HALF_CONFIG, and</p>
                                          <p class="p">- FLOAT_CONFIG</p>
                                       </td>
                                       <td class="entry" align="left" valign="top" width="23.316062176165808%" rowspan="1" colspan="1">
                                          <p class="p"><strong class="ph b">Dilation</strong>: 1 for all dimensions. 
                                          </p>
                                          <p dir="ltr" class="p">- convDesc's vertical and horizontal filter stride must
                                             									equal 1
                                          </p>
                                          <p dir="ltr" class="p">- wDesc's filter <strong class="ph b">height </strong>must be 3
                                          </p>
                                          <p dir="ltr" class="p">- wDesc's filter <strong class="ph b">width </strong>must be 3
                                          </p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" align="left" valign="top" width="24.870466321243526%" rowspan="1" colspan="1"><strong class="ph b">_WINOGRAD_NONFUSED</strong></td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="19.86183074265976%" rowspan="1" colspan="1">
                                          <p class="p">- TRUE_HALF_CONFIG,</p>
                                          <p class="p">- PSEUDO_HALF_CONFIG, and</p>
                                          <p class="p">- FLOAT_CONFIG</p>
                                       </td>
                                       <td class="entry" align="left" valign="top" width="23.316062176165808%" rowspan="1" colspan="1">
                                          <p class="p"><strong class="ph b">Dilation</strong>: 1 for all dimensions. 
                                          </p>
                                          <p dir="ltr" class="p">- convDesc's vertical and horizontal filter stride must
                                             									equal 1
                                          </p>
                                          <p dir="ltr" class="p">- wDesc's filter (height, width) must be (3,3) or
                                             									(5,5)
                                          </p>
                                          <p dir="ltr" class="p">- If wDesc's filter (height, width) is (5,5), then data
                                             									type config TRUE_HALF_CONFIG is not supported
                                          </p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" align="left" valign="top" width="24.870466321243526%" rowspan="1" colspan="1"><strong class="ph b">_DIRECT</strong></td>
                                       <td class="entry" dir="ltr" colspan="4" align="left" valign="top" rowspan="1">Currently not implemented
                                          								in cuDNN.
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" colspan="5" align="left" valign="top" rowspan="1">
                                          <p class="p"></p>
                                          <p dir="ltr" class="p"><strong class="ph b">Filter descriptor </strong><samp class="ph codeph"><strong class="ph b">wDesc:
                                                   										</strong></samp><samp class="ph codeph">_<strong class="ph b">NHWC</strong></samp></p>
                                          <p class="p"><samp class="ph codeph">convDesc</samp> Group count support: Greater than
                                             									0.
                                          </p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" align="left" valign="top" width="24.870466321243526%" rowspan="1" colspan="1"><strong class="ph b">Algo Name </strong></td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="14.680483592400693%" rowspan="1" colspan="1"><strong class="ph b"><samp class="ph codeph">xDesc</samp></strong></td>
                                       <td class="entry" align="left" valign="top" width="17.271157167530227%" rowspan="1" colspan="1"><strong class="ph b"><samp class="ph codeph">yDesc</samp></strong></td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="19.86183074265976%" rowspan="1" colspan="1"><strong class="ph b">Data Type Configurations Support</strong></td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="23.316062176165808%" rowspan="1" colspan="1"><strong class="ph b">Important</strong></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" align="left" valign="top" width="24.870466321243526%" rowspan="1" colspan="1"><strong class="ph b">_IMPLICIT_GEMM</strong></td>
                                       <td class="entry" align="left" valign="top" width="14.680483592400693%" rowspan="1" colspan="1">NCHWC HWC-packed</td>
                                       <td class="entry" align="left" valign="top" width="17.271157167530227%" rowspan="1" colspan="1">NCHWC HWC-packed</td>
                                       <td class="entry" align="left" valign="top" width="19.86183074265976%" rowspan="1" colspan="1">
                                          <p class="p">- PSEUDO_HALF_CONFIG, and</p>
                                          <p class="p">- FLOAT_CONFIG</p>
                                       </td>
                                       <td class="entry" align="left" valign="top" width="23.316062176165808%" rowspan="1" colspan="1">
                                          <p class="p"><strong class="ph b">Dilation</strong>: Greater than 0 for all dimensions. 
                                          </p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" colspan="5" align="left" valign="top" rowspan="1">
                                          <p class="p"></p>
                                          <p dir="ltr" class="p"><strong class="ph b">Filter descriptor </strong><samp class="ph codeph"><strong class="ph b">wDesc:
                                                   										</strong></samp><samp class="ph codeph">_<strong class="ph b">NHWC</strong></samp></p>
                                          <p class="p"><samp class="ph codeph">convDesc </samp>Group count support: Greater than
                                             									0.
                                          </p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" align="left" valign="top" width="24.870466321243526%" rowspan="1" colspan="1"><strong class="ph b">Algo Name </strong></td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="14.680483592400693%" rowspan="1" colspan="1"><strong class="ph b"><samp class="ph codeph">xDesc</samp></strong></td>
                                       <td class="entry" align="left" valign="top" width="17.271157167530227%" rowspan="1" colspan="1"><strong class="ph b"><samp class="ph codeph">yDesc</samp></strong></td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="19.86183074265976%" rowspan="1" colspan="1"><strong class="ph b">Data Type Configurations Support</strong></td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="23.316062176165808%" rowspan="1" colspan="1"><strong class="ph b">Important</strong></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" align="left" valign="top" width="24.870466321243526%" rowspan="1" colspan="1"><strong class="ph b">_IMPLICIT_PRECOMP_GEMM</strong></td>
                                       <td class="entry" align="left" valign="top" width="14.680483592400693%" rowspan="1" colspan="1">NHWC </td>
                                       <td class="entry" align="left" valign="top" width="17.271157167530227%" rowspan="1" colspan="1">NHWC </td>
                                       <td class="entry" align="left" valign="top" width="19.86183074265976%" rowspan="1" colspan="1">
                                          <p class="p">- INT8_CONFIG,</p>
                                          <p class="p">- INT8_EXT_CONFIG,</p>
                                          <p class="p">- INT8x4_CONFIG,</p>
                                          <p class="p">- INT8x4_EXT_CONFIG,</p>
                                          <p class="p">- UINT8x4_CONFIG, and</p>
                                          <p class="p">- UINT8x4_EXT_CONFIG</p>
                                       </td>
                                       <td class="entry" align="left" valign="top" width="23.316062176165808%" rowspan="1" colspan="1">
                                          <p class="p"><strong class="ph b">Dilation</strong>: 1 for all dimensions. 
                                          </p>
                                          <p class="p">Input and output features maps must be multiple of 4. </p>
                                       </td>
                                    </tr>
                                 </tbody>
                              </table>
                           </div>
                        </div>
                        <p class="p"><strong class="ph b">FOR 3D CONVOLUTIONS.</strong></p>
                        <div class="p">
                           <div class="tablenoborder"><a name="cudnnConvolutionForward__table_ipg_rzt_y3b" shape="rect">
                                 <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnConvolutionForward__table_ipg_rzt_y3b" class="table" frame="border" border="1" rules="all">
                                 <tbody class="tbody">
                                    <tr class="row">
                                       <td class="entry" colspan="5" align="left" valign="top" rowspan="1">
                                          <p dir="ltr" class="p"><strong class="ph b">Filter descriptor </strong><samp class="ph codeph"><strong class="ph b">wDesc:
                                                   										</strong></samp><samp class="ph codeph">_<strong class="ph b">NCHW</strong></samp></p>
                                          <p class="p"><samp class="ph systemoutput">convDesc</samp> Group count support:
                                             									Greater than 0, for all algos.
                                          </p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" align="left" valign="top" width="24.870466321243526%" rowspan="1" colspan="1"><strong class="ph b">Algo Name </strong></td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="14.680483592400693%" rowspan="1" colspan="1"><strong class="ph b"><samp class="ph codeph">xDesc</samp></strong></td>
                                       <td class="entry" align="left" valign="top" width="17.271157167530227%" rowspan="1" colspan="1"><strong class="ph b"><samp class="ph codeph">yDesc</samp></strong></td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="19.86183074265976%" rowspan="1" colspan="1"><strong class="ph b">Data Type Configurations Support</strong></td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="23.316062176165808%" rowspan="1" colspan="1"><strong class="ph b">Important</strong></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" align="left" valign="top" width="24.870466321243526%" rowspan="1" colspan="1"><strong class="ph b">_IMPLICIT_GEMM</strong></td>
                                       <td class="entry" dir="ltr" rowspan="2" align="left" valign="top" width="14.680483592400693%" colspan="1">All except <samp class="ph codeph">_NCHW_VECT_C</samp>.  
                                       </td>
                                       <td class="entry" rowspan="2" align="left" valign="top" width="17.271157167530227%" colspan="1">All except <samp class="ph codeph">_NCHW_VECT_C</samp>.  
                                       </td>
                                       <td class="entry" dir="ltr" rowspan="2" align="left" valign="top" width="19.86183074265976%" colspan="1">
                                          <p class="p">- PSEUDO_HALF_CONFIG,</p>
                                          <p class="p">- FLOAT_CONFIG, and </p>
                                          <p class="p">- DOUBLE_CONFIG.</p>
                                       </td>
                                       <td class="entry" align="left" valign="top" width="23.316062176165808%" rowspan="1" colspan="1">
                                          <p class="p"><strong class="ph b">Dilation</strong>: Greater than 0 for all dimensions. 
                                          </p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" align="left" valign="top" width="24.870466321243526%" rowspan="1" colspan="1"><strong class="ph b">_IMPLICIT_PRECOMP_GEMM</strong></td>
                                       <td class="entry" align="left" valign="top" width="23.316062176165808%" rowspan="1" colspan="1">
                                          <p class="p"><strong class="ph b">Dilation</strong>: 1 for all dimensions. 
                                          </p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" dir="ltr" align="left" valign="top" width="24.870466321243526%" rowspan="1" colspan="1"><strong class="ph b">_FFT_TILING</strong></td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="14.680483592400693%" rowspan="1" colspan="1">NCDHW DHW-packed</td>
                                       <td class="entry" align="left" valign="top" width="17.271157167530227%" rowspan="1" colspan="1">NCDHW DHW-packed</td>
                                       <td class="entry" dir="ltr" align="left" valign="top" width="19.86183074265976%" rowspan="1" colspan="1">
                                          <p class="p">- PSEUDO_HALF_CONFIG,</p>
                                          <p class="p">- FLOAT_CONFIG, and</p>
                                          <p class="p">- DOUBLE_CONFIG.</p>
                                       </td>
                                       <td class="entry" align="left" valign="top" width="23.316062176165808%" rowspan="1" colspan="1">
                                          <p class="p"><strong class="ph b">Dilation</strong>: 1 for all dimensions. 
                                          </p>
                                          <p class="p">-<samp class="ph codeph">wDesc</samp>'s filter height must equal 16 or less
                                          </p>
                                          <p class="p">- <samp class="ph codeph">wDesc</samp>'s filter width must equal 16 or less
                                          </p>
                                          <p class="p">-<samp class="ph codeph">wDesc</samp>'s filter depth must equal 16 or less 
                                          </p>
                                          <p class="p">- <samp class="ph codeph">convDesc</samp>'s must have all filter strides equal
                                             									to 1 
                                          </p>
                                          <p class="p">- <samp class="ph codeph">wDesc</samp>'s filter height must be greater than
                                             										<samp class="ph codeph">convDesc</samp>'s zero-padding height 
                                          </p>
                                          <p class="p">- <samp class="ph codeph">wDesc</samp>'s filter width must be greater than
                                             										<samp class="ph codeph">convDesc</samp>'s zero-padding width 
                                          </p>
                                          <p class="p">- <samp class="ph codeph">wDesc</samp>'s filter depth must be greater than
                                             										<samp class="ph codeph">convDesc</samp>'s zero-padding width 
                                          </p>
                                       </td>
                                    </tr>
                                 </tbody>
                              </table>
                           </div>
                        </div>
                        <div class="note note"><span class="notetitle">Note:</span> Tensors can be converted to, and from, CUDNN_TENSOR_NCHW_VECT_C with
                           				<samp class="ph codeph">cudnnTransformTensor().</samp></div>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The operation was launched successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">At least one of the following conditions are met: <a name="cudnnConvolutionForward__ul_fvt_5hb_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnConvolutionForward__ul_fvt_5hb_s1b">
                                 <li class="li">At least one of the following is NULL: handle, <samp class="ph codeph">xDesc</samp>,
                                    								<samp class="ph codeph">wDesc</samp>, <samp class="ph codeph">convDesc</samp>,
                                    								<samp class="ph codeph">yDesc</samp>, <samp class="ph codeph">xData</samp>, <samp class="ph codeph">w</samp>,
                                    								<samp class="ph codeph">yData</samp>, <samp class="ph codeph">alpha</samp>,
                                    								<samp class="ph codeph">beta</samp></li>
                                 <li class="li"><samp class="ph codeph">xDesc</samp> and <samp class="ph codeph">yDesc</samp> have a non-matching
                                    							number of dimensions
                                 </li>
                                 <li class="li"><samp class="ph codeph">xDesc</samp> and <samp class="ph codeph">wDesc</samp> have a non-matching
                                    							number of dimensions
                                 </li>
                                 <li class="li"><samp class="ph codeph">xDesc</samp> has fewer than three number of dimensions
                                 </li>
                                 <li class="li"><samp class="ph codeph">xDesc</samp>'s number of dimensions is not equal to
                                    								<samp class="ph codeph">convDesc</samp>'s array length + 2
                                 </li>
                                 <li class="li"><samp class="ph codeph">xDesc</samp> and <samp class="ph codeph">wDesc</samp> have a non-matching
                                    							number of input feature maps per image (or group in case of Grouped
                                    							Convolutions)
                                 </li>
                                 <li class="li"><samp class="ph codeph">yDesc</samp> or <samp class="ph codeph">wDesc</samp> indicate an output
                                    							channel count that isn't a multiple of group count (if group count has
                                    							been set in convDesc).
                                 </li>
                                 <li class="li"><samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">wDesc</samp> and
                                    								<samp class="ph codeph">yDesc</samp> have a non-matching data type
                                 </li>
                                 <li class="li">For some spatial dimension, <samp class="ph codeph">wDesc</samp> has a spatial size
                                    							that is larger than the input spatial size (including zero-padding
                                    							size)
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">At least one of the following conditions are met: <a name="cudnnConvolutionForward__ul_jvt_5hb_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnConvolutionForward__ul_jvt_5hb_s1b">
                                 <li class="li"><samp class="ph codeph">xDesc</samp> or <samp class="ph codeph">yDesc</samp> have negative tensor
                                    							striding
                                 </li>
                                 <li class="li"><samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">wDesc</samp> or <samp class="ph codeph">yDesc</samp>
                                    							has a number of dimensions that is not 4 or 5
                                 </li>
                                 <li class="li"><samp class="ph codeph">yDescs's</samp> spatial sizes do not match with the expected
                                    							size as determined by
                                    								<samp class="ph codeph">cudnnGetConvolutionNdForwardOutputDim</samp></li>
                                 <li class="li">The chosen algo does not support the parameters provided; see above for
                                    							exhaustive list of parameter support for each algo
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_MAPPING_ERROR</samp></dt>
                           <dd class="dd">
                              <p class="p">An error occured during the texture binding of the filter data.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function failed to launch on the GPU.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnCreate"><a name="cudnnCreate" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCreate" name="cudnnCreate" shape="rect">4.14.&nbsp;cudnnCreate</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnCreate(cudnnHandle_t *handle)</pre><p class="p">This function initializes the cuDNN library and creates a handle to an opaque structure
                           holding the cuDNN library context. It allocates hardware resources on the host and
                           device and must be called prior to making any other cuDNN library calls. 
                        </p>
                        <p class="p">The cuDNN library handle is tied to the current CUDA device (context). To use the library
                           on multiple devices, one cuDNN handle needs to be created for each device. 
                        </p>
                        <p class="p">For a given device, multiple cuDNN handles with different configurations (e.g., different
                           current CUDA streams) may be created. Because <samp class="ph codeph">cudnnCreate</samp> allocates
                           some internal resources, the release of those resources by calling <samp class="ph codeph"><a class="xref" href="index.html#cudnnDestroy" shape="rect">cudnnDestroy</a></samp> will implicitly call
                           <samp class="ph codeph"><a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g10e20b05a95f638a4071a655503df25d" target="_blank" shape="rect">cudaDeviceSynchronize</a></samp>; therefore,
                           the recommended best practice is to call <samp class="ph codeph">cudnnCreate/cudnnDestroy</samp>
                           outside of performance-critical code paths. 
                        </p>
                        <p class="p">For multithreaded applications that use the same device from different threads, the
                           recommended programming model is to create one (or a few, as is convenient) cuDNN
                           handle(s) per thread and use that cuDNN handle for the entire life of the thread. 
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Pointer to pointer where to store the address to the allocated
                                 cuDNN handle. See <a class="xref" href="index.html#cudnnHandle_t" shape="rect">cudnnHandle_t.</a></p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">Invalid (NULL) input pointer supplied.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_INITIALIZED</samp></dt>
                           <dd class="dd">
                              <p class="p">No compatible GPU found, CUDA driver not installed or disabled, CUDA runtime
                                 API initialization failed.
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_ARCH_MISMATCH</samp></dt>
                           <dd class="dd">
                              <p class="p">NVIDIA GPU architecture is too old.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">Host memory allocation failed.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_INTERNAL_ERROR</samp></dt>
                           <dd class="dd">
                              <p class="p">CUDA resource allocation failed.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_LICENSE_ERROR</samp></dt>
                           <dd class="dd">
                              <p class="p">cuDNN license validation failed (only when the feature is enabled).</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">cuDNN handle was created successfully.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnCreateActivationDescriptor"><a name="cudnnCreateActivationDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCreateActivationDescriptor" name="cudnnCreateActivationDescriptor" shape="rect">4.15.&nbsp;cudnnCreateActivationDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnCreateActivationDescriptor(
        cudnnActivationDescriptor_t   *activationDesc)</pre><p class="p">This function creates a activation descriptor object by allocating the memory needed to
                           hold its opaque structure. See <a class="xref" href="index.html#cudnnActivationDescriptor_t" shape="rect">cudnnActivationDescriptor_t</a>.
                           
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was created successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The resources could not be allocated.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnCreateAlgorithmDescriptor"><a name="cudnnCreateAlgorithmDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCreateAlgorithmDescriptor" name="cudnnCreateAlgorithmDescriptor" shape="rect">4.16.&nbsp;cudnnCreateAlgorithmDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnCreateAlgorithmDescriptor(
    cudnnAlgorithmDescriptor_t *algoDesc)</pre><p class="p"><strong class="ph b">(New for 7.1)</strong></p>
                        <p class="p">This function creates an algorithm descriptor object by allocating the memory needed to hold its opaque structure.</p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was created successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The resources could not be allocated.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnCreateAlgorithmPerformance"><a name="cudnnCreateAlgorithmPerformance" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCreateAlgorithmPerformance" name="cudnnCreateAlgorithmPerformance" shape="rect">4.17.&nbsp;cudnnCreateAlgorithmPerformance</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnCreateAlgorithmPerformance(
    cudnnAlgorithmPerformance_t *algoPerf,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                         numberToCreate)</pre><p class="p"><strong class="ph b">(New for 7.1)</strong></p>
                        <p class="p">This function creates multiple algorithm performance objects by allocating the memory needed to hold their opaque structures.</p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was created successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The resources could not be allocated.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnCreateAttnDescriptor"><a name="cudnnCreateAttnDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCreateAttnDescriptor" name="cudnnCreateAttnDescriptor" shape="rect">4.18.&nbsp;cudnnCreateAttnDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnCreateAttnDescriptor(cudnnAttnDescriptor_t *attnDesc);</pre><p dir="ltr" class="p" id="cudnnCreateAttnDescriptor__docs-internal-guid-87763921-7fff-67bc-4609-cd6018ef2ef4"><a name="cudnnCreateAttnDescriptor__docs-internal-guid-87763921-7fff-67bc-4609-cd6018ef2ef4" shape="rect">
                              <!-- --></a>This function
                           			creates an attention descriptor object by allocating the memory needed to hold its
                           			structure. Use the <a class="xref" href="index.html#cudnnSetAttnDescriptor" shape="rect">cudnnSetAttnDescriptor</a> function to initialize the descriptor, and the
                           			<a class="xref" href="index.html#cudnnDestroyAttnDescriptor" shape="rect">cudnnDestroyAttnDescriptor</a> function to destroy the descriptor. 
                        </p>
                        <p class="p"><strong class="ph b">Parameters:</strong></p>
                        <div class="tablenoborder"><a name="cudnnCreateAttnDescriptor__table_hpj_hcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnCreateAttnDescriptor__table_hpj_hcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1"><strong class="ph b">Parameter</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1"><strong class="ph b">Input / Output</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">attnDesc</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">An uninitialized attention descriptor.</td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                        <p class="p"><strong class="ph b">Returns:</strong></p>
                        <div class="tablenoborder"><a name="cudnnCreateAttnDescriptor__table_usk_kcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnCreateAttnDescriptor__table_usk_kcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Return Value</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_SUCCESS</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">The descriptor object is created successfully.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_BAD_PARAM</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">The <samp class="ph codeph">attnDesc</samp> is NULL.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_ALLOC_FAILED</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">The memory allocation failed.</td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnCreateConvolutionDescriptor"><a name="cudnnCreateConvolutionDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCreateConvolutionDescriptor" name="cudnnCreateConvolutionDescriptor" shape="rect">4.19.&nbsp;cudnnCreateConvolutionDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnCreateConvolutionDescriptor(
    cudnnConvolutionDescriptor_t *convDesc)</pre><p class="p">This function creates a convolution descriptor object by allocating the memory needed to
                           hold its opaque structure. See <a class="xref" href="index.html#cudnnConvolutionDescriptor_t" shape="rect">cudnnConvolutionDescriptor_t</a>.
                           
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was created successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The resources could not be allocated.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnCreateCTCLossDescriptor"><a name="cudnnCreateCTCLossDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCreateCTCLossDescriptor" name="cudnnCreateCTCLossDescriptor" shape="rect">4.20.&nbsp;cudnnCreateCTCLossDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnCreateCTCLossDescriptor(
    cudnnCTCLossDescriptor_t* ctcLossDesc)</pre><p class="p">This function creates a CTC loss function descriptor. .</p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">ctcLossDesc</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. CTC loss descriptor to be set. See <a class="xref" href="index.html#cudnnCTCLossDescriptor_t" shape="rect">cudnnCTCLossDescriptor_t</a>.
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The function returned successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">CTC loss descriptor passed to the function is invalid.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">Memory allocation for this CTC loss descriptor failed.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnCreateDropoutDescriptor"><a name="cudnnCreateDropoutDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCreateDropoutDescriptor" name="cudnnCreateDropoutDescriptor" shape="rect">4.21.&nbsp;cudnnCreateDropoutDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnCreateDropoutDescriptor(
    cudnnDropoutDescriptor_t    *dropoutDesc)</pre><p class="p">This function creates a generic dropout descriptor object by allocating the memory needed
                           to hold its opaque structure. See <a class="xref" href="index.html#cudnnDropoutDescriptor_t" shape="rect">cudnnDropoutDescriptor_t</a>.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was created successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The resources could not be allocated.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnCreateFilterDescriptor"><a name="cudnnCreateFilterDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCreateFilterDescriptor" name="cudnnCreateFilterDescriptor" shape="rect">4.22.&nbsp;cudnnCreateFilterDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnCreateFilterDescriptor(
    cudnnFilterDescriptor_t *filterDesc)</pre><p class="p">This function creates a filter descriptor object by allocating the memory needed to hold
                           its opaque structure. See <a class="xref" href="index.html#cudnnFilterDescriptor_t" shape="rect">cudnnFilterDescriptor_t</a>.
                           
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was created successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The resources could not be allocated.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnCreateFusedOpsConstParamPack"><a name="cudnnCreateFusedOpsConstParamPack" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCreateFusedOpsConstParamPack" name="cudnnCreateFusedOpsConstParamPack" shape="rect">4.23.&nbsp;cudnnCreateFusedOpsConstParamPack</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnCreateFusedOpsConstParamPack(
	cudnnFusedOpsConstParamPack_t *constPack, 
	cudnnFusedOps_t ops);		</pre><p class="p">This function creates an opaque structure to store the various problem size information,
                           			such as the shape, layout and the type of Tensors, and the descriptors for convolution and
                           			activation, for the selected sequence of cudnnFusedOps computations. 
                        </p>
                        <p class="p"><strong class="ph b">Parameters:</strong></p>
                        <div class="tablenoborder"><a name="cudnnCreateFusedOpsConstParamPack__table_hpj_hcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnCreateFusedOpsConstParamPack__table_hpj_hcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1"><strong class="ph b">Parameter</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1"><strong class="ph b">Input / Output</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">constPack</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">The opaque structure that is created by this function. See <a class="xref" href="index.html#cudnnFusedOpsConstParamPack_t" shape="rect">cudnnFusedOpsConstParamPack_t</a></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">ops</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">The specific sequence of computations to perform in the cudnnFusedOps
                                       							computations, as defined in the enumerated type <a class="xref" href="index.html#cudnnFusedOps_t" shape="rect">cudnnFusedOps_t</a>. 
                                    </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                        <p class="p"><strong class="ph b">Returns:</strong></p>
                        <div class="tablenoborder"><a name="cudnnCreateFusedOpsConstParamPack__table_usk_kcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnCreateFusedOpsConstParamPack__table_usk_kcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Return Value</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_BAD_PARAM</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">If either <samp class="ph codeph">constPack</samp> or <samp class="ph codeph">ops</samp> is
                                       							NULL.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_SUCCESS</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">If the descriptor is created successfully. </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_NOT_SUPPORTED</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">If the <samp class="ph codeph">ops</samp> enum value is not supported or
                                       							reserved for future use.
                                    </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnCreateFusedOpsPlan"><a name="cudnnCreateFusedOpsPlan" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCreateFusedOpsPlan" name="cudnnCreateFusedOpsPlan" shape="rect">4.24.&nbsp;cudnnCreateFusedOpsPlan</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnCreateFusedOpsPlan(
	cudnnFusedOpsPlan_t *plan, 
	cudnnFusedOps_t ops);		</pre><p class="p">This function creates the plan descriptor for the cudnnFusedOps computation. This
                           			descriptor contains the plan information, including the problem type and size, which
                           			kernels should be run, and the internal workspace partition. 
                        </p>
                        <p class="p"><strong class="ph b">Parameters:</strong></p>
                        <div class="tablenoborder"><a name="cudnnCreateFusedOpsPlan__table_hpj_hcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnCreateFusedOpsPlan__table_hpj_hcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1"><strong class="ph b">Parameter</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1"><strong class="ph b">Input / Output</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">plan</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">A pointer to the instance of the descriptor created by this
                                       							function. 
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">ops</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">The specific sequence of fused operations computations for which this plan
                                       							descriptor should be created. See <a class="xref" href="index.html#cudnnFusedOps_t" shape="rect">cudnnFusedOps_t</a>.
                                    </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                        <p class="p"><strong class="ph b">Returns:</strong></p>
                        <div class="tablenoborder"><a name="cudnnCreateFusedOpsPlan__table_usk_kcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnCreateFusedOpsPlan__table_usk_kcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Return Value</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_BAD_PARAM</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">If either the input *plan is NULL, or the ops input is not a
                                       							valid cudnnFusedOp enum.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_NOT_SUPPORTED</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">The ops input provided is not supported.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_SUCCESS</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">The plan descriptor is created successfully. </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnCreateFusedOpsVariantParamPack"><a name="cudnnCreateFusedOpsVariantParamPack" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCreateFusedOpsVariantParamPack" name="cudnnCreateFusedOpsVariantParamPack" shape="rect">4.25.&nbsp;cudnnCreateFusedOpsVariantParamPack</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnCreateFusedOpsVariantParamPack(
	cudnnFusedOpsVariantParamPack_t *varPack, 
	cudnnFusedOps_t ops);		</pre><p class="p">This function creates a descriptor for cudnnFusedOps constant parameters. </p>
                        <p class="p"><strong class="ph b">Parameters:</strong></p>
                        <div class="tablenoborder"><a name="cudnnCreateFusedOpsVariantParamPack__table_hpj_hcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnCreateFusedOpsVariantParamPack__table_hpj_hcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1"><strong class="ph b">Parameter</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1"><strong class="ph b">Input / Output</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">varPack</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Pointer to the descriptor created by this function. See <a class="xref" href="index.html#cudnnFusedOpsVariantParamPack_t" shape="rect">cudnnFusedOpsVariantParamPack_t</a></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">ops</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">The specific sequence of fused operations computations for which
                                       							this descriptor should be created. 
                                    </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                        <p class="p"><strong class="ph b">Returns:</strong></p>
                        <div class="tablenoborder"><a name="cudnnCreateFusedOpsVariantParamPack__table_usk_kcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnCreateFusedOpsVariantParamPack__table_usk_kcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Return Value</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_SUCCESS</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"> The descriptor is successfully created. </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_BAD_PARAM</td>
                                    <td class="entry" valign="top" width="50%" rowspan="1" colspan="1"> If any input is invalid. </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnCreateLRNDescriptor"><a name="cudnnCreateLRNDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCreateLRNDescriptor" name="cudnnCreateLRNDescriptor" shape="rect">4.26.&nbsp;cudnnCreateLRNDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnCreateLRNDescriptor(
            cudnnLRNDescriptor_t    *poolingDesc)</pre><p class="p">This function allocates the memory needed to hold the data needed for LRN and
                           DivisiveNormalization layers operation and returns a descriptor used with subsequent
                           layer forward and backward calls. 
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was created successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The resources could not be allocated.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnCreateOpTensorDescriptors"><a name="cudnnCreateOpTensorDescriptors" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCreateOpTensorDescriptors" name="cudnnCreateOpTensorDescriptors" shape="rect">cudnnCreateOpTensorDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnCreateOpTensorDescriptor(
    cudnnOpTensorDescriptor_t* 	opTensorDesc)</pre><p class="p">This function creates a Tensor Pointwise math descriptor. See <a class="xref" href="index.html#cudnnOpTensorDescriptor_t" shape="rect">cudnnOpTensorDescriptor_t</a>.
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">opTensorDesc</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Pointer to the structure holding the description of the Tensor Pointwise math such as Add, Multiply, and more.
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The function returned successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">Tensor Pointwise math descriptor passed to the function is invalid.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">Memory allocation for this Tensor Pointwise math descriptor failed.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnCreatePersistentRNNPlan"><a name="cudnnCreatePersistentRNNPlan" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCreatePersistentRNNPlan" name="cudnnCreatePersistentRNNPlan" shape="rect">4.28.&nbsp;cudnnCreatePersistentRNNPlan</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnCreatePersistentRNNPlan(
    cudnnRNNDescriptor_t        rnnDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                   minibatch,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnDataType_t       dataType,
    cudnnPersistentRNNPlan_t   *plan)</pre><p class="p">This function creates a plan to execute persistent RNNs when using the
                           <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_DYNAMIC</samp> algo. This plan is tailored to the
                           current GPU and problem hyperparemeters. This function call is expected to be expensive
                           in terms of runtime, and should be used infrequently. See <a class="xref" href="index.html#cudnnRNNDescriptor_t" shape="rect">cudnnRNNDescriptor_t</a>, <a class="xref" href="index.html#cudnnDataType_t" shape="rect">cudnnDataType_t</a>, and <a class="xref" href="index.html#cudnnPersistentRNNPlan_t" shape="rect">cudnnPersistentRNNPlan_t</a>.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was created successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The resources could not be allocated.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_RUNTIME_PREREQUISITE_MISSING</samp></dt>
                           <dd class="dd">
                              <p class="p">A prerequisite runtime library cannot be found.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The current hyperparameters are invalid.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnCreatePoolingDescriptor"><a name="cudnnCreatePoolingDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCreatePoolingDescriptor" name="cudnnCreatePoolingDescriptor" shape="rect">4.29.&nbsp;cudnnCreatePoolingDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnCreatePoolingDescriptor(
    cudnnPoolingDescriptor_t    *poolingDesc)</pre><p class="p">This function creates a pooling descriptor object by allocating the memory needed to hold
                           its opaque structure, 
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was created successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The resources could not be allocated.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnCreateReduceTensorDescriptor"><a name="cudnnCreateReduceTensorDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCreateReduceTensorDescriptor" name="cudnnCreateReduceTensorDescriptor" shape="rect">4.30.&nbsp;cudnnCreateReduceTensorDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnCreateReduceTensorDescriptor(
	cudnnReduceTensorDescriptor_t*	reduceTensorDesc)</pre><p class="p">This function creates a reduce tensor descriptor object by allocating the memory needed to hold its opaque structure.</p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <p class="p">None.</p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was created successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">reduceTensorDesc is a NULL pointer.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The resources could not be allocated.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnCreateRNNDataDescriptor"><a name="cudnnCreateRNNDataDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCreateRNNDataDescriptor" name="cudnnCreateRNNDataDescriptor" shape="rect">4.31.&nbsp;cudnnCreateRNNDataDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">
cudnnStatus_t cudnnCreateRNNDataDescriptor(
    cudnnRNNDataDescriptor_t *RNNDataDesc)
</pre><p class="p">This function creates a RNN data descriptor object by allocating the memory needed to
                           hold its opaque structure. 
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The RNN data descriptor object was created successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">RNNDataDesc is NULL. </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The resources could not be allocated. </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnCreateRNNDescriptor"><a name="cudnnCreateRNNDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCreateRNNDescriptor" name="cudnnCreateRNNDescriptor" shape="rect">4.32.&nbsp;cudnnCreateRNNDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnCreateRNNDescriptor(
    cudnnRNNDescriptor_t    *rnnDesc)</pre><p class="p">This function creates a generic RNN descriptor object by allocating the memory needed to
                           hold its opaque structure.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was created successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The resources could not be allocated.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnCreateSeqDataDescriptor"><a name="cudnnCreateSeqDataDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCreateSeqDataDescriptor" name="cudnnCreateSeqDataDescriptor" shape="rect">4.33.&nbsp;cudnnCreateSeqDataDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnCreateSeqDataDescriptor(cudnnSeqDataDescriptor_t *seqDataDesc);	</pre><p dir="ltr" class="p" id="cudnnCreateSeqDataDescriptor__docs-internal-guid-18f121c5-7fff-c892-ee04-b1a7cf1bc944"><a name="cudnnCreateSeqDataDescriptor__docs-internal-guid-18f121c5-7fff-c892-ee04-b1a7cf1bc944" shape="rect">
                              <!-- --></a>This function
                           			creates a sequence data descriptor object by allocating the memory needed to hold its
                           			opaque structure. The sequence data is initialized to be all zero. Use the
                           			<a class="xref" href="index.html#cudnnSetSeqDataDescriptor" shape="rect">cudnnSetSeqDataDescriptor</a> function to initialize the descriptor created by this function. 
                        </p>
                        <p class="p"><strong class="ph b">Parameters:</strong></p>
                        <div class="tablenoborder"><a name="cudnnCreateSeqDataDescriptor__table_hpj_hcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnCreateSeqDataDescriptor__table_hpj_hcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1"><strong class="ph b">Parameter</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1"><strong class="ph b">Input / Output</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">seqDataDesc</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">A sequence data descriptor whose sequence data is initialized to
                                       							be all zero.
                                    </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                        <p class="p"><strong class="ph b">Returns:</strong></p>
                        <div class="tablenoborder"><a name="cudnnCreateSeqDataDescriptor__table_usk_kcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnCreateSeqDataDescriptor__table_usk_kcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Return Value</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_SUCCESS</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">The descriptor object was created successfully.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_BAD_PARAM</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">The <samp class="ph codeph">seqDataDesc</samp> is NULL.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_ALLOC_FAILED</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">The memory allocation failed.</td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnCreateSpatialTransformerDescriptor"><a name="cudnnCreateSpatialTransformerDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCreateSpatialTransformerDescriptor" name="cudnnCreateSpatialTransformerDescriptor" shape="rect">4.34.&nbsp;cudnnCreateSpatialTransformerDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnCreateSpatialTransformerDescriptor(
    cudnnSpatialTransformerDescriptor_t *stDesc)</pre><p class="p">This function creates a generic spatial transformer descriptor object by allocating the
                           memory needed to hold its opaque structure.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was created successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The resources could not be allocated.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnCreateTensorDescriptor"><a name="cudnnCreateTensorDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCreateTensorDescriptor" name="cudnnCreateTensorDescriptor" shape="rect">4.35.&nbsp;cudnnCreateTensorDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnCreateTensorDescriptor(
    cudnnTensorDescriptor_t *tensorDesc)</pre><p class="p">This function creates a generic tensor descriptor object by allocating the memory needed
                           to hold its opaque structure. The data is initialized to be all zero.
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">tensorDesc</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointer to pointer where the address to the allocated tensor
                                 descriptor object should be stored.
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">Invalid input argument.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The resources could not be allocated.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was created successfully.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnCreateTensorTransformDescriptor"><a name="cudnnCreateTensorTransformDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCreateTensorTransformDescriptor" name="cudnnCreateTensorTransformDescriptor" shape="rect">4.36.&nbsp;cudnnCreateTensorTransformDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnCreateTensorTransformDescriptor(
	cudnnTensorTransformDescriptor_t *transformDesc);
</pre><p dir="ltr" class="p" id="cudnnCreateTensorTransformDescriptor__docs-internal-guid-d5e5edab-7fff-b771-e7f1-bf48dfd82bce"><a name="cudnnCreateTensorTransformDescriptor__docs-internal-guid-d5e5edab-7fff-b771-e7f1-bf48dfd82bce" shape="rect">
                              <!-- --></a>This function
                           			creates a Tensor transform descriptor object by allocating the memory needed to hold its
                           			opaque structure. The Tensor data is initialized to be all zero. Use the
                           				<a class="xref" href="index.html#cudnnSetTensorTransformDescriptor" shape="rect">cudnnSetTensorTransformDescriptor</a> function to initialize the
                           			descriptor created by this function. 
                        </p>
                        <p class="p"><strong class="ph b">Parameters:</strong></p>
                        <div class="tablenoborder"><a name="cudnnCreateTensorTransformDescriptor__table_hpj_hcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnCreateTensorTransformDescriptor__table_hpj_hcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1"><strong class="ph b">Parameter</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1"><strong class="ph b">Input / Output</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">transformDesc</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">A pointer to an uninitialized Tensor transform descriptor.</td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                        <p class="p"><strong class="ph b">Returns:</strong></p>
                        <div class="tablenoborder"><a name="cudnnCreateTensorTransformDescriptor__table_usk_kcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnCreateTensorTransformDescriptor__table_usk_kcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Return Value</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_SUCCESS</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">The descriptor object was created successfully.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_BAD_PARAM</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">The <samp class="ph codeph">transformDesc</samp> is NULL.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_ALLOC_FAILED</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">The memory allocation failed.</td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnCTCLoss"><a name="cudnnCTCLoss" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnCTCLoss" name="cudnnCTCLoss" shape="rect">4.37.&nbsp;cudnnCTCLoss</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnCTCLoss(
    cudnnHandle_t                        handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>   cudnnTensorDescriptor_t      probsDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                        *probs,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                         *labels,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                         *labelLengths,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                         *inputLengths,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *costs,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>   cudnnTensorDescriptor_t      gradientsDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                        *gradients,
    cudnnCTCLossAlgo_t                   algo,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>   cudnnCTCLossDescriptor_t     ctcLossDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *workspace,
    size_t                              *workSpaceSizeInBytes)</pre><div class="p">This function returns the ctc costs and gradients, given the probabilities and labels.
                           				
                           <div class="note note"><span class="notetitle">Note:</span> This function has an inconsistent interface, i.e., the <samp class="ph codeph">probs</samp>
                              				input is probability normalized by softmax, but the <samp class="ph codeph">gradients</samp> output is
                              				with respect to the unnormalized activation.
                           </div>
                        </div>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context. See <a class="xref" href="index.html#cudnnHandle_t" shape="rect">cudnnHandle_t.</a></p>
                           </dd>
                           <dt class="dt dlterm">probsDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized probabilities tensor
                                 descriptor. See <a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t.</a></p>
                           </dd>
                           <dt class="dt dlterm">probs </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointer to a previously initialized probabilities tensor. These
                                 						input probabilities are normalized by softmax.
                              </p>
                           </dd>
                           <dt class="dt dlterm">labels </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointer to a previously initialized labels list.
                              </p>
                           </dd>
                           <dt class="dt dlterm">labelLengths </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointer to a previously initialized lengths list, to walk the
                                 above labels list.
                              </p>
                           </dd>
                           <dt class="dt dlterm">inputLengths </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointer to a previously initialized list of the lengths of the
                                 timing steps in each batch.
                              </p>
                           </dd>
                           <dt class="dt dlterm">costs </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Pointer to the computed costs of CTC.
                              </p>
                           </dd>
                           <dt class="dt dlterm">gradientsDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized gradients tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">gradients </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Pointer to the computed gradients of CTC. These computed
                                 						gradient outputs are with respect to the unnormalized activation.
                              </p>
                           </dd>
                           <dt class="dt dlterm">algo </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Enumerant that specifies the chosen CTC loss algorithm. See
                                 <a class="xref" href="index.html#cudnnCTCLossAlgo_t" shape="rect">cudnnCTCLossAlgo_t</a>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">ctcLossDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized CTC loss descriptor. See
                                 <a class="xref" href="index.html#cudnnCTCLossDescriptor_t" shape="rect">cudnnCTCLossDescriptor_t</a>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">workspace </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointer to GPU memory of a workspace needed to able to execute
                                 the specified algorithm.
                              </p>
                           </dd>
                           <dt class="dt dlterm">sizeInBytes </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Amount of GPU memory needed as workspace to be able to execute
                                 the CTC loss computation with the specified <samp class="ph codeph">algo</samp>.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The query was successful.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnCTCLoss__ul_zpd_lg3_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnCTCLoss__ul_zpd_lg3_s1b">
                                 <li class="li">The dimensions of probsDesc do not match the dimensions of
                                    gradientsDesc.
                                 </li>
                                 <li class="li">The inputLengths do not agree with the first dimension of
                                    probsDesc.
                                 </li>
                                 <li class="li">The workSpaceSizeInBytes is not sufficient.</li>
                                 <li class="li">The labelLengths is greater than 256.</li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">A compute or data type other than FLOAT was chosen, or an unknown algorithm
                                 type was chosen.
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function failed to launch on the GPU</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnDeriveBNTensorDescriptor"><a name="cudnnDeriveBNTensorDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDeriveBNTensorDescriptor" name="cudnnDeriveBNTensorDescriptor" shape="rect">4.38.&nbsp;cudnnDeriveBNTensorDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnDeriveBNTensorDescriptor(
    cudnnTensorDescriptor_t         derivedBnDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   xDesc,
    cudnnBatchNormMode_t            mode)</pre><p class="p">This function derives a secondary tensor descriptor for the batch normalization scale,
                           invVariance, bnBias, bnScale subtensors from the layer's <samp class="ph codeph">x</samp> data
                           descriptor. 
                        </p>
                        <p class="p">Use the tensor descriptor produced by this function as the
                           <samp class="ph codeph">bnScaleBiasMeanVarDesc</samp> parameter for the <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormalizationForwardInference" shape="rect">cudnnBatchNormalizationForwardInference</a></samp> and <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormalizationForwardTraining" shape="rect">cudnnBatchNormalizationForwardTraining</a></samp> functions, and as the
                           <samp class="ph codeph">bnScaleBiasDiffDesc</samp> parameter in the  <samp class="ph codeph"><a class="xref" href="index.html#cudnnBatchNormalizationBackward" shape="rect">cudnnBatchNormalizationBackward</a></samp> function. 
                        </p>
                        <p class="p">The resulting dimensions will be 1xCx1x1 for 4D and 1xCx1x1x1 for 5D for
                           BATCHNORM_MODE_SPATIAL, and 1xCxHxW for 4D and 1xCxDxHxW for 5D for
                           BATCHNORM_MODE_PER_ACTIVATION mode. 
                        </p>
                        <p class="p">For HALF input data type the resulting tensor descriptor will have a FLOAT type. For
                           other data types it will have the same type as the input data.
                        </p>
                        <div class="note note"><span class="notetitle">Note:</span> Only 4D and 5D tensors are supported.
                        </div>
                        <div class="note note"><span class="notetitle">Note:</span> The <samp class="ph codeph">derivedBnDesc</samp> should be first created using <samp class="ph codeph"><a class="xref" href="index.html#cudnnCreateTensorDescriptor" shape="rect">cudnnCreateTensorDescriptor</a></samp>.
                        </div>
                        <div class="note note"><span class="notetitle">Note:</span><samp class="ph codeph">xDesc</samp> is the descriptor for the layer's <samp class="ph codeph">x</samp> data and
                           has to be setup with proper dimensions prior to calling this function.
                        </div>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">derivedBnDesc</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Handle to a previously created tensor descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">xDesc</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created and initialized layer's
                                 <samp class="ph codeph">x</samp> data descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">mode</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Batch normalization layer mode of operation. 
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The computation was performed successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">Invalid Batch Normalization mode.</dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnDestroy"><a name="cudnnDestroy" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDestroy" name="cudnnDestroy" shape="rect">4.39.&nbsp;cudnnDestroy</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnDestroy(cudnnHandle_t handle)</pre><p class="p">This function releases resources used by the cuDNN handle. This function is usually the
                           last call with a particular handle to the cuDNN handle. Because
                           <samp class="ph codeph">cudnnCreate</samp> allocates some internal resources, the release of those
                           resources by calling <samp class="ph codeph">cudnnDestroy</samp> will implicitly call
                           <samp class="ph codeph">cudaDeviceSynchronize</samp>; therefore, the recommended best practice is
                           to call <samp class="ph codeph">cudnnCreate/cudnnDestroy</samp> outside of performance-critical code
                           paths. 
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointer to the cuDNN handle to be destroyed.
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The cuDNN context destruction was successful.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">Invalid (NULL) pointer supplied.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnDestroyActivationDescriptor"><a name="cudnnDestroyActivationDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDestroyActivationDescriptor" name="cudnnDestroyActivationDescriptor" shape="rect">4.40.&nbsp;cudnnDestroyActivationDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnDestroyActivationDescriptor(
        cudnnActivationDescriptor_t activationDesc)</pre><p class="p">This function destroys a previously created activation descriptor object. </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was destroyed successfully.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnDestroyAlgorithmDescriptor"><a name="cudnnDestroyAlgorithmDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDestroyAlgorithmDescriptor" name="cudnnDestroyAlgorithmDescriptor" shape="rect">4.41.&nbsp;cudnnDestroyAlgorithmDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnDestroyAlgorithmDescriptor(
        cudnnActivationDescriptor_t algorithmDesc)</pre><p class="p"><strong class="ph b">(New for 7.1)</strong></p>
                        <p class="p">This function destroys a previously created algorithm descriptor object.</p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was destroyed successfully.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnDestroyAlgorithmPerformance"><a name="cudnnDestroyAlgorithmPerformance" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDestroyAlgorithmPerformance" name="cudnnDestroyAlgorithmPerformance" shape="rect">4.42.&nbsp;cudnnDestroyAlgorithmPerformance</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnDestroyAlgorithmPerformance(
        cudnnAlgorithmPerformance_t     algoPerf)</pre><p class="p"><strong class="ph b">(New for 7.1)</strong></p>
                        <p class="p">This function destroys a previously created algorithm descriptor object.</p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was destroyed successfully.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnDestroyAttnDescriptor"><a name="cudnnDestroyAttnDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDestroyAttnDescriptor" name="cudnnDestroyAttnDescriptor" shape="rect">4.43.&nbsp;cudnnDestroyAttnDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnDestroyAttnDescriptor(
	cudnnAttnDescriptor_t attnDesc);
</pre><p dir="ltr" class="p" id="cudnnDestroyAttnDescriptor__docs-internal-guid-87763921-7fff-67bc-4609-cd6018ef2ef4"><a name="cudnnDestroyAttnDescriptor__docs-internal-guid-87763921-7fff-67bc-4609-cd6018ef2ef4" shape="rect">
                              <!-- --></a>This function destroys a
                           			previously created attention descriptor.
                        </p>
                        <p class="p"><strong class="ph b">Parameters:</strong></p>
                        <div class="tablenoborder"><a name="cudnnDestroyAttnDescriptor__table_hpj_hcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnDestroyAttnDescriptor__table_hpj_hcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1"><strong class="ph b">Parameter</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1"><strong class="ph b">Input / Output</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1"><samp class="ph codeph">attnDesc</samp></td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">The attention descriptor to be destroyed.</td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                        <p class="p"><strong class="ph b">Returns:</strong></p>
                        <div class="tablenoborder"><a name="cudnnDestroyAttnDescriptor__table_usk_kcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnDestroyAttnDescriptor__table_usk_kcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Return Value</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_SUCCESS</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">The descriptor was destroyed successfully.</td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnDestroyConvolutionDescriptor"><a name="cudnnDestroyConvolutionDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDestroyConvolutionDescriptor" name="cudnnDestroyConvolutionDescriptor" shape="rect">4.44.&nbsp;cudnnDestroyConvolutionDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnDestroyConvolutionDescriptor(
    cudnnConvolutionDescriptor_t convDesc)</pre><p class="p">This function destroys a previously created convolution descriptor object. </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was destroyed successfully.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnDestroyCTCLossDescriptor"><a name="cudnnDestroyCTCLossDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDestroyCTCLossDescriptor" name="cudnnDestroyCTCLossDescriptor" shape="rect">4.45.&nbsp;cudnnDestroyCTCLossDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnDestroyCTCLossDescriptor(
    cudnnCTCLossDescriptor_t 	ctcLossDesc)</pre><p class="p">This function destroys a CTC loss function descriptor object.</p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">ctcLossDesc</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. CTC loss function descriptor to be destroyed.
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The function returned successfully.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnDestroyDropoutDescriptor"><a name="cudnnDestroyDropoutDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDestroyDropoutDescriptor" name="cudnnDestroyDropoutDescriptor" shape="rect">4.46.&nbsp;cudnnDestroyDropoutDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnDestroyDropoutDescriptor(
    cudnnDropoutDescriptor_t dropoutDesc)</pre><p class="p">This function destroys a previously created dropout descriptor object. </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was destroyed successfully.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnDestroyFilterDescriptor"><a name="cudnnDestroyFilterDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDestroyFilterDescriptor" name="cudnnDestroyFilterDescriptor" shape="rect">4.47.&nbsp;cudnnDestroyFilterDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnDestroyFilterDescriptor(
    cudnnFilterDescriptor_t filterDesc)</pre><p class="p">This function destroys a previously created Tensor4D descriptor object. </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was destroyed successfully.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnDestroyFusedOpsConstParamPack"><a name="cudnnDestroyFusedOpsConstParamPack" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDestroyFusedOpsConstParamPack" name="cudnnDestroyFusedOpsConstParamPack" shape="rect">4.48.&nbsp;cudnnDestroyFusedOpsConstParamPack</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnDestroyFusedOpsConstParamPack(
	cudnnFusedOpsConstParamPack_t constPack);		</pre><p class="p">This function destroys a previously-created <a class="xref" href="index.html#cudnnFusedOpsConstParamPack_t" shape="rect">cudnnFusedOpsConstParamPack_t</a>
                           			structure. 
                        </p>
                        <p class="p"><strong class="ph b">Parameters:</strong></p>
                        <div class="tablenoborder"><a name="cudnnDestroyFusedOpsConstParamPack__table_hpj_hcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnDestroyFusedOpsConstParamPack__table_hpj_hcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1"><strong class="ph b">Parameter</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1"><strong class="ph b">Input / Output</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">constPack</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">The cudnnFusedOpsConstParamPack_t structure that should be destroyed.  </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                        <p class="p"><strong class="ph b">Returns:</strong></p>
                        <div class="tablenoborder"><a name="cudnnDestroyFusedOpsConstParamPack__table_usk_kcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnDestroyFusedOpsConstParamPack__table_usk_kcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Return Value</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_SUCCESS</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">If the descriptor is destroyed successfully. </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_INTERNAL_ERROR</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">If the <samp class="ph codeph">ops</samp> enum value is not supported or invalid. 
                                    </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnDestroyFusedOpsPlan"><a name="cudnnDestroyFusedOpsPlan" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDestroyFusedOpsPlan" name="cudnnDestroyFusedOpsPlan" shape="rect">4.49.&nbsp;cudnnDestroyFusedOpsPlan</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnDestroyFusedOpsPlan(
	cudnnFusedOpsPlan_t plan);		</pre><p class="p">This function destroys the plan descriptor provided. </p>
                        <p class="p"><strong class="ph b">Parameters:</strong></p>
                        <div class="tablenoborder"><a name="cudnnDestroyFusedOpsPlan__table_hpj_hcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnDestroyFusedOpsPlan__table_hpj_hcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1"><strong class="ph b">Parameter</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1"><strong class="ph b">Input / Output</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">plan</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">The descriptor that should be destroyed by this function.  </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                        <p class="p"><strong class="ph b">Returns:</strong></p>
                        <div class="tablenoborder"><a name="cudnnDestroyFusedOpsPlan__table_usk_kcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnDestroyFusedOpsPlan__table_usk_kcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Return Value</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_SUCCESS</td>
                                    <td class="entry" valign="top" width="50%" rowspan="1" colspan="1">If either the plan descriptor is NULL or the descriptor is successfully
                                       							destroyed.
                                    </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnDestroyFusedOpsVariantParamPack"><a name="cudnnDestroyFusedOpsVariantParamPack" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDestroyFusedOpsVariantParamPack" name="cudnnDestroyFusedOpsVariantParamPack" shape="rect">4.50.&nbsp;cudnnDestroyFusedOpsVariantParamPack</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnDestroyFusedOpsVariantParamPack(
	cudnnFusedOpsVariantParamPack_t varPack);		</pre><p class="p">This function destroys a previously-created descriptor for cudnnFusedOps constant parameters. </p>
                        <p class="p"><strong class="ph b">Parameters:</strong></p>
                        <div class="tablenoborder"><a name="cudnnDestroyFusedOpsVariantParamPack__table_hpj_hcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnDestroyFusedOpsVariantParamPack__table_hpj_hcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1"><strong class="ph b">Parameter</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1"><strong class="ph b">Input / Output</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">varPack</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">The descriptor that should be destroyed. </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                        <p class="p"><strong class="ph b">Returns:</strong></p>
                        <div class="tablenoborder"><a name="cudnnDestroyFusedOpsVariantParamPack__table_usk_kcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnDestroyFusedOpsVariantParamPack__table_usk_kcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Return Value</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_SUCCESS</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"> The descriptor is successfully destroyed. </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnDestroyLRNDescriptor"><a name="cudnnDestroyLRNDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDestroyLRNDescriptor" name="cudnnDestroyLRNDescriptor" shape="rect">4.51.&nbsp;cudnnDestroyLRNDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnDestroyLRNDescriptor(
    cudnnLRNDescriptor_t lrnDesc)</pre><p class="p">This function destroys a previously created LRN descriptor object. </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was destroyed successfully.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnDestroyOpTensorDescriptor"><a name="cudnnDestroyOpTensorDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDestroyOpTensorDescriptor" name="cudnnDestroyOpTensorDescriptor" shape="rect">4.52.&nbsp;cudnnDestroyOpTensorDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnDestroyOpTensorDescriptor(
    cudnnOpTensorDescriptor_t   opTensorDesc)</pre><p class="p">This function deletes a Tensor Pointwise math descriptor object.</p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">opTensorDesc</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointer to the structure holding the description of the Tensor Pointwise math to be deleted.
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The function returned successfully.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnDestroyPersistentRNNPlan"><a name="cudnnDestroyPersistentRNNPlan" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDestroyPersistentRNNPlan" name="cudnnDestroyPersistentRNNPlan" shape="rect">4.53.&nbsp;cudnnDestroyPersistentRNNPlan</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnDestroyPersistentRNNPlan(
    cudnnPersistentRNNPlan_t plan)</pre><p class="p">This function destroys a previously created persistent RNN plan object. </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was destroyed successfully.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnDestroyPoolingDescriptor"><a name="cudnnDestroyPoolingDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDestroyPoolingDescriptor" name="cudnnDestroyPoolingDescriptor" shape="rect">4.54.&nbsp;cudnnDestroyPoolingDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnDestroyPoolingDescriptor(
    cudnnPoolingDescriptor_t poolingDesc)</pre><p class="p">This function destroys a previously created pooling descriptor object. </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was destroyed successfully.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnDestroyReduceTensorDescriptor"><a name="cudnnDestroyReduceTensorDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDestroyReduceTensorDescriptor" name="cudnnDestroyReduceTensorDescriptor" shape="rect">4.55.&nbsp;cudnnDestroyReduceTensorDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnDestroyReduceTensorDescriptor(
    cudnnReduceTensorDescriptor_t   tensorDesc)</pre><p class="p">This function destroys a previously created reduce tensor descriptor object. When the input pointer is NULL, this function
                           performs no destroy operation.
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">tensorDesc</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointer to the reduce tensor descriptor object to be destroyed.
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was destroyed successfully.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnDestroyRNNDataDescriptor"><a name="cudnnDestroyRNNDataDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDestroyRNNDataDescriptor" name="cudnnDestroyRNNDataDescriptor" shape="rect">4.56.&nbsp;cudnnDestroyRNNDataDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">
cudnnStatus_t cudnnDestroyRNNDataDescriptor(
    cudnnRNNDataDescriptor_t RNNDataDesc)
</pre><p class="p">This function destroys a previously created RNN data descriptor object.  </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The RNN data descriptor object was destroyed successfully.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnDestroyRNNDescriptor"><a name="cudnnDestroyRNNDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDestroyRNNDescriptor" name="cudnnDestroyRNNDescriptor" shape="rect">4.57.&nbsp;cudnnDestroyRNNDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnDestroyRNNDescriptor(
    cudnnRNNDescriptor_t rnnDesc)</pre><p class="p">This function destroys a previously created RNN descriptor object. </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was destroyed successfully.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnDestroySeqDataDescriptor"><a name="cudnnDestroySeqDataDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDestroySeqDataDescriptor" name="cudnnDestroySeqDataDescriptor" shape="rect">4.58.&nbsp;cudnnDestroySeqDataDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnDestroySeqDataDescriptor(cudnnSeqDataDescriptor_t seqDataDesc);
</pre><p dir="ltr" class="p" id="cudnnDestroySeqDataDescriptor__docs-internal-guid-8869f1a1-7fff-2069-9257-5dc4bf26996a"><a name="cudnnDestroySeqDataDescriptor__docs-internal-guid-8869f1a1-7fff-2069-9257-5dc4bf26996a" shape="rect">
                              <!-- --></a>Destroys a
                           			previously created sequence data descriptor.
                        </p>
                        <p class="p"><strong class="ph b">Parameters:</strong></p>
                        <div class="tablenoborder"><a name="cudnnDestroySeqDataDescriptor__table_hpj_hcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnDestroySeqDataDescriptor__table_hpj_hcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1"><strong class="ph b">Parameter</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1"><strong class="ph b">Input / Output</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">seqDataDesc</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">The sequence data descriptor to be destroyed. </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                        <p class="p"><strong class="ph b">Returns:</strong></p>
                        <div class="tablenoborder"><a name="cudnnDestroySeqDataDescriptor__table_usk_kcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnDestroySeqDataDescriptor__table_usk_kcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Return Value</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_SUCCESS</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">The descriptor was destroyed successfully.</td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnDestroySpatialTransformerDescriptor"><a name="cudnnDestroySpatialTransformerDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDestroySpatialTransformerDescriptor" name="cudnnDestroySpatialTransformerDescriptor" shape="rect">4.59.&nbsp;cudnnDestroySpatialTransformerDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnDestroySpatialTransformerDescriptor(
    cudnnSpatialTransformerDescriptor_t stDesc)</pre><p class="p">This function destroys a previously created spatial transformer descriptor object. </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was destroyed successfully.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnDestroyTensorDescriptor"><a name="cudnnDestroyTensorDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDestroyTensorDescriptor" name="cudnnDestroyTensorDescriptor" shape="rect">4.60.&nbsp;cudnnDestroyTensorDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnDestroyTensorDescriptor(cudnnTensorDescriptor_t tensorDesc)</pre><p class="p">This function destroys a previously created tensor descriptor object. When the input
                           pointer is NULL, this function performs no destroy operation.
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">tensorDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointer to the tensor descriptor object to be destroyed.
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was destroyed successfully.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnDestroyTensorTransformDescriptor"><a name="cudnnDestroyTensorTransformDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDestroyTensorTransformDescriptor" name="cudnnDestroyTensorTransformDescriptor" shape="rect">4.61.&nbsp;cudnnDestroyTensorTransformDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnDestroyTensorTransformDescriptor(
	cudnnTensorTransformDescriptor_t transformDesc);
</pre><p dir="ltr" class="p" id="cudnnDestroyTensorTransformDescriptor__docs-internal-guid-667464f6-7fff-5fc8-2e68-45b904e91c8a"><a name="cudnnDestroyTensorTransformDescriptor__docs-internal-guid-667464f6-7fff-5fc8-2e68-45b904e91c8a" shape="rect">
                              <!-- --></a>Destroys a
                           			previously created Tensor transform descriptor.
                        </p>
                        <p class="p"><strong class="ph b">Parameters:</strong></p>
                        <div class="tablenoborder"><a name="cudnnDestroyTensorTransformDescriptor__table_hpj_hcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnDestroyTensorTransformDescriptor__table_hpj_hcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1"><strong class="ph b">Parameter</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1"><strong class="ph b">Input / Output</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">transformDesc</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1"> The Tensor transform descriptor to be destroyed. </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                        <p class="p"><strong class="ph b">Returns:</strong></p>
                        <div class="tablenoborder"><a name="cudnnDestroyTensorTransformDescriptor__table_usk_kcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnDestroyTensorTransformDescriptor__table_usk_kcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Return Value</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_SUCCESS</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">The descriptor was destroyed successfully.</td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnDivisiveNormalizationBackward"><a name="cudnnDivisiveNormalizationBackward" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDivisiveNormalizationBackward" name="cudnnDivisiveNormalizationBackward" shape="rect">4.62.&nbsp;cudnnDivisiveNormalizationBackward</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve"> cudnnStatus_t cudnnDivisiveNormalizationBackward(
    cudnnHandle_t                    handle,
    cudnnLRNDescriptor_t             normDesc,
    cudnnDivNormMode_t               mode,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *alpha,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *means,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *dy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *temp,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *temp2,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *beta,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    dxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *dx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *dMeans)</pre><p class="p">This function performs the backward DivisiveNormalization layer computation. </p>
                        <div class="note note"><span class="notetitle">Note:</span> Supported tensor formats are NCHW for 4D and NCDHW for 5D with any non-overlapping
                           non-negative strides. Only 4D and 5D tensors are supported. 
                        </div>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN library descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">normDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously intialized LRN parameter descriptor
                                 (this descriptor is used for both LRN and DivisiveNormalization layers).
                              </p>
                           </dd>
                           <dt class="dt dlterm">mode </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. DivisiveNormalization layer mode of operation. Currently only
                                 CUDNN_DIVNORM_PRECOMPUTED_MEANS is implemented. Normalization is performed
                                 using the means input tensor that is expected to be precomputed by the user.
                                 
                              </p>
                           </dd>
                           <dt class="dt dlterm">alpha, beta </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointers to scaling factors (in host memory) used to blend the
                                 layer output value with prior value in the destination tensor as follows:
                                 dstValue = alpha[0]*resultValue + beta[0]*priorDstValue. <a class="xref" href="index.html#general-description" shape="rect"> Please refer to this
                                    section for additional details. </a></p>
                           </dd>
                           <dt class="dt dlterm">xDesc, x, means </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Tensor descriptor and pointers in device memory for the layer's
                                 x and means data. Note: the means tensor is expected to be precomputed by
                                 the user. It can also contain any valid values (not required to be actual
                                 means, and can be for instance a result of a convolution with a Gaussian
                                 kernel). 
                              </p>
                           </dd>
                           <dt class="dt dlterm">dy </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Tensor pointer in device memory for the layer's dy cumulative
                                 loss differential data (error backpropagation).
                              </p>
                           </dd>
                           <dt class="dt dlterm">temp, temp2 </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Workspace</em>. Temporary tensors in device memory. These are used for
                                 computing intermediate values during the backward pass. These tensors do not
                                 have to be preserved from forward to backward pass. Both use xDesc as a
                                 descriptor. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">dxDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Tensor descriptor for dx and dMeans.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dx, dMeans </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Tensor pointers (in device memory) for the layer's resulting
                                 cumulative gradients dx and dMeans (dLoss/dx and dLoss/dMeans). Both share
                                 the same descriptor. 
                              </p>
                           </dd>
                        </dl>
                        <p class="p">Possible error values returned by this function and their meanings are listed below.</p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The computation was performed successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnDivisiveNormalizationBackward__ul_zsg_fb3_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnDivisiveNormalizationBackward__ul_zsg_fb3_s1b">
                                 <li class="li">One of the tensor pointers <samp class="ph codeph">x, dx, temp, tmep2, dy</samp> is
                                    NULL.
                                 </li>
                                 <li class="li">Number of any of the input or output tensor dimensions is not within the
                                    [4,5] range.
                                 </li>
                                 <li class="li">Either alpha or beta pointer is NULL.</li>
                                 <li class="li">A mismatch in dimensions between xDesc and dxDesc.</li>
                                 <li class="li">LRN descriptor parameters are outside of their valid ranges.</li>
                                 <li class="li">Any of the tensor strides is negative.</li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_UNSUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function does not support the provided configuration. See the following
                                 for some examples of non-supported configurations:
                              </p><a name="cudnnDivisiveNormalizationBackward__ul_dtg_fb3_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnDivisiveNormalizationBackward__ul_dtg_fb3_s1b">
                                 <li class="li">Any of the input and output tensor strides mismatch (for the same
                                    dimension).
                                 </li>
                              </ul>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnDivisiveNormalizationForward"><a name="cudnnDivisiveNormalizationForward" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDivisiveNormalizationForward" name="cudnnDivisiveNormalizationForward" shape="rect">4.63.&nbsp;cudnnDivisiveNormalizationForward</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">
cudnnStatus_t cudnnDivisiveNormalizationForward(
    cudnnHandle_t                    handle,
    cudnnLRNDescriptor_t             normDesc,
    cudnnDivNormMode_t               mode,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *alpha,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *means,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *temp,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *temp2,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *beta,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *y)</pre><p class="p">This function performs the forward spatial DivisiveNormalization layer computation. It
                           divides every value in a layer by the standard deviation of its spatial neighbors as
                           described in <em class="ph i">"What is the Best Multi-Stage Architecture for Object Recognition"</em>,
                           Jarrett 2009, Local Contrast Normalization Layer section. Note that Divisive
                           Normalization only implements the x/max(c, sigma_x) portion of the computation, where
                           sigma_x is the variance over the spatial neighborhood of x. The full LCN (Local
                           Contrastive Normalization) computation can be implemented as a two-step process:
                        </p>
                        <p class="p"></p>
                        <p class="p">x_m = x-mean(x);</p>
                        <p class="p">y = x_m/max(c, sigma(x_m));</p>
                        <p class="p"></p>
                        <p class="p">The "x-mean(x)" which is often referred to as "subtractive normalization" portion of the
                           computation can be implemented using cuDNN average pooling layer followed by a call to
                           addTensor.
                        </p>
                        <div class="note note"><span class="notetitle">Note:</span> Supported tensor formats are NCHW for 4D and NCDHW for 5D with any non-overlapping
                           non-negative strides. Only 4D and 5D tensors are supported. 
                        </div>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN library descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">normDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously intialized LRN parameter descriptor.
                                 This descriptor is used for both LRN and DivisiveNormalization layers.
                              </p>
                           </dd>
                           <dt class="dt dlterm">divNormMode </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. DivisiveNormalization layer mode of operation. Currently only
                                 CUDNN_DIVNORM_PRECOMPUTED_MEANS is implemented. Normalization is performed
                                 using the means input tensor that is expected to be precomputed by the user.
                                 
                              </p>
                           </dd>
                           <dt class="dt dlterm">alpha, beta </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointers to scaling factors (in host memory) used to blend the
                                 layer output value with prior value in the destination tensor as follows:
                                 dstValue = alpha[0]*resultValue + beta[0]*priorDstValue. <a class="xref" href="index.html#general-description" shape="rect"> Please refer to this
                                    section for additional details. </a></p>
                           </dd>
                           <dt class="dt dlterm">xDesc, yDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Tensor descriptor objects for the input and output tensors.
                                 Note that xDesc is shared between x, means, temp and temp2 tensors. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">x </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Input tensor data pointer in device memory.
                              </p>
                           </dd>
                           <dt class="dt dlterm">means </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Input means tensor data pointer in device memory. Note that
                                 this tensor can be NULL (in that case its values are assumed to be zero
                                 during the computation). This tensor also doesn't have to contain means,
                                 these can be any values, a frequently used variation is a result of
                                 convolution with a normalized positive kernel (such as Gaussian). 
                              </p>
                           </dd>
                           <dt class="dt dlterm">temp, temp2 </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Workspace</em>. Temporary tensors in device memory. These are used for
                                 computing intermediate values during the forward pass. These tensors do not
                                 have to be preserved as inputs from forward to the backward pass. Both use
                                 xDesc as their descriptor. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">y </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Pointer in device memory to a tensor for the result of the
                                 forward DivisiveNormalization computation. 
                              </p>
                           </dd>
                        </dl>
                        <p class="p">Possible error values returned by this function and their meanings are listed below.</p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The computation was performed successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnDivisiveNormalizationForward__ul_oh5_bb3_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnDivisiveNormalizationForward__ul_oh5_bb3_s1b">
                                 <li class="li">One of the tensor pointers <samp class="ph codeph">x, y, temp, temp2</samp> is
                                    NULL.
                                 </li>
                                 <li class="li">Number of input tensor or output tensor dimensions is outside of [4,5]
                                    range.
                                 </li>
                                 <li class="li">A mismatch in dimensions between any two of the input or output
                                    tensors.
                                 </li>
                                 <li class="li">For in-place computation when pointers x == y, a mismatch in strides
                                    between the input data and output data tensors.
                                 </li>
                                 <li class="li">Alpha or beta pointer is NULL.</li>
                                 <li class="li">LRN descriptor parameters are outside of their valid ranges.</li>
                                 <li class="li">Any of the tensor strides are negative.</li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_UNSUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function does not support the provided configuration. See the following
                                 for some examples of non-supported configurations:
                              </p><a name="cudnnDivisiveNormalizationForward__ul_wh5_bb3_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnDivisiveNormalizationForward__ul_wh5_bb3_s1b">
                                 <li class="li">Any of the input and output tensor strides mismatch (for the same
                                    dimension).
                                 </li>
                              </ul>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnDropoutBackward"><a name="cudnnDropoutBackward" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDropoutBackward" name="cudnnDropoutBackward" shape="rect">4.64.&nbsp;cudnnDropoutBackward</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnDropoutBackward(
    cudnnHandle_t                   handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnDropoutDescriptor_t  dropoutDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   dydesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *dy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   dxdesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *dx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *reserveSpace,
    size_t                          reserveSpaceSizeInBytes)</pre><p class="p">This function performs backward dropout operation over <samp class="ph codeph">dy</samp> returning
                           results in <samp class="ph codeph">dx</samp>. If during forward dropout operation value from
                           <samp class="ph codeph">x</samp> was propagated to <samp class="ph codeph">y</samp> then during backward
                           operation value from <samp class="ph codeph">dy</samp> will be propagated to <samp class="ph codeph">dx</samp>,
                           otherwise, <samp class="ph codeph">dx</samp> value will be set to <samp class="ph codeph">0</samp>.
                        </p>
                        <div class="note note"><span class="notetitle">Note:</span> Better performance is obtained for fully packed tensors
                        </div>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dropoutDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Previously created dropout descriptor object.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dyDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dy </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointer to data of the tensor described by the
                                 <samp class="ph codeph">dyDesc</samp> descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dxDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dx </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Pointer to data of the tensor described by the
                                 <samp class="ph codeph">dxDesc</samp> descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">reserveSpace </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointer to user-allocated GPU memory used by this function. It
                                 is expected that <samp class="ph codeph">reserveSpace</samp> was populated during a call
                                 to <samp class="ph codeph">cudnnDropoutForward</samp> and has not been changed. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">reserveSpaceSizeInBytes </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Specifies size in bytes of the provided memory for the reserve
                                 space
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The call was successful.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function does not support the provided configuration.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnDropoutBackward__ul_hmp_5h3_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnDropoutBackward__ul_hmp_5h3_s1b">
                                 <li class="li">The number of elements of input tensor and output tensors differ.</li>
                                 <li class="li">The <samp class="ph codeph">datatype</samp> of the input tensor and output tensors
                                    differs.
                                 </li>
                                 <li class="li">The strides of the input tensor and output tensors differ and in-place
                                    operation is used (i.e., <samp class="ph codeph">x</samp> and <samp class="ph codeph">y</samp>
                                    pointers are equal).
                                 </li>
                                 <li class="li">The provided <samp class="ph codeph">reserveSpaceSizeInBytes</samp> is less then the
                                    value returned by <samp class="ph codeph">cudnnDropoutGetReserveSpaceSize</samp></li>
                                 <li class="li"><samp class="ph codeph">cudnnSetDropoutDescriptor</samp> has not been called on
                                    <samp class="ph codeph">dropoutDesc</samp> with the non-NULL
                                    <samp class="ph codeph">states</samp> argument
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function failed to launch on the GPU.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnDropoutForward"><a name="cudnnDropoutForward" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDropoutForward" name="cudnnDropoutForward" shape="rect">4.65.&nbsp;cudnnDropoutForward</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnDropoutForward(
    cudnnHandle_t                       handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnDropoutDescriptor_t      dropoutDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       xdesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                         *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       ydesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                               *y,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                               *reserveSpace,
    size_t                              reserveSpaceSizeInBytes)</pre><p class="p">This function performs forward dropout operation over <samp class="ph codeph">x</samp> returning
                           results in <samp class="ph codeph">y</samp>. If <samp class="ph codeph">dropout</samp> was used as a parameter to
                           <samp class="ph codeph">cudnnSetDropoutDescriptor</samp>, the approximately
                           <samp class="ph codeph">dropout</samp> fraction of <samp class="ph codeph">x</samp> values will be replaces by
                           <samp class="ph codeph">0</samp>, and the rest will be scaled by <samp class="ph codeph">1/(1-dropout)</samp>
                           This function should not be running concurrently with another
                           <samp class="ph codeph">cudnnDropoutForward</samp> function using the same
                           <samp class="ph codeph">states</samp>.
                        </p>
                        <div class="note note"><span class="notetitle">Note:</span> Better performance is obtained for fully packed tensors
                        </div>
                        <div class="note note"><span class="notetitle">Note:</span> Should not be called during inference
                        </div>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dropoutDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Previously created dropout descriptor object.
                              </p>
                           </dd>
                           <dt class="dt dlterm">xDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">x </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointer to data of the tensor described by the
                                 <samp class="ph codeph">xDesc</samp> descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">yDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">y </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Pointer to data of the tensor described by the
                                 <samp class="ph codeph">yDesc</samp> descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">reserveSpace </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Pointer to user-allocated GPU memory used by this function. It
                                 is expected that contents of <samp class="ph codeph">reserveSpace</samp> doe not change
                                 between <samp class="ph codeph">cudnnDropoutForward</samp> and
                                 <samp class="ph codeph">cudnnDropoutBackward</samp> calls.
                              </p>
                           </dd>
                           <dt class="dt dlterm">reserveSpaceSizeInBytes </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Specifies size in bytes of the provided memory for the reserve
                                 space.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The call was successful.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function does not support the provided configuration.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnDropoutForward__ul_gwh_ph3_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnDropoutForward__ul_gwh_ph3_s1b">
                                 <li class="li">The number of elements of input tensor and output tensors differ.</li>
                                 <li class="li">The <samp class="ph codeph">datatype</samp> of the input tensor and output tensors
                                    differs.
                                 </li>
                                 <li class="li">The strides of the input tensor and output tensors differ and in-place
                                    operation is used (i.e., <samp class="ph codeph">x</samp> and <samp class="ph codeph">y</samp>
                                    pointers are equal).
                                 </li>
                                 <li class="li">The provided <samp class="ph codeph">reserveSpaceSizeInBytes</samp> is less then the
                                    value returned by <samp class="ph codeph">cudnnDropoutGetReserveSpaceSize</samp>.
                                 </li>
                                 <li class="li"><samp class="ph codeph">cudnnSetDropoutDescriptor</samp> has not been called on
                                    <samp class="ph codeph">dropoutDesc</samp> with the non-NULL
                                    <samp class="ph codeph">states</samp> argument.
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function failed to launch on the GPU.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnDropoutGetReserveSpaceSize"><a name="cudnnDropoutGetReserveSpaceSize" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDropoutGetReserveSpaceSize" name="cudnnDropoutGetReserveSpaceSize" shape="rect">4.66.&nbsp;cudnnDropoutGetReserveSpaceSize</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnDropoutGetReserveSpaceSize(
    cudnnTensorDescriptor_t     xDesc,
    size_t                     *sizeInBytes)</pre><p class="p">This function is used to query the amount of reserve needed to run dropout with the input
                           dimensions given by <samp class="ph codeph">xDesc</samp>. The same reserve space is expected to be
                           passed to <samp class="ph codeph">cudnnDropoutForward</samp> and
                           <samp class="ph codeph">cudnnDropoutBackward</samp>, and its contents is expected to remain unchanged
                           between <samp class="ph codeph">cudnnDropoutForward</samp> and <samp class="ph codeph">cudnnDropoutBackward</samp>
                           calls.
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">xDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor,
                                 describing input to a dropout operation.
                              </p>
                           </dd>
                           <dt class="dt dlterm">sizeInBytes </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Amount of GPU memory needed as reserve space to be able to run
                                 dropout with an input tensor descriptor specified by xDesc.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The query was successful.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnDropoutGetStatesSize"><a name="cudnnDropoutGetStatesSize" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnDropoutGetStatesSize" name="cudnnDropoutGetStatesSize" shape="rect">4.67.&nbsp;cudnnDropoutGetStatesSize</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnDropoutGetStatesSize(
    cudnnHandle_t       handle,
    size_t             *sizeInBytes)</pre><p class="p">This function is used to query the amount of space required to store the states of the
                           random number generators used by <samp class="ph codeph">cudnnDropoutForward</samp> function.
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">sizeInBytes </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Amount of GPU memory needed to store random generator
                                 states.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The query was successful.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnFindConvolutionBackwardDataAlgorithm"><a name="cudnnFindConvolutionBackwardDataAlgorithm" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnFindConvolutionBackwardDataAlgorithm" name="cudnnFindConvolutionBackwardDataAlgorithm" shape="rect">4.68.&nbsp;cudnnFindConvolutionBackwardDataAlgorithm</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnFindConvolutionBackwardDataAlgorithm(
    cudnnHandle_t                          handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t          wDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t          dyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnConvolutionDescriptor_t     convDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t          dxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                              requestedAlgoCount,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                   *returnedAlgoCount,
    cudnnConvolutionBwdDataAlgoPerf_t     *perfResults)</pre><p class="p">This function attempts all algorithms available for <a class="xref" href="index.html#cudnnConvolutionBackwardData" shape="rect">cudnnConvolutionBackwardData</a><samp class="ph codeph">()</samp>. It will attempt both the
                           			provided <samp class="ph codeph">convDesc</samp>'s <samp class="ph codeph">mathType</samp> and CUDNN_DEFAULT_MATH
                           			(assuming the two differ).
                        </p>
                        <div class="p">
                           <div class="note note"><span class="notetitle">Note:</span>  Algorithms without the CUDNN_TENSOR_OP_MATH  availability will only be tried with
                              				CUDNN_DEFAULT_MATH, and returned as such.
                           </div>
                        </div>
                        <p class="p">Memory is allocated via <samp class="ph codeph">cudaMalloc()</samp>. The performance metrics are returned
                           			in the user-allocated array of <a class="xref" href="index.html#cudnnConvolutionBwdDataAlgoPerf_t" shape="rect">cudnnConvolutionBwdDataAlgoPerf_t</a>. These
                           			metrics are written in a sorted fashion where the first element has the lowest compute
                           			time. The total number of resulting algorithms can be queried through the API <a class="xref" href="index.html#cudnnGetConvolutionBackwardDataAlgorithmMaxCount" shape="rect">cudnnGetConvolutionBackwardDataAlgorithmMaxCount</a><samp class="ph codeph">()</samp>.
                        </p>
                        <div class="note note"><span class="notetitle">Note:</span> This function is host blocking.
                        </div>
                        <div class="note note"><span class="notetitle">Note:</span> It is recommend to run this function prior to allocating layer data; doing otherwise
                           may needlessly inhibit some algorithm options due to resource usage.
                        </div>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">wDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dyDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized input differential tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">convDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Previously initialized convolution descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dxDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized output tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">requestedAlgoCount </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. The maximum number of elements to be stored in perfResults.
                              </p>
                           </dd>
                           <dt class="dt dlterm">returnedAlgoCount </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. The number of output elements stored in perfResults.
                              </p>
                           </dd>
                           <dt class="dt dlterm">perfResults </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. A user-allocated array to store performance metrics sorted
                                 ascending by compute time.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The query was successful.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnFindConvolutionBackwardDataAlgorithm__ul_hh5_ljb_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnFindConvolutionBackwardDataAlgorithm__ul_hh5_ljb_s1b">
                                 <li class="li"><samp class="ph codeph">handle</samp> is not allocated properly.
                                 </li>
                                 <li class="li"><samp class="ph codeph">wDesc</samp>, <samp class="ph codeph">dyDesc</samp> or
                                    <samp class="ph codeph">dxDesc</samp> is not allocated properly.
                                 </li>
                                 <li class="li"><samp class="ph codeph">wDesc</samp>, <samp class="ph codeph">dyDesc</samp> or
                                    <samp class="ph codeph">dxDesc</samp> has fewer than 1 dimension.
                                 </li>
                                 <li class="li">Either <samp class="ph codeph">returnedCount</samp> or <samp class="ph codeph">perfResults</samp> is
                                    nil.
                                 </li>
                                 <li class="li"><samp class="ph codeph">requestedCount</samp> is less than 1.
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">This function was unable to allocate memory to store sample input, filters
                                 and output.
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_INTERNAL_ERROR</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnFindConvolutionBackwardDataAlgorithm__ul_nh5_ljb_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnFindConvolutionBackwardDataAlgorithm__ul_nh5_ljb_s1b">
                                 <li class="li">The function was unable to allocate neccesary timing objects.</li>
                                 <li class="li">The function was unable to deallocate neccesary timing objects.</li>
                                 <li class="li">The function was unable to deallocate sample input, filters and
                                    output.
                                 </li>
                              </ul>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnFindConvolutionBackwardDataAlgorithmEx"><a name="cudnnFindConvolutionBackwardDataAlgorithmEx" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnFindConvolutionBackwardDataAlgorithmEx" name="cudnnFindConvolutionBackwardDataAlgorithmEx" shape="rect">4.69.&nbsp;cudnnFindConvolutionBackwardDataAlgorithmEx</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnFindConvolutionBackwardDataAlgorithmEx(
    cudnnHandle_t                          handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t          wDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *w,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t          dyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *dy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnConvolutionDescriptor_t     convDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t          dxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                  *dx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                              requestedAlgoCount,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                   *returnedAlgoCount,
    cudnnConvolutionBwdDataAlgoPerf_t     *perfResults,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                  *workSpace,
    size_t                                 workSpaceSizeInBytes)</pre><p class="p">This function attempts all algorithms available for <a class="xref" href="index.html#cudnnConvolutionBackwardData" shape="rect">cudnnConvolutionBackwardData</a><samp class="ph codeph">()</samp>. It will attempt both the
                           			provided <samp class="ph codeph">convDesc</samp>'s <samp class="ph codeph">mathType</samp> and CUDNN_DEFAULT_MATH
                           			(assuming the two differ).
                        </p>
                        <div class="p">
                           <div class="note note"><span class="notetitle">Note:</span>  Algorithms without the CUDNN_TENSOR_OP_MATH  availability will only be tried with
                              				CUDNN_DEFAULT_MATH, and returned as such.
                           </div>
                        </div>
                        <p class="p">Memory is allocated via <samp class="ph codeph">cudaMalloc()</samp>. The performance metrics are returned
                           			in the user-allocated array of <a class="xref" href="index.html#cudnnConvolutionBwdDataAlgoPerf_t" shape="rect">cudnnConvolutionBwdDataAlgoPerf_t</a>. These
                           			metrics are written in a sorted fashion where the first element has the lowest compute
                           			time. The total number of resulting algorithms can be queried through the API <a class="xref" href="index.html#cudnnGetConvolutionBackwardDataAlgorithmMaxCount" shape="rect">cudnnGetConvolutionBackwardDataAlgorithmMaxCount</a><samp class="ph codeph">()</samp>.
                        </p>
                        <div class="note note"><span class="notetitle">Note:</span> This function is host blocking.
                        </div>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">wDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">w </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the filter
                                 descriptor <samp class="ph codeph">wDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dyDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized input differential tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dy </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the filter
                                 descriptor <samp class="ph codeph">dyDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">convDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Previously initialized convolution descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dxDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized output tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dxDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input/Output</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">dxDesc</samp>. The content of this tensor will be
                                 overwritten with arbitary values.
                              </p>
                           </dd>
                           <dt class="dt dlterm">requestedAlgoCount </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. The maximum number of elements to be stored in perfResults.
                              </p>
                           </dd>
                           <dt class="dt dlterm">returnedAlgoCount </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. The number of output elements stored in perfResults.
                              </p>
                           </dd>
                           <dt class="dt dlterm">perfResults </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. A user-allocated array to store performance metrics sorted
                                 ascending by compute time.
                              </p>
                           </dd>
                           <dt class="dt dlterm">workSpace </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory that is a necessary workspace for
                                 some algorithms. The size of this workspace will determine the availabilty
                                 of algorithms. A nil pointer is considered a workSpace of 0 bytes.
                              </p>
                           </dd>
                           <dt class="dt dlterm">workSpaceSizeInBytes </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                 <samp class="ph codeph">workSpace</samp></p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The query was successful.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnFindConvolutionBackwardDataAlgorithmEx__ul_nmk_rjb_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnFindConvolutionBackwardDataAlgorithmEx__ul_nmk_rjb_s1b">
                                 <li class="li"><samp class="ph codeph">handle</samp> is not allocated properly.
                                 </li>
                                 <li class="li"><samp class="ph codeph">wDesc</samp>, <samp class="ph codeph">dyDesc</samp> or
                                    <samp class="ph codeph">dxDesc</samp> is not allocated properly.
                                 </li>
                                 <li class="li"><samp class="ph codeph">wDesc</samp>, <samp class="ph codeph">dyDesc</samp> or
                                    <samp class="ph codeph">dxDesc</samp> has fewer than 1 dimension.
                                 </li>
                                 <li class="li"><samp class="ph codeph">w</samp>, <samp class="ph codeph">dy</samp> or <samp class="ph codeph">dx</samp> is
                                    nil.
                                 </li>
                                 <li class="li">Either <samp class="ph codeph">returnedCount</samp> or <samp class="ph codeph">perfResults</samp> is
                                    nil.
                                 </li>
                                 <li class="li"><samp class="ph codeph">requestedCount</samp> is less than 1.
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_INTERNAL_ERROR</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnFindConvolutionBackwardDataAlgorithmEx__ul_rmk_rjb_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnFindConvolutionBackwardDataAlgorithmEx__ul_rmk_rjb_s1b">
                                 <li class="li">The function was unable to allocate neccesary timing objects.</li>
                                 <li class="li">The function was unable to deallocate neccesary timing objects.</li>
                                 <li class="li">The function was unable to deallocate sample input, filters and
                                    output.
                                 </li>
                              </ul>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnFindConvolutionBackwardFilterAlgorithm"><a name="cudnnFindConvolutionBackwardFilterAlgorithm" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnFindConvolutionBackwardFilterAlgorithm" name="cudnnFindConvolutionBackwardFilterAlgorithm" shape="rect">4.70.&nbsp;cudnnFindConvolutionBackwardFilterAlgorithm</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnFindConvolutionBackwardFilterAlgorithm(
cudnnHandle_t                          handle,
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t          xDesc,
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t          dyDesc,
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnConvolutionDescriptor_t     convDesc,
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t          dwDesc,
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                              requestedAlgoCount,
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                   *returnedAlgoCount,
cudnnConvolutionBwdFilterAlgoPerf_t   *perfResults)</pre><p class="p">This function attempts all algorithms available for <a class="xref" href="index.html#cudnnConvolutionBackwardFilter" shape="rect">cudnnConvolutionBackwardFilter</a><samp class="ph codeph">()</samp>. It will attempt both the
                           			provided <samp class="ph codeph">convDesc</samp>'s <samp class="ph codeph">mathType</samp> and CUDNN_DEFAULT_MATH
                           			(assuming the two differ).
                        </p>
                        <div class="p">
                           <div class="note note"><span class="notetitle">Note:</span>  Algorithms without the CUDNN_TENSOR_OP_MATH  availability will only be tried with
                              				CUDNN_DEFAULT_MATH, and returned as such.
                           </div>
                        </div>
                        <p class="p">Memory is allocated via <samp class="ph codeph">cudaMalloc()</samp>. The performance metrics are returned
                           			in the user-allocated array of <a class="xref" href="index.html#cudnnConvolutionBwdFilterAlgoPerf_t" shape="rect">cudnnConvolutionBwdFilterAlgoPerf_t</a>. These
                           			metrics are written in a sorted fashion where the first element has the lowest compute
                           			time. The total number of resulting algorithms can be queried through the API <a class="xref" href="index.html#cudnnGetConvolutionBackwardFilterAlgorithmMaxCount" shape="rect">cudnnGetConvolutionBackwardFilterAlgorithmMaxCount</a><samp class="ph codeph">()</samp>.
                        </p>
                        <div class="note note"><span class="notetitle">Note:</span> This function is host blocking.
                        </div>
                        <div class="note note"><span class="notetitle">Note:</span> It is recommend to run this function prior to allocating layer data; doing otherwise
                           may needlessly inhibit some algorithm options due to resource usage.
                        </div>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">xDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized input tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dyDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized input differential tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">convDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Previously initialized convolution descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dwDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">requestedAlgoCount </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. The maximum number of elements to be stored in perfResults.
                              </p>
                           </dd>
                           <dt class="dt dlterm">returnedAlgoCount </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. The number of output elements stored in perfResults.
                              </p>
                           </dd>
                           <dt class="dt dlterm">perfResults </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. A user-allocated array to store performance metrics sorted
                                 ascending by compute time.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The query was successful.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnFindConvolutionBackwardFilterAlgorithm__ul_o1g_g3b_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnFindConvolutionBackwardFilterAlgorithm__ul_o1g_g3b_s1b">
                                 <li class="li"><samp class="ph codeph">handle</samp> is not allocated properly.
                                 </li>
                                 <li class="li"><samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">dyDesc</samp> or
                                    <samp class="ph codeph">dwDesc</samp> is not allocated properly.
                                 </li>
                                 <li class="li"><samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">dyDesc</samp> or
                                    <samp class="ph codeph">dwDesc</samp> has fewer than 1 dimension.
                                 </li>
                                 <li class="li">Either <samp class="ph codeph">returnedCount</samp> or <samp class="ph codeph">perfResults</samp> is
                                    nil.
                                 </li>
                                 <li class="li"><samp class="ph codeph">requestedCount</samp> is less than 1.
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">This function was unable to allocate memory to store sample input, filters
                                 and output.
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_INTERNAL_ERROR</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnFindConvolutionBackwardFilterAlgorithm__ul_u1g_g3b_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnFindConvolutionBackwardFilterAlgorithm__ul_u1g_g3b_s1b">
                                 <li class="li">The function was unable to allocate neccesary timing objects.</li>
                                 <li class="li">The function was unable to deallocate neccesary timing objects.</li>
                                 <li class="li">The function was unable to deallocate sample input, filters and
                                    output.
                                 </li>
                              </ul>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnFindConvolutionBackwardFilterAlgorithmEx"><a name="cudnnFindConvolutionBackwardFilterAlgorithmEx" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnFindConvolutionBackwardFilterAlgorithmEx" name="cudnnFindConvolutionBackwardFilterAlgorithmEx" shape="rect">4.71.&nbsp;cudnnFindConvolutionBackwardFilterAlgorithmEx</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnFindConvolutionBackwardFilterAlgorithmEx(
    cudnnHandle_t                          handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t          xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t          dyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *dy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnConvolutionDescriptor_t     convDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t          dwDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                  *dw,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                              requestedAlgoCount,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                   *returnedAlgoCount,
    cudnnConvolutionBwdFilterAlgoPerf_t   *perfResults,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                  *workSpace,
    size_t                                 workSpaceSizeInBytes)</pre><p class="p">This function attempts all algorithms available for <a class="xref" href="index.html#cudnnConvolutionBackwardFilter" shape="rect">cudnnConvolutionBackwardFilter</a><samp class="ph codeph">()</samp>. It will attempt both the
                           			provided <samp class="ph codeph">convDesc</samp>'s <samp class="ph codeph">mathType</samp> and CUDNN_DEFAULT_MATH
                           			(assuming the two differ).
                        </p>
                        <div class="p">
                           <div class="note note"><span class="notetitle">Note:</span>  Algorithms without the CUDNN_TENSOR_OP_MATH  availability will only be tried with
                              				CUDNN_DEFAULT_MATH, and returned as such.
                           </div>
                        </div>
                        <p class="p">Memory is allocated via <samp class="ph codeph">cudaMalloc()</samp>. The performance metrics are returned
                           			in the user-allocated array of <a class="xref" href="index.html#cudnnConvolutionBwdFilterAlgoPerf_t" shape="rect">cudnnConvolutionBwdFilterAlgoPerf_t</a>. These
                           			metrics are written in a sorted fashion where the first element has the lowest compute
                           			time. The total number of resulting algorithms can be queried through the API <a class="xref" href="index.html#cudnnGetConvolutionBackwardFilterAlgorithmMaxCount" shape="rect">cudnnGetConvolutionBackwardFilterAlgorithmMaxCount</a><samp class="ph codeph">()</samp>.
                        </p>
                        <div class="note note"><span class="notetitle">Note:</span> This function is host blocking.
                        </div>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">xDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized input tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">x </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the filter
                                 descriptor <samp class="ph codeph">xDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dyDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized input differential tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dy </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">dyDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">convDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Previously initialized convolution descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dwDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dw </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input/Output</em>. Data pointer to GPU memory associated with the filter
                                 descriptor <samp class="ph codeph">dwDesc</samp>. The content of this tensor will be
                                 overwritten with arbitary values.
                              </p>
                           </dd>
                           <dt class="dt dlterm">requestedAlgoCount </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. The maximum number of elements to be stored in perfResults.
                              </p>
                           </dd>
                           <dt class="dt dlterm">returnedAlgoCount </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. The number of output elements stored in perfResults.
                              </p>
                           </dd>
                           <dt class="dt dlterm">perfResults </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. A user-allocated array to store performance metrics sorted
                                 ascending by compute time.
                              </p>
                           </dd>
                           <dt class="dt dlterm">workSpace </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory that is a necessary workspace for
                                 some algorithms. The size of this workspace will determine the availabilty
                                 of algorithms. A nil pointer is considered a workSpace of 0 bytes.
                              </p>
                           </dd>
                           <dt class="dt dlterm">workSpaceSizeInBytes </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                 <samp class="ph codeph">workSpace</samp></p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The query was successful.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnFindConvolutionBackwardFilterAlgorithmEx__ul_lgv_k3b_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnFindConvolutionBackwardFilterAlgorithmEx__ul_lgv_k3b_s1b">
                                 <li class="li"><samp class="ph codeph">handle</samp> is not allocated properly.
                                 </li>
                                 <li class="li"><samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">dyDesc</samp> or
                                    <samp class="ph codeph">dwDesc</samp> is not allocated properly.
                                 </li>
                                 <li class="li"><samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">dyDesc</samp> or
                                    <samp class="ph codeph">dwDesc</samp> has fewer than 1 dimension.
                                 </li>
                                 <li class="li"><samp class="ph codeph">x</samp>, <samp class="ph codeph">dy</samp> or <samp class="ph codeph">dw</samp> is
                                    nil.
                                 </li>
                                 <li class="li">Either <samp class="ph codeph">returnedCount</samp> or <samp class="ph codeph">perfResults</samp> is
                                    nil.
                                 </li>
                                 <li class="li"><samp class="ph codeph">requestedCount</samp> is less than 1.
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_INTERNAL_ERROR</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnFindConvolutionBackwardFilterAlgorithmEx__ul_ugv_k3b_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnFindConvolutionBackwardFilterAlgorithmEx__ul_ugv_k3b_s1b">
                                 <li class="li">The function was unable to allocate neccesary timing objects.</li>
                                 <li class="li">The function was unable to deallocate neccesary timing objects.</li>
                                 <li class="li">The function was unable to deallocate sample input, filters and
                                    output.
                                 </li>
                              </ul>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnFindConvolutionForwardAlgorithm"><a name="cudnnFindConvolutionForwardAlgorithm" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnFindConvolutionForwardAlgorithm" name="cudnnFindConvolutionForwardAlgorithm" shape="rect">4.72.&nbsp;cudnnFindConvolutionForwardAlgorithm</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnFindConvolutionForwardAlgorithm(
    cudnnHandle_t                      handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t      xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t      wDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnConvolutionDescriptor_t convDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t      yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                          requestedAlgoCount,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                               *returnedAlgoCount,
    cudnnConvolutionFwdAlgoPerf_t     *perfResults)</pre><p class="p">This function attempts all algorithms available for <a class="xref" href="index.html#cudnnConvolutionForward" shape="rect">cudnnConvolutionForward</a><samp class="ph codeph">()</samp>. It will attempt both the provided <samp class="ph codeph">convDesc</samp>'s
                           				<samp class="ph codeph">mathType</samp> and CUDNN_DEFAULT_MATH (assuming the two differ).
                        </p>
                        <div class="p">
                           <div class="note note"><span class="notetitle">Note:</span>  Algorithms without the CUDNN_TENSOR_OP_MATH  availability will only be tried with
                              				CUDNN_DEFAULT_MATH, and returned as such.
                           </div>
                        </div>
                        <p class="p">Memory is allocated via <samp class="ph codeph">cudaMalloc()</samp>. The performance metrics are returned
                           			in the user-allocated array of <a class="xref" href="index.html#cudnnConvolutionFwdAlgoPerf_t" shape="rect">cudnnConvolutionFwdAlgoPerf_t</a>. These
                           			metrics are written in a sorted fashion where the first element has the lowest compute
                           			time. The total number of resulting algorithms can be queried through the API <a class="xref" href="index.html#cudnnGetConvolutionForwardAlgorithmMaxCount" shape="rect">cudnnGetConvolutionForwardAlgorithmMaxCount</a><samp class="ph codeph">()</samp>.
                        </p>
                        <div class="note note"><span class="notetitle">Note:</span> This function is host blocking.
                        </div>
                        <div class="note note"><span class="notetitle">Note:</span> It is recommend to run this function prior to allocating layer data; doing otherwise
                           may needlessly inhibit some algorithm options due to resource usage.
                        </div>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">xDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized input tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">wDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">convDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Previously initialized convolution descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">yDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized output tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">requestedAlgoCount </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. The maximum number of elements to be stored in perfResults.
                              </p>
                           </dd>
                           <dt class="dt dlterm">returnedAlgoCount </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. The number of output elements stored in perfResults.
                              </p>
                           </dd>
                           <dt class="dt dlterm">perfResults </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. A user-allocated array to store performance metrics sorted
                                 ascending by compute time.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The query was successful.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnFindConvolutionForwardAlgorithm__ul_cfc_bhb_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnFindConvolutionForwardAlgorithm__ul_cfc_bhb_s1b">
                                 <li class="li"><samp class="ph codeph">handle</samp> is not allocated properly.
                                 </li>
                                 <li class="li"><samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">wDesc</samp> or <samp class="ph codeph">yDesc</samp>
                                    is not allocated properly.
                                 </li>
                                 <li class="li"><samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">wDesc</samp> or <samp class="ph codeph">yDesc</samp>
                                    has fewer than 1 dimension.
                                 </li>
                                 <li class="li">Either <samp class="ph codeph">returnedCount</samp> or <samp class="ph codeph">perfResults</samp> is
                                    nil.
                                 </li>
                                 <li class="li"><samp class="ph codeph">requestedCount</samp> is less than 1.
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">This function was unable to allocate memory to store sample input, filters
                                 and output.
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_INTERNAL_ERROR</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnFindConvolutionForwardAlgorithm__ul_kfc_bhb_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnFindConvolutionForwardAlgorithm__ul_kfc_bhb_s1b">
                                 <li class="li">The function was unable to allocate neccesary timing objects.</li>
                                 <li class="li">The function was unable to deallocate neccesary timing objects.</li>
                                 <li class="li">The function was unable to deallocate sample input, filters and
                                    output.
                                 </li>
                              </ul>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnFindConvolutionForwardAlgorithmEx"><a name="cudnnFindConvolutionForwardAlgorithmEx" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnFindConvolutionForwardAlgorithmEx" name="cudnnFindConvolutionForwardAlgorithmEx" shape="rect">4.73.&nbsp;cudnnFindConvolutionForwardAlgorithmEx</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnFindConvolutionForwardAlgorithmEx(
    cudnnHandle_t                      handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t      xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                        *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t      wDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                        *w,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnConvolutionDescriptor_t convDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t      yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                              *y,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                          requestedAlgoCount,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                               *returnedAlgoCount,
    cudnnConvolutionFwdAlgoPerf_t     *perfResults,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                              *workSpace,
    size_t                             workSpaceSizeInBytes)</pre><p class="p">This function attempts all algorithms available for <a class="xref" href="index.html#cudnnConvolutionForward" shape="rect">cudnnConvolutionForward</a><samp class="ph codeph">()</samp>. It will attempt both the provided <samp class="ph codeph">convDesc</samp>'s
                           				<samp class="ph codeph">mathType</samp> and CUDNN_DEFAULT_MATH (assuming the two differ).
                        </p>
                        <div class="p">
                           <div class="note note"><span class="notetitle">Note:</span>  Algorithms without the CUDNN_TENSOR_OP_MATH  availability will only be tried with
                              				CUDNN_DEFAULT_MATH, and returned as such.
                           </div>
                        </div>
                        <p class="p">Memory is allocated via <samp class="ph codeph">cudaMalloc()</samp>. The performance metrics are returned
                           			in the user-allocated array of <a class="xref" href="index.html#cudnnConvolutionFwdAlgoPerf_t" shape="rect">cudnnConvolutionFwdAlgoPerf_t</a>. These
                           			metrics are written in a sorted fashion where the first element has the lowest compute
                           			time. The total number of resulting algorithms can be queried through the API <a class="xref" href="index.html#cudnnGetConvolutionForwardAlgorithmMaxCount" shape="rect">cudnnGetConvolutionForwardAlgorithmMaxCount</a><samp class="ph codeph">()</samp>.
                        </p>
                        <div class="note note"><span class="notetitle">Note:</span> This function is host blocking.
                        </div>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">xDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized input tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">x </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">xDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">wDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">w </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the filter
                                 descriptor <samp class="ph codeph">wDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">convDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Previously initialized convolution descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">yDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized output tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">y </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input/Output</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">yDesc</samp>. The content of this tensor will be
                                 overwritten with arbitary values.
                              </p>
                           </dd>
                           <dt class="dt dlterm">requestedAlgoCount </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. The maximum number of elements to be stored in perfResults.
                              </p>
                           </dd>
                           <dt class="dt dlterm">returnedAlgoCount </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. The number of output elements stored in perfResults.
                              </p>
                           </dd>
                           <dt class="dt dlterm">perfResults </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. A user-allocated array to store performance metrics sorted
                                 ascending by compute time.
                              </p>
                           </dd>
                           <dt class="dt dlterm">workSpace </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory that is a necessary workspace for
                                 some algorithms. The size of this workspace will determine the availability
                                 of algorithms. A nil pointer is considered a workSpace of 0 bytes.
                              </p>
                           </dd>
                           <dt class="dt dlterm">workSpaceSizeInBytes </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                 <samp class="ph codeph">workSpace</samp>.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The query was successful.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnFindConvolutionForwardAlgorithmEx__ul_m1w_fhb_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnFindConvolutionForwardAlgorithmEx__ul_m1w_fhb_s1b">
                                 <li class="li"><samp class="ph codeph">handle</samp> is not allocated properly.
                                 </li>
                                 <li class="li"><samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">wDesc</samp> or <samp class="ph codeph">yDesc</samp>
                                    is not allocated properly.
                                 </li>
                                 <li class="li"><samp class="ph codeph">xDesc</samp>, <samp class="ph codeph">wDesc</samp> or <samp class="ph codeph">yDesc</samp>
                                    has fewer than 1 dimension.
                                 </li>
                                 <li class="li"><samp class="ph codeph">x</samp>, <samp class="ph codeph">w</samp> or <samp class="ph codeph">y</samp> is
                                    nil.
                                 </li>
                                 <li class="li">Either <samp class="ph codeph">returnedCount</samp> or <samp class="ph codeph">perfResults</samp> is
                                    nil.
                                 </li>
                                 <li class="li"><samp class="ph codeph">requestedCount</samp> is less than 1.
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_INTERNAL_ERROR</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnFindConvolutionForwardAlgorithmEx__ul_z1w_fhb_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnFindConvolutionForwardAlgorithmEx__ul_z1w_fhb_s1b">
                                 <li class="li">The function was unable to allocate neccesary timing objects.</li>
                                 <li class="li">The function was unable to deallocate neccesary timing objects.</li>
                                 <li class="li">The function was unable to deallocate sample input, filters and
                                    output.
                                 </li>
                              </ul>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnFindRNNBackwardDataAlgorithmEx"><a name="cudnnFindRNNBackwardDataAlgorithmEx" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnFindRNNBackwardDataAlgorithmEx" name="cudnnFindRNNBackwardDataAlgorithmEx" shape="rect">4.74.&nbsp;cudnnFindRNNBackwardDataAlgorithmEx</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">
cudnnStatus_t cudnnFindRNNBackwardDataAlgorithmEx(
    cudnnHandle_t                    handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDescriptor_t       rnnDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                        seqLength,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    *yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *y,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    *dyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *dy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    dhyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *dhy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    dcyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *dcy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t    wDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *w,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    hxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *hx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    cxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *cx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    *dxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                             *dx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    dhxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                             *dhx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    dcxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                             *dcx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>                      findIntensity,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                        requestedAlgoCount,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                              *returnedAlgoCount,
    cudnnAlgorithmPerformance_t      *perfResults,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                             *workspace,
    size_t                           workSpaceSizeInBytes,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *reserveSpace,
    size_t                           reserveSpaceSizeInBytes)</pre><p class="p"><strong class="ph b">(New for 7.1)</strong></p>
                        <p class="p"> This function attempts all available cuDNN algorithms for
                           <samp class="ph codeph">cudnnRNNBackwardData</samp>, using user-allocated GPU memory. It outputs
                           the parameters that influence the performance of the algorithm to a user-allocated array
                           of <samp class="ph codeph">cudnnAlgorithmPerformance_t</samp>. These parameter metrics are written in
                           sorted fashion where the first element has the lowest compute time. 
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">rnnDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A previously initialized RNN descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">seqLength </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Number of iterations to unroll over. The value of this
                                 							<samp class="ph codeph">seqLength</samp> must not exceed the value that was used in
                                 							<samp class="ph codeph">cudnnGetRNNWorkspaceSize() </samp>function for querying the
                                 						workspace size required to execute the RNN. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">yDesc </dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. An array of fully packed tensor descriptors describing the
                                 output from each recurrent iteration (one descriptor per iteration). The
                                 second dimension of the tensor depends on the <samp class="ph codeph">direction</samp>
                                 argument passed to the <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to
                                 initialize <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnFindRNNBackwardDataAlgorithmEx__ul_xgb_1g3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnFindRNNBackwardDataAlgorithmEx__ul_xgb_1g3_s1b">
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the second dimension
                                       should match the <samp class="ph codeph">hiddenSize</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the second dimension should
                                       match double the <samp class="ph codeph">hiddenSize</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                 </ul>
                                 
                                 The first dimension of the tensor <samp class="ph codeph">n</samp> must match the
                                 first dimension of the tensor <samp class="ph codeph">n</samp> in
                                 <samp class="ph codeph">dyDesc</samp>.
                              </div>
                           </dd>
                           <dt class="dt dlterm">y </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the output tensor
                                 descriptor <samp class="ph codeph">yDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dyDesc </dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. An array of fully packed tensor descriptors describing the
                                 gradient at the output from each recurrent iteration (one descriptor per
                                 iteration). The second dimension of the tensor depends on the
                                 <samp class="ph codeph">direction</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnFindRNNBackwardDataAlgorithmEx__ul_zgb_1g3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnFindRNNBackwardDataAlgorithmEx__ul_zgb_1g3_s1b">
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the second dimension
                                       should match the <samp class="ph codeph">hiddenSize</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the second dimension should
                                       match double the <samp class="ph codeph">hiddenSize</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                 </ul>
                                 
                                 The first dimension of the tensor <samp class="ph codeph">n</samp> must match the
                                 second dimension of the tensor <samp class="ph codeph">n</samp> in
                                 <samp class="ph codeph">dxDesc</samp>.
                              </div>
                           </dd>
                           <dt class="dt dlterm">dy </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptors in the array <samp class="ph codeph">dyDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dhyDesc </dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the gradients at
                                 						the final hidden state of the RNN. The first dimension of the tensor depends
                                 						on the <samp class="ph codeph">direction</samp> argument passed to the
                                 							<samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 							<samp class="ph codeph">rnnDesc</samp>: <a name="cudnnFindRNNBackwardDataAlgorithmEx__ul_bhb_1g3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnFindRNNBackwardDataAlgorithmEx__ul_bhb_1g3_s1b">
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       									<samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first dimension should
                                       								match the <samp class="ph codeph">numLayers</samp> argument passed to
                                       									<samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       									<samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension should
                                       								match double the <samp class="ph codeph">numLayers</samp> argument passed to
                                       									<samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                 </ul>
                                 
                                 The second dimension must match the first dimension of the tensors
                                 						described in <samp class="ph codeph">dxDesc</samp>. The third dimension must match the
                                 							<samp class="ph codeph">hiddenSize</samp> argument passed to the
                                 							<samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 							<samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                              </div>
                           </dd>
                           <dt class="dt dlterm">dhy </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">dhyDesc</samp>. If a NULL pointer is passed, the
                                 gradients at the final hidden state of the network will be initialized to
                                 zero.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dcyDesc </dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the gradients at
                                 						the final cell state of the RNN. The first dimension of the tensor depends
                                 						on the <samp class="ph codeph">direction</samp> argument passed to the
                                 							<samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 							<samp class="ph codeph">rnnDesc</samp>: <a name="cudnnFindRNNBackwardDataAlgorithmEx__ul_chb_1g3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnFindRNNBackwardDataAlgorithmEx__ul_chb_1g3_s1b">
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       									<samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first dimension should
                                       								match the <samp class="ph codeph">numLayers</samp> argument passed to
                                       									<samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       									<samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension should
                                       								match double the <samp class="ph codeph">numLayers</samp> argument passed to
                                       									<samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                 </ul>
                                 
                                 The second dimension must match the first dimension of the tensors
                                 						described in <samp class="ph codeph">dxDesc</samp>. The third dimension must match the
                                 							<samp class="ph codeph">hiddenSize</samp> argument passed to the
                                 							<samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 							<samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                              </div>
                           </dd>
                           <dt class="dt dlterm">dcy </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">dcyDesc</samp>. If a NULL pointer is passed, the
                                 gradients at the final cell state of the network will be initialized to
                                 zero.
                              </p>
                           </dd>
                           <dt class="dt dlterm">wDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor describing
                                 the weights for the RNN.
                              </p>
                           </dd>
                           <dt class="dt dlterm">w </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the filter
                                 descriptor <samp class="ph codeph">wDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">hxDesc </dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the initial hidden
                                 						state of the RNN. The first dimension of the tensor depends on the
                                 							<samp class="ph codeph">direction</samp> argument passed to the
                                 							<samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 							<samp class="ph codeph">rnnDesc</samp>: <a name="cudnnFindRNNBackwardDataAlgorithmEx__ul_ehb_1g3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnFindRNNBackwardDataAlgorithmEx__ul_ehb_1g3_s1b">
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       									<samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first dimension should
                                       								match the <samp class="ph codeph">numLayers</samp> argument passed to
                                       									<samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       									<samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension should
                                       								match double the <samp class="ph codeph">numLayers</samp> argument passed to
                                       									<samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                 </ul>
                                 
                                 The second dimension must match the first dimension of the tensors
                                 						described in <samp class="ph codeph">dxDesc</samp>. The third dimension must match the
                                 							<samp class="ph codeph">hiddenSize</samp> argument passed to the
                                 							<samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 							<samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                              </div>
                           </dd>
                           <dt class="dt dlterm">hx </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">hxDesc</samp>. If a NULL pointer is passed, the initial
                                 hidden state of the network will be initialized to zero.
                              </p>
                           </dd>
                           <dt class="dt dlterm">cxDesc </dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the initial cell
                                 						state for LSTM networks. The first dimension of the tensor depends on the
                                 							<samp class="ph codeph">direction</samp> argument passed to the
                                 							<samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 							<samp class="ph codeph">rnnDesc</samp>: <a name="cudnnFindRNNBackwardDataAlgorithmEx__ul_fhb_1g3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnFindRNNBackwardDataAlgorithmEx__ul_fhb_1g3_s1b">
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       									<samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first dimension should
                                       								match the <samp class="ph codeph">numLayers</samp> argument passed to
                                       									<samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       									<samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension should
                                       								match double the <samp class="ph codeph">numLayers</samp> argument passed to
                                       									<samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                 </ul>
                                 
                                 The second dimension must match the first dimension of the tensors
                                 						described in <samp class="ph codeph">dxDesc</samp>. The third dimension must match the
                                 							<samp class="ph codeph">hiddenSize</samp> argument passed to the
                                 							<samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 							<samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                              </div>
                           </dd>
                           <dt class="dt dlterm">cx </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">cxDesc</samp>. If a NULL pointer is passed, the initial
                                 cell state of the network will be initialized to zero.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dxDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. An array of fully packed tensor descriptors describing the
                                 gradient at the input of each recurrent iteration (one descriptor per
                                 iteration). The first dimension (batch size) of the tensors may decrease
                                 from element <samp class="ph codeph">n</samp> to element <samp class="ph codeph">n+1</samp> but may not
                                 increase. Each tensor descriptor must have the same second dimension (vector
                                 length).
                              </p>
                           </dd>
                           <dt class="dt dlterm">dx </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the tensor
                                 descriptors in the array <samp class="ph codeph">dxDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dhxDesc </dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the gradient at the
                                 						initial hidden state of the RNN. The first dimension of the tensor depends
                                 						on the <samp class="ph codeph">direction</samp> argument passed to the
                                 							<samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 							<samp class="ph codeph">rnnDesc</samp>: <a name="cudnnFindRNNBackwardDataAlgorithmEx__ul_hhb_1g3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnFindRNNBackwardDataAlgorithmEx__ul_hhb_1g3_s1b">
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       									<samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first dimension should
                                       								match the <samp class="ph codeph">numLayers</samp> argument passed to
                                       									<samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       									<samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension should
                                       								match double the <samp class="ph codeph">numLayers</samp> argument passed to
                                       									<samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                 </ul>
                                 
                                 The second dimension must match the first dimension of the tensors
                                 						described in <samp class="ph codeph">dxDesc</samp>. The third dimension must match the
                                 							<samp class="ph codeph">hiddenSize</samp> argument passed to the
                                 							<samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 							<samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                              </div>
                           </dd>
                           <dt class="dt dlterm">dhx </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">dhxDesc</samp>. If a NULL pointer is passed, the
                                 gradient at the hidden input of the network will not be set.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dcxDesc </dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the gradient at the
                                 						initial cell state of the RNN. The first dimension of the tensor depends on
                                 						the <samp class="ph codeph">direction</samp> argument passed to the
                                 							<samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 							<samp class="ph codeph">rnnDesc</samp>: <a name="cudnnFindRNNBackwardDataAlgorithmEx__ul_jhb_1g3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnFindRNNBackwardDataAlgorithmEx__ul_jhb_1g3_s1b">
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       									<samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first dimension should
                                       								match the <samp class="ph codeph">numLayers</samp> argument passed to
                                       									<samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       									<samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension should
                                       								match double the <samp class="ph codeph">numLayers</samp> argument passed to
                                       									<samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                 </ul>
                                 
                                 The second dimension must match the first dimension of the tensors
                                 						described in <samp class="ph codeph">dxDesc</samp>. The third dimension must match the
                                 							<samp class="ph codeph">hiddenSize</samp> argument passed to the
                                 							<samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 							<samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                              </div>
                           </dd>
                           <dt class="dt dlterm">dcx </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">dcxDesc</samp>. If a NULL pointer is passed, the
                                 gradient at the cell input of the network will not be set.
                              </p>
                           </dd>
                           <dt class="dt dlterm">findIntensity</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>.This input was previously unused in versions prior to 7.2.0. It
                                 is used in cuDNN 7.2.0 and later versions to control the overall runtime of
                                 the RNN find algorithms, by selecting the percentage of a large Cartesian
                                 product space to be searched. 
                              </p>
                              <div class="p"><a name="cudnnFindRNNBackwardDataAlgorithmEx__ul_gyf_fh1_l2b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnFindRNNBackwardDataAlgorithmEx__ul_gyf_fh1_l2b">
                                    <li class="li">Setting <samp class="ph codeph">findIntensity</samp> within the range (0,1.] will
                                       set a percentage of the entire RNN search space to search. When
                                       <samp class="ph codeph">findIntensity</samp> is set to 1.0, a full search is
                                       performed over all RNN parameters. 
                                    </li>
                                    <li class="li">When <samp class="ph codeph">findIntensity</samp> is set to 0.0f, a quick, minimal
                                       search is performed. This setting has the best runtime. However, in
                                       this case the parameters returned by this function will not
                                       correspond to the best performance of the algorithm; a longer search
                                       might discover better parameters. This option will execute up to
                                       three instances of the configured RNN problem. Runtime will vary
                                       proportionally to RNN problem size, as it will in the other cases,
                                       hence no guarantee of an explicit time bound can be given. 
                                    </li>
                                    <li class="li">Setting <samp class="ph codeph">findIntensity</samp> within the range [-1.,0) sets
                                       a percentage of a reduced Cartesian product space to be searched.
                                       This reduced searched space has been heuristically selected to have
                                       good performance. The setting of -1.0 represents a full search over
                                       this reduced search space. 
                                    </li>
                                    <li class="li">Values outside the range [-1,1] are truncated to the range [-1,1],
                                       and then interpreted as per the above. 
                                    </li>
                                    <li class="li">Setting <samp class="ph codeph">findIntensity</samp> to 1.0 in cuDNN 7.2 and later
                                       versions is equivalent to the behavior of this function in versions
                                       prior to cuDNN 7.2.0. 
                                    </li>
                                    <li class="li">This function times the single RNN executions over large parameter
                                       spaces--one execution per parameter combination. The times returned
                                       by this function are latencies. 
                                    </li>
                                 </ul>
                              </div>
                           </dd>
                           <dt class="dt dlterm">requestedAlgoCount</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. The maximum number of elements to be stored in perfResults.
                              </p>
                           </dd>
                           <dt class="dt dlterm">returnedAlgoCount</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. The number of output elements stored in perfResults.
                              </p>
                           </dd>
                           <dt class="dt dlterm">perfResults</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. A user-allocated array to store performance metrics sorted ascending by compute time.
                              </p>
                           </dd>
                           <dt class="dt dlterm">workspace </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory to be used as a workspace for this
                                 call.
                              </p>
                           </dd>
                           <dt class="dt dlterm">workSpaceSizeInBytes </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                 <samp class="ph codeph">workspace</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">reserveSpace </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input/Output</em>. Data pointer to GPU memory to be used as a reserve space
                                 for this call.
                              </p>
                           </dd>
                           <dt class="dt dlterm">reserveSpaceSizeInBytes </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                 <samp class="ph codeph">reserveSpace</samp>.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The function launched successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function does not support the provided configuration.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnFindRNNBackwardDataAlgorithmEx__ul_khb_1g3_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnFindRNNBackwardDataAlgorithmEx__ul_khb_1g3_s1b">
                                 <li class="li">The descriptor <samp class="ph codeph">rnnDesc</samp> is invalid.
                                 </li>
                                 <li class="li">At least one of the descriptors <samp class="ph codeph">dhxDesc, wDesc, hxDesc, cxDesc,
                                       dcxDesc, dhyDesc, dcyDesc</samp> or one of the descriptors in
                                    <samp class="ph codeph">yDesc, dxdesc, dydesc</samp> is invalid.
                                 </li>
                                 <li class="li">The descriptors in one of <samp class="ph codeph">yDesc, dxDesc, dyDesc, dhxDesc, wDesc,
                                       hxDesc, cxDesc, dcxDesc, dhyDesc, dcyDesc</samp> has incorrect
                                    strides or dimensions.
                                 </li>
                                 <li class="li"><samp class="ph codeph">workSpaceSizeInBytes</samp> is too small.
                                 </li>
                                 <li class="li"><samp class="ph codeph">reserveSpaceSizeInBytes</samp> is too small.
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function failed to launch on the GPU.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function was unable to allocate memory.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnFindRNNBackwardWeightsAlgorithmEx"><a name="cudnnFindRNNBackwardWeightsAlgorithmEx" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnFindRNNBackwardWeightsAlgorithmEx" name="cudnnFindRNNBackwardWeightsAlgorithmEx" shape="rect">4.75.&nbsp;cudnnFindRNNBackwardWeightsAlgorithmEx</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">
cudnnStatus_t cudnnFindRNNBackwardWeightsAlgorithmEx(
    cudnnHandle_t                    handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDescriptor_t       rnnDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                        seqLength,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    *xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    hxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *hx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    *yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *y,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>                      findIntensity,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                        requestedAlgoCount,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                              *returnedAlgoCount,
    cudnnAlgorithmPerformance_t      *perfResults,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *workspace,
    size_t                           workSpaceSizeInBytes,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t    dwDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                             *dw,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *reserveSpace,
    size_t                           reserveSpaceSizeInBytes)</pre><p class="p"><strong class="ph b">(New for 7.1)</strong></p>
                        <p class="p">This function attempts all available cuDNN algorithms for
                           <samp class="ph codeph">cudnnRNNBackwardWeights</samp>, using user-allocated GPU memory. It
                           outputs the parameters that influence the performance of the algorithm to a
                           user-allocated array of <samp class="ph codeph">cudnnAlgorithmPerformance_t</samp>. These parameter
                           metrics are written in sorted fashion where the first element has the lowest compute
                           time. 
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">rnnDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A previously initialized RNN descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">seqLength </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Number of iterations to unroll over. The value of this
                                 							<samp class="ph codeph">seqLength</samp> must not exceed the value that was used in
                                 							<samp class="ph codeph">cudnnGetRNNWorkspaceSize() </samp>function for querying the
                                 						workspace size required to execute the RNN. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">xDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. An array of fully packed tensor descriptors describing the
                                 input to each recurrent iteration (one descriptor per iteration). The first
                                 dimension (batch size) of the tensors may decrease from element
                                 <samp class="ph codeph">n</samp> to element <samp class="ph codeph">n+1</samp> but may not increase.
                                 Each tensor descriptor must have the same second dimension (vector
                                 length).
                              </p>
                           </dd>
                           <dt class="dt dlterm">x </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptors in the array <samp class="ph codeph">xDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">hxDesc </dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the initial hidden
                                 state of the RNN. The first dimension of the tensor depends on the
                                 <samp class="ph codeph">direction</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnFindRNNBackwardWeightsAlgorithmEx__ul_qjf_2g3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnFindRNNBackwardWeightsAlgorithmEx__ul_qjf_2g3_s1b">
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first dimension should
                                       match the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension should
                                       match double the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                 </ul>
                                 
                                 The second dimension must match the first dimension of the tensors
                                 described in <samp class="ph codeph">xDesc</samp>. The third dimension must match the
                                 <samp class="ph codeph">hiddenSize</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                              </div>
                           </dd>
                           <dt class="dt dlterm">hx </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">hxDesc</samp>. If a NULL pointer is passed, the initial
                                 hidden state of the network will be initialized to zero.
                              </p>
                           </dd>
                           <dt class="dt dlterm">yDesc </dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. An array of fully packed tensor descriptors describing the
                                 output from each recurrent iteration (one descriptor per iteration). The
                                 second dimension of the tensor depends on the <samp class="ph codeph">direction</samp>
                                 argument passed to the <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to
                                 initialize <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnFindRNNBackwardWeightsAlgorithmEx__ul_ujf_2g3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnFindRNNBackwardWeightsAlgorithmEx__ul_ujf_2g3_s1b">
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the second dimension
                                       should match the <samp class="ph codeph">hiddenSize</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the second dimension should
                                       match double the <samp class="ph codeph">hiddenSize</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                 </ul>
                                 
                                 The first dimension of the tensor <samp class="ph codeph">n</samp> must match the
                                 first dimension of the tensor <samp class="ph codeph">n</samp> in
                                 <samp class="ph codeph">dyDesc</samp>.
                              </div>
                           </dd>
                           <dt class="dt dlterm">y </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the output tensor
                                 descriptor <samp class="ph codeph">yDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">findIntensity</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>.This input was previously unused in versions prior to 7.2.0. It
                                 is used in cuDNN 7.2.0 and later versions to control the overall runtime of
                                 the RNN find algorithms, by selecting the percentage of a large Cartesian
                                 product space to be searched. 
                              </p>
                              <div class="p"><a name="cudnnFindRNNBackwardWeightsAlgorithmEx__ul_gyf_fh1_l2b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnFindRNNBackwardWeightsAlgorithmEx__ul_gyf_fh1_l2b">
                                    <li class="li">Setting <samp class="ph codeph">findIntensity</samp> within the range (0,1.] will
                                       set a percentage of the entire RNN search space to search. When
                                       <samp class="ph codeph">findIntensity</samp> is set to 1.0, a full search is
                                       performed over all RNN parameters. 
                                    </li>
                                    <li class="li">When <samp class="ph codeph">findIntensity</samp> is set to 0.0f, a quick, minimal
                                       search is performed. This setting has the best runtime. However, in
                                       this case the parameters returned by this function will not
                                       correspond to the best performance of the algorithm; a longer search
                                       might discover better parameters. This option will execute up to
                                       three instances of the configured RNN problem. Runtime will vary
                                       proportionally to RNN problem size, as it will in the other cases,
                                       hence no guarantee of an explicit time bound can be given. 
                                    </li>
                                    <li class="li">Setting <samp class="ph codeph">findIntensity</samp> within the range [-1.,0) sets
                                       a percentage of a reduced Cartesian product space to be searched.
                                       This reduced searched space has been heuristically selected to have
                                       good performance. The setting of -1.0 represents a full search over
                                       this reduced search space. 
                                    </li>
                                    <li class="li">Values outside the range [-1,1] are truncated to the range [-1,1],
                                       and then interpreted as per the above. 
                                    </li>
                                    <li class="li">Setting <samp class="ph codeph">findIntensity</samp> to 1.0 in cuDNN 7.2 and later
                                       versions is equivalent to the behavior of this function in versions
                                       prior to cuDNN 7.2.0. 
                                    </li>
                                    <li class="li">This function times the single RNN executions over large parameter
                                       spaces--one execution per parameter combination. The times returned
                                       by this function are latencies. 
                                    </li>
                                 </ul>
                              </div>
                           </dd>
                           <dt class="dt dlterm">requestedAlgoCount</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. The maximum number of elements to be stored in perfResults.
                              </p>
                           </dd>
                           <dt class="dt dlterm">returnedAlgoCount</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. The number of output elements stored in perfResults.
                              </p>
                           </dd>
                           <dt class="dt dlterm">perfResults</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. A user-allocated array to store performance metrics sorted ascending by compute time.
                              </p>
                           </dd>
                           <dt class="dt dlterm">workspace </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory to be used as a workspace for this
                                 call.
                              </p>
                           </dd>
                           <dt class="dt dlterm">workSpaceSizeInBytes </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                 <samp class="ph codeph">workspace</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dwDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor describing
                                 the gradients of the weights for the RNN.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dw </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input/Output</em>. Data pointer to GPU memory associated with the filter
                                 descriptor <samp class="ph codeph">dwDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">reserveSpace </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory to be used as a reserve space for
                                 this call.
                              </p>
                           </dd>
                           <dt class="dt dlterm">reserveSpaceSizeInBytes </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                 <samp class="ph codeph">reserveSpace</samp></p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The function launched successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function does not support the provided configuration.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnFindRNNBackwardWeightsAlgorithmEx__ul_yjf_2g3_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnFindRNNBackwardWeightsAlgorithmEx__ul_yjf_2g3_s1b">
                                 <li class="li">The descriptor <samp class="ph codeph">rnnDesc</samp> is invalid.
                                 </li>
                                 <li class="li">At least one of the descriptors <samp class="ph codeph">hxDesc, dwDesc</samp> or one
                                    of the descriptors in <samp class="ph codeph">xDesc, yDesc</samp> is invalid.
                                 </li>
                                 <li class="li">The descriptors in one of <samp class="ph codeph">xDesc, hxDesc, yDesc, dwDesc</samp>
                                    has incorrect strides or dimensions.
                                 </li>
                                 <li class="li"><samp class="ph codeph">workSpaceSizeInBytes</samp> is too small.
                                 </li>
                                 <li class="li"><samp class="ph codeph">reserveSpaceSizeInBytes</samp> is too small.
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function failed to launch on the GPU.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function was unable to allocate memory.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnFindRNNForwardInferenceAlgorithmEx"><a name="cudnnFindRNNForwardInferenceAlgorithmEx" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnFindRNNForwardInferenceAlgorithmEx" name="cudnnFindRNNForwardInferenceAlgorithmEx" shape="rect">4.76.&nbsp;cudnnFindRNNForwardInferenceAlgorithmEx</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">
cudnnStatus_t cudnnFindRNNForwardInferenceAlgorithmEx(
    cudnnHandle_t                   handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDescriptor_t      rnnDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                       seqLength,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t  *xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   hxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *hx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   cxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *cx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t   wDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *w,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   *yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *y,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   hyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *hy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   cyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *cy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>                    findIntensity,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                      requestedAlgoCount,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                            *returnedAlgoCount,
    cudnnAlgorithmPerformance_t    *perfResults,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *workspace,
    size_t                          workSpaceSizeInBytes)</pre><p class="p"><strong class="ph b">(New for 7.1)</strong></p>
                        <p class="p">This function attempts all available cuDNN algorithms for
                           <samp class="ph codeph">cudnnRNNForwardInference</samp>, using user-allocated GPU memory. It
                           outputs the parameters that influence the performance of the algorithm to a
                           user-allocated array of <samp class="ph codeph">cudnnAlgorithmPerformance_t</samp>. These parameter
                           metrics are written in sorted fashion where the first element has the lowest compute
                           time. 
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">rnnDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A previously initialized RNN descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">seqLength </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Number of iterations to unroll over. The value of this
                                 							<samp class="ph codeph">seqLength</samp> must not exceed the value that was used in
                                 							<samp class="ph codeph">cudnnGetRNNWorkspaceSize() </samp>function for querying the
                                 						workspace size required to execute the RNN. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">xDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. An array of fully packed tensor descriptors describing the
                                 input to each recurrent iteration (one descriptor per iteration). The first
                                 dimension (batch size) of the tensors may decrease from element
                                 <samp class="ph codeph">n</samp> to element <samp class="ph codeph">n+1</samp> but may not increase.
                                 Each tensor descriptor must have the same second dimension (vector
                                 length).
                              </p>
                           </dd>
                           <dt class="dt dlterm">x </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptors in the array <samp class="ph codeph">xDesc</samp>. The data are expected to be
                                 packed contiguously with the first element of iteration n+1 following
                                 directly from the last element of iteration n.
                              </p>
                           </dd>
                           <dt class="dt dlterm">hxDesc </dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the initial hidden
                                 state of the RNN. The first dimension of the tensor depends on the
                                 <samp class="ph codeph">direction</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnFindRNNForwardInferenceAlgorithmEx__ul_bsf_sf3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnFindRNNForwardInferenceAlgorithmEx__ul_bsf_sf3_s1b">
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first dimension should
                                       match the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension should
                                       match double the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                 </ul>
                                 
                                 The second dimension must match the first dimension of the tensors
                                 described in <samp class="ph codeph">xDesc</samp>. The third dimension must match the
                                 <samp class="ph codeph">hiddenSize</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                              </div>
                           </dd>
                           <dt class="dt dlterm">hx </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">hxDesc</samp>. If a NULL pointer is passed, the initial
                                 hidden state of the network will be initialized to zero.
                              </p>
                           </dd>
                           <dt class="dt dlterm">cxDesc </dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the initial cell
                                 state for LSTM networks. The first dimension of the tensor depends on the
                                 <samp class="ph codeph">direction</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnFindRNNForwardInferenceAlgorithmEx__ul_dsf_sf3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnFindRNNForwardInferenceAlgorithmEx__ul_dsf_sf3_s1b">
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first dimension should
                                       match the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension should
                                       match double the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                 </ul>
                                 
                                 The second dimension must match the first dimension of the tensors
                                 described in <samp class="ph codeph">xDesc</samp>. The third dimension must match the
                                 <samp class="ph codeph">hiddenSize</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                              </div>
                           </dd>
                           <dt class="dt dlterm">cx </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">cxDesc</samp>. If a NULL pointer is passed, the initial
                                 cell state of the network will be initialized to zero.
                              </p>
                           </dd>
                           <dt class="dt dlterm">wDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor describing
                                 the weights for the RNN.
                              </p>
                           </dd>
                           <dt class="dt dlterm">w </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the filter
                                 descriptor <samp class="ph codeph">wDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">yDesc </dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. An array of fully packed tensor descriptors describing the
                                 output from each recurrent iteration (one descriptor per iteration). The
                                 second dimension of the tensor depends on the <samp class="ph codeph">direction</samp>
                                 argument passed to the <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to
                                 initialize <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnFindRNNForwardInferenceAlgorithmEx__ul_fsf_sf3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnFindRNNForwardInferenceAlgorithmEx__ul_fsf_sf3_s1b">
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the second dimension
                                       should match the <samp class="ph codeph">hiddenSize</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the second dimension should
                                       match double the <samp class="ph codeph">hiddenSize</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                 </ul>
                                 
                                 The first dimension of the tensor <samp class="ph codeph">n</samp> must match the
                                 first dimension of the tensor <samp class="ph codeph">n</samp> in
                                 <samp class="ph codeph">xDesc</samp>.
                              </div>
                           </dd>
                           <dt class="dt dlterm">y </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the output tensor
                                 descriptor <samp class="ph codeph">yDesc</samp>. The data are expected to be packed
                                 contiguously with the first element of iteration n+1 following directly from
                                 the last element of iteration n.
                              </p>
                           </dd>
                           <dt class="dt dlterm">hyDesc </dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the final hidden
                                 state of the RNN. The first dimension of the tensor depends on the
                                 <samp class="ph codeph">direction</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnFindRNNForwardInferenceAlgorithmEx__ul_gsf_sf3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnFindRNNForwardInferenceAlgorithmEx__ul_gsf_sf3_s1b">
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first dimension should
                                       match the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension should
                                       match double the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                 </ul>
                                 
                                 The second dimension must match the first dimension of the tensors
                                 described in <samp class="ph codeph">xDesc</samp>. The third dimension must match the
                                 <samp class="ph codeph">hiddenSize</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                              </div>
                           </dd>
                           <dt class="dt dlterm">hy </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">hyDesc</samp>. If a NULL pointer is passed, the final
                                 hidden state of the network will not be saved.
                              </p>
                           </dd>
                           <dt class="dt dlterm">cyDesc </dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the final cell
                                 state for LSTM networks. The first dimension of the tensor depends on the
                                 <samp class="ph codeph">direction</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnFindRNNForwardInferenceAlgorithmEx__ul_isf_sf3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnFindRNNForwardInferenceAlgorithmEx__ul_isf_sf3_s1b">
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first dimension should
                                       match the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension should
                                       match double the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                 </ul>
                                 
                                 The second dimension must match the first dimension of the tensors
                                 described in <samp class="ph codeph">xDesc</samp>. The third dimension must match the
                                 <samp class="ph codeph">hiddenSize</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                              </div>
                           </dd>
                           <dt class="dt dlterm">cy </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">cyDesc</samp>. If a NULL pointer is passed, the final
                                 cell state of the network will be not be saved.
                              </p>
                           </dd>
                           <dt class="dt dlterm">findIntensity</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>.This input was previously unused in versions prior to 7.2.0. It
                                 is used in cuDNN 7.2.0 and later versions to control the overall runtime of
                                 the RNN find algorithms, by selecting the percentage of a large Cartesian
                                 product space to be searched. 
                              </p>
                              <div class="p"><a name="cudnnFindRNNForwardInferenceAlgorithmEx__ul_gyf_fh1_l2b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnFindRNNForwardInferenceAlgorithmEx__ul_gyf_fh1_l2b">
                                    <li class="li">Setting <samp class="ph codeph">findIntensity</samp> within the range (0,1.] will
                                       set a percentage of the entire RNN search space to search. When
                                       <samp class="ph codeph">findIntensity</samp> is set to 1.0, a full search is
                                       performed over all RNN parameters. 
                                    </li>
                                    <li class="li">When <samp class="ph codeph">findIntensity</samp> is set to 0.0f, a quick, minimal
                                       search is performed. This setting has the best runtime. However, in
                                       this case the parameters returned by this function will not
                                       correspond to the best performance of the algorithm; a longer search
                                       might discover better parameters. This option will execute up to
                                       three instances of the configured RNN problem. Runtime will vary
                                       proportionally to RNN problem size, as it will in the other cases,
                                       hence no guarantee of an explicit time bound can be given. 
                                    </li>
                                    <li class="li">Setting <samp class="ph codeph">findIntensity</samp> within the range [-1.,0) sets
                                       a percentage of a reduced Cartesian product space to be searched.
                                       This reduced searched space has been heuristically selected to have
                                       good performance. The setting of -1.0 represents a full search over
                                       this reduced search space. 
                                    </li>
                                    <li class="li">Values outside the range [-1,1] are truncated to the range [-1,1],
                                       and then interpreted as per the above. 
                                    </li>
                                    <li class="li">Setting <samp class="ph codeph">findIntensity</samp> to 1.0 in cuDNN 7.2 and later
                                       versions is equivalent to the behavior of this function in versions
                                       prior to cuDNN 7.2.0. 
                                    </li>
                                    <li class="li">This function times the single RNN executions over large parameter
                                       spaces--one execution per parameter combination. The times returned
                                       by this function are latencies. 
                                    </li>
                                 </ul>
                              </div>
                           </dd>
                           <dt class="dt dlterm">requestedAlgoCount</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. The maximum number of elements to be stored in perfResults.
                              </p>
                           </dd>
                           <dt class="dt dlterm">returnedAlgoCount</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. The number of output elements stored in perfResults.
                              </p>
                           </dd>
                           <dt class="dt dlterm">perfResults</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. A user-allocated array to store performance metrics sorted ascending by compute time.
                              </p>
                           </dd>
                           <dt class="dt dlterm">workspace </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory to be used as a workspace for this
                                 call.
                              </p>
                           </dd>
                           <dt class="dt dlterm">workSpaceSizeInBytes </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                 <samp class="ph codeph">workspace</samp>.
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The function launched successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function does not support the provided configuration.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnFindRNNForwardInferenceAlgorithmEx__ul_ksf_sf3_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnFindRNNForwardInferenceAlgorithmEx__ul_ksf_sf3_s1b">
                                 <li class="li">The descriptor <samp class="ph codeph">rnnDesc</samp> is invalid.
                                 </li>
                                 <li class="li">At least one of the descriptors <samp class="ph codeph">hxDesc, cxDesc, wDesc, hyDesc,
                                       cyDesc</samp> or one of the descriptors in <samp class="ph codeph">xDesc,
                                       yDesc</samp> is invalid.
                                 </li>
                                 <li class="li">The descriptors in one of <samp class="ph codeph">xDesc, hxDesc, cxDesc, wDesc, yDesc,
                                       hyDesc, cyDesc</samp> have incorrect strides or dimensions.
                                 </li>
                                 <li class="li"><samp class="ph codeph">workSpaceSizeInBytes</samp> is too small.
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function failed to launch on the GPU.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function was unable to allocate memory.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnFindRNNForwardTrainingAlgorithmEx"><a name="cudnnFindRNNForwardTrainingAlgorithmEx" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnFindRNNForwardTrainingAlgorithmEx" name="cudnnFindRNNForwardTrainingAlgorithmEx" shape="rect">4.77.&nbsp;cudnnFindRNNForwardTrainingAlgorithmEx</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnFindRNNForwardTrainingAlgorithmEx(
    cudnnHandle_t                   handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDescriptor_t      rnnDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                       seqLength,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t  *xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   hxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *hx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   cxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *cx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t   wDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *w,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t  *yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *y,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   hyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *hy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   cyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *cy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>                    findIntensity,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                      requestedAlgoCount,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                            *returnedAlgoCount,
    cudnnAlgorithmPerformance_t    *perfResults,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *workspace,
    size_t                          workSpaceSizeInBytes,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *reserveSpace,
    size_t                          reserveSpaceSizeInBytes)</pre><p class="p"><strong class="ph b">(New for 7.1)</strong></p>
                        <p class="p">This function attempts all available cuDNN algorithms for
                           <samp class="ph codeph">cudnnRNNForwardTraining</samp>, using user-allocated GPU memory.  It
                           outputs the parameters that influence the performance of the algorithm to a
                           user-allocated array of <samp class="ph codeph">cudnnAlgorithmPerformance_t</samp>. These parameter
                           metrics are written in sorted fashion where the first element has the lowest compute
                           time. 
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">rnnDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A previously initialized RNN descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">xDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. An array of fully packed tensor descriptors describing the
                                 input to each recurrent iteration (one descriptor per iteration). The first
                                 dimension (batch size) of the tensors may decrease from element
                                 <samp class="ph codeph">n</samp> to element <samp class="ph codeph">n+1</samp> but may not increase.
                                 Each tensor descriptor must have the same second dimension (vector
                                 length).
                              </p>
                           </dd>
                           <dt class="dt dlterm">seqLength </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Number of iterations to unroll over. The value of this
                                 							<samp class="ph codeph">seqLength</samp> must not exceed the value that was used in
                                 							<samp class="ph codeph">cudnnGetRNNWorkspaceSize() </samp>function for querying the
                                 						workspace size required to execute the RNN. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">x </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptors in the array <samp class="ph codeph">xDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">hxDesc </dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the initial hidden
                                 state of the RNN. The first dimension of the tensor depends on the
                                 <samp class="ph codeph">direction</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnFindRNNForwardTrainingAlgorithmEx__ul_hqb_wf3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnFindRNNForwardTrainingAlgorithmEx__ul_hqb_wf3_s1b">
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first dimension should
                                       match the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension should
                                       match double the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                 </ul>
                                 
                                 The second dimension must match the first dimension of the tensors
                                 described in <samp class="ph codeph">xDesc</samp>. The third dimension must match the
                                 <samp class="ph codeph">hiddenSize</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                              </div>
                           </dd>
                           <dt class="dt dlterm">hx </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">hxDesc</samp>. If a NULL pointer is passed, the initial
                                 hidden state of the network will be initialized to zero.
                              </p>
                           </dd>
                           <dt class="dt dlterm">cxDesc </dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the initial cell
                                 state for LSTM networks. The first dimension of the tensor depends on the
                                 <samp class="ph codeph">direction</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnFindRNNForwardTrainingAlgorithmEx__ul_kqb_wf3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnFindRNNForwardTrainingAlgorithmEx__ul_kqb_wf3_s1b">
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first dimension should
                                       match the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension should
                                       match double the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                 </ul>
                                 
                                 The second dimension must match the first dimension of the tensors
                                 described in <samp class="ph codeph">xDesc</samp>. The third dimension must match the
                                 <samp class="ph codeph">hiddenSize</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                              </div>
                           </dd>
                           <dt class="dt dlterm">cx </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">cxDesc</samp>. If a NULL pointer is passed, the initial
                                 cell state of the network will be initialized to zero.
                              </p>
                           </dd>
                           <dt class="dt dlterm">wDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor describing
                                 the weights for the RNN.
                              </p>
                           </dd>
                           <dt class="dt dlterm">w </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the filter
                                 descriptor <samp class="ph codeph">wDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">yDesc </dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. An array of fully packed tensor descriptors describing the
                                 output from each recurrent iteration (one descriptor per iteration). The
                                 second dimension of the tensor depends on the <samp class="ph codeph">direction</samp>
                                 argument passed to the <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to
                                 initialize <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnFindRNNForwardTrainingAlgorithmEx__ul_mqb_wf3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnFindRNNForwardTrainingAlgorithmEx__ul_mqb_wf3_s1b">
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the second dimension
                                       should match the <samp class="ph codeph">hiddenSize</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the second dimension should
                                       match double the <samp class="ph codeph">hiddenSize</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                 </ul>
                                 
                                 The first dimension of the tensor <samp class="ph codeph">n</samp> must match the
                                 first dimension of the tensor <samp class="ph codeph">n</samp> in
                                 <samp class="ph codeph">xDesc</samp>.
                              </div>
                           </dd>
                           <dt class="dt dlterm">y </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the output tensor
                                 descriptor <samp class="ph codeph">yDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">hyDesc </dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the final hidden
                                 state of the RNN. The first dimension of the tensor depends on the
                                 <samp class="ph codeph">direction</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnFindRNNForwardTrainingAlgorithmEx__ul_oqb_wf3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnFindRNNForwardTrainingAlgorithmEx__ul_oqb_wf3_s1b">
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first dimension should
                                       match the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension should
                                       match double the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                 </ul>
                                 
                                 The second dimension must match the first dimension of the tensors
                                 described in <samp class="ph codeph">xDesc</samp>. The third dimension must match the
                                 <samp class="ph codeph">hiddenSize</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                              </div>
                           </dd>
                           <dt class="dt dlterm">hy </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">hyDesc</samp>. If a NULL pointer is passed, the final
                                 hidden state of the network will not be saved.
                              </p>
                           </dd>
                           <dt class="dt dlterm">cyDesc </dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the final cell
                                 state for LSTM networks. The first dimension of the tensor depends on the
                                 <samp class="ph codeph">direction</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnFindRNNForwardTrainingAlgorithmEx__ul_qqb_wf3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnFindRNNForwardTrainingAlgorithmEx__ul_qqb_wf3_s1b">
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first dimension should
                                       match the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension should
                                       match double the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                 </ul>
                                 
                                 The second dimension must match the first dimension of the tensors
                                 described in <samp class="ph codeph">xDesc</samp>. The third dimension must match the
                                 <samp class="ph codeph">hiddenSize</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                              </div>
                           </dd>
                           <dt class="dt dlterm">cy </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">cyDesc</samp>. If a NULL pointer is passed, the final
                                 cell state of the network will be not be saved.
                              </p>
                           </dd>
                           <dt class="dt dlterm">findIntensity</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>.This input was previously unused in versions prior to 7.2.0. It
                                 is used in cuDNN 7.2.0 and later versions to control the overall runtime of
                                 the RNN find algorithms, by selecting the percentage of a large Cartesian
                                 product space to be searched. 
                              </p>
                              <div class="p"><a name="cudnnFindRNNForwardTrainingAlgorithmEx__ul_gyf_fh1_l2b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnFindRNNForwardTrainingAlgorithmEx__ul_gyf_fh1_l2b">
                                    <li class="li">Setting <samp class="ph codeph">findIntensity</samp> within the range (0,1.] will
                                       set a percentage of the entire RNN search space to search. When
                                       <samp class="ph codeph">findIntensity</samp> is set to 1.0, a full search is
                                       performed over all RNN parameters. 
                                    </li>
                                    <li class="li">When <samp class="ph codeph">findIntensity</samp> is set to 0.0f, a quick, minimal
                                       search is performed. This setting has the best runtime. However, in
                                       this case the parameters returned by this function will not
                                       correspond to the best performance of the algorithm; a longer search
                                       might discover better parameters. This option will execute up to
                                       three instances of the configured RNN problem. Runtime will vary
                                       proportionally to RNN problem size, as it will in the other cases,
                                       hence no guarantee of an explicit time bound can be given. 
                                    </li>
                                    <li class="li">Setting <samp class="ph codeph">findIntensity</samp> within the range [-1.,0) sets
                                       a percentage of a reduced Cartesian product space to be searched.
                                       This reduced searched space has been heuristically selected to have
                                       good performance. The setting of -1.0 represents a full search over
                                       this reduced search space. 
                                    </li>
                                    <li class="li">Values outside the range [-1,1] are truncated to the range [-1,1],
                                       and then interpreted as per the above. 
                                    </li>
                                    <li class="li">Setting <samp class="ph codeph">findIntensity</samp> to 1.0 in cuDNN 7.2 and later
                                       versions is equivalent to the behavior of this function in versions
                                       prior to cuDNN 7.2.0. 
                                    </li>
                                    <li class="li">This function times the single RNN executions over large parameter
                                       spaces--one execution per parameter combination. The times returned
                                       by this function are latencies. 
                                    </li>
                                 </ul>
                              </div>
                           </dd>
                           <dt class="dt dlterm">requestedAlgoCount</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. The maximum number of elements to be stored in perfResults.
                              </p>
                           </dd>
                           <dt class="dt dlterm">returnedAlgoCount</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. The number of output elements stored in perfResults.
                              </p>
                           </dd>
                           <dt class="dt dlterm">perfResults</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. A user-allocated array to store performance metrics sorted ascending by compute time.
                              </p>
                           </dd>
                           <dt class="dt dlterm">workspace </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory to be used as a workspace for this
                                 call.
                              </p>
                           </dd>
                           <dt class="dt dlterm">workSpaceSizeInBytes </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                 <samp class="ph codeph">workspace</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">reserveSpace </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input/Output</em>. Data pointer to GPU memory to be used as a reserve space
                                 for this call.
                              </p>
                           </dd>
                           <dt class="dt dlterm">reserveSpaceSizeInBytes </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                 <samp class="ph codeph">reserveSpace</samp></p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The function launched successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnFindRNNForwardTrainingAlgorithmEx__ul_rqb_wf3_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnFindRNNForwardTrainingAlgorithmEx__ul_rqb_wf3_s1b">
                                 <li class="li">The descriptor <samp class="ph codeph">rnnDesc</samp> is invalid.
                                 </li>
                                 <li class="li">At least one of the descriptors <samp class="ph codeph">hxDesc, cxDesc, wDesc, hyDesc,
                                       cyDesc</samp> or one of the descriptors in <samp class="ph codeph">xDesc,
                                       yDesc</samp> is invalid.
                                 </li>
                                 <li class="li">The descriptors in one of <samp class="ph codeph">xDesc, hxDesc, cxDesc, wDesc, yDesc,
                                       hyDesc, cyDesc</samp> have incorrect strides or dimensions.
                                 </li>
                                 <li class="li"><samp class="ph codeph">workSpaceSizeInBytes</samp> is too small.
                                 </li>
                                 <li class="li"><samp class="ph codeph">reserveSpaceSizeInBytes</samp> is too small.
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function failed to launch on the GPU.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function was unable to allocate memory.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnFusedOpsExecute"><a name="cudnnFusedOpsExecute" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnFusedOpsExecute" name="cudnnFusedOpsExecute" shape="rect">4.78.&nbsp;cudnnFusedOpsExecute</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnFusedOpsExecute(
	cudnnHandle_t handle, 
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFusedOpsPlan_t plan, 
	cudnnFusedOpsVariantParamPack_t varPack);		</pre><p class="p">This function executes the sequence of cudnnFusedOps operations. </p>
                        <p class="p"><strong class="ph b">Parameters:</strong></p>
                        <div class="tablenoborder"><a name="cudnnFusedOpsExecute__table_hpj_hcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnFusedOpsExecute__table_hpj_hcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1"><strong class="ph b">Parameter</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1"><strong class="ph b">Input / Output</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">handle</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Pointer to the cuDNN library context. </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">plan</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Pointer to a previously-created and initialized plan descriptor.
                                       						
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">varPack</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Pointer to the descriptor to the variant parameters pack.
                                       						
                                    </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                        <p class="p"><strong class="ph b">Returns:</strong></p>
                        <div class="tablenoborder"><a name="cudnnFusedOpsExecute__table_usk_kcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnFusedOpsExecute__table_usk_kcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Return Value</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_BAD_PARAM</td>
                                    <td class="entry" valign="top" width="50%" rowspan="1" colspan="1">If the type of <samp class="ph codeph">cudnnFusedOps_t</samp> in the plan descriptor is
                                       							unsupported.
                                    </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetActivationDescriptor"><a name="cudnnGetActivationDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetActivationDescriptor" name="cudnnGetActivationDescriptor" shape="rect">4.79.&nbsp;cudnnGetActivationDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetActivationDescriptor(
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnActivationDescriptor_t   activationDesc,
        cudnnActivationMode_t              *mode,
        cudnnNanPropagation_t              *reluNanOpt,
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>                             *coef)</pre><p class="p">This function queries a previously initialized generic activation descriptor object. </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">activationDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created activation descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">mode </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Enumerant to specify the activation mode.
                              </p>
                           </dd>
                           <dt class="dt dlterm">reluNanOpt </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Enumerant to specify the <samp class="ph codeph">Nan</samp> propagation
                                 mode.
                              </p>
                           </dd>
                           <dt class="dt dlterm">coef </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Floating point number to specify the clipping threashod when
                                 the activation mode is set to <samp class="ph codeph">CUDNN_ACTIVATION_CLIPPED_RELU</samp>
                                 or to specify the alpha coefficient when the activation mode is set to
                                 <samp class="ph codeph">CUDNN_ACTIVATION_ELU</samp>. 
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was queried successfully.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetAlgorithmDescriptor"><a name="cudnnGetAlgorithmDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetAlgorithmDescriptor" name="cudnnGetAlgorithmDescriptor" shape="rect">4.80.&nbsp;cudnnGetAlgorithmDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetAlgorithmDescriptor(        
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnAlgorithmDescriptor_t    algoDesc,
        cudnnAlgorithm_t                    *algorithm)</pre><p class="p"><strong class="ph b">(New for 7.1)</strong></p>
                        <p class="p">This function queries a previously initialized generic algorithm descriptor object.</p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">algorithmDesc</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created algorithm descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">algorithm</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Struct to specify the algorithm.
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was queried successfully.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetAlgorithmPerformance"><a name="cudnnGetAlgorithmPerformance" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetAlgorithmPerformance" name="cudnnGetAlgorithmPerformance" shape="rect">4.81.&nbsp;cudnnGetAlgorithmPerformance</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetAlgorithmPerformance(
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnAlgorithmPerformance_t   algoPerf,
        cudnnAlgorithmDescriptor_t*         algoDesc,
        cudnnStatus_t*                      status,
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>*                              time,
        size_t*                             memory)</pre><p class="p"><strong class="ph b">(New for 7.1)</strong></p>
                        <p class="p">This function queries a previously initialized generic algorithm performance object.</p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">algoPerf</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input/Output</em>. Handle to a previously created algorithm performance object.
                              </p>
                           </dd>
                           <dt class="dt dlterm">algoDesc</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. The algorithm descriptor which the performance results describe.
                              </p>
                           </dd>
                           <dt class="dt dlterm">status</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. The cudnn status returned from running the algoDesc algorithm.
                              </p>
                           </dd>
                           <dt class="dt dlterm">timecoef</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. The GPU time spent running the algoDesc algorithm.
                              </p>
                           </dd>
                           <dt class="dt dlterm">memory</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. The GPU memory needed to run the algoDesc algorithm.
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was queried successfully.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetAlgorithmSpaceSize"><a name="cudnnGetAlgorithmSpaceSize" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetAlgorithmSpaceSize" name="cudnnGetAlgorithmSpaceSize" shape="rect">4.82.&nbsp;cudnnGetAlgorithmSpaceSize</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetAlgorithmSpaceSize(    
    cudnnHandle_t               handle,
    cudnnAlgorithmDescriptor_t  algoDesc,
    size_t*                     algoSpaceSizeInBytes)</pre><p class="p"><strong class="ph b">(New for 7.1)</strong></p>
                        <p class="p">This function queries for the amount of host memory needed to call <samp class="ph codeph">cudnnSaveAlgorithm</samp>, much like the “get workspace size” functions query for the amount of device memory needed.
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">algoDesc</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A previously created algorithm descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">algoSpaceSizeInBytes</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Ouptut</em>. Amount of host memory needed as workspace to be able to save the metadata from the specified <samp class="ph codeph">algoDesc</samp>.
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The function launched successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the arguments is null.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetAttnDescriptor"><a name="cudnnGetAttnDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetAttnDescriptor" name="cudnnGetAttnDescriptor" shape="rect">4.83.&nbsp;cudnnGetAttnDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetAttnDescriptor(
	cudnnAttnDescriptor_t attnDesc,
	cudnnAttnQueryMap_t *queryMap,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *nHeads,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span> *smScaler,
	cudnnDataType_t *dataType,
	cudnnDataType_t *computePrec,
	cudnnMathType_t *mathType,
	cudnnDropoutDescriptor_t *attnDropoutDesc,
	cudnnDropoutDescriptor_t *postDropoutDesc,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *qSize,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *kSize,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *vSize,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *qProjSize,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *kProjSize,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *vProjSize,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *oProjSize,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *qoMaxSeqLength,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *kvMaxSeqLength,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *maxBatchSize,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *maxBeamSize);</pre><p dir="ltr" class="p" id="cudnnGetAttnDescriptor__docs-internal-guid-4093296c-7fff-aebd-dfd2-2dba9fa310b0"><a name="cudnnGetAttnDescriptor__docs-internal-guid-4093296c-7fff-aebd-dfd2-2dba9fa310b0" shape="rect">
                              <!-- --></a>This function
                           			retrieves the values from a previously initialized attention descriptor.
                        </p>
                        <p class="p"><strong class="ph b">Parameters:</strong></p>
                        <div class="tablenoborder"><a name="cudnnGetAttnDescriptor__table_hpj_hcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnGetAttnDescriptor__table_hpj_hcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1"><strong class="ph b">Parameter</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1"><strong class="ph b">Input / Output</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">attnDesc</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Attention descriptor whose values are to be retrieved. </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">queryMap</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Query mapping mode.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">nHeads</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Number of attention heads.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">smScaler</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Softmax smoothing, or sharpening, coefficient.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">dataType</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Data type for Q,K,V inputs, weights, and the output.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">computePrec</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Compute data type (precision).</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">mathType</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">The Tensor Core Operations settings.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">attnDropoutDesc</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Dropout descriptor for the dropout at the attention
                                       							layer.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">postDropoutDesc</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Dropout descriptor for the dropout at the output.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">qSize, kSize, vSize</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Hidden size of Q, K, and V input sequence data.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">qProjSize, kProjSize, vProjSize</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Hidden size of projected Q, K and V sequence data; 0 if no
                                       							projection.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">oProjSize</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Output projection size.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">qoMaxSeqLength</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Largest sequence length allowed in sequence data Q and O.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">kvMaxSeqLength</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Largest sequence length allowed in sequence data K and V.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">maxBatchSize</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Largest batch size allowed in sequence data.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">maxBeamSize</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Largest beam size allowed in sequence data.</td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                        <p class="p"><strong class="ph b">Returns:</strong></p>
                        <div class="tablenoborder"><a name="cudnnGetAttnDescriptor__table_usk_kcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnGetAttnDescriptor__table_usk_kcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Return Value</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_BAD_PARAM </td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><samp class="ph codeph">attDesc</samp> is a NULL pointer.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_SUCCESS </td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">The attention descriptor structure values are retrieved
                                       							successfully.
                                    </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnBatchNormalizationBackwardExWorkspaceSize"><a name="cudnnBatchNormalizationBackwardExWorkspaceSize" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnBatchNormalizationBackwardExWorkspaceSize" name="cudnnBatchNormalizationBackwardExWorkspaceSize" shape="rect">cudnnBatchNormalizationBackwardExWorkspaceSize</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetBatchNormalizationBackwardExWorkspaceSize(
    cudnnHandle_t                       handle,
    cudnnBatchNormMode_t                mode,
    cudnnBatchNormOps_t                 bnOps,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       yDesc, 
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       dyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       dzDesc, 
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       dxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       dBnScaleBiasDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnActivationDescriptor_t   activationDesc, 
    size_t                              *sizeInBytes);
</pre><p class="p">This function returns the amount of GPU memory workspace the user should allocate to be
                           able to call <a class="xref" href="index.html#cudnnBatchNormalizationBackwardEx" shape="rect">cudnnGetBatchNormalizationBackwardEx()</a> function for the specified
                           <samp class="ph codeph">bnOps</samp> input setting. The workspace allocated will then be passed to
                           the function <samp class="ph codeph">cudnnGetBatchNormalizationBackwardEx()</samp>. 
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN library descriptor. See
                                 <a class="xref" href="index.html#cudnnHandle_t" shape="rect">cudnnHandle_t.</a></p>
                           </dd>
                           <dt class="dt dlterm">mode</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Mode of operation (spatial or per-activation). See <a class="xref" href="index.html#datatypes-reference" shape="rect">cudnnBatchNormMode_t.</a></p>
                           </dd>
                           <dt class="dt dlterm">bnOps</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Mode of operation for the fast NHWC kernel. See <a class="xref" href="index.html#datatypes-reference" shape="rect">cudnnBatchNormOps_t.</a>  This input can be used to set this
                                 function to perform either only the batch normalization, or batch
                                 normalization followed by activation, or batch normalization followed by
                                 element-wise addition and then activation. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">xDesc, yDesc, dyDesc, dzDesc, dxDesc </dt>
                           <dd class="dd">
                              <p class="p">Tensor descriptors and pointers in the device memory for the layer's
                                 <samp class="ph codeph">x</samp> data, back propagated differential
                                 <samp class="ph codeph">dy</samp> (inputs), the optional <samp class="ph codeph">y</samp> input
                                 data, the optional <samp class="ph codeph">dz </samp>output, and the <samp class="ph codeph">dx
                                    </samp>output, which is the resulting differential with respect to
                                 <samp class="ph codeph">x</samp>.  See <a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t.</a></p>
                           </dd>
                           <dt class="dt dlterm">dBnScaleBiasDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Shared tensor descriptor for the following six tensors:
                                 <samp class="ph codeph">bnScaleData, bnBiasData, dBnScaleData, dBnBiasData, savedMean,
                                    and savedInvVariance.</samp> This is the shared tensor descriptor desc
                                 for the secondary tensor that was derived by <a class="xref" href="index.html#cudnnDeriveBNTensorDescriptor" shape="rect">cudnnDeriveBNTensorDescriptor()</a>. The dimensions for this tensor
                                 descriptor are dependent on normalization mode. Note: The data type of this
                                 tensor descriptor must be 'float' for FP16 and FP32 input tensors, and
                                 'double' for FP64 input tensors. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">activationDesc</dt>
                           <dd class="dd"><em class="ph i">Input</em>. Tensor descriptor for the activation operation. 
                           </dd>
                           <dt class="dt dlterm">*sizeInBytes </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Amount of GPU memory required for the workspace, as determined
                                 by this function, to be able to execute the
                                 <samp class="ph codeph">cudnnGetBatchNormalizationBackwardEx()</samp> function with
                                 the specified <samp class="ph codeph">bnOps</samp> input setting. 
                              </p>
                           </dd>
                        </dl>
                        <p class="p">Possible error values returned by this function and their meanings are listed below.</p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The computation was performed successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function does not support the provided configuration.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnBatchNormalizationBackwardExWorkspaceSize__ul_gx5_kph_jt" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnBatchNormalizationBackwardExWorkspaceSize__ul_gx5_kph_jt">
                                 <li class="li">Number of <samp class="ph codeph">xDesc</samp> or <samp class="ph codeph">yDesc</samp> or
                                    <samp class="ph codeph">dxDesc</samp> tensor descriptor dimensions is not within
                                    the range of [4,5] (only 4D and 5D tensors are supported.) 
                                 </li>
                                 <li class="li"><samp class="ph codeph">dBnScaleBiasDesc</samp> dimensions not 1xCx1x1 for 4D and
                                    1xCx1x1x1 for 5D for spatial, and are not 1xCxHxW for 4D and 1xCxDxHxW
                                    for 5D for per-activation mode. 
                                 </li>
                                 <li class="li">Dimensions or data types mismatch for any pair of xDesc, dyDesc,
                                    dxDesc
                                 </li>
                              </ul>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnBatchNormalizationForwardTrainingExWorkspaceSize"><a name="cudnnBatchNormalizationForwardTrainingExWorkspaceSize" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnBatchNormalizationForwardTrainingExWorkspaceSize" name="cudnnBatchNormalizationForwardTrainingExWorkspaceSize" shape="rect">cudnnBatchNormalizationForwardTrainingExWorkspaceSize</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve"> cudnnStatus_t cudnnGetBatchNormalizationForwardTrainingExWorkspaceSize(
    cudnnHandle_t                           handle,
    cudnnBatchNormMode_t                    mode,
    cudnnBatchNormOps_t                     bnOps,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t           xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t           zDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t           yDesc, 
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t           bnScaleBiasMeanVarDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnActivationDescriptor_t       activationDesc, 
    size_t                                  *sizeInBytes);</pre><p class="p">This function returns the amount of GPU memory workspace the user should allocate to be
                           able to call <samp class="ph codeph">cudnnGetBatchNormalizationForwardTrainingEx()</samp> function for
                           the specified <samp class="ph codeph">bnOps</samp> input setting. The workspace allocated should then
                           be passed by the user to the function
                           <samp class="ph codeph">cudnnGetBatchNormalizationForwardTrainingEx()</samp>. 
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN library descriptor. See
                                 <a class="xref" href="index.html#cudnnHandle_t" shape="rect">cudnnHandle_t.</a></p>
                           </dd>
                           <dt class="dt dlterm">mode </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Mode of operation (spatial or per-activation). See <a class="xref" href="index.html#datatypes-reference" shape="rect">cudnnBatchNormMode_t.</a></p>
                           </dd>
                           <dt class="dt dlterm">bnOps</dt>
                           <dd class="dd"><em class="ph i">Input</em>. Mode of operation for the fast NHWC kernel. See <a class="xref" href="index.html#datatypes-reference" shape="rect">cudnnBatchNormOps_t.</a>. This input can be used to set this function to
                              perform either only the batch normalization, or batch normalization followed by
                              activation, or batch normalization followed by element-wise addition and then
                              activation. 
                           </dd>
                           <dt class="dt dlterm">xDesc, zDesc, yDesc </dt>
                           <dd class="dd">
                              <p class="p">Tensor descriptors and pointers in the device memory for the layer's
                                 <samp class="ph codeph">x</samp> data, the optional <samp class="ph codeph">z</samp> input data, and
                                 the <samp class="ph codeph">y</samp> output.  See <a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t.</a></p>
                           </dd>
                           <dt class="dt dlterm">bnScaleBiasMeanVarDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Shared tensor descriptor for the following six tensors:
                                 <samp class="ph codeph">bnScaleData, bnBiasData, dBnScaleData, dBnBiasData, savedMean,
                                    and savedInvVariance</samp>. This is the shared tensor descriptor desc
                                 for the secondary tensor that was derived by <a class="xref" href="index.html#cudnnDeriveBNTensorDescriptor" shape="rect">cudnnDeriveBNTensorDescriptor()</a>. The dimensions for this tensor
                                 descriptor are dependent on normalization mode. Note: The data type of this
                                 tensor descriptor must be 'float' for FP16 and FP32 input tensors, and
                                 'double' for FP64 input tensors. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">activationDesc</dt>
                           <dd class="dd"><em class="ph i">Input</em>. Tensor descriptor for the activation operation. When the
                              <samp class="ph codeph">bnOps</samp> input is set to either
                              CUDNN_BATCHNORM_OPS_BN_ACTIVATION or CUDNN_BATCHNORM_OPS_BN_ADD_ACTIVATION then
                              this activation is used. 
                           </dd>
                        </dl>
                        <dl class="dl">
                           <dt class="dt dlterm">*sizeInBytes</dt>
                           <dd class="dd"><em class="ph i">Output</em>. Amount of GPU memory required for the workspace, as determined by
                              this function, to be able to execute the
                              <samp class="ph codeph">cudnnGetBatchNormalizationForwardTrainingEx()</samp> function with
                              the specified <samp class="ph codeph">bnOps</samp> input setting. 
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The computation was performed successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function does not support the provided configuration.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnBatchNormalizationForwardTrainingExWorkspaceSize__ul_qnn_k4g_jt" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnBatchNormalizationForwardTrainingExWorkspaceSize__ul_qnn_k4g_jt">
                                 <li class="li">Number of <samp class="ph codeph">xDesc</samp> or <samp class="ph codeph">yDesc</samp> or
                                    <samp class="ph codeph">dxDesc</samp> tensor descriptor dimensions is not within
                                    the range of [4,5] (only 4D and 5D tensors are supported.) 
                                 </li>
                                 <li class="li"><samp class="ph codeph">dBnScaleBiasDesc</samp> dimensions not 1xCx1x1 for 4D and
                                    1xCx1x1x1 for 5D for spatial, and are not 1xCxHxW for 4D and 1xCxDxHxW
                                    for 5D for per-activation mode. 
                                 </li>
                                 <li class="li">Dimensions or data types mismatch for <samp class="ph codeph">xDesc,
                                       yDesc</samp>.
                                 </li>
                              </ul>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetBatchNormalizationTrainingExReserveSpaceSize"><a name="cudnnGetBatchNormalizationTrainingExReserveSpaceSize" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetBatchNormalizationTrainingExReserveSpaceSize" name="cudnnGetBatchNormalizationTrainingExReserveSpaceSize" shape="rect">4.86.&nbsp;cudnnGetBatchNormalizationTrainingExReserveSpaceSize</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetBatchNormalizationTrainingExReserveSpaceSize(
    cudnnHandle_t                       handle,
    cudnnBatchNormMode_t                mode,
    cudnnBatchNormOps_t                 bnOps,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnActivationDescriptor_t   activationDesc, 
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       xDesc, 
    size_t                              *sizeInBytes);</pre><p class="p">This function returns the amount of reserve GPU memory workspace the user should allocate
                           for the batch normalization operation, for the specified <samp class="ph codeph">bnOps</samp> input
                           setting. In contrast to the <samp class="ph codeph">workspace</samp>, the reserved space should be
                           preserved between the forward and backward calls, and the data should not be
                           altered.
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p dir="ltr" class="p" id="cudnnGetBatchNormalizationTrainingExReserveSpaceSize__docs-internal-guid-f8a203ce-7fff-2534-2441-0f5efa63bac6"><a name="cudnnGetBatchNormalizationTrainingExReserveSpaceSize__docs-internal-guid-f8a203ce-7fff-2534-2441-0f5efa63bac6" shape="rect">
                                    <!-- --></a><em class="ph i">Input</em>. Handle to a previously created cuDNN library descriptor.
                                 See <a class="xref" href="index.html#cudnnHandle_t" shape="rect">cudnnHandle_t.</a></p>
                           </dd>
                           <dt class="dt dlterm">mode</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Mode of operation (spatial or per-activation). See <a class="xref" href="index.html#datatypes-reference" shape="rect">cudnnBatchNormMode_t.</a></p>
                           </dd>
                           <dt class="dt dlterm">bnOps</dt>
                           <dd class="dd"><em class="ph i">Input</em>. Mode of operation for the fast NHWC kernel. See <a class="xref" href="index.html#datatypes-reference" shape="rect">cudnnBatchNormOps_t.</a>. This input can be used to set this function to
                              perform either only the batch normalization, or batch normalization followed by
                              activation, or batch normalization followed by element-wise addition and then
                              activation. 
                           </dd>
                           <dt class="dt dlterm">xDesc </dt>
                           <dd class="dd">
                              <p class="p">Tensor descriptors for the layer's x data. See <a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t.</a></p>
                           </dd>
                           <dt class="dt dlterm">activationDesc</dt>
                           <dd class="dd"><em class="ph i">Input</em>. Tensor descriptor for the activation operation.
                           </dd>
                           <dt class="dt dlterm">*sizeInBytes</dt>
                           <dd class="dd"><em class="ph i">Output</em>. Amount of GPU memory reserved.
                           </dd>
                        </dl>
                        <p class="p">Possible error values returned by this function and their meanings are listed below.</p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The computation was performed successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function does not support the provided configuration.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnGetBatchNormalizationTrainingExReserveSpaceSize__ul_gx5_kph_jt" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnGetBatchNormalizationTrainingExReserveSpaceSize__ul_gx5_kph_jt">
                                 <li class="li">The <samp class="ph codeph">xDesc</samp> tensor descriptor dimension is not within the
                                    [4,5] range (only 4D and 5D tensors are supported.) 
                                 </li>
                              </ul>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetCallback"><a name="cudnnGetCallback" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetCallback" name="cudnnGetCallback" shape="rect">4.87.&nbsp;cudnnGetCallback</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetCallback(
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span>            mask,
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                **udata,
        cudnnCallback_t     fptr)</pre><p class="p"><strong class="ph b">(New for 7.1)</strong></p>
                        <p class="p">This function queries the internal states of cuDNN error reporting functionality.</p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">mask</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Pointer to the address where the current internal error reporting message bit mask will be outputted.
                              </p>
                           </dd>
                           <dt class="dt dlterm">udata</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Pointer to the address where the current internally stored udata address will be stored.
                              </p>
                           </dd>
                           <dt class="dt dlterm">fptr</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Pointer to the address where the current internally stored callback function pointer will be stored. When the built-in default
                                 callback function is used, NULL will be outputted.
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The function launched successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">If any of the input parameters are NULL.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetConvolution2dDescriptor"><a name="cudnnGetConvolution2dDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetConvolution2dDescriptor" name="cudnnGetConvolution2dDescriptor" shape="rect">4.88.&nbsp;cudnnGetConvolution2dDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetConvolution2dDescriptor(
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnConvolutionDescriptor_t  convDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                *pad_h,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                *pad_w,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                *u,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                *v,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                *dilation_h,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                *dilation_w,
    cudnnConvolutionMode_t             *mode,
    cudnnDataType_t                    *computeType)</pre><p class="p">This function queries a previously initialized 2D convolution descriptor object. </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">convDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input/Output</em>. Handle to a previously created convolution
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">pad_h </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. zero-padding height: number of rows of zeros implicitly
                                 concatenated onto the top and onto the bottom of input images.
                              </p>
                           </dd>
                           <dt class="dt dlterm">pad_w </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. zero-padding width: number of columns of zeros implicitly
                                 concatenated onto the left and onto the right of input images.
                              </p>
                           </dd>
                           <dt class="dt dlterm">u </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Vertical filter stride.
                              </p>
                           </dd>
                           <dt class="dt dlterm">v </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Horizontal filter stride.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dilation_h </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Filter height dilation.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dilation_w </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Filter width dilation.
                              </p>
                           </dd>
                           <dt class="dt dlterm">mode </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Convolution mode.
                              </p>
                           </dd>
                           <dt class="dt dlterm">computeType </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Compute precision.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The operation was successful.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">The parameter <samp class="ph codeph">convDesc</samp> is nil.
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetConvolution2dForwardOutputDim"><a name="cudnnGetConvolution2dForwardOutputDim" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetConvolution2dForwardOutputDim" name="cudnnGetConvolution2dForwardOutputDim" shape="rect">4.89.&nbsp;cudnnGetConvolution2dForwardOutputDim</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetConvolution2dForwardOutputDim(
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnConvolutionDescriptor_t  convDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       inputTensorDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t       filterDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                *n,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                *c,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                *h,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                *w)</pre><p class="p">This function returns the dimensions of the resulting 4D tensor of a 2D convolution,
                           given the convolution descriptor, the input tensor descriptor and the filter descriptor
                           This function can help to setup the output tensor and allocate the proper amount of
                           memory prior to launch the actual convolution. 
                        </p>
                        <p class="p">Each dimension <samp class="ph codeph">h and w</samp> of the output images is computed as followed:
                        </p><pre xml:space="preserve">
    outputDim = 1 + ( inputDim + 2*pad - (((filterDim-1)*dilation)+1) )/convolutionStride;
    </pre><div class="note note"><span class="notetitle">Note:</span> The dimensions provided by this routine must be strictly respected when calling
                           <samp class="ph codeph">cudnnConvolutionForward()</samp> or
                           <samp class="ph codeph">cudnnConvolutionBackwardBias()</samp>. Providing a smaller or larger
                           output tensor is not supported by the convolution routines.
                        </div>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">convDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created convolution descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">inputTensorDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">filterDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">n </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Number of output images.
                              </p>
                           </dd>
                           <dt class="dt dlterm">c </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Number of output feature maps per image.
                              </p>
                           </dd>
                           <dt class="dt dlterm">h </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Height of each output feature map.
                              </p>
                           </dd>
                           <dt class="dt dlterm">w </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Width of each output feature map.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">One or more of the descriptors has not been created correctly or there is a
                                 mismatch between the feature maps of <samp class="ph codeph">inputTensorDesc</samp> and
                                 <samp class="ph codeph">filterDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was set successfully.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetConvolutionBackwardDataAlgorithm"><a name="cudnnGetConvolutionBackwardDataAlgorithm" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetConvolutionBackwardDataAlgorithm" name="cudnnGetConvolutionBackwardDataAlgorithm" shape="rect">4.90.&nbsp;cudnnGetConvolutionBackwardDataAlgorithm</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetConvolutionBackwardDataAlgorithm(
    cudnnHandle_t                          handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t          wDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t          dyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnConvolutionDescriptor_t     convDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t          dxDesc,
    cudnnConvolutionBwdDataPreference_t    preference,
    size_t                                 memoryLimitInBytes,
    cudnnConvolutionBwdDataAlgo_t         *algo)</pre><p class="p">This function serves as a heuristic for obtaining the best suited algorithm for
                           <samp class="ph codeph">cudnnConvolutionBackwardData</samp> for the given layer specifications.
                           Based on the input preference, this function will either return the fastest algorithm or
                           the fastest algorithm within a given memory limit. For an exhaustive search for the
                           fastest algorithm, please use
                           <samp class="ph codeph">cudnnFindConvolutionBackwardDataAlgorithm</samp>. 
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">wDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dyDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized input differential tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">convDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Previously initialized convolution descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dxDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized output tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">preference </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Enumerant to express the preference criteria in terms of memory
                                 requirement and speed.
                              </p>
                           </dd>
                           <dt class="dt dlterm">memoryLimitInBytes </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. It is to specify the maximum amount of GPU memory the user is
                                 willing to use as a workspace. This is currently a placeholder and is not
                                 used. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">algo </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Enumerant that specifies which convolution algorithm should be
                                 used to compute the results according to the specified preference
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The query was successful.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnGetConvolutionBackwardDataAlgorithm__ul_ymw_vjb_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnGetConvolutionBackwardDataAlgorithm__ul_ymw_vjb_s1b">
                                 <li class="li">The numbers of feature maps of the input tensor and output tensor
                                    differ.
                                 </li>
                                 <li class="li">The <samp class="ph codeph">dataType</samp> of the two tensor descriptors or the
                                    filter are different.
                                 </li>
                              </ul>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetConvolutionBackwardDataAlgorithm_v7"><a name="cudnnGetConvolutionBackwardDataAlgorithm_v7" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetConvolutionBackwardDataAlgorithm_v7" name="cudnnGetConvolutionBackwardDataAlgorithm_v7" shape="rect">4.91.&nbsp;cudnnGetConvolutionBackwardDataAlgorithm_v7</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetConvolutionBackwardDataAlgorithm_v7(
    cudnnHandle_t                          handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t          wDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t          dyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnConvolutionDescriptor_t     convDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t          dxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                              requestedAlgoCount,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                   *returnedAlgoCount,
    cudnnConvolutionBwdDataAlgoPerf_t     *perfResults)</pre><p class="p">This function serves as a heuristic for obtaining the best suited algorithm for
                           <samp class="ph codeph">cudnnConvolutionBackwardData</samp> for the given layer specifications.
                           This function will return all algorithms (including CUDNN_TENSOR_OP_MATH and CUDNN_DEFAULT_MATH 
                           versions of algorithms where CUDNN_TENSOR_OP_MATH may be available) sorted by expected (based on internal
                           heuristic) relative performance with fastest being index 0 of perfResults. For an
                           exhaustive search for the fastest algorithm, please use
                           <samp class="ph codeph">cudnnFindConvolutionBackwardDataAlgorithm</samp>.  The total number of resulting algorithms can be queried through 
                           the API <samp class="ph codeph">cudnnGetConvolutionBackwardMaxCount()</samp>.
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">wDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dyDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized input differential tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">convDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Previously initialized convolution descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dxDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized output tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">requestedAlgoCount </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. The maximum number of elements to be stored in perfResults.
                              </p>
                           </dd>
                           <dt class="dt dlterm">returnedAlgoCount </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. The number of output elements stored in perfResults.
                              </p>
                           </dd>
                           <dt class="dt dlterm">perfResults </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. A user-allocated array to store performance metrics sorted
                                 ascending by compute time.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The query was successful.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnGetConvolutionBackwardDataAlgorithm_v7__ul_zxk_1kb_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnGetConvolutionBackwardDataAlgorithm_v7__ul_zxk_1kb_s1b">
                                 <li class="li">One of the parameters handle, wDesc, dyDesc, convDesc, dxDesc,
                                    perfResults, returnedAlgoCount is NULL.
                                 </li>
                                 <li class="li">The numbers of feature maps of the input tensor and output tensor
                                    differ.
                                 </li>
                                 <li class="li">The <samp class="ph codeph">dataType</samp> of the two tensor descriptors or the
                                    filter are different.
                                 </li>
                                 <li class="li">requestedAlgoCount is less than or equal to 0.</li>
                              </ul>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetConvolutionBackwardDataAlgorithmMaxCount"><a name="cudnnGetConvolutionBackwardDataAlgorithmMaxCount" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetConvolutionBackwardDataAlgorithmMaxCount" name="cudnnGetConvolutionBackwardDataAlgorithmMaxCount" shape="rect">4.92.&nbsp;cudnnGetConvolutionBackwardDataAlgorithmMaxCount</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetConvolutionBackwardDataAlgorithmMaxCount(
    cudnnHandle_t       handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                 *count)</pre><p class="p">This function returns the maximum number of algorithms which can be returned from cudnnFindConvolutionBackwardDataAlgorithm()
                           and cudnnGetConvolutionForwardAlgorithm_v7(). This is the sum of all algorithms plus the sum of all algorithms with Tensor
                           Core operations supported for the current device.
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">count</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. The resulting maximum number of algorithms.
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The function was successful.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">The provided handle is not allocated properly.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetConvolutionBackwardDataWorkspaceSize"><a name="cudnnGetConvolutionBackwardDataWorkspaceSize" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetConvolutionBackwardDataWorkspaceSize" name="cudnnGetConvolutionBackwardDataWorkspaceSize" shape="rect">4.93.&nbsp;cudnnGetConvolutionBackwardDataWorkspaceSize</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetConvolutionBackwardDataWorkspaceSize(
    cudnnHandle_t                       handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t       wDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       dyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnConvolutionDescriptor_t  convDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       dxDesc,
    cudnnConvolutionBwdDataAlgo_t       algo,
    size_t                             *sizeInBytes)</pre><p class="p">This function returns the amount of GPU memory workspace the user needs to allocate to be
                           able to call <samp class="ph codeph">cudnnConvolutionBackwardData</samp> with the specified algorithm.
                           The workspace allocated will then be passed to the routine
                           <samp class="ph codeph">cudnnConvolutionBackwardData</samp>. The specified algorithm can be the
                           result of the call to <samp class="ph codeph">cudnnGetConvolutionBackwardDataAlgorithm</samp> or can
                           be chosen arbitrarily by the user. Note that not every algorithm is available for every
                           configuration of the input tensor and/or every configuration of the convolution
                           descriptor. 
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">wDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dyDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized input differential tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">convDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Previously initialized convolution descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dxDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized output tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">algo </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Enumerant that specifies the chosen convolution algorithm 
                              </p>
                           </dd>
                           <dt class="dt dlterm">sizeInBytes </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Amount of GPU memory needed as workspace to be able to execute
                                 a forward convolution with the specified <samp class="ph codeph">algo</samp></p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The query was successful.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnGetConvolutionBackwardDataWorkspaceSize__ul_lg1_fkb_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnGetConvolutionBackwardDataWorkspaceSize__ul_lg1_fkb_s1b">
                                 <li class="li">The numbers of feature maps of the input tensor and output tensor
                                    differ.
                                 </li>
                                 <li class="li">The <samp class="ph codeph">dataType</samp> of the two tensor descriptors or the
                                    filter are different.
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The combination of the tensor descriptors, filter descriptor and convolution
                                 descriptor is not supported for the specified algorithm.
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetConvolutionBackwardFilterAlgorithm"><a name="cudnnGetConvolutionBackwardFilterAlgorithm" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetConvolutionBackwardFilterAlgorithm" name="cudnnGetConvolutionBackwardFilterAlgorithm" shape="rect">4.94.&nbsp;cudnnGetConvolutionBackwardFilterAlgorithm</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetConvolutionBackwardFilterAlgorithm(
    cudnnHandle_t                          handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t          xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t          dyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnConvolutionDescriptor_t     convDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t          dwDesc,
    cudnnConvolutionBwdFilterPreference_t  preference,
    size_t                                 memoryLimitInBytes,
    cudnnConvolutionBwdFilterAlgo_t       *algo)</pre><p class="p">This function serves as a heuristic for obtaining the best suited algorithm for
                           <samp class="ph codeph">cudnnConvolutionBackwardFilter</samp> for the given layer specifications.
                           Based on the input preference, this function will either return the fastest algorithm or
                           the fastest algorithm within a given memory limit. For an exhaustive search for the
                           fastest algorithm, please use
                           <samp class="ph codeph">cudnnFindConvolutionBackwardFilterAlgorithm</samp>. 
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">xDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized input tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dyDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized input differential tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">convDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Previously initialized convolution descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dwDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">preference </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Enumerant to express the preference criteria in terms of memory
                                 requirement and speed.
                              </p>
                           </dd>
                           <dt class="dt dlterm">memoryLimitInBytes </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. It is to specify the maximum amount of GPU memory the user is
                                 willing to use as a workspace. This is currently a placeholder and is not
                                 used.
                              </p>
                           </dd>
                           <dt class="dt dlterm">algo </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Enumerant that specifies which convolution algorithm should be
                                 used to compute the results according to the specified preference.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The query was successful.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnGetConvolutionBackwardFilterAlgorithm__ul_nbm_43b_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnGetConvolutionBackwardFilterAlgorithm__ul_nbm_43b_s1b">
                                 <li class="li">The numbers of feature maps of the input tensor and output tensor
                                    differ.
                                 </li>
                                 <li class="li">The <samp class="ph codeph">dataType</samp> of the two tensor descriptors or the
                                    filter are different.
                                 </li>
                              </ul>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetConvolutionBackwardFilterAlgorithm_v7"><a name="cudnnGetConvolutionBackwardFilterAlgorithm_v7" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetConvolutionBackwardFilterAlgorithm_v7" name="cudnnGetConvolutionBackwardFilterAlgorithm_v7" shape="rect">4.95.&nbsp;cudnnGetConvolutionBackwardFilterAlgorithm_v7</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetConvolutionBackwardFilterAlgorithm_v7(
    cudnnHandle_t                          handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t          xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t          dyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnConvolutionDescriptor_t     convDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t          dwDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                              requestedAlgoCount,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                   *returnedAlgoCount,
    cudnnConvolutionBwdFilterAlgoPerf_t   *perfResults)</pre><p class="p">This function serves as a heuristic for obtaining the best suited algorithm for
                           <samp class="ph codeph">cudnnConvolutionBackwardFilter</samp> for the given layer specifications.
                           This function will return all algorithms  (including CUDNN_TENSOR_OP_MATH and CUDNN_DEFAULT_MATH 
                           versions of algorithms where CUDNN_TENSOR_OP_MATH may be available) sorted by expected (based on internal
                           heuristic) relative performance with fastest being index 0 of perfResults. For an
                           exhaustive search for the fastest algorithm, please use
                           <samp class="ph codeph">cudnnFindConvolutionBackwardFilterAlgorithm</samp>. The total number of resulting algorithms can be queried through 
                           the API <samp class="ph codeph">cudnnGetConvolutionBackwardMaxCount()</samp>.
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">xDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized input tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dyDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized input differential tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">convDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Previously initialized convolution descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dwDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">requestedAlgoCount </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. The maximum number of elements to be stored in perfResults.
                              </p>
                           </dd>
                           <dt class="dt dlterm">returnedAlgoCount </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. The number of output elements stored in perfResults.
                              </p>
                           </dd>
                           <dt class="dt dlterm">perfResults </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. A user-allocated array to store performance metrics sorted
                                 ascending by compute time.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The query was successful.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnGetConvolutionBackwardFilterAlgorithm_v7__ul_f44_s3b_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnGetConvolutionBackwardFilterAlgorithm_v7__ul_f44_s3b_s1b">
                                 <li class="li">One of the parameters handle, xDesc, dyDesc, convDesc, dwDesc,
                                    perfResults, returnedAlgoCount is NULL.
                                 </li>
                                 <li class="li">The numbers of feature maps of the input tensor and output tensor
                                    differ.
                                 </li>
                                 <li class="li">The <samp class="ph codeph">dataType</samp> of the two tensor descriptors or the
                                    filter are different.
                                 </li>
                                 <li class="li">requestedAlgoCount is less than or equal to 0.</li>
                              </ul>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetConvolutionBackwardFilterAlgorithmMaxCount"><a name="cudnnGetConvolutionBackwardFilterAlgorithmMaxCount" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetConvolutionBackwardFilterAlgorithmMaxCount" name="cudnnGetConvolutionBackwardFilterAlgorithmMaxCount" shape="rect">4.96.&nbsp;cudnnGetConvolutionBackwardFilterAlgorithmMaxCount</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetConvolutionBackwardFilterAlgorithmMaxCount(
    cudnnHandle_t       handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                 *count)</pre><p class="p">This function returns the maximum number of algorithms which can be returned from cudnnFindConvolutionBackwardFilterAlgorithm()
                           and cudnnGetConvolutionForwardAlgorithm_v7(). This is the sum of all algorithms plus the sum of all algorithms with Tensor
                           Core operations supported for the current device.
                           
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">count</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. The resulting maximum count of algorithms.
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The function was successful.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">The provided handle is not allocated properly.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetConvolutionBackwardFilterWorkspaceSize"><a name="cudnnGetConvolutionBackwardFilterWorkspaceSize" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetConvolutionBackwardFilterWorkspaceSize" name="cudnnGetConvolutionBackwardFilterWorkspaceSize" shape="rect">4.97.&nbsp;cudnnGetConvolutionBackwardFilterWorkspaceSize</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetConvolutionBackwardFilterWorkspaceSize(
    cudnnHandle_t                       handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       dyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnConvolutionDescriptor_t  convDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t       dwDesc,
    cudnnConvolutionBwdFilterAlgo_t     algo,
    size_t                             *sizeInBytes)</pre><p class="p">This function returns the amount of GPU memory workspace the user needs to allocate to be
                           able to call <samp class="ph codeph">cudnnConvolutionBackwardFilter</samp> with the specified
                           algorithm. The workspace allocated will then be passed to the routine
                           <samp class="ph codeph">cudnnConvolutionBackwardFilter</samp>. The specified algorithm can be the
                           result of the call to <samp class="ph codeph">cudnnGetConvolutionBackwardFilterAlgorithm</samp> or can
                           be chosen arbitrarily by the user. Note that not every algorithm is available for every
                           configuration of the input tensor and/or every configuration of the convolution
                           descriptor. 
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">xDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized input tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dyDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized input differential tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">convDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Previously initialized convolution descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dwDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">algo </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Enumerant that specifies the chosen convolution algorithm. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">sizeInBytes </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Amount of GPU memory needed as workspace to be able to execute
                                 a forward convolution with the specified <samp class="ph codeph">algo</samp>.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The query was successful.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnGetConvolutionBackwardFilterWorkspaceSize__ul_cyh_w3b_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnGetConvolutionBackwardFilterWorkspaceSize__ul_cyh_w3b_s1b">
                                 <li class="li">The numbers of feature maps of the input tensor and output tensor
                                    differ.
                                 </li>
                                 <li class="li">The <samp class="ph codeph">dataType</samp> of the two tensor descriptors or the
                                    filter are different.
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The combination of the tensor descriptors, filter descriptor and convolution
                                 descriptor is not supported for the specified algorithm.
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetConvolutionForwardAlgorithm"><a name="cudnnGetConvolutionForwardAlgorithm" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetConvolutionForwardAlgorithm" name="cudnnGetConvolutionForwardAlgorithm" shape="rect">4.98.&nbsp;cudnnGetConvolutionForwardAlgorithm</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetConvolutionForwardAlgorithm(
    cudnnHandle_t                      handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t      xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t      wDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnConvolutionDescriptor_t convDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t      yDesc,
    cudnnConvolutionFwdPreference_t    preference,
    size_t                             memoryLimitInBytes,
    cudnnConvolutionFwdAlgo_t         *algo)</pre><p class="p">This function serves as a heuristic for obtaining the best suited algorithm for
                           <samp class="ph codeph">cudnnConvolutionForward</samp> for the given layer specifications. Based
                           on the input preference, this function will either return the fastest algorithm or the
                           fastest algorithm within a given memory limit. For an exhaustive search for the fastest
                           algorithm, please use <samp class="ph codeph">cudnnFindConvolutionForwardAlgorithm</samp>. 
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">xDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized input tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">wDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized convolution filter
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">convDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Previously initialized convolution descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">yDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized output tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">preference </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Enumerant to express the preference criteria in terms of memory
                                 requirement and speed.
                              </p>
                           </dd>
                           <dt class="dt dlterm">memoryLimitInBytes </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. It is used when enumerant <samp class="ph codeph">preference</samp> is set to
                                 <samp class="ph codeph">CUDNN_CONVOLUTION_FWD_SPECIFY_WORKSPACE_LIMIT</samp> to
                                 specify the maximum amount of GPU memory the user is willing to use as a
                                 workspace
                              </p>
                           </dd>
                           <dt class="dt dlterm">algo </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Enumerant that specifies which convolution algorithm should be
                                 used to compute the results according to the specified preference
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The query was successful.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnGetConvolutionForwardAlgorithm__ul_ekr_jhb_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnGetConvolutionForwardAlgorithm__ul_ekr_jhb_s1b">
                                 <li class="li">One of the parameters handle, xDesc, wDesc, convDesc, yDesc is
                                    NULL.
                                 </li>
                                 <li class="li">Either yDesc or wDesc have different dimensions from xDesc.</li>
                                 <li class="li">The data types of tensors xDesc, yDesc or wDesc are not all the
                                    same.
                                 </li>
                                 <li class="li">The number of feature maps in xDesc and wDesc differs.</li>
                                 <li class="li">The tensor xDesc has a dimension smaller than 3.</li>
                              </ul>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetConvolutionForwardAlgorithm_v7"><a name="cudnnGetConvolutionForwardAlgorithm_v7" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetConvolutionForwardAlgorithm_v7" name="cudnnGetConvolutionForwardAlgorithm_v7" shape="rect">4.99.&nbsp;cudnnGetConvolutionForwardAlgorithm_v7</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetConvolutionForwardAlgorithm_v7(
    cudnnHandle_t                       handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t       wDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnConvolutionDescriptor_t  convDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                           requestedAlgoCount,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                *returnedAlgoCount,
    cudnnConvolutionFwdAlgoPerf_t      *perfResults)</pre><p class="p">This function serves as a heuristic for obtaining the best suited algorithm for
                           <samp class="ph codeph">cudnnConvolutionForward</samp> for the given layer specifications. This
                           function will return all algorithms  (including CUDNN_TENSOR_OP_MATH and CUDNN_DEFAULT_MATH 
                           versions of algorithms where CUDNN_TENSOR_OP_MATH may be available) sorted by expected (based on internal heuristic)
                           relative performance with fastest being index 0 of perfResults. For an exhaustive search
                           for the fastest algorithm, please use
                           <samp class="ph codeph">cudnnFindConvolutionForwardAlgorithm</samp>.  The total number of resulting algorithms can be queried through 
                           the API <samp class="ph codeph">cudnnGetConvolutionForwardMaxCount()</samp>.
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">xDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized input tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">wDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized convolution filter
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">convDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Previously initialized convolution descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">yDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized output tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">requestedAlgoCount </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. The maximum number of elements to be stored in perfResults.
                              </p>
                           </dd>
                           <dt class="dt dlterm">returnedAlgoCount </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. The number of output elements stored in perfResults.
                              </p>
                           </dd>
                           <dt class="dt dlterm">perfResults </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. A user-allocated array to store performance metrics sorted
                                 ascending by compute time.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The query was successful.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnGetConvolutionForwardAlgorithm_v7__ul_xz5_nhb_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnGetConvolutionForwardAlgorithm_v7__ul_xz5_nhb_s1b">
                                 <li class="li">One of the parameters handle, xDesc, wDesc, convDesc, yDesc,
                                    perfResults, returnedAlgoCount is NULL.
                                 </li>
                                 <li class="li">Either yDesc or wDesc have different dimensions from xDesc.</li>
                                 <li class="li">The data types of tensors xDesc, yDesc or wDesc are not all the
                                    same.
                                 </li>
                                 <li class="li">The number of feature maps in xDesc and wDesc differs.</li>
                                 <li class="li">The tensor xDesc has a dimension smaller than 3.</li>
                                 <li class="li">requestedAlgoCount is less than or equal to 0.</li>
                              </ul>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetConvolutionForwardAlgorithmMaxCount"><a name="cudnnGetConvolutionForwardAlgorithmMaxCount" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetConvolutionForwardAlgorithmMaxCount" name="cudnnGetConvolutionForwardAlgorithmMaxCount" shape="rect">4.100.&nbsp;cudnnGetConvolutionForwardAlgorithmMaxCount</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetConvolutionForwardAlgorithmMaxCount(
    cudnnHandle_t   handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>             *count)</pre><p class="p">This function returns the maximum number of algorithms which can be returned from cudnnFindConvolutionForwardAlgorithm() and
                           cudnnGetConvolutionForwardAlgorithm_v7(). This is the sum of all algorithms plus the sum of all algorithms with Tensor Core
                           operations supported for the current device.
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">count</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. The resulting maximum number of algorithms.
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The function was successful.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">The provided handle is not allocated properly.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetConvolutionForwardWorkspaceSize"><a name="cudnnGetConvolutionForwardWorkspaceSize" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetConvolutionForwardWorkspaceSize" name="cudnnGetConvolutionForwardWorkspaceSize" shape="rect">4.101.&nbsp;cudnnGetConvolutionForwardWorkspaceSize</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetConvolutionForwardWorkspaceSize(
    cudnnHandle_t   handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>   cudnnTensorDescriptor_t         xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>   cudnnFilterDescriptor_t         wDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>   cudnnConvolutionDescriptor_t    convDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>   cudnnTensorDescriptor_t         yDesc,
    cudnnConvolutionFwdAlgo_t               algo,
    size_t                                 *sizeInBytes)</pre><p class="p">This function returns the amount of GPU memory workspace the user needs to allocate to be
                           able to call <samp class="ph codeph">cudnnConvolutionForward</samp> with the specified algorithm. The
                           workspace allocated will then be passed to the routine
                           <samp class="ph codeph">cudnnConvolutionForward</samp>. The specified algorithm can be the result
                           of the call to <samp class="ph codeph">cudnnGetConvolutionForwardAlgorithm</samp> or can be chosen
                           arbitrarily by the user. Note that not every algorithm is available for every
                           configuration of the input tensor and/or every configuration of the convolution
                           descriptor. 
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">xDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized x tensor descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">wDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">convDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Previously initialized convolution descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">yDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized y tensor descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">algo </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Enumerant that specifies the chosen convolution algorithm 
                              </p>
                           </dd>
                           <dt class="dt dlterm">sizeInBytes </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Amount of GPU memory needed as workspace to be able to execute
                                 a forward convolution with the specified <samp class="ph codeph">algo</samp></p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The query was successful.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnGetConvolutionForwardWorkspaceSize__ul_lmf_rhb_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnGetConvolutionForwardWorkspaceSize__ul_lmf_rhb_s1b">
                                 <li class="li">One of the parameters handle, xDesc, wDesc, convDesc, yDesc is
                                    NULL.
                                 </li>
                                 <li class="li">The tensor yDesc or wDesc are not of the same dimension as xDesc.</li>
                                 <li class="li">The tensor xDesc, yDesc or wDesc are not of the same data type.</li>
                                 <li class="li">The numbers of feature maps of the tensor xDesc and wDesc differ.</li>
                                 <li class="li">The tensor xDesc has a dimension smaller than 3.</li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The combination of the tensor descriptors, filter descriptor and convolution
                                 descriptor is not supported for the specified algorithm.
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetConvolutionGroupCount"><a name="cudnnGetConvolutionGroupCount" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetConvolutionGroupCount" name="cudnnGetConvolutionGroupCount" shape="rect">4.102.&nbsp;cudnnGetConvolutionGroupCount</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetConvolutionGroupCount(
    cudnnConvolutionDescriptor_t    convDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                            *groupCount)</pre><p class="p">This function returns the group count specified in the given convolution descriptor. </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The group count was returned successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">An invalid convolution descriptor was provided.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetConvolutionMathType"><a name="cudnnGetConvolutionMathType" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetConvolutionMathType" name="cudnnGetConvolutionMathType" shape="rect">4.103.&nbsp;cudnnGetConvolutionMathType</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetConvolutionMathType(
    cudnnConvolutionDescriptor_t    convDesc,
    cudnnMathType_t                *mathType)</pre><p class="p">This function returns the math type specified in a given convolution descriptor. </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The math type was returned successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">An invalid convolution descriptor was provided.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetConvolutionNdDescriptor"><a name="cudnnGetConvolutionNdDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetConvolutionNdDescriptor" name="cudnnGetConvolutionNdDescriptor" shape="rect">4.104.&nbsp;cudnnGetConvolutionNdDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetConvolutionNdDescriptor(
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnConvolutionDescriptor_t  convDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                 arrayLengthRequested,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                *arrayLength,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                 padA[],
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                 filterStrideA[],
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                 dilationA[],
    cudnnConvolutionMode_t             *mode,
    cudnnDataType_t                    *dataType)</pre><p class="p">This function queries a previously initialized convolution descriptor object. </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">convDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input/Output</em>. Handle to a previously created convolution
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">arrayLengthRequested </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Dimension of the expected convolution descriptor. It is also
                                 the minimum size of the arrays <samp class="ph codeph">padA</samp>,
                                 <samp class="ph codeph">filterStrideA</samp> and <samp class="ph codeph">dilationA</samp> in order
                                 to be able to hold the results
                              </p>
                           </dd>
                           <dt class="dt dlterm">arrayLength </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Actual dimension of the convolution descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">padA </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Array of dimension of at least
                                 <samp class="ph codeph">arrayLengthRequested</samp> that will be filled with the
                                 padding parameters from the provided convolution descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">filterStrideA </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Array of dimension of at least
                                 <samp class="ph codeph">arrayLengthRequested</samp> that will be filled with the
                                 filter stride from the provided convolution descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dilationA </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Array of dimension of at least
                                 <samp class="ph codeph">arrayLengthRequested</samp> that will be filled with the
                                 dilation parameters from the provided convolution descriptor. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">mode </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Convolution mode of the provided descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">datatype </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Datatype of the provided descriptor.
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The query was successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnGetConvolutionNdDescriptor__ul_egc_pgb_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnGetConvolutionNdDescriptor__ul_egc_pgb_s1b">
                                 <li class="li">The descriptor <samp class="ph codeph">convDesc</samp> is nil.
                                 </li>
                                 <li class="li">The <samp class="ph codeph">arrayLengthRequest</samp> is negative.
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The <samp class="ph codeph">arrayLengthRequested</samp> is greater than CUDNN_DIM_MAX-2.
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetConvolutionNdForwardOutputDim"><a name="cudnnGetConvolutionNdForwardOutputDim" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetConvolutionNdForwardOutputDim" name="cudnnGetConvolutionNdForwardOutputDim" shape="rect">4.105.&nbsp;cudnnGetConvolutionNdForwardOutputDim</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetConvolutionNdForwardOutputDim(
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnConvolutionDescriptor_t  convDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       inputTensorDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t       filterDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                 nbDims,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                 tensorOuputDimA[])</pre><p class="p">This function returns the dimensions of the resulting n-D tensor of a
                           <samp class="ph codeph">nbDims-2</samp>-D convolution, given the convolution descriptor, the input
                           tensor descriptor and the filter descriptor This function can help to setup the output
                           tensor and allocate the proper amount of memory prior to launch the actual convolution. 
                        </p>
                        <p class="p">Each dimension of the <samp class="ph codeph">(nbDims-2)-D</samp> images of the output tensor is
                           computed as followed:
                        </p><pre xml:space="preserve">
    outputDim = 1 + ( inputDim + 2*pad - (((filterDim-1)*dilation)+1) )/convolutionStride;
    </pre><div class="note note"><span class="notetitle">Note:</span> The dimensions provided by this routine must be strictly respected when calling
                           <samp class="ph codeph">cudnnConvolutionForward()</samp> or
                           <samp class="ph codeph">cudnnConvolutionBackwardBias()</samp>. Providing a smaller or larger
                           output tensor is not supported by the convolution routines.
                        </div>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">convDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created convolution descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">inputTensorDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">filterDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">nbDims </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Dimension of the output tensor
                              </p>
                           </dd>
                           <dt class="dt dlterm">tensorOuputDimA </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Array of dimensions <samp class="ph codeph">nbDims</samp> that contains on
                                 exit of this routine the sizes of the output tensor
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnGetConvolutionNdForwardOutputDim__ul_spl_tgb_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnGetConvolutionNdForwardOutputDim__ul_spl_tgb_s1b">
                                 <li class="li">One of the parameters <samp class="ph codeph">convDesc</samp>,
                                    <samp class="ph codeph">inputTensorDesc,</samp> and <samp class="ph codeph">filterDesc,</samp>
                                    is nil
                                 </li>
                                 <li class="li">The dimension of the filter descriptor <samp class="ph codeph">filterDesc</samp> is
                                    different from the dimension of input tensor descriptor
                                    <samp class="ph codeph">inputTensorDesc</samp>.
                                 </li>
                                 <li class="li">The dimension of the convolution descriptor is different from the
                                    dimension of input tensor descriptor <samp class="ph codeph">inputTensorDesc</samp> -2
                                    .
                                 </li>
                                 <li class="li">The features map of the filter descriptor <samp class="ph codeph">filterDesc</samp> is
                                    different from the one of input tensor descriptor
                                    <samp class="ph codeph">inputTensorDesc</samp>.
                                 </li>
                                 <li class="li">The size of the dilated filter <samp class="ph codeph">filterDesc</samp> is larger
                                    than the padded sizes of the input tensor.
                                 </li>
                                 <li class="li">The dimension <samp class="ph codeph">nbDims</samp> of the output array is negative or
                                    greater than the dimension of input tensor descriptor
                                    <samp class="ph codeph">inputTensorDesc</samp>.
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The routine exits successfully.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetConvolutionReorderType"><a name="cudnnGetConvolutionReorderType" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetConvolutionReorderType" name="cudnnGetConvolutionReorderType" shape="rect">4.106.&nbsp;cudnnGetConvolutionReorderType</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetConvolutionReorderType(
	cudnnConvolutionDescriptor_t convDesc,
	cudnnReorderType_t *reorderType);		</pre><p dir="ltr" class="p" id="cudnnGetConvolutionReorderType__docs-internal-guid-0eaa8c2b-7fff-7d3b-da2a-c0eee8303faf"><a name="cudnnGetConvolutionReorderType__docs-internal-guid-0eaa8c2b-7fff-7d3b-da2a-c0eee8303faf" shape="rect">
                              <!-- --></a>This function retrieves
                           			the convolution reorder type from the given convolution descriptor. 
                        </p>
                        <p class="p"><strong class="ph b">Parameters:</strong></p>
                        <div class="tablenoborder"><a name="cudnnGetConvolutionReorderType__table_hpj_hcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnGetConvolutionReorderType__table_hpj_hcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1"><strong class="ph b">Parameter</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1"><strong class="ph b">Input / Output</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">convDesc</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">The convolution descriptor from which the reorder type should be
                                       							retrieved. 
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">reorderType</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">The retrieved reorder type. See <a class="xref" href="index.html#cudnnReorderType_t" shape="rect">cudnnReorderType_t</a>.
                                    </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                        <p class="p"><strong class="ph b">Returns:</strong></p>
                        <div class="tablenoborder"><a name="cudnnGetConvolutionReorderType__table_usk_kcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnGetConvolutionReorderType__table_usk_kcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Return Value</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_BAD_PARAM</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">One of the inputs to this function is not valid. </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_SUCCESS</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">The reorder type is retrieved successfully. </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetCTCLossDescriptor"><a name="cudnnGetCTCLossDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetCTCLossDescriptor" name="cudnnGetCTCLossDescriptor" shape="rect">4.107.&nbsp;cudnnGetCTCLossDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetCTCLossDescriptor(
    cudnnCTCLossDescriptor_t         ctcLossDesc,
    cudnnDataType_t*                 compType)</pre><p class="p">This function returns configuration of the passed CTC loss function descriptor.</p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">ctcLossDesc</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. CTC loss function descriptor passed, from which to retrieve the configuration.
                              </p>
                           </dd>
                           <dt class="dt dlterm">compType</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Compute type associated with this CTC loss function descriptor.
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The function returned successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">Input OpTensor descriptor passed is invalid.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetCTCLossWorkspaceSize"><a name="cudnnGetCTCLossWorkspaceSize" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetCTCLossWorkspaceSize" name="cudnnGetCTCLossWorkspaceSize" shape="rect">4.108.&nbsp;cudnnGetCTCLossWorkspaceSize</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetCTCLossWorkspaceSize(
    cudnnHandle_t                        handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>   cudnnTensorDescriptor_t      probsDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>   cudnnTensorDescriptor_t      gradientsDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                         *labels,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                         *labelLengths,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                         *inputLengths,
    cudnnCTCLossAlgo_t                   algo,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>   cudnnCTCLossDescriptor_t     ctcLossDesc,
    size_t                              *sizeInBytes)</pre><p class="p">This function returns the amount of GPU memory workspace the user needs to allocate to be
                           able to call <samp class="ph codeph">cudnnCTCLoss</samp> with the specified algorithm. The workspace
                           allocated will then be passed to the routine <samp class="ph codeph">cudnnCTCLoss</samp>. 
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">probsDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized probabilities tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">gradientsDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized gradients tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">labels </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointer to a previously initialized labels list.
                              </p>
                           </dd>
                           <dt class="dt dlterm">labelLengths </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointer to a previously initialized lengths list, to walk the
                                 above labels list.
                              </p>
                           </dd>
                           <dt class="dt dlterm">inputLengths </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointer to a previously initialized list of the lengths of the
                                 timing steps in each batch.
                              </p>
                           </dd>
                           <dt class="dt dlterm">algo </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Enumerant that specifies the chosen CTC loss algorithm 
                              </p>
                           </dd>
                           <dt class="dt dlterm">ctcLossDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized CTC loss descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">sizeInBytes </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Amount of GPU memory needed as workspace to be able to execute
                                 the CTC loss computation with the specified <samp class="ph codeph">algo</samp>.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The query was successful.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnGetCTCLossWorkspaceSize__ul_jkx_hg3_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnGetCTCLossWorkspaceSize__ul_jkx_hg3_s1b">
                                 <li class="li">The dimensions of probsDesc do not match the dimensions of
                                    gradientsDesc.
                                 </li>
                                 <li class="li">The inputLengths do not agree with the first dimension of
                                    probsDesc.
                                 </li>
                                 <li class="li">The workSpaceSizeInBytes is not sufficient.</li>
                                 <li class="li">The labelLengths is greater than 256.</li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">A compute or data type other than FLOAT was chosen, or an unknown algorithm
                                 type was chosen.
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetCudartVersion"><a name="cudnnGetCudartVersion" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetCudartVersion" name="cudnnGetCudartVersion" shape="rect">4.109.&nbsp;cudnnGetCudartVersion</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">size_t cudnnGetCudartVersion()</pre><p class="p"> The same version of a given cuDNN library can be compiled against different CUDA Toolkit
                           versions. This routine returns the CUDA Toolkit version that the currently used cuDNN
                           library has been compiled against. 
                        </p>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetDropoutDescriptor"><a name="cudnnGetDropoutDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetDropoutDescriptor" name="cudnnGetDropoutDescriptor" shape="rect">4.110.&nbsp;cudnnGetDropoutDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetDropoutDescriptor(
    cudnnDropoutDescriptor_t    dropoutDesc,
    cudnnHandle_t               handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>                      *dropout,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       **states,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span>         *seed)</pre><p class="p">This function queries the fields of a previously initialized dropout descriptor.</p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">dropoutDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Previously initialized dropout descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dropout </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. The probability with which the value from input is set to 0
                                 during the dropout layer.
                              </p>
                           </dd>
                           <dt class="dt dlterm">states </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Pointer to user-allocated GPU memory that holds random number
                                 generator states.
                              </p>
                           </dd>
                           <dt class="dt dlterm">seed </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Seed used to initialize random number generator states.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The call was successful.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">One or more of the arguments was an invalid pointer.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetErrorString"><a name="cudnnGetErrorString" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetErrorString" name="cudnnGetErrorString" shape="rect">4.111.&nbsp;cudnnGetErrorString</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">char</span> * cudnnGetErrorString(cudnnStatus_t status)</pre><p class="p">This function converts the cuDNN status code to a NUL terminated (ASCIIZ) static string.
                           For example, when the input argument is CUDNN_STATUS_SUCCESS, the returned string is
                           "CUDNN_STATUS_SUCCESS". When an invalid status value is passed to the function, the
                           returned string is "CUDNN_UNKNOWN_STATUS".
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">status</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. cuDNN enumerated status code.
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <p class="p">Pointer to a static, NUL terminated string with the status name.</p>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetFilter4dDescriptor"><a name="cudnnGetFilter4dDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetFilter4dDescriptor" name="cudnnGetFilter4dDescriptor" shape="rect">4.112.&nbsp;cudnnGetFilter4dDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetFilter4dDescriptor(
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t     filterDesc,
    cudnnDataType_t            *dataType,
    cudnnTensorFormat_t        *format,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                        *k,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                        *c,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                        *h,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                        *w)</pre><p class="p">This function queries the parameters of the previouly initialized filter descriptor
                           object. 
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">filterDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created filter descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">datatype </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Data type.
                              </p>
                           </dd>
                           <dt class="dt dlterm">format </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Type of format.
                              </p>
                           </dd>
                           <dt class="dt dlterm">k </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Number of output feature maps.
                              </p>
                           </dd>
                           <dt class="dt dlterm">c </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Number of input feature maps.
                              </p>
                           </dd>
                           <dt class="dt dlterm">h </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Height of each filter.
                              </p>
                           </dd>
                           <dt class="dt dlterm">w </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Width of each filter.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was set successfully.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetFilterNdDescriptor"><a name="cudnnGetFilterNdDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetFilterNdDescriptor" name="cudnnGetFilterNdDescriptor" shape="rect">4.113.&nbsp;cudnnGetFilterNdDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetFilterNdDescriptor(
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t   wDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                             nbDimsRequested,
    cudnnDataType_t                *dataType,
    cudnnTensorFormat_t            *format,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                            *nbDims,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                             filterDimA[])</pre><p class="p">This function queries a previously initialized filter descriptor object. </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">wDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">nbDimsRequested </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Dimension of the expected filter descriptor. It is also the
                                 minimum size of the arrays <samp class="ph codeph">filterDimA</samp> in order to be able
                                 to hold the results
                              </p>
                           </dd>
                           <dt class="dt dlterm">datatype </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Data type.
                              </p>
                           </dd>
                           <dt class="dt dlterm">format </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Type of format.
                              </p>
                           </dd>
                           <dt class="dt dlterm">nbDims </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Actual dimension of the filter.
                              </p>
                           </dd>
                           <dt class="dt dlterm">filterDimA </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Array of dimension of at least
                                 <samp class="ph codeph">nbDimsRequested</samp> that will be filled with the filter
                                 parameters from the provided filter descriptor.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was set successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">The parameter <samp class="ph codeph">nbDimsRequested</samp> is negative. 
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetFusedOpsConstParamPackAttribute"><a name="cudnnGetFusedOpsConstParamPackAttribute" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetFusedOpsConstParamPackAttribute" name="cudnnGetFusedOpsConstParamPackAttribute" shape="rect">4.114.&nbsp;cudnnGetFusedOpsConstParamPackAttribute</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetFusedOpsConstParamPackAttribute(
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFusedOpsConstParamPack_t constPack,
	cudnnFusedOpsConstParamLabel_t paramLabel,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *param,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *isNULL);		</pre><p class="p">This function retrieves the values of the descriptor pointed to by the
                           				<samp class="ph codeph">param</samp> pointer input. The type of the descriptor is indicated by the
                           			enum value of <samp class="ph codeph">paramLabel</samp> input. 
                        </p>
                        <p class="p"><strong class="ph b">Parameters:</strong></p>
                        <div class="tablenoborder"><a name="cudnnGetFusedOpsConstParamPackAttribute__table_hpj_hcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnGetFusedOpsConstParamPackAttribute__table_hpj_hcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1"><strong class="ph b">Parameter</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1"><strong class="ph b">Input / Output</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">constPack</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">The opaque <a class="xref" href="index.html#cudnnFusedOpsConstParamPack_t" shape="rect">cudnnFusedOpsConstParamPack_t</a>  structure that
                                       							contains the various problem size information, such as the shape, layout and
                                       							the type of Tensors, and the descriptors for convolution and activation, for
                                       							the selected sequence of cudnnFusedOps computations. 
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">paramLabel</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Several types of descriptors can be retrieved by this getter function. The
                                       								<samp class="ph codeph">param</samp> input points to the descriptor itself, and this input
                                       							indicates the type of the descriptor pointed to by the <samp class="ph codeph">param</samp>
                                       							input. The <a class="xref" href="index.html#cudnnFusedOpsConstParamLabel_t" shape="rect">cudnnFusedOpsConstParamLabel_t</a>  enumerated type
                                       							enables the selection of the type of the descriptor. See the
                                       								<samp class="ph codeph">param</samp> description below.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">param</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">
                                       <p dir="ltr" class="p">Data pointer to the host memory associated with the descriptor that should be
                                          								retrieved. The type of this descriptor depends on the value of
                                          									<samp class="ph codeph">paramLabel</samp>. For the given <samp class="ph codeph">paramLabel</samp>,
                                          								if the associated value inside the constPack is set to NULL or by default
                                          								NULL, then cuDNN will copy the value or the opaque structure in the
                                          								constPack to the host memory buffer pointed to by <samp class="ph codeph">param</samp>.
                                          								See the table in <span class="keyword apiname">cudnnFusedOpsConstParamLabel_t</span>. 
                                       </p>
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">isNULL</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input/Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">User must pass a pointer to an integer in the host memory in this
                                       							field. If the value in the constPack associated with the given
                                       								<samp class="ph codeph">paramLabel</samp> is by default NULL or previously set by the user
                                       							to NULL, then cuDNN will write a non-zero value to the location pointed by
                                       								<samp class="ph codeph">isNULL</samp>.
                                    </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                        <p class="p"><strong class="ph b">Returns:</strong></p>
                        <div class="tablenoborder"><a name="cudnnGetFusedOpsConstParamPackAttribute__table_usk_kcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnGetFusedOpsConstParamPackAttribute__table_usk_kcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Return Value</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_SUCCESS</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">The descriptor values are retrieved successfully. </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_BAD_PARAM</td>
                                    <td class="entry" valign="top" width="50%" rowspan="1" colspan="1">If either <samp class="ph codeph">constPack</samp> or <samp class="ph codeph">param</samp> or
                                       								<samp class="ph codeph">isNULL</samp> is NULL; or if <samp class="ph codeph">paramLabel</samp> is
                                       							invalid. 
                                    </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetFusedOpsVariantParamPackAttribute"><a name="cudnnGetFusedOpsVariantParamPackAttribute" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetFusedOpsVariantParamPackAttribute" name="cudnnGetFusedOpsVariantParamPackAttribute" shape="rect">4.115.&nbsp;cudnnGetFusedOpsVariantParamPackAttribute</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetFusedOpsVariantParamPackAttribute(
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFusedOpsVariantParamPack_t varPack,
	cudnnFusedOpsVariantParamLabel_t paramLabel,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *ptr);		</pre><p dir="ltr" class="p" id="cudnnGetFusedOpsVariantParamPackAttribute__docs-internal-guid-1c059c8b-7fff-a080-0ddd-32f411cc1965"><a name="cudnnGetFusedOpsVariantParamPackAttribute__docs-internal-guid-1c059c8b-7fff-a080-0ddd-32f411cc1965" shape="rect">
                              <!-- --></a>This function
                           			retrieves the settings of the variable parameter pack descriptor. 
                        </p>
                        <p class="p"><strong class="ph b">Parameters:</strong></p>
                        <div class="tablenoborder"><a name="cudnnGetFusedOpsVariantParamPackAttribute__table_hpj_hcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnGetFusedOpsVariantParamPackAttribute__table_hpj_hcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1"><strong class="ph b">Parameter</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1"><strong class="ph b">Input / Output</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">varPack</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Pointer to the cudnnFusedOps variant parameter pack
                                       								(<samp class="ph codeph">varPack</samp>) descriptor.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">paramLabel</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Type of the buffer pointer parameter (in the <samp class="ph codeph">varPack</samp>
                                       							descriptor). See <a class="xref" href="index.html#cudnnFusedOpsConstParamLabel_t" shape="rect">cudnnFusedOpsConstParamLabel_t</a>. The retrieved
                                       							descriptor values vary according to this type. 
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">ptr</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Pointer to the host or device memory where the retrieved value is written by
                                       							this function. The data type of the pointer, and the host/device memory
                                       							location, depend on the <samp class="ph codeph">paramLabel</samp> input selection. See
                                       								<span class="keyword apiname">cudnnFusedOpsVariantParamLabel_t</span>. 
                                    </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                        <p class="p"><strong class="ph b">Returns:</strong></p>
                        <div class="tablenoborder"><a name="cudnnGetFusedOpsVariantParamPackAttribute__table_usk_kcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnGetFusedOpsVariantParamPackAttribute__table_usk_kcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Return Value</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_SUCCESS</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">The descriptor values are retrieved successfully. </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_BAD_PARAM</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">If either <samp class="ph codeph">varPack</samp> or <samp class="ph codeph">ptr</samp> is
                                       							NULL, or if <samp class="ph codeph">paramLabel</samp> is set to invalid value.
                                    </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetLRNDescriptor"><a name="cudnnGetLRNDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetLRNDescriptor" name="cudnnGetLRNDescriptor" shape="rect">4.116.&nbsp;cudnnGetLRNDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetLRNDescriptor(
    cudnnLRNDescriptor_t    normDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span>               *lrnN,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>                 *lrnAlpha,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>                 *lrnBeta,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>                 *lrnK)</pre><p class="p">This function retrieves values stored in the previously initialized LRN descriptor
                           object. 
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">normDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Handle to a previously created LRN descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">lrnN, lrnAlpha, lrnBeta, lrnK </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Pointers to receive values of parameters stored in the
                                 descriptor object. See <a class="xref" href="index.html#cudnnGetLRNDescriptor" shape="rect">cudnnSetLRNDescriptor</a> for more details. Any of these pointers
                                 can be NULL (no value is returned for the corresponding parameter). 
                              </p>
                           </dd>
                        </dl>
                        <p class="p">Possible error values returned by this function and their meanings are listed below.</p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">Function completed successfully.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetMultiHeadAttnBuffers"><a name="cudnnGetMultiHeadAttnBuffers" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetMultiHeadAttnBuffers" name="cudnnGetMultiHeadAttnBuffers" shape="rect">4.117.&nbsp;cudnnGetMultiHeadAttnBuffers</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetMultiHeadAttnBuffers(
	cudnnHandle_t handle,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnAttnDescriptor_t attnDesc,
	size_t *weightSizeInBytes,
	size_t *workSpaceSizeInBytes,
	size_t *reserveSpaceSizeInBytes);</pre><p dir="ltr" class="p" id="cudnnGetMultiHeadAttnBuffers__docs-internal-guid-abbc405b-7fff-eed1-7b48-a0f164998f1e"><a name="cudnnGetMultiHeadAttnBuffers__docs-internal-guid-abbc405b-7fff-eed1-7b48-a0f164998f1e" shape="rect">
                              <!-- --></a>This function
                           			obtains workspace and reserve space sizes for the multihead attention. When only the
                           			workspace size is requested with NULL value for <samp class="ph codeph">reserveSpaceSizeInBytes</samp>,
                           			it is assumed that the user intention is to invoke
                           				<a class="xref" href="index.html#cudnnMultiHeadAttnForward" shape="rect">cudnnMultiHeadAttnForward</a> in the "inference" mode.
                        </p>
                        <p class="p"><strong class="ph b">Parameters:</strong></p>
                        <div class="tablenoborder"><a name="cudnnGetMultiHeadAttnBuffers__table_hpj_hcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnGetMultiHeadAttnBuffers__table_hpj_hcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1"><strong class="ph b">Parameter</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1"><strong class="ph b">Input / Output</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">handle</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">cuDNN handle.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">attnDesc</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Pointer to a previously initialized multi-head attention
                                       							descriptor.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">weightSizeInBytes</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Size required to store various projection weights.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">workSpaceSizeInBytes</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Size required for workspace. </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">reserveSpaceSizeInBytes</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Size required for the reserve space in training mode. </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                        <p class="p"><strong class="ph b">Returns:</strong></p>
                        <div class="tablenoborder"><a name="cudnnGetMultiHeadAttnBuffers__table_usk_kcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnGetMultiHeadAttnBuffers__table_usk_kcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Return Value</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_SUCCESS </td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">The requested spaces values are evaluated successfully.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_BAD_PARAM </td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">Either invalid values in <samp class="ph codeph">attnDesc</samp> or
                                       								<samp class="ph codeph">workSpaceSizeInBytes</samp> is NULL.
                                    </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetMultiHeadAttnWeights"><a name="cudnnGetMultiHeadAttnWeights" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetMultiHeadAttnWeights" name="cudnnGetMultiHeadAttnWeights" shape="rect">4.118.&nbsp;cudnnGetMultiHeadAttnWeights</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetMultiHeadAttnWeights(
	cudnnHandle_t handle,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnAttnDescriptor_t attnDesc,
	cudnnMultiHeadAttnWeightKind_t wKind,
	size_t weightSizeInBytes,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *w,
	cudnnTensorDescriptor_t wDesc,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> **wAddr);</pre><p dir="ltr" class="p" id="cudnnGetMultiHeadAttnWeights__docs-internal-guid-be2a28f7-7fff-db42-38d1-ff00faafe353"><a name="cudnnGetMultiHeadAttnWeights__docs-internal-guid-be2a28f7-7fff-db42-38d1-ff00faafe353" shape="rect">
                              <!-- --></a>This function
                           			obtains the tensor descriptors and pointers to project weight of a particular kind in the
                           			weight buffer w of size <samp class="ph codeph">weightSizeInBytes</samp>. There are four kinds of
                           			weights, enumerated in the type <a class="xref" href="index.html#cudnnMultiHeadAttnWeightKind_t" shape="rect">cudnnMultiHeadAttnWeightKind_t</a>.
                        </p>
                        <p class="p"><strong class="ph b">Parameters:</strong></p>
                        <div class="tablenoborder"><a name="cudnnGetMultiHeadAttnWeights__table_hpj_hcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnGetMultiHeadAttnWeights__table_hpj_hcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1"><strong class="ph b">Parameter</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1"><strong class="ph b">Input / Output</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">handle</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">A cuDNN context handle.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">attnDesc</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">A previously initialized multi-head attention descriptor.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">wKind</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">The specific weight group (Q, K, V, or O) whose attention weights
                                       							should be retrieved. 
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">weightSizeInBytes</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Pointer to a location, in host memory, where the attention weight
                                       							sizes (in bytes) are stored.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">w</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Pointer to weight buffer in device memory.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">wDesc</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Output</td>
                                    <td class="entry" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">
                                       <p dir="ltr" class="p">Tensor descriptor for the attention weights. </p>
                                       <p dir="ltr" class="p"><samp class="ph codeph">- wDesc.dimA</samp> are all [nHeads, projected size,
                                          								input size]
                                       </p>
                                       <p dir="ltr" class="p"><samp class="ph codeph">- wDesc.strideA</samp> describe how the buffer is
                                          								packed, depending on the projection weight kind.
                                       </p>
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">wAddr</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Output</td>
                                    <td class="entry" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">
                                       <p dir="ltr" class="p">Pointer to a location, in device memory, of the requested weight
                                          								tensor. Weight tensor is three dimensional whose dimensions and layout are
                                          								also returned in tensor descriptor <samp class="ph codeph">wDesc</samp>.
                                       </p>
                                       <p dir="ltr" class="p">If any of queries, keys, values, or output projection size is zero
                                          								in the attention descriptor, then <samp class="ph codeph">wAddr</samp> is set to NULL.
                                          								Check for this before applying the weights.
                                       </p>
                                    </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                        <p class="p"><strong class="ph b">Returns:</strong></p>
                        <div class="tablenoborder"><a name="cudnnGetMultiHeadAttnWeights__table_usk_kcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnGetMultiHeadAttnWeights__table_usk_kcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Return Value</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_SUCCESS </td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">When weight tensor descriptor and address in the device memory
                                       							are successfully determined.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_BAD_PARAM </td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">Invalid or inconsistent value is found. For example when
                                       								<samp class="ph codeph">wKind</samp> does not have a valid value or when
                                       								<samp class="ph codeph">weightSizeInBytes</samp> is not equal to the weight buffer size as
                                       							computed by <a class="xref" href="index.html#cudnnGetMultiHeadAttnBuffers" shape="rect">cudnnGetMultiHeadAttnBuffers</a>.
                                    </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetOpTensorDescriptor"><a name="cudnnGetOpTensorDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetOpTensorDescriptor" name="cudnnGetOpTensorDescriptor" shape="rect">4.119.&nbsp;cudnnGetOpTensorDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetOpTensorDescriptor(
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnOpTensorDescriptor_t opTensorDesc,
    cudnnOpTensorOp_t               *opTensorOp,
    cudnnDataType_t                 *opTensorCompType,
    cudnnNanPropagation_t           *opTensorNanOpt)</pre><p class="p">This function returns configuration of the passed Tensor Pointwise math descriptor.</p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">opTensorDesc</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Tensor Pointwise math descriptor passed, to get the configuration from.
                              </p>
                           </dd>
                           <dt class="dt dlterm">opTensorOp</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Pointer to the Tensor Pointwise math operation type, associated with this Tensor Pointwise math descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">opTensorCompType</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Pointer to the cuDNN data-type associated with this Tensor Pointwise math descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">opTensorNanOpt</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Pointer to the NAN propagation option associated with this Tensor Pointwise math descriptor.
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The function returned successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">Input Tensor Pointwise math descriptor passed is invalid.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetPooling2dDescriptor"><a name="cudnnGetPooling2dDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetPooling2dDescriptor" name="cudnnGetPooling2dDescriptor" shape="rect">4.120.&nbsp;cudnnGetPooling2dDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetPooling2dDescriptor(
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnPoolingDescriptor_t      poolingDesc,
    cudnnPoolingMode_t                 *mode,
    cudnnNanPropagation_t              *maxpoolingNanOpt,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                *windowHeight,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                *windowWidth,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                *verticalPadding,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                *horizontalPadding,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                *verticalStride,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                *horizontalStride)</pre><p class="p">This function queries a previously created 2D pooling descriptor object. </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">poolingDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created pooling descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">mode </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Enumerant to specify the pooling mode.
                              </p>
                           </dd>
                           <dt class="dt dlterm">maxpoolingNanOpt </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Enumerant to specify the Nan propagation mode.
                              </p>
                           </dd>
                           <dt class="dt dlterm">windowHeight </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Height of the pooling window.
                              </p>
                           </dd>
                           <dt class="dt dlterm">windowWidth </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Width of the pooling window.
                              </p>
                           </dd>
                           <dt class="dt dlterm">verticalPadding </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Size of vertical padding.
                              </p>
                           </dd>
                           <dt class="dt dlterm">horizontalPadding </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Size of horizontal padding.
                              </p>
                           </dd>
                           <dt class="dt dlterm">verticalStride </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Pooling vertical stride.
                              </p>
                           </dd>
                           <dt class="dt dlterm">horizontalStride </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Pooling horizontal stride.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was set successfully.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetPooling2dForwardOutputDim"><a name="cudnnGetPooling2dForwardOutputDim" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetPooling2dForwardOutputDim" name="cudnnGetPooling2dForwardOutputDim" shape="rect">4.121.&nbsp;cudnnGetPooling2dForwardOutputDim</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetPooling2dForwardOutputDim(
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnPoolingDescriptor_t      poolingDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       inputDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                *outN,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                *outC,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                *outH,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                *outW)</pre><p class="p"> This function provides the output dimensions of a tensor after 2d pooling has been
                           applied 
                        </p>
                        <p class="p">Each dimension <samp class="ph codeph">h and w</samp> of the output images is computed as followed:
                        </p><pre xml:space="preserve">
    outputDim = 1 + (inputDim + 2*padding - windowDim)/poolingStride;
    </pre><p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">poolingDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously inititalized pooling descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">inputDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized input tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">N </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Number of images in the output.
                              </p>
                           </dd>
                           <dt class="dt dlterm">C </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Number of channels in the output.
                              </p>
                           </dd>
                           <dt class="dt dlterm">H </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Height of images in the output.
                              </p>
                           </dd>
                           <dt class="dt dlterm">W </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Width of images in the output.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The function launched successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnGetPooling2dForwardOutputDim__ul_c1g_nyh_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnGetPooling2dForwardOutputDim__ul_c1g_nyh_s1b">
                                 <li class="li"><samp class="ph codeph">poolingDesc</samp> has not been initialized.
                                 </li>
                                 <li class="li"><samp class="ph codeph">poolingDesc</samp> or <samp class="ph codeph">inputDesc</samp> has an
                                    invalid number of dimensions (2 and 4 respectively are required).
                                 </li>
                              </ul>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetPoolingNdDescriptor"><a name="cudnnGetPoolingNdDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetPoolingNdDescriptor" name="cudnnGetPoolingNdDescriptor" shape="rect">4.122.&nbsp;cudnnGetPoolingNdDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetPoolingNdDescriptor(
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnPoolingDescriptor_t      poolingDesc,
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                 nbDimsRequested,
cudnnPoolingMode_t                 *mode,
cudnnNanPropagation_t              *maxpoolingNanOpt,
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                *nbDims,
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                 windowDimA[],
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                 paddingA[],
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                                 strideA[])</pre><p class="p">This function queries a previously initialized generic pooling descriptor object. </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">poolingDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created pooling descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">nbDimsRequested </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Dimension of the expected pooling descriptor. It is also the
                                 minimum size of the arrays <samp class="ph codeph">windowDimA</samp>,
                                 <samp class="ph codeph">paddingA</samp> and <samp class="ph codeph">strideA</samp> in order to be
                                 able to hold the results.
                              </p>
                           </dd>
                           <dt class="dt dlterm">mode </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Enumerant to specify the pooling mode.
                              </p>
                           </dd>
                           <dt class="dt dlterm">maxpoolingNanOpt </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Enumerant to specify the Nan propagation mode.
                              </p>
                           </dd>
                           <dt class="dt dlterm">nbDims </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Actual dimension of the pooling descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">windowDimA </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Array of dimension of at least
                                 <samp class="ph codeph">nbDimsRequested</samp> that will be filled with the window
                                 parameters from the provided pooling descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">paddingA </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Array of dimension of at least
                                 <samp class="ph codeph">nbDimsRequested</samp> that will be filled with the padding
                                 parameters from the provided pooling descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">strideA </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Array of dimension at least <samp class="ph codeph">nbDimsRequested</samp>
                                 that will be filled with the stride parameters from the provided pooling
                                 descriptor. 
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was queried successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The parameter <samp class="ph codeph">nbDimsRequested</samp> is greater than
                                 CUDNN_DIM_MAX.
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetPoolingNdForwardOutputDim"><a name="cudnnGetPoolingNdForwardOutputDim" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetPoolingNdForwardOutputDim" name="cudnnGetPoolingNdForwardOutputDim" shape="rect">4.123.&nbsp;cudnnGetPoolingNdForwardOutputDim</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetPoolingNdForwardOutputDim(
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnPoolingDescriptor_t  poolingDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   inputDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                             nbDims,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                             outDimA[])</pre><p class="p"> This function provides the output dimensions of a tensor after Nd pooling has been
                           applied 
                        </p>
                        <p class="p">Each dimension of the <samp class="ph codeph">(nbDims-2)-D</samp> images of the output tensor is
                           computed as followed:
                        </p><pre xml:space="preserve">
    outputDim = 1 + (inputDim + 2*padding - windowDim)/poolingStride;
    </pre><p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">poolingDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously inititalized pooling descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">inputDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized input tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">nbDims </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Number of dimensions in which pooling is to be applied.
                              </p>
                           </dd>
                           <dt class="dt dlterm">outDimA </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Array of nbDims output dimensions. 
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The function launched successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnGetPoolingNdForwardOutputDim__ul_vff_ryh_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnGetPoolingNdForwardOutputDim__ul_vff_ryh_s1b">
                                 <li class="li"><samp class="ph codeph">poolingDesc</samp> has not been initialized.
                                 </li>
                                 <li class="li">The value of <samp class="ph codeph">nbDims</samp> is inconsistent with the
                                    dimensionality of <samp class="ph codeph">poolingDesc</samp> and
                                    <samp class="ph codeph">inputDesc</samp>.
                                 </li>
                              </ul>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetProperty"><a name="cudnnGetProperty" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetProperty" name="cudnnGetProperty" shape="rect">4.124.&nbsp;cudnnGetProperty</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetProperty(
    libraryPropertyType     type,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                    *value)</pre><p class="p">This function writes a specific part of the cuDNN library version number into the
                           provided host storage.
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">type </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Enumerated type that instructs the function to report the
                                 numerical value of the cuDNN major version, minor version, or the patch
                                 level. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">value </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Host pointer where the version information should be written.
                                 
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_INVALID_VALUE</samp></dt>
                           <dd class="dd">
                              <p class="p">Invalid value of the <samp class="ph codeph">type</samp> argument. 
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">Version information was stored successfully at the provided address. </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetReduceTensorDescriptor"><a name="cudnnGetReduceTensorDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetReduceTensorDescriptor" name="cudnnGetReduceTensorDescriptor" shape="rect">4.125.&nbsp;cudnnGetReduceTensorDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetReduceTensorDescriptor(
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnReduceTensorDescriptor_t reduceTensorDesc,
    cudnnReduceTensorOp_t               *reduceTensorOp,
    cudnnDataType_t                     *reduceTensorCompType,
    cudnnNanPropagation_t               *reduceTensorNanOpt,
    cudnnReduceTensorIndices_t          *reduceTensorIndices,
    cudnnIndicesType_t                  *reduceTensorIndicesType)</pre><p class="p">This function queries a previously initialized reduce tensor descriptor object.</p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">reduceTensorDesc</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointer to a previously initialized reduce tensor descriptor object.
                              </p>
                           </dd>
                           <dt class="dt dlterm">reduceTensorOp</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Enumerant to specify the reduce tensor operation.
                              </p>
                           </dd>
                           <dt class="dt dlterm">reduceTensorCompType</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Enumerant to specify the computation datatype of the reduction.
                              </p>
                           </dd>
                           <dt class="dt dlterm">reduceTensorNanOpt</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Enumerant to specify the Nan propagation mode.
                              </p>
                           </dd>
                           <dt class="dt dlterm">reduceTensorIndices</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Enumerant to specify the reduce tensor indices.
                              </p>
                           </dd>
                           <dt class="dt dlterm">reduceTensorIndicesType</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Enumerant to specify the reduce tensor indices type.
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was queried successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">reduceTensorDesc is NULL.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetReductionIndicesSize"><a name="cudnnGetReductionIndicesSize" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetReductionIndicesSize" name="cudnnGetReductionIndicesSize" shape="rect">4.126.&nbsp;cudnnGetReductionIndicesSize</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetReductionIndicesSize(
    cudnnHandle_t                       handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnReduceTensorDescriptor_t reduceDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       aDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       cDesc,
    size_t                              *sizeInBytes)</pre><p class="p">This is a helper function to return the minimum size of the index space to be passed to the reduction given the input and
                           output tensors.
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN library descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">reduceDesc</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointer to a previously initialized reduce tensor descriptor object.
                              </p>
                           </dd>
                           <dt class="dt dlterm">aDesc</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointer to the input tensor descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">cDesc</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointer to the output tensor descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">sizeInBytes</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Minimum size of the index space to be passed to the reduction.
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The index space size is returned successfully.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetReductionWorkspaceSize"><a name="cudnnGetReductionWorkspaceSize" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetReductionWorkspaceSize" name="cudnnGetReductionWorkspaceSize" shape="rect">4.127.&nbsp;cudnnGetReductionWorkspaceSize</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetReductionWorkspaceSize(
    cudnnHandle_t                       handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnReduceTensorDescriptor_t reduceDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       aDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       cDesc,
    size_t                              *sizeInBytes)</pre><p class="p">This is a helper function to return the minimum size of the workspace to be passed to the reduction given the input and output
                           tensors.
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN library descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">reduceDesc</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointer to a previously initialized reduce tensor descriptor object.
                              </p>
                           </dd>
                           <dt class="dt dlterm">aDesc</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointer to the input tensor descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">cDesc</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointer to the output tensor descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">sizeInBytes</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Minimum size of the index space to be passed to the reduction.
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The workspace size is returned successfully.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetRNNBiasMode"><a name="cudnnGetRNNBiasMode" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetRNNBiasMode" name="cudnnGetRNNBiasMode" shape="rect">4.128.&nbsp;cudnnGetRNNBiasMode</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">
cudnnStatus_t cudnnGetRNNBiasMode(
   cudnnRNNDescriptor_t   rnnDesc,
   cudnnRNNBiasMode_t     *biasMode)</pre><p class="p">This function retrieves the RNN bias mode that was configured by <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNBiasMode" shape="rect">cudnnSetRNNBiasMode()</a></samp>. The default value of
                           				<samp class="ph codeph">biasMode</samp> in <samp class="ph codeph">rnnDesc</samp> after <samp class="ph codeph"><a class="xref" href="index.html#cudnnCreateRNNDescriptor" shape="rect">cudnnCreateRNNDescriptor()</a></samp>is
                           				<samp class="ph codeph">CUDNN_RNN_DOUBLE_BIAS</samp>.
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">rnnDesc</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A previously created RNN descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">*biasMode</dt>
                           <dd class="dd"><em class="ph i">Input</em>. Pointer where RNN bias mode should be saved.
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">Either the <samp class="ph codeph">rnnDesc</samp> or <samp class="ph codeph">*biasMode</samp> is
                                 						NULL.
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The <samp class="ph codeph">biasMode</samp> parameter was retrieved set successfully.
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetRNNDataDescriptor"><a name="cudnnGetRNNDataDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetRNNDataDescriptor" name="cudnnGetRNNDataDescriptor" shape="rect">4.129.&nbsp;cudnnGetRNNDataDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">
cudnnStatus_t cudnnGetRNNDataDescriptor(
    cudnnRNNDataDescriptor_t       RNNDataDesc,
    cudnnDataType_t                *dataType,
    cudnnRNNDataLayout_t           *layout,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                            *maxSeqLength,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                            *batchSize,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                            *vectorSize,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                            arrayLengthRequested,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                            seqLengthArray[],
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *paddingFill);
</pre><p class="p">This function retrieves a previously created RNN data descriptor object.</p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">RNNDataDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A previously created and initialized RNN descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dataType </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Pointer to the host memory location to store the datatype of
                                 the RNN data tensor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">layout </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Pointer to the host memory location to store the memory layout
                                 of the RNN data tensor. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">maxSeqLength </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. The maximum sequence length within this RNN data tensor,
                                 including the padding vectors.  
                              </p>
                           </dd>
                           <dt class="dt dlterm">batchSize </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. The number of sequences within the mini-batch. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">vectorSize </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. The vector length (i.e. embedding size) of the input or output
                                 tensor at each timestep. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">arrayLengthRequested </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. The number of elements that the user requested for
                                 <samp class="ph codeph">seqLengthArray</samp>.  
                              </p>
                           </dd>
                           <dt class="dt dlterm">seqLengthArray </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Pointer to the host memory location to store the integer array
                                 describing the length (i.e. number of timesteps) of each sequence. This is
                                 allowed to be a NULL pointer if <samp class="ph codeph">arrayLengthRequested</samp> is
                                 zero. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">paddingFill </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Pointer to the host memory location to store the user defined
                                 symbol. The symbol should be interpreted as the same data type as the RNN
                                 data tensor. 
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The parameters are fetched successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">Any one of these have occurred: </p>
                              <div class="p"><a name="cudnnGetRNNDataDescriptor__ul_g4k_bsr_h2b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnGetRNNDataDescriptor__ul_g4k_bsr_h2b">
                                    <li class="li">Any of <samp class="ph codeph">RNNDataDesc</samp>, <samp class="ph codeph">dataType</samp>,
                                       <samp class="ph codeph">layout</samp>, <samp class="ph codeph">maxSeqLength</samp>,
                                       <samp class="ph codeph">batchSize</samp>, <samp class="ph codeph">vectorSize</samp>,
                                       <samp class="ph codeph">paddingFill</samp> is NULL. 
                                    </li>
                                    <li class="li"><samp class="ph codeph">seqLengthArray</samp> is NULL while
                                       <samp class="ph codeph">arrayLengthRequested</samp> is greater than zero. 
                                    </li>
                                    <li class="li"><samp class="ph codeph">arrayLengthRequested</samp> is less than zero. 
                                    </li>
                                 </ul>
                              </div>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetRNNDescriptor"><a name="cudnnGetRNNDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetRNNDescriptor" name="cudnnGetRNNDescriptor" shape="rect">4.130.&nbsp;cudnnGetRNNDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetRNNDescriptor(
    cudnnHandle_t               handle,
    cudnnRNNDescriptor_t        rnnDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *                       hiddenSize,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *                       numLayers,
    cudnnDropoutDescriptor_t *  dropoutDesc,
    cudnnRNNInputMode_t *       inputMode,
    cudnnDirectionMode_t *      direction,
    cudnnRNNMode_t *            mode,
    cudnnRNNAlgo_t *            algo,
    cudnnDataType_t *           dataType)</pre><p class="p">This function retrieves RNN network parameters that were configured by cudnnSetRNNDescriptor(). All pointers passed to the
                           function should be not-NULL or CUDNN_STATUS_BAD_PARAM is reported.  The function does not check the validity of retrieved
                           network parameters. The parameters are verified when they are written to the RNN descriptor.
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN library descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">rnnDesc</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A previously created and initialized RNN descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">hiddenSize</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Pointer where the size of the hidden state should be stored (the same value is used in every layer).
                              </p>
                           </dd>
                           <dt class="dt dlterm">numLayers </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Pointer where the number of RNN layers should be stored.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dropoutDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Pointer where the handle to a previously configured dropout descriptor should be stored.
                              </p>
                           </dd>
                           <dt class="dt dlterm">inputMode </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Pointer where the mode of the first RNN layer should be saved.
                              </p>
                           </dd>
                           <dt class="dt dlterm">direction</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Pointer where RNN uni-directional/bi-directional mode should be saved.
                              </p>
                           </dd>
                           <dt class="dt dlterm">mode</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Pointer where RNN cell type should be saved.
                              </p>
                           </dd>
                           <dt class="dt dlterm">algo</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Pointer where RNN algorithm type should be stored.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dataType </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Pointer where the data type of RNN weights/biases should be stored.
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">RNN parameters were successfully retrieved from the RNN descriptor.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one pointer passed to the cudnnGetRNNDescriptor() function is NULL.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetRNNLinLayerBiasParams"><a name="cudnnGetRNNLinLayerBiasParams" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetRNNLinLayerBiasParams" name="cudnnGetRNNLinLayerBiasParams" shape="rect">4.131.&nbsp;cudnnGetRNNLinLayerBiasParams</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetRNNLinLayerBiasParams(
    cudnnHandle_t                   handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDescriptor_t      rnnDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                       pseudoLayer,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t   wDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *w,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                       linLayerID,
    cudnnFilterDescriptor_t         linLayerBiasDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           **linLayerBias)</pre><p class="p">This function is used to obtain a pointer and a descriptor of every RNN bias column vector 
                           in each pseudo-layer within the recurrent network defined by rnnDesc and its input width 
                           specified in <samp class="ph codeph">xDesc</samp>.
                        </p>
                        <div class="note note"><span class="notetitle">Note:</span> The <samp class="ph codeph">cudnnGetRNNLinLayerBiasParams()</samp> function was changed in cuDNN version 7.1.1 to match the 
                           behavior of <samp class="ph codeph">cudnnGetRNNLinLayerMatrixParams()</samp>.
                        </div>
                        <p class="p">The <samp class="ph codeph">cudnnGetRNNLinLayerBiasParams()</samp> function returns the RNN bias vector
                           			size in two dimensions: rows and columns. 
                        </p>
                        <div class="p">Due to historical reasons, the minimum number of dimensions in the filter descriptor is three.
                           			In previous versions of the cuDNN library, the function returned the total number of vector
                           			elements in <samp class="ph codeph">linLayerBiasDesc</samp> as follows:
                           			<pre xml:space="preserve">filterDimA[0]=total_size, 
filterDimA[1]=1, 
filterDimA[2]=1</pre> (see the
                           			description of the <a class="xref" href="index.html#cudnnGetFilterNdDescriptor" shape="rect">cudnnGetFilterNdDescriptor()</a> function). 
                        </div>
                        <div class="p">In v7.1.1, the format was changed to:
                           			<pre xml:space="preserve">filterDimA[0]=1, 
filterDimA[1]=rows, 
filterDimA[2]=1 (number of columns). </pre>In
                           			both cases, the "format" field of the filter descriptor should be ignored when retrieved by
                           				<samp class="ph codeph">cudnnGetFilterNdDescriptor()</samp>. 
                        </div>
                        <p class="p">Note that the RNN implementation in cuDNN uses two bias vectors before the cell non-linear
                           			function (see equations in Chapter 3 describing the <samp class="ph codeph">cudnnRNNMode_t</samp> enumerated
                           			type). 
                        </p>
                        <div class="p">Note that the RNN implementation in cuDNN depends on the number of bias vectors before the cell
                           			non-linear function. See the equations in the <a class="xref" href="index.html#datatypes-reference" shape="rect">cudnnRNNMode_t</a> description, for the
                           			enumerated type based on the value of
                           					<strong class="ph b"><samp class="ph codeph">cudnnRNNBiasMode_t</samp></strong><strong class="ph b"><samp class="ph codeph">biasMode</samp></strong> in
                           					<strong class="ph b"><samp class="ph codeph">rnnDesc</samp></strong>. If nonexistent biases are referenced by
                           				<samp class="ph codeph">linLayerID</samp>, then this function sets
                           				<strong class="ph b"><samp class="ph codeph">linLayerBiasDesc</samp></strong> to a zeroed filter descriptor where:
                           			<pre xml:space="preserve">filterDimA[0]=0, 
filterDimA[1]=0, and 
filterDimA[2]=2</pre> and sets
                           					<strong class="ph b"><samp class="ph codeph">linLayerBias</samp></strong> to NULL. See the details for function parameter
                           					<strong class="ph b"><samp class="ph codeph">linLayerID</samp></strong> to determine the relevant values of
                           					<strong class="ph b"><samp class="ph codeph">linLayerID</samp></strong> based on <strong class="ph b"><samp class="ph codeph">biasMode</samp></strong>.
                        </div>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN library descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">rnnDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A previously initialized RNN descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">pseudoLayer </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. The pseudo-layer to query. In uni-directional RNN-s, a pseudo-layer 
                                 is the same as a "physical" layer (pseudoLayer=0 is the RNN input layer, 
                                 pseudoLayer=1 is the first hidden layer). In bi-directional RNN-s there are 
                                 twice as many pseudo-layers in comparison to "physical" layers (pseudoLayer=0 and 
                                 pseudoLayer=1 are both input layers; pseudoLayer=0 refers to the forward part and 
                                 pseudoLayer=1 refers to the backward part of the "physical" input layer; 
                                 pseudoLayer=2 is the forward part of the first hidden layer, and so on).
                              </p>
                           </dd>
                           <dt class="dt dlterm">xDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the input to one
                                 recurrent iteration (to retrieve the RNN input width).
                              </p>
                           </dd>
                           <dt class="dt dlterm">wDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor describing
                                 the weights for the RNN.
                              </p>
                           </dd>
                           <dt class="dt dlterm">w </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the filter
                                 descriptor <samp class="ph codeph">wDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">linLayerID </dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. The linear layer to obtain information about: <a name="cudnnGetRNNLinLayerBiasParams__ul_fcm_nf3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnGetRNNLinLayerBiasParams__ul_fcm_nf3_s1b">
                                    <li class="li"><a name="cudnnGetRNNLinLayerBiasParams__ul_ehk_2fx_ngb" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnGetRNNLinLayerBiasParams__ul_ehk_2fx_ngb">
                                          <li class="li">If <strong class="ph b"><samp class="ph codeph">mode</samp></strong> in <strong class="ph b"><samp class="ph codeph">rnnDesc</samp></strong> was set to
                                             												<strong class="ph b"><samp class="ph codeph">CUDNN_RNN_RELU</samp></strong> or
                                             											<strong class="ph b"><samp class="ph codeph">CUDNN_RNN_TANH</samp></strong>:<a name="cudnnGetRNNLinLayerBiasParams__ul_fhk_2fx_ngb" shape="rect">
                                                <!-- --></a><ul class="ul" id="cudnnGetRNNLinLayerBiasParams__ul_fhk_2fx_ngb">
                                                <li class="li">Value 0 references the bias applied to the input from the previous layer
                                                   												(relevant if <strong class="ph b"><samp class="ph codeph">biasMode</samp></strong> in
                                                   													<strong class="ph b"><samp class="ph codeph">rnnDesc</samp></strong> is <strong class="ph b"><samp class="ph codeph">CUDNN_RNN_SINGLE_INP_BIAS
                                                         													</samp></strong>or <strong class="ph b"><samp class="ph codeph">CUDNN_RNN_DOUBLE_BIAS</samp></strong>).
                                                </li>
                                                <li class="li">Value 1 references the bias applied to the recurrent input (relevant if
                                                   														<strong class="ph b"><samp class="ph codeph">biasMode</samp></strong> in <strong class="ph b"><samp class="ph codeph">rnnDesc</samp></strong> is
                                                   														<strong class="ph b"><samp class="ph codeph">CUDNN_RNN_DOUBLE_BIAS</samp></strong> or
                                                   														<strong class="ph b"><samp class="ph codeph">CUDNN_RNN_SINGLE_REC_BIAS</samp></strong>).
                                                </li>
                                             </ul>
                                          </li>
                                          <li class="li">If mode in <strong class="ph b"><samp class="ph codeph">rnnDesc</samp></strong> was set to
                                             												<strong class="ph b"><samp class="ph codeph">CUDNN_LSTM</samp></strong>,<a name="cudnnGetRNNLinLayerBiasParams__ul_ghk_2fx_ngb" shape="rect">
                                                <!-- --></a><ul class="ul" id="cudnnGetRNNLinLayerBiasParams__ul_ghk_2fx_ngb">
                                                <li class="li">Values of 0, 1, 2 and 3 reference bias applied to the input from the
                                                   												previous layer (relevant if <strong class="ph b"><samp class="ph codeph">biasMode</samp></strong> in
                                                   														<strong class="ph b"><samp class="ph codeph">rnnDesc</samp></strong> is <strong class="ph b"><samp class="ph codeph">CUDNN_RNN_SINGLE_INP_BIAS
                                                         													</samp></strong>or <strong class="ph b"><samp class="ph codeph">CUDNN_RNN_DOUBLE_BIAS</samp></strong>).
                                                </li>
                                                <li class="li">Values of 4, 5, 6 and 7 reference bias applied to the recurrent input
                                                   												(relevant if <strong class="ph b"><samp class="ph codeph">biasMode</samp></strong> in
                                                   													<strong class="ph b"><samp class="ph codeph">rnnDesc</samp></strong> is
                                                   														<strong class="ph b"><samp class="ph codeph">CUDNN_RNN_DOUBLE_BIAS</samp></strong> or
                                                   														<strong class="ph b"><samp class="ph codeph">CUDNN_RNN_SINGLE_REC_BIAS</samp></strong>).
                                                </li>
                                                <li class="li">Values and their associated gates:<a name="cudnnGetRNNLinLayerBiasParams__ul_hhk_2fx_ngb" shape="rect">
                                                      <!-- --></a><ul class="ul" id="cudnnGetRNNLinLayerBiasParams__ul_hhk_2fx_ngb">
                                                      <li class="li">Values 0 and 4 reference the input gate.</li>
                                                      <li class="li">Values 1 and 5 reference the forget gate.</li>
                                                      <li class="li">Values 2 and 6 reference the new memory gate.</li>
                                                      <li class="li">Values 3 and 7 reference the output gate.</li>
                                                   </ul>
                                                </li>
                                             </ul>
                                          </li>
                                          <li class="li">If mode in <strong class="ph b"><samp class="ph codeph">rnnDesc</samp></strong> was set to
                                             												<strong class="ph b"><samp class="ph codeph">CUDNN_GRU</samp></strong>,<a name="cudnnGetRNNLinLayerBiasParams__ul_ihk_2fx_ngb" shape="rect">
                                                <!-- --></a><ul class="ul" id="cudnnGetRNNLinLayerBiasParams__ul_ihk_2fx_ngb">
                                                <li class="li">Values of 0, 1 and 2 reference bias applied to the input from the previous
                                                   												layer (relevant if <strong class="ph b"><samp class="ph codeph">biasMode</samp></strong> in
                                                   														<strong class="ph b"><samp class="ph codeph">rnnDesc</samp></strong> is <strong class="ph b"><samp class="ph codeph">CUDNN_RNN_SINGLE_INP_BIAS
                                                         													</samp></strong>or <strong class="ph b"><samp class="ph codeph">CUDNN_RNN_DOUBLE_BIAS</samp></strong>).
                                                </li>
                                                <li class="li">Values of 3, 4 and 5 reference bias applied to the recurrent input
                                                   												(relevant if <strong class="ph b"><samp class="ph codeph">biasMode</samp></strong> in
                                                   													<strong class="ph b"><samp class="ph codeph">rnnDesc</samp></strong> is
                                                   														<strong class="ph b"><samp class="ph codeph">CUDNN_RNN_DOUBLE_BIAS</samp></strong> or
                                                   														<strong class="ph b"><samp class="ph codeph">CUDNN_RNN_SINGLE_REC_BIAS</samp></strong>).
                                                </li>
                                                <li class="li">Values and their associated gates:<a name="cudnnGetRNNLinLayerBiasParams__ul_jhk_2fx_ngb" shape="rect">
                                                      <!-- --></a><ul class="ul" id="cudnnGetRNNLinLayerBiasParams__ul_jhk_2fx_ngb">
                                                      <li class="li">Values 0 and 3 reference the reset gate.</li>
                                                      <li class="li">Values 1 and 4 reference the update gate.</li>
                                                      <li class="li">Values 2 and 5 reference the new memory gate.</li>
                                                   </ul>
                                                </li>
                                             </ul>
                                          </li>
                                       </ul>
                                    </li>
                                 </ul><a class="xref" href="index.html#datatypes-reference" shape="rect">Also refer to cudnnRNNMode_t for
                                    							additional details on modes and bias modes.</a></div>
                           </dd>
                           <dt class="dt dlterm">linLayerBiasDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Handle to a previously created filter descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">linLayerBias </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the filter
                                 descriptor <samp class="ph codeph">linLayerBiasDesc</samp>.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed below.</p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The query was successful.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function does not support the provided configuration.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <div class="p">At least one of the following conditions are met: <a name="cudnnGetRNNLinLayerBiasParams__ul_ycm_nf3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnGetRNNLinLayerBiasParams__ul_ycm_nf3_s1b">
                                    <li class="li">One of the following arguments is NULL: <samp class="ph codeph">handle</samp>, <samp class="ph codeph">rnnDesc</samp>, <samp class="ph codeph">xDesc</samp>, 
                                       <samp class="ph codeph">wDesc</samp>, <samp class="ph codeph">linLayerBiasDesc</samp>, <samp class="ph codeph">linLayerBias</samp>.
                                    </li>
                                    <li class="li">A data type mismatch was detected between rnnDesc and other descriptors.</li>
                                    <li class="li">Minimum requirement for the 'w' pointer alignment is not satisfied.</li>
                                    <li class="li">The value of <samp class="ph codeph">pseudoLayer</samp> or <samp class="ph codeph">linLayerID</samp> is out of range.
                                    </li>
                                 </ul>
                              </div>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_INVALID_VALUE</samp></dt>
                           <dd class="dd">
                              <p class="p">Some elements of the <samp class="ph codeph">linLayerBias</samp> vector are be outside the 'w' buffer boundaries 
                                 as specified by the <samp class="ph codeph">wDesc</samp> descriptor.
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetRNNLinLayerMatrixParams"><a name="cudnnGetRNNLinLayerMatrixParams" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetRNNLinLayerMatrixParams" name="cudnnGetRNNLinLayerMatrixParams" shape="rect">4.132.&nbsp;cudnnGetRNNLinLayerMatrixParams</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetRNNLinLayerMatrixParams(
cudnnHandle_t                   handle,
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDescriptor_t      rnnDesc,
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                       pseudoLayer,
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   xDesc,
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t   wDesc,
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *w,
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                       linLayerID,
cudnnFilterDescriptor_t         linLayerMatDesc,
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           **linLayerMat)</pre><p class="p">This function is used to obtain a pointer and a descriptor of every RNN 
                           weight matrix in each pseudo-layer within the recurrent network defined by 
                           <samp class="ph codeph">rnnDesc</samp> and its input width specified in <samp class="ph codeph">xDesc</samp>.
                        </p>
                        <div class="note note"><span class="notetitle">Note:</span> The <samp class="ph codeph">cudnnGetRNNLinLayerMatrixParams()</samp> function was enhanced in cuDNN version 7.1.1 
                           without changing its prototype. Instead of reporting the total number of elements in 
                           each weight matrix in the “linLayerMatDesc” filter descriptor, the function returns the 
                           matrix size as two dimensions: rows and columns. Moreover, when a weight matrix does 
                           not exist, e.g due to CUDNN_SKIP_INPUT mode, the function returns NULL in <samp class="ph codeph">linLayerMat</samp> 
                           and all fields of linLayerMatDesc are zero.
                        </div>
                        <p class="p">The <samp class="ph codeph">cudnnGetRNNLinLayerMatrixParams()</samp> function returns the RNN matrix size in two dimensions: 
                           rows and columns.  This allows the user to easily print and initialize RNN weight matrices. 
                           Elements in each weight matrix are arranged in the row-major order. Due to historical reasons, 
                           the minimum number of dimensions in the filter descriptor is three. In previous versions of 
                           the cuDNN library, the function returned the total number of weights in linLayerMatDesc as 
                           follows: filterDimA[0]=total_size, filterDimA[1]=1, filterDimA[2]=1 (see the description 
                           of the cudnnGetFilterNdDescriptor() function). In v7.1.1, the format was changed to: 
                           filterDimA[0]=1, filterDimA[1]=rows, filterDimA[2]=columns. In both cases, the "format" 
                           field of the filter descriptor should be ignored when retrieved by <samp class="ph codeph">cudnnGetFilterNdDescriptor()</samp>.
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN library descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">rnnDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A previously initialized RNN descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">pseudoLayer </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. The pseudo-layer to query. In uni-directional RNN-s, a pseudo-layer is 
                                 the same as a "physical" layer (pseudoLayer=0 is the RNN input layer, pseudoLayer=1 is 
                                 the first hidden layer).  In bi-directional RNN-s there are twice as many pseudo-layers 
                                 in comparison to "physical" layers (pseudoLayer=0 and pseudoLayer=1 are both input layers; 
                                 pseudoLayer=0 refers to the forward part and pseudoLayer=1 refers to the backward part of 
                                 the "physical" input layer; pseudoLayer=2 is the forward part of the first hidden layer, 
                                 and so on).
                              </p>
                           </dd>
                           <dt class="dt dlterm">xDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the input to one
                                 recurrent iteration (to retrieve the RNN input width).
                              </p>
                           </dd>
                           <dt class="dt dlterm">wDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor describing
                                 the weights for the RNN.
                              </p>
                           </dd>
                           <dt class="dt dlterm">w </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the filter
                                 descriptor <samp class="ph codeph">wDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">linLayerID </dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. The linear layer to obtain information about: <a name="cudnnGetRNNLinLayerMatrixParams__ul_ors_jf3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnGetRNNLinLayerMatrixParams__ul_ors_jf3_s1b">
                                    <li class="li">If <samp class="ph codeph">mode</samp> in <samp class="ph codeph">rnnDesc</samp> was set to
                                       <samp class="ph codeph">CUDNN_RNN_RELU</samp> or
                                       <samp class="ph codeph">CUDNN_RNN_TANH</samp> a value of 0 references the
                                       matrix multiplication applied to the input from the previous layer,
                                       a value of 1 references the matrix multiplication applied to the
                                       recurrent input. 
                                    </li>
                                    <li class="li">If <samp class="ph codeph">mode</samp> in <samp class="ph codeph">rnnDesc</samp> was set to
                                       <samp class="ph codeph">CUDNN_LSTM</samp> values of 0-3 reference matrix
                                       multiplications applied to the input from the previous layer, value
                                       of 4-7 reference matrix multiplications applied to the recurrent
                                       input. <a name="cudnnGetRNNLinLayerMatrixParams__ul_yrs_jf3_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnGetRNNLinLayerMatrixParams__ul_yrs_jf3_s1b">
                                          <li class="li">Values 0 and 4 reference the input gate.</li>
                                          <li class="li">Values 1 and 5 reference the forget gate.</li>
                                          <li class="li">Values 2 and 6 reference the new memory gate.</li>
                                          <li class="li">Values 3 and 7 reference the output gate.</li>
                                          <li class="li">Value 8 references the "recurrent" projection matrix when 
                                             enabled by the cudnnSetRNNProjectionLayers() function.
                                          </li>
                                       </ul>
                                    </li>
                                    <li class="li">If <samp class="ph codeph">mode</samp> in <samp class="ph codeph">rnnDesc</samp> was set to
                                       <samp class="ph codeph">CUDNN_GRU</samp> values of 0-2 reference matrix
                                       multiplications applied to the input from the previous layer, value
                                       of 3-5 reference matrix multiplications applied to the recurrent
                                       input. <a name="cudnnGetRNNLinLayerMatrixParams__ul_ass_jf3_s1b" shape="rect">
                                          <!-- --></a><ul class="ul" id="cudnnGetRNNLinLayerMatrixParams__ul_ass_jf3_s1b">
                                          <li class="li">Values 0 and 3 reference the reset gate.</li>
                                          <li class="li">Values 1 and 4 reference the update gate.</li>
                                          <li class="li">Values 2 and 5 reference the new memory gate.</li>
                                       </ul>
                                    </li>
                                 </ul><a class="xref" href="index.html#datatypes-reference" shape="rect">Please refer to Chapter 3 
                                    for additional details on modes.</a></div>
                           </dd>
                           <dt class="dt dlterm">linLayerMatDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Handle to a previously created filter descriptor. When the weight matrix 
                                 does not exist, the returned filer descriptor has all fields set to zero.
                              </p>
                           </dd>
                           <dt class="dt dlterm">linLayerMat</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the filter
                                 descriptor <samp class="ph codeph">linLayerMatDesc</samp>. When the weight matrix does 
                                 not exist, the returned pointer is NULL.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The query was successful.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function does not support the provided configuration.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <div class="p">At least one of the following conditions are met: <a name="cudnnGetRNNLinLayerMatrixParams__ul_bss_jf3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnGetRNNLinLayerMatrixParams__ul_bss_jf3_s1b">
                                    <li class="li">One of the following arguments is NULL: <samp class="ph codeph">handle</samp>, <samp class="ph codeph">rnnDesc</samp>, <samp class="ph codeph">xDesc</samp>, 
                                       <samp class="ph codeph">wDesc</samp>, <samp class="ph codeph">linLayerMatDesc</samp>, <samp class="ph codeph">linLayerMat</samp>.
                                    </li>
                                    <li class="li">A data type mismatch was detected between rnnDesc and other descriptors.</li>
                                    <li class="li">Minimum requirement for the <samp class="ph codeph">'w'</samp> pointer alignment is not satisfied.
                                    </li>
                                    <li class="li">The value of pseudoLayer or linLayerID is out of range.</li>
                                 </ul>
                              </div>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_INVALID_VALUE</samp></dt>
                           <dd class="dd">
                              <p class="p">Some elements of the <samp class="ph codeph">linLayerMat</samp> vector are be outside the <samp class="ph codeph">'w'</samp> buffer boundaries 
                                 as specified by the <samp class="ph codeph">wDesc</samp> descriptor.
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetRNNPaddingMode"><a name="cudnnGetRNNPaddingMode" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetRNNPaddingMode" name="cudnnGetRNNPaddingMode" shape="rect">4.133.&nbsp;cudnnGetRNNPaddingMode</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetRNNPaddingMode(
    cudnnRNNDescriptor_t        rnnDesc,
    cudnnRNNPaddingMode_t       *paddingMode)</pre><p class="p">This function retrieves the RNN padding mode from the RNN descriptor.</p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">rnnDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input/Output</em>. A previously created RNN descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">*paddingMode </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointer to the host memory where the RNN padding mode is saved. 
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The RNN padding mode parameter was retrieved successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">Either the <samp class="ph codeph">rnnDesc</samp> or <samp class="ph codeph">*paddingMode</samp> is NULL. 
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetRNNParamsSize"><a name="cudnnGetRNNParamsSize" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetRNNParamsSize" name="cudnnGetRNNParamsSize" shape="rect">4.134.&nbsp;cudnnGetRNNParamsSize</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetRNNParamsSize(
    cudnnHandle_t                   handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDescriptor_t      rnnDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   xDesc,
    size_t                         *sizeInBytes,
    cudnnDataType_t                 dataType)</pre><p class="p">This function is used to query the amount of parameter space required to execute the RNN
                           described by <samp class="ph codeph">rnnDesc</samp> with inputs dimensions defined by
                           <samp class="ph codeph">xDesc</samp>.
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN library descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">rnnDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A previously initialized RNN descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">xDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the input to one
                                 recurrent iteration.
                              </p>
                           </dd>
                           <dt class="dt dlterm">sizeInBytes </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Minimum amount of GPU memory needed as parameter space to be
                                 able to execute an RNN with the specified descriptor and input tensors.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dataType </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. The data type of the parameters.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The query was successful.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <div class="p">At least one of the following conditions are met: <a name="cudnnGetRNNParamsSize__ul_pg4_ff3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnGetRNNParamsSize__ul_pg4_ff3_s1b">
                                    <li class="li">The descriptor <samp class="ph codeph">rnnDesc</samp> is invalid.
                                    </li>
                                    <li class="li">The descriptor <samp class="ph codeph">xDesc</samp> is invalid.
                                    </li>
                                    <li class="li">The descriptor <samp class="ph codeph">xDesc</samp> is not fully packed.
                                    </li>
                                    <li class="li">The combination of <samp class="ph codeph">dataType</samp> and tensor descriptor
                                       data type is invalid.
                                    </li>
                                 </ul>
                              </div>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The combination of the RNN descriptor and tensor descriptors is not
                                 supported. 
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetRNNProjectionLayers"><a name="cudnnGetRNNProjectionLayers" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetRNNProjectionLayers" name="cudnnGetRNNProjectionLayers" shape="rect">4.135.&nbsp;cudnnGetRNNProjectionLayers</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetRNNProjectionLayers(
    cudnnHandle_t           handle,
    cudnnRNNDescriptor_t    rnnDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                     *recProjSize,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                     *outProjSize)</pre><p class="p"><strong class="ph b">(New for 7.1)</strong></p>
                        <p class="p">This function retrieves the current RNN “projection” parameters. 
                           By default the projection feature is disabled so invoking this function immediately after cudnnSetRNNDescriptor() will yield
                           recProjSize equal to hiddenSize and outProjSize set to zero. 
                           The <samp class="ph codeph">cudnnSetRNNProjectionLayers()</samp> method enables the RNN projection.
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN library descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">rnnDesc</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A previously created and initialized RNN descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">recProjSize</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Pointer where the “recurrent” projection size should be stored.
                              </p>
                           </dd>
                           <dt class="dt dlterm">outProjSize</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Pointer where the “output” projection size should be stored.
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">RNN projection parameters were retrieved successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">A NULL pointer was passed to the function.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetRNNTrainingReserveSize"><a name="cudnnGetRNNTrainingReserveSize" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetRNNTrainingReserveSize" name="cudnnGetRNNTrainingReserveSize" shape="rect">4.136.&nbsp;cudnnGetRNNTrainingReserveSize</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetRNNTrainingReserveSize(
    cudnnHandle_t                   handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDescriptor_t      rnnDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                       seqLength,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t  *xDesc,
    size_t                         *sizeInBytes)</pre><p class="p">This function is used to query the amount of reserved space required for training the RNN
                           described by <samp class="ph codeph">rnnDesc</samp> with inputs dimensions defined by
                           <samp class="ph codeph">xDesc</samp>. The same reserved space buffer must be passed to
                           <samp class="ph codeph">cudnnRNNForwardTraining</samp>, <samp class="ph codeph">cudnnRNNBackwardData</samp> and
                           <samp class="ph codeph">cudnnRNNBackwardWeights</samp>. Each of these calls overwrites the
                           contents of the reserved space, however it can safely be backed up and restored between
                           calls if reuse of the memory is desired.
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN library descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">rnnDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A previously initialized RNN descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">seqLength </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Number of iterations to unroll over. The value of this
                                 							<samp class="ph codeph">seqLength</samp> must not exceed the value that was used in
                                 							<samp class="ph codeph">cudnnGetRNNWorkspaceSize() </samp>function for querying the
                                 						workspace size required to execute the RNN. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">xDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. An array of tensor descriptors describing the input to each
                                 recurrent iteration (one descriptor per iteration). The first dimension
                                 (batch size) of the tensors may decrease from element <samp class="ph codeph">n</samp> to
                                 element <samp class="ph codeph">n+1</samp> but may not increase. Each tensor descriptor
                                 must have the same second dimension (vector length).
                              </p>
                           </dd>
                           <dt class="dt dlterm">sizeInBytes </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Minimum amount of GPU memory needed as reserve space to be
                                 able to train an RNN with the specified descriptor and input tensors.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The query was successful.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <div class="p">At least one of the following conditions are met: <a name="cudnnGetRNNTrainingReserveSize__ul_gxd_cf3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnGetRNNTrainingReserveSize__ul_gxd_cf3_s1b">
                                    <li class="li">The descriptor <samp class="ph codeph">rnnDesc</samp> is invalid.
                                    </li>
                                    <li class="li">At least one of the descriptors in <samp class="ph codeph">xDesc</samp> is
                                       invalid.
                                    </li>
                                    <li class="li">The descriptors in <samp class="ph codeph">xDesc</samp> have inconsistent second
                                       dimensions, strides or data types.
                                    </li>
                                    <li class="li">The descriptors in <samp class="ph codeph">xDesc</samp> have increasing first
                                       dimensions.
                                    </li>
                                    <li class="li">The descriptors in <samp class="ph codeph">xDesc</samp> is not fully packed.
                                    </li>
                                 </ul>
                              </div>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The the data types in tensors described by xDesc is not supported. </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetRNNWorkspaceSize"><a name="cudnnGetRNNWorkspaceSize" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetRNNWorkspaceSize" name="cudnnGetRNNWorkspaceSize" shape="rect">4.137.&nbsp;cudnnGetRNNWorkspaceSize</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetRNNWorkspaceSize(
    cudnnHandle_t                   handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDescriptor_t      rnnDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                       seqLength,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t  *xDesc,
    size_t                         *sizeInBytes)</pre><p class="p">This function is used to query the amount of work space required to execute the RNN
                           described by <samp class="ph codeph">rnnDesc</samp> with inputs dimensions defined by
                           <samp class="ph codeph">xDesc</samp>.
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN library descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">rnnDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A previously initialized RNN descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">seqLength </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Number of iterations to unroll over. Workspace that is
                                 						allocated, based on the size this function provides, cannot be used for
                                 						sequences longer than <samp class="ph codeph">seqLength</samp>. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">xDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. An array of tensor descriptors describing the input to each
                                 						recurrent iteration (one descriptor per iteration). The first dimension
                                 						(batch size) of the tensors may decrease from element <samp class="ph codeph">n</samp> to
                                 						element <samp class="ph codeph">n+1</samp> but may not increase. For example, if you have
                                 						multiple time series in a batch, they can be different lengths. This
                                 						dimension is the batch size for the particular iteration of the sequence,
                                 						and so it should decrease when a sequence in the batch has terminated. 
                              </p>
                              <p class="p">Each tensor descriptor must have the same second dimension (vector
                                 						length).
                              </p>
                           </dd>
                           <dt class="dt dlterm">sizeInBytes </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Minimum amount of GPU memory needed as workspace to be able to
                                 execute an RNN with the specified descriptor and input tensors.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The query was successful.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnGetRNNWorkspaceSize__ul_rlk_w23_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnGetRNNWorkspaceSize__ul_rlk_w23_s1b">
                                 <li class="li">The descriptor <samp class="ph codeph">rnnDesc</samp> is invalid.
                                 </li>
                                 <li class="li">At least one of the descriptors in <samp class="ph codeph">xDesc</samp> is
                                    invalid.
                                 </li>
                                 <li class="li">The descriptors in <samp class="ph codeph">xDesc</samp> have inconsistent second
                                    dimensions, strides or data types.
                                 </li>
                                 <li class="li">The descriptors in <samp class="ph codeph">xDesc</samp> have increasing first
                                    dimensions.
                                 </li>
                                 <li class="li">The descriptors in <samp class="ph codeph">xDesc</samp> is not fully packed.
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The data types in tensors described by xDesc is not supported. </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetSeqDataDescriptor"><a name="cudnnGetSeqDataDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetSeqDataDescriptor" name="cudnnGetSeqDataDescriptor" shape="rect">4.138.&nbsp;cudnnGetSeqDataDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetSeqDataDescriptor(
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnSeqDataDescriptor_t seqDataDesc,
	cudnnDataType_t *dataType,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *nbDims,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> nbDimsRequested,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> dimA[],
	cudnnSeqDataAxis_t axes[],
	size_t *seqLengthArraySize,
	size_t seqLengthSizeRequsted,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> seqLengthArray[],
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *paddingFill);</pre><p dir="ltr" class="p" id="cudnnGetSeqDataDescriptor__docs-internal-guid-d963544c-7fff-ed00-2f73-71bf647e875c"><a name="cudnnGetSeqDataDescriptor__docs-internal-guid-d963544c-7fff-ed00-2f73-71bf647e875c" shape="rect">
                              <!-- --></a>This function
                           			returns the current values stored in a previously initialized sequence data descriptor.
                        </p>
                        <p class="p"><strong class="ph b">Parameters:</strong></p>
                        <div class="tablenoborder"><a name="cudnnGetSeqDataDescriptor__table_hpj_hcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnGetSeqDataDescriptor__table_hpj_hcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1"><strong class="ph b">Parameter</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1"><strong class="ph b">Input / Output</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">seqDataDesc</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input </td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">A sequence data descriptor whose present value is
                                       							requested.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">dataType</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">The data type of the sequence data.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">nbDims</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Number of dimensions.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">nbDimsRequested</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Number of elements of <samp class="ph codeph">dimA</samp> (the axes array)
                                       							requested. Only the first <samp class="ph codeph">nbDimsRequested</samp> elements or
                                       								<samp class="ph codeph">nbDims</samp> elements, whichever is smaller, is reported.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">dimA[]</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Size of the axes dimensions.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">axes[]</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Axes, in the order of outermost to innermost dimension.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">seqLengthArraySize</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Length of <samp class="ph codeph">seqLengthArray</samp>.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">seqLengthSizeRequested</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Number of elements of <samp class="ph codeph">seqLengthArray</samp> requested.
                                       							Only the first <samp class="ph codeph">seqLengthArraySize</samp> elements, or
                                       								<samp class="ph codeph">seqLengthSizeRequsted</samp> elements, whichever is smaller, is
                                       							reported.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">seqLengthArray[]</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Length of each sequence. </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">paddingFill</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Value used for filling the padding elements in the buffer.
                                       						
                                    </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                        <p class="p"><strong class="ph b">Returns:</strong></p>
                        <div class="tablenoborder"><a name="cudnnGetSeqDataDescriptor__table_usk_kcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnGetSeqDataDescriptor__table_usk_kcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Return Value</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_SUCCESS</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">The requested values were obtained successfully.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_BAD_PARAM</td>
                                    <td class="entry" valign="top" width="50%" rowspan="1" colspan="1">
                                       <p dir="ltr" class="p">Any of the below is true for the input arguments:</p>
                                       <p dir="ltr" class="p">-<samp class="ph codeph">seqDataDesc</samp> is NULL.
                                       </p>
                                       <p dir="ltr" class="p">-<samp class="ph codeph">nbDimsRequested</samp> is not positive.
                                       </p>
                                       <p dir="ltr" class="p">-<samp class="ph codeph">seqLengthSizeRequsted</samp> is larger than
                                          									<samp class="ph codeph">seqLengthArraySize dimA[CUDNN_SEQDATA_BATCH_DIM] *
                                             									dimA[CUDNN_SEQDATA_BEAM_DIM]</samp></p>
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_NOT_SUPPORTED</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">A value not supported is encountered. For example, the
                                       								<samp class="ph codeph">nbDimsRequested</samp> is larger than CUDNN_SEQDATA_DIM_COUNT. See
                                       								<samp class="ph codeph">cudnnSeqDataAxis_t</samp>.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_INTERNAL_ERROR</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">Encountered an invalid field value in
                                       								<samp class="ph codeph">seqDataDesc</samp>.
                                    </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetStream"><a name="cudnnGetStream" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetStream" name="cudnnGetStream" shape="rect">4.139.&nbsp;cudnnGetStream</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetStream(
    cudnnHandle_t   handle,
    cudaStream_t   *streamId)</pre><p class="p">This function retrieves the user CUDA stream programmed in the cuDNN handle. When the
                           user's CUDA stream was not set in the cuDNN handle, this function reports the
                           null-stream. 
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointer to the cuDNN handle.
                              </p>
                           </dd>
                           <dt class="dt dlterm">streamID</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Pointer where the current CUDA stream from the cuDNN handle
                                 should be stored.
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">Invalid (NULL) handle.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The stream identifier was retrieved successfully.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetTensor4dDescriptor"><a name="cudnnGetTensor4dDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetTensor4dDescriptor" name="cudnnGetTensor4dDescriptor" shape="rect">4.140.&nbsp;cudnnGetTensor4dDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetTensor4dDescriptor(
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t  tensorDesc,
    cudnnDataType_t         *dataType,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                     *n,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                     *c,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                     *h,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                     *w,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                     *nStride,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                     *cStride,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                     *hStride,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                     *wStride)</pre><p class="p">This function queries the parameters of the previouly initialized Tensor4D descriptor
                           object.
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">tensorDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously insitialized tensor descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">datatype </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Data type.
                              </p>
                           </dd>
                           <dt class="dt dlterm">n </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Number of images.
                              </p>
                           </dd>
                           <dt class="dt dlterm">c </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Number of feature maps per image.
                              </p>
                           </dd>
                           <dt class="dt dlterm">h </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Height of each feature map.
                              </p>
                           </dd>
                           <dt class="dt dlterm">w </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Width of each feature map.
                              </p>
                           </dd>
                           <dt class="dt dlterm">nStride </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Stride between two consecutive images.
                              </p>
                           </dd>
                           <dt class="dt dlterm">cStride </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Stride between two consecutive feature maps.
                              </p>
                           </dd>
                           <dt class="dt dlterm">hStride </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Stride between two consecutive rows.
                              </p>
                           </dd>
                           <dt class="dt dlterm">wStride </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Stride between two consecutive columns.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The operation succeeded.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetTensorNdDescriptor"><a name="cudnnGetTensorNdDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetTensorNdDescriptor" name="cudnnGetTensorNdDescriptor" shape="rect">4.141.&nbsp;cudnnGetTensorNdDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetTensorNdDescriptor(
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   tensorDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                             nbDimsRequested,
    cudnnDataType_t                *dataType,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                            *nbDims,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                             dimA[],
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                             strideA[])</pre><p class="p">This function retrieves values stored in a previously initialized Tensor descriptor
                           object.
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">tensorDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">nbDimsRequested </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Number of dimensions to extract from a given tensor descriptor.
                                 It is also the minimum size of the arrays <samp class="ph codeph">dimA</samp> and
                                 <samp class="ph codeph">strideA</samp>. If this number is greater than the resulting
                                 nbDims[0], only nbDims[0] dimensions will be returned.
                              </p>
                           </dd>
                           <dt class="dt dlterm">datatype </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Data type.
                              </p>
                           </dd>
                           <dt class="dt dlterm">nbDims </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Actual number of dimensions of the tensor will be returned in
                                 nbDims[0].
                              </p>
                           </dd>
                           <dt class="dt dlterm">dimA </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Array of dimension of at least
                                 <samp class="ph codeph">nbDimsRequested</samp> that will be filled with the dimensions
                                 from the provided tensor descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">strideA </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Array of dimension of at least <samp class="ph codeph">nbDimsRequested</samp>
                                 that will be filled with the strides from the provided tensor
                                 descriptor.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The results were returned successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">Either <samp class="ph codeph">tensorDesc</samp> or <samp class="ph codeph">nbDims</samp> pointer is
                                 NULL. 
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetTensorSizeInBytes"><a name="cudnnGetTensorSizeInBytes" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetTensorSizeInBytes" name="cudnnGetTensorSizeInBytes" shape="rect">4.142.&nbsp;cudnnGetTensorSizeInBytes</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetTensorSizeInBytes(
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   tensorDesc,
    size_t                         *size)</pre><p class="p">This function returns the size of the tensor in memory in respect to the given
                           descriptor. This function can be used to know the amount of GPU memory to be allocated
                           to hold that tensor. 
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">tensorDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">size </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Size in bytes needed to hold the tensor in GPU memory.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The results were returned successfully.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetTensorTransformDescriptor"><a name="cudnnGetTensorTransformDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetTensorTransformDescriptor" name="cudnnGetTensorTransformDescriptor" shape="rect">4.143.&nbsp;cudnnGetTensorTransformDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnGetTensorTransformDescriptor(
	cudnnTensorTransformDescriptor_t transformDesc,
	uint32_t nbDimsRequested,
	cudnnTensorFormat_t *destFormat,
	int32_t padBeforeA[],
	int32_t padAfterA[],
	uint32_t foldA[],
	cudnnFoldingDirection_t *direction);
</pre><p dir="ltr" class="p" id="cudnnGetTensorTransformDescriptor__docs-internal-guid-ea0d5d03-7fff-23b1-f188-4be3bd37224f"><a name="cudnnGetTensorTransformDescriptor__docs-internal-guid-ea0d5d03-7fff-23b1-f188-4be3bd37224f" shape="rect">
                              <!-- --></a>This function
                           			returns the values stored in a previously initialized Tensor transform descriptor.
                        </p>
                        <p class="p"><strong class="ph b">Parameters:</strong></p>
                        <div class="tablenoborder"><a name="cudnnGetTensorTransformDescriptor__table_hpj_hcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnGetTensorTransformDescriptor__table_hpj_hcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1"><strong class="ph b">Parameter</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1"><strong class="ph b">Input / Output</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">transformDesc</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">A previously initialized Tensor transform descriptor.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">nbDimsRequested</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">The number of dimensions to consider. See also <a class="xref" href="https://docs.nvidia.com/deeplearning/sdk/cudnn-developer-guide/index.html#tensor-descriptor" target="_blank" shape="rect"><u class="ph u">https://docs.nvidia.com/deeplearning/sdk/cudnn-developer-guide/index.html#tensor-descriptor</u></a></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">destFormat</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">The transform format that will be returned.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">padBeforeA[]</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">An array filled with the amount of padding to add before each
                                       							dimension. The dimension of this <samp class="ph codeph">padBeforeA[]</samp> parameter equal
                                       							to <samp class="ph codeph">nbDimsRequested</samp>.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">padAfterA[]</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">An array filled with the amount of padding to add after each
                                       							dimension. The dimension of this <samp class="ph codeph">padBeforeA[]</samp> parameter is
                                       							equal to <samp class="ph codeph">nbDimsRequested</samp>.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">foldA[]</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">An array that was filled with the folding parameters for each
                                       							spatial dimension. The dimension of this <samp class="ph codeph">foldA[]</samp> array is
                                       								<samp class="ph codeph">nbDimsRequested - 2</samp>.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">direction</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">The setting that selects folding or unfolding. See <a class="xref" href="index.html#cudnnFoldingDirection_t" shape="rect">cudnnFoldingDirection_t</a>.
                                    </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                        <p class="p"><strong class="ph b">Returns:</strong></p>
                        <div class="tablenoborder"><a name="cudnnGetTensorTransformDescriptor__table_usk_kcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnGetTensorTransformDescriptor__table_usk_kcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Return Value</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_SUCCESS</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"> The results were obtained successfully. </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_BAD_PARAM</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">If <samp class="ph codeph">transformDesc</samp> is NULL, or if
                                       								<samp class="ph codeph">nbDimsRequested</samp> is less than 3 or greater than
                                       							CUDNN_DIM_MAX.
                                    </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnGetVersion"><a name="cudnnGetVersion" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnGetVersion" name="cudnnGetVersion" shape="rect">4.144.&nbsp;cudnnGetVersion</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">size_t cudnnGetVersion()</pre><p class="p">This function returns the version number of the cuDNN Library. It returns the
                           <samp class="ph codeph">CUDNN_VERSION</samp> define present in the cudnn.h header file. Starting
                           with release R2, the routine can be used to identify dynamically the current cuDNN
                           Library used by the application. The define <samp class="ph codeph">CUDNN_VERSION</samp> can be used
                           to have the same application linked against different cuDNN versions using conditional
                           compilation statements. 
                        </p>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnIm2Col"><a name="cudnnIm2Col" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnIm2Col" name="cudnnIm2Col" shape="rect">4.145.&nbsp;cudnnIm2Col</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnIm2Col(
    cudnnHandle_t                   handle,
    cudnnTensorDescriptor_t         srcDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *srcData,
    cudnnFilterDescriptor_t         filterDesc,   
    cudnnConvolutionDescriptor_t    convDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *colBuffer)</pre><p class="p">This function constructs the A matrix necessary to perform a forward pass of GEMM convolution. 
                           This A matrix has a height of batch_size*y_height*y_width and width of input_channels*filter_height*filter_width, where batch_size
                           is xDesc's first dimension, 
                           y_height/y_width are computed from <samp class="ph codeph">cudnnGetConvolutionNdForwardOutputDim()</samp>, input_channels is xDesc's second dimension, 
                           filter_height/filter_width are wDesc's third and fourth dimension. The A matrix is stored in format HW-fully-packed in GPU
                           memory.
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">srcDesc</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">srcData</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the input tensor descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">filterDesc</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">convDesc</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized convolution descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">colBuffer</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Data pointer to GPU memory storing the output matrix.
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">srcData or colBuffer is NULL.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">Any of srcDesc, filterDesc, convDesc has dataType of CUDNN_DATA_INT8, CUDNN_DATA_INT8x4, CUDNN_DATA_INT8, or CUDNN_DATA_INT8x4
                                 convDesc has groupCount larger than 1.
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The cuda kernel execution was unsuccessful.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The output data array is successfully generated.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnInitTransformDest"><a name="cudnnInitTransformDest" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnInitTransformDest" name="cudnnInitTransformDest" shape="rect">4.146.&nbsp;cudnnInitTransformDest</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnInitTransformDest(
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorTransformDescriptor_t transformDesc,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t srcDesc,
	cudnnTensorDescriptor_t destDesc,
	size_t *destSizeInBytes);
</pre><div class="p" dir="ltr" id="cudnnInitTransformDest__docs-internal-guid-667464f6-7fff-5fc8-2e68-45b904e91c8a"><a name="cudnnInitTransformDest__docs-internal-guid-667464f6-7fff-5fc8-2e68-45b904e91c8a" shape="rect">
                              <!-- --></a>
                           			
                           			This function
                           					initializes and returns a destination Tensor descriptor <samp class="ph codeph">destDesc</samp> for
                           					Tensor transform operations. The initialization is done with the desired parameters
                           					described in the transform descriptor <a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a>. 
                           				
                           <div class="note note"><span class="notetitle">Note:</span> The returned Tensor descriptor will be packed.
                           </div>
                        </div>
                        <p class="p"><strong class="ph b">Parameters:</strong></p>
                        <div class="tablenoborder"><a name="cudnnInitTransformDest__table_hpj_hcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnInitTransformDest__table_hpj_hcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1"><strong class="ph b">Parameter</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1"><strong class="ph b">Input / Output</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">transformDesc</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Handle to a previously initialized Tensor transform
                                       							descriptor.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">srcDesc</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Handle to a previously initialized Tensor descriptor.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">destDesc</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Handle of the Tensor descriptor that will be initialized and
                                       							returned.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">destSizeInBytes</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">A pointer to hold the size, in bytes, of the new Tensor.</td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                        <p class="p"><strong class="ph b">Returns:</strong></p>
                        <div class="tablenoborder"><a name="cudnnInitTransformDest__table_usk_kcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnInitTransformDest__table_usk_kcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Return Value</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_SUCCESS</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">The Tensor descriptor was initialized successfully.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_BAD_PARAM</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">If either <samp class="ph codeph">srcDesc</samp> or <samp class="ph codeph">destDesc</samp>
                                       							is NULL, or if the Tensor descriptor’s <a class="xref" href="https://docs.nvidia.com/deeplearning/sdk/cudnn-developer-guide/index.html#tensor-descriptor" target="_blank" shape="rect"><u class="ph u">nbDims </u></a>is incorrect.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_NOT_SUPPORTED</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">If the provided configuration is not 4D.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_EXECUTION_FAILED</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">Function failed to launch on the GPU.</td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnLRNCrossChannelBackward"><a name="cudnnLRNCrossChannelBackward" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnLRNCrossChannelBackward" name="cudnnLRNCrossChannelBackward" shape="rect">4.147.&nbsp;cudnnLRNCrossChannelBackward</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnLRNCrossChannelBackward(
    cudnnHandle_t                    handle,
    cudnnLRNDescriptor_t             normDesc,
    cudnnLRNMode_t                   lrnMode,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *alpha,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *y,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    dyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *dy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *beta,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    dxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *dx)</pre><p class="p">This function performs the backward LRN layer computation. </p>
                        <div class="note note"><span class="notetitle">Note:</span> Supported formats are: positive-strided, NCHW for 4D x and y, and only NCDHW
                           DHW-packed for 5D (for both x and y). Only non-overlapping 4D and 5D tensors are
                           supported. 
                        </div>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN library descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">normDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously intialized LRN parameter descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">lrnMode </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. LRN layer mode of operation. Currently only
                                 CUDNN_LRN_CROSS_CHANNEL_DIM1 is implemented. Normalization is performed
                                 along the tensor's dimA[1]. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">alpha, beta </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointers to scaling factors (in host memory) used to blend the
                                 layer output value with prior value in the destination tensor as follows:
                                 dstValue = alpha[0]*resultValue + beta[0]*priorDstValue. <a class="xref" href="index.html#general-description" shape="rect"> Please refer to this
                                    section for additional details. </a></p>
                           </dd>
                           <dt class="dt dlterm">yDesc, y </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Tensor descriptor and pointer in device memory for the layer's
                                 y data.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dyDesc, dy </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Tensor descriptor and pointer in device memory for the layer's
                                 input cumulative loss differential data dy (including error
                                 backpropagation).
                              </p>
                           </dd>
                           <dt class="dt dlterm">xDesc, x </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Tensor descriptor and pointer in device memory for the layer's
                                 x data. Note that these values are not modified during backpropagation.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dxDesc, dx </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Tensor descriptor and pointer in device memory for the layer's
                                 resulting cumulative loss differential data dx (including error
                                 backpropagation).
                              </p>
                           </dd>
                        </dl>
                        <p class="p">Possible error values returned by this function and their meanings are listed below.</p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The computation was performed successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnLRNCrossChannelBackward__ul_uhk_x13_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnLRNCrossChannelBackward__ul_uhk_x13_s1b">
                                 <li class="li">One of the tensor pointers <samp class="ph codeph">x, y</samp> is NULL.
                                 </li>
                                 <li class="li">Number of input tensor dimensions is 2 or less.</li>
                                 <li class="li">LRN descriptor parameters are outside of their valid ranges.</li>
                                 <li class="li">One of tensor parameters is 5D but is not in NCDHW DHW-packed
                                    format.
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function does not support the provided configuration. See the following
                                 for some examples of non-supported configurations:
                              </p><a name="cudnnLRNCrossChannelBackward__ul_c3k_x13_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnLRNCrossChannelBackward__ul_c3k_x13_s1b">
                                 <li class="li">Any of the input tensor datatypes is not the same as any of the output
                                    tensor datatype.
                                 </li>
                                 <li class="li">Any pairwise tensor dimensions mismatch for x,y,dx,dy.</li>
                                 <li class="li">Any tensor parameters strides are negative.</li>
                              </ul>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnLRNCrossChannelForward"><a name="cudnnLRNCrossChannelForward" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnLRNCrossChannelForward" name="cudnnLRNCrossChannelForward" shape="rect">4.148.&nbsp;cudnnLRNCrossChannelForward</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnLRNCrossChannelForward(
    cudnnHandle_t                    handle,
    cudnnLRNDescriptor_t             normDesc,
    cudnnLRNMode_t                   lrnMode,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *alpha,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *beta,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *y)</pre><p class="p">This function performs the forward LRN layer computation. </p>
                        <div class="note note"><span class="notetitle">Note:</span> Supported formats are: positive-strided, NCHW for 4D x and y, and only NCDHW
                           DHW-packed for 5D (for both x and y). Only non-overlapping 4D and 5D tensors are
                           supported. 
                        </div>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN library descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">normDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously intialized LRN parameter descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">lrnMode </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. LRN layer mode of operation. Currently only
                                 CUDNN_LRN_CROSS_CHANNEL_DIM1 is implemented. Normalization is performed
                                 along the tensor's dimA[1]. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">alpha, beta </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointers to scaling factors (in host memory) used to blend the
                                 layer output value with prior value in the destination tensor as follows:
                                 dstValue = alpha[0]*resultValue + beta[0]*priorDstValue. <a class="xref" href="index.html#general-description" shape="rect"> Please refer to this
                                    section for additional details. </a></p>
                           </dd>
                           <dt class="dt dlterm">xDesc, yDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Tensor descriptor objects for the input and output tensors.
                              </p>
                           </dd>
                           <dt class="dt dlterm">x </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Input tensor data pointer in device memory.
                              </p>
                           </dd>
                           <dt class="dt dlterm">y </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Output tensor data pointer in device memory.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">Possible error values returned by this function and their meanings are listed below.</p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The computation was performed successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnLRNCrossChannelForward__ul_bhx_s13_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnLRNCrossChannelForward__ul_bhx_s13_s1b">
                                 <li class="li">One of the tensor pointers <samp class="ph codeph">x, y</samp> is NULL.
                                 </li>
                                 <li class="li">Number of input tensor dimensions is 2 or less.</li>
                                 <li class="li">LRN descriptor parameters are outside of their valid ranges.</li>
                                 <li class="li">One of tensor parameters is 5D but is not in NCDHW DHW-packed
                                    format.
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function does not support the provided configuration. See the following
                                 for some examples of non-supported configurations:
                              </p><a name="cudnnLRNCrossChannelForward__ul_jhx_s13_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnLRNCrossChannelForward__ul_jhx_s13_s1b">
                                 <li class="li">Any of the input tensor datatypes is not the same as any of the output
                                    tensor datatype.
                                 </li>
                                 <li class="li">x and y tensor dimensions mismatch.</li>
                                 <li class="li">Any tensor parameters strides are negative.</li>
                              </ul>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnMakeFusedOpsPlan"><a name="cudnnMakeFusedOpsPlan" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnMakeFusedOpsPlan" name="cudnnMakeFusedOpsPlan" shape="rect">4.149.&nbsp;cudnnMakeFusedOpsPlan</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnMakeFusedOpsPlan(
	cudnnHandle_t handle,
	cudnnFusedOpsPlan_t plan,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFusedOpsConstParamPack_t constPack,
	size_t *workspaceSizeInBytes); 		</pre><p class="p">This function determines the optimum kernel to execute, and the workspace size the user should
                           			allocate, prior to the actual execution of the fused operations by <a class="xref" href="index.html#cudnnFusedOpsExecute" shape="rect">cudnnFusedOpsExecute</a>. 
                        </p>
                        <p class="p"><strong class="ph b">Parameters:</strong></p>
                        <div class="tablenoborder"><a name="cudnnMakeFusedOpsPlan__table_hpj_hcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnMakeFusedOpsPlan__table_hpj_hcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1"><strong class="ph b">Parameter</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1"><strong class="ph b">Input / Output</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">handle</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Pointer to the cuDNN library context. </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">plan</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Pointer to a previously-created and initialized plan descriptor.
                                       						
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">constPack</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Pointer to the descriptor to the const parameters pack. </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">workspaceSizeInBytes</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">The amount of workspace size the user should allocate for the
                                       							execution of this plan. 
                                    </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                        <p class="p"><strong class="ph b">Returns:</strong></p>
                        <div class="tablenoborder"><a name="cudnnMakeFusedOpsPlan__table_usk_kcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnMakeFusedOpsPlan__table_usk_kcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Return Value</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_BAD_PARAM</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">If any of the inputs is NULL, or if the type of cudnnFusedOps_t
                                       							in the <samp class="ph codeph">constPack</samp> descriptor is unsupported.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_SUCCESS</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">The function executed successfully. </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnMultiHeadAttnBackwardData"><a name="cudnnMultiHeadAttnBackwardData" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnMultiHeadAttnBackwardData" name="cudnnMultiHeadAttnBackwardData" shape="rect">4.150.&nbsp;cudnnMultiHeadAttnBackwardData</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnMultiHeadAttnBackwardData(
	cudnnHandle_t handle,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnAttnDescriptor_t attnDesc,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *loWinIdx,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *hiWinIdx,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *seqLengthArrayDQDO,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *seqLengthArrayDKDV,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnSeqDataDescriptor_t doDesc,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *dout,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnSeqDataDescriptor_t dqDesc,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *dqueries,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *queries,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnSeqDataDescriptor_t dkDesc,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *dkeys,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *keys,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnSeqDataDescriptor_t dvDesc,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *dvalues,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *values,
	size_t weightSizeInBytes,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *w,
	size_t workSpaceSizeInBytes,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *workSpace,
	size_t reserveSpaceSizeInBytes,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *reserveSpace);</pre><p dir="ltr" class="p" id="cudnnMultiHeadAttnBackwardData__docs-internal-guid-0eaa8c2b-7fff-7d3b-da2a-c0eee8303faf"><a name="cudnnMultiHeadAttnBackwardData__docs-internal-guid-0eaa8c2b-7fff-7d3b-da2a-c0eee8303faf" shape="rect">
                              <!-- --></a>This function
                           			computes the data gradients with backpropagation. 
                        </p>
                        <p class="p"><strong class="ph b">Parameters:</strong></p>
                        <div class="tablenoborder"><a name="cudnnMultiHeadAttnBackwardData__table_hpj_hcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnMultiHeadAttnBackwardData__table_hpj_hcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1"><strong class="ph b">Parameter</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1"><strong class="ph b">Input / Output</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">handle</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">A cuDNN context handle.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">attnDesc</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">A previously initialized multi-head attention descriptor.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">loWinIdx, hiWinIdx</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">An array of lower (inclusive) and upper (exclusive) key and value
                                       							time steps windows.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">seqLengthArrayDQDO</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Sequence lengths of queries and output sequences data.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">seqLengthArrayDKDV</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Sequence lengths of keys and values sequences data.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">doDesc</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Descriptor for output gradient sequence data.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">dout</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Output gradient data in device memory.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">dqDesc</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Descriptor for queries sequence data.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">dqueries</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Queries gradient data in device memory.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">queries</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Queries data in device memory.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">dkDesc</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Descriptor for the keys vectors.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">dkeys</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Keys gradient data in device memory.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">keys</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Keys data in device memory.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">dvDesc</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Descriptor for the values vectors.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">dvalues</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Values gradient data in device memory.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">values</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Values data in device memory.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">weightSizeInBytes</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Pointer to a location, in host memory, where the attention weight
                                       							sizes (in bytes) are stored.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">w</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Weight data in device memory.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">workSpaceSizeInBytes</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Pointer to a location, in host memory, of the workspace size (in
                                       							bytes). For inference and training.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">workSpace</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Workspace data in device memory.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">reserveSpaceSizeInBytes</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Pointer to a location, in host memory, of the reserve space size
                                       							(in bytes). For training.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">reserveSpace</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input/Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Reserve space data in device memory.</td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                        <p class="p"><strong class="ph b">Returns:</strong></p>
                        <div class="tablenoborder"><a name="cudnnMultiHeadAttnBackwardData__table_usk_kcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnMultiHeadAttnBackwardData__table_usk_kcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Return Value</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_SUCCESS </td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">The forward calculation is successful.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_EXECUTION_FAILED</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">Failed to launch the kernel, or other kernel errors.</td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnMultiHeadAttnBackwardWeights"><a name="cudnnMultiHeadAttnBackwardWeights" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnMultiHeadAttnBackwardWeights" name="cudnnMultiHeadAttnBackwardWeights" shape="rect">4.151.&nbsp;cudnnMultiHeadAttnBackwardWeights</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnMultiHeadAttnBackwardWeights(
	cudnnHandle_t handle,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnAttnDescriptor_t attnDesc,
	cudnnWgradMode_t addGrad,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnSeqDataDescriptor_t qDesc,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *queries,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnSeqDataDescriptor_t kDesc,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *keys,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnSeqDataDescriptor_t vDesc,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *values,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnSeqDataDescriptor_t doDesc,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *dout,
	size_t weightSizeInBytes,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *w,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *dw,
	size_t workSpaceSizeInBytes,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *workSpace,
	size_t reserveSpaceSizeInBytes,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *reserveSpace);</pre><p dir="ltr" class="p" id="cudnnMultiHeadAttnBackwardWeights__docs-internal-guid-41e9a3f8-7fff-0b94-4614-fe248914b563"><a name="cudnnMultiHeadAttnBackwardWeights__docs-internal-guid-41e9a3f8-7fff-0b94-4614-fe248914b563" shape="rect">
                              <!-- --></a>This function
                           			computes the weight gradients with backpropagation. 
                        </p>
                        <p class="p"><strong class="ph b">Parameters:</strong></p>
                        <div class="tablenoborder"><a name="cudnnMultiHeadAttnBackwardWeights__table_hpj_hcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnMultiHeadAttnBackwardWeights__table_hpj_hcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1"><strong class="ph b">Parameter</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1"><strong class="ph b">Input / Output</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">handle</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">A cuDNN context handle.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">attnDesc</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">A previously initialized multi-head attention descriptor.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">addGrad</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Weight gradient output mode. See cudnnWgradMode_t
                                       							&lt;link&gt;.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">qDesc</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Descriptor of the query sequence data.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">queries</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Query data in device memory.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">kDesc</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Descriptor for the keys sequence data.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">keys</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Keys data in device memory.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">vDesc</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Descriptor for the values sequence data.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">values</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Values data in device memory.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">doDesc</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Descriptor for the output gradient sequence data.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">dout</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Output gradient data in device memory.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">weightSizeInBytes</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Pointer to a location, in host memory, where the attention weight
                                       							sizes (in bytes) are stored.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">w</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Pointer to the weight buffer address.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">dw</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Weight gradient data in device memory.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">workSpaceSizeInBytes</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Pointer to a location, in host memory, of the workspace size (in
                                       							bytes). For inference and training.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">workSpace</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Workspace data in device memory.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">reserveSpaceSizeInBytes</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Pointer to a location, in host memory, of the reserve space size
                                       							(in bytes). For training.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">reserveSpace</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Reserve space data in device memory.</td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                        <p class="p"><strong class="ph b">Returns:</strong></p>
                        <div class="tablenoborder"><a name="cudnnMultiHeadAttnBackwardWeights__table_usk_kcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnMultiHeadAttnBackwardWeights__table_usk_kcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Return Value</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_SUCCESS </td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">The forward calculation is successful.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_EXECUTION_FAILED</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">Failed to launch the kernel, or other kernel errors.</td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnMultiHeadAttnForward"><a name="cudnnMultiHeadAttnForward" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnMultiHeadAttnForward" name="cudnnMultiHeadAttnForward" shape="rect">4.152.&nbsp;cudnnMultiHeadAttnForward</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnMultiHeadAttnForward(
	cudnnHandle_t handle,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnAttnDescriptor_t attnDesc,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> currIdx,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *loWinIdx,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *hiWinIdx,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *seqLengthArrayQRO,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *seqLengthArrayKV,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnSeqDataDescriptor_t qDesc,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *queries,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *residuals,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnSeqDataDescriptor_t kDesc,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *keys,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnSeqDataDescriptor_t vDesc,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *values,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnSeqDataDescriptor_t oDesc,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *out,
	size_t weightSizeInBytes,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *w,
	size_t workSpaceSizeInBytes,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *workSpace,
	size_t reserveSpaceSizeInBytes,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *reserveSpace);</pre><p class="p">The function cudnnMultiHeadAttnForward() performs the multi-head attention response
                           			computation, as described in the paper <a class="xref" href="https://arxiv.org/abs/1706.03762" target="_blank" shape="rect">Attention Is All You Need.</a></p>
                        <p class="p"><strong class="ph b">Parameters:</strong></p>
                        <div class="tablenoborder"><a name="cudnnMultiHeadAttnForward__table_hpj_hcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnMultiHeadAttnForward__table_hpj_hcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1"><strong class="ph b">Parameter</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1"><strong class="ph b">Input / Output</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">handle</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">A cuDNN context handle.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">attnDesc</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">A previously initialized multi-head attention descriptor.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">currIdx</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Output timestep(s) to compute. &lt; 0 for the training mode, and
                                       							&gt;=0 for the inference mode.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">loWinIdx, hiWinIdx</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">An array of lower (inclusive) and upper (exclusive) key and value
                                       							time steps windows.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">seqLengthArrayQRO</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Length of each sequence of the query, residual, and output
                                       							data.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">seqLengthArrayKV</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Length of each sequence of the key and value data.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">qDesc</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Descriptor for the queries and residual sequence data.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">queries</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Queries data in device memory.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">residuals</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Residual data in device memory. NULL if no residual connection.
                                       						
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">kDesc</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Descriptor for the keys sequence data.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">keys</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Keys data in device memory.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">vDesc</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Descriptor for the values sequence data.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">values</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Values data in device memory.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">oDesc</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Descriptor for the multi-head attention output sequence
                                       							data.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">out</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Output data in device memory.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">weightSizeInBytes</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Pointer to a location, in host memory, where the attention weight
                                       							sizes (in bytes) are stored.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">w</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Weight data in device memory.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">workSpaceSizeInBytes</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Pointer to a location, in host memory, of the workspace size (in
                                       							bytes). For inference and training.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">workSpace</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Workspace data in device memory.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">reserveSpaceSizeInBytes</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Pointer to a location, in host memory, of the reserve space size
                                       							(in bytes). For training.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">reserveSpace</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input/Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Reserve space data in device memory. If this is NULL it is
                                       							inference mode, otherwise it is training. 
                                    </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                        <p class="p"><strong class="ph b">Returns:</strong></p>
                        <div class="tablenoborder"><a name="cudnnMultiHeadAttnForward__table_usk_kcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnMultiHeadAttnForward__table_usk_kcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Return Value</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_SUCCESS </td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">The forward calculation is successful.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_EXECUTION_FAILED</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">Failed to launch the kernel, or other kernel errors.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_INTERNAL_ERROR</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">Inconsistent internal state(s) encountered.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_BAD_PARAM</td>
                                    <td class="entry" valign="top" width="50%" rowspan="1" colspan="1">
                                       <p dir="ltr" class="p">An invalid or incompatible parameter value is encountered. For
                                          								example:
                                       </p>
                                       <p dir="ltr" class="p">- Any required input pointers are NULL </p>
                                       <p dir="ltr" class="p">- currIdx is out of bound or is negative in inference mode
                                          								(indicated by reserveSpace == NULL) 
                                       </p>
                                       <p dir="ltr" class="p">- The descriptor value for attention, query, key, value, and
                                          								output are incompatible with one another. 
                                       </p>
                                       <p dir="ltr" class="p">- Dropout is enabled but with dropout rate &gt;= 1.</p>
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_NOT_SUPPORTED</td>
                                    <td class="entry" valign="top" width="50%" rowspan="1" colspan="1">
                                       <p dir="ltr" class="p">An unsupported parameter value is encountered. For example:</p>
                                       <p dir="ltr" class="p">- A combination of <samp class="ph codeph">dataType</samp> and
                                          									<samp class="ph codeph">mathPrec</samp> that is not supported.
                                       </p>
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_ALLOC_FAILED</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">Not enough device share memory to launch kernel.</td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnOpTensor"><a name="cudnnOpTensor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnOpTensor" name="cudnnOpTensor" shape="rect">4.153.&nbsp;cudnnOpTensor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnOpTensor(
    cudnnHandle_t                     handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnOpTensorDescriptor_t   opTensorDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *alpha1,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t     aDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *A,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *alpha2,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t     bDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *B,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *beta,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t     cDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                             *C)</pre><p class="p">This function implements the equation C = op(alpha1[0] * A, alpha2[0] * B) + beta[0] * C,
                           			given the Tensors A, B, and C and the scaling factors alpha1, alpha2, and beta. The
                           				<samp class="ph codeph">op</samp> to use is indicated by the descriptor <a class="xref" href="index.html#cudnnOpTensorDescriptor_t" shape="rect">cudnnOpTensorDescriptor_t</a>, i.e., the type of <samp class="ph codeph">opTensorDesc</samp>.
                           			Currently-supported ops are listed by the <a class="xref" href="index.html#cudnnOpTensorOp_t" shape="rect">cudnnOpTensorOp_t</a> enum.
                        </p>
                        <div class="p">The following restrictions on the input and destination Tensors apply:<a name="cudnnOpTensor__ul_atx_hl5_yhb" shape="rect">
                              <!-- --></a><ul class="ul" id="cudnnOpTensor__ul_atx_hl5_yhb">
                              <li class="li liexpand">Each dimension of the input Tensor <samp class="ph codeph">A</samp> must match the corresponding
                                 					dimension of the destination Tensor <samp class="ph codeph">C</samp>, and each dimension of the
                                 					input Tensor <samp class="ph codeph">B</samp> must match the corresponding dimension of the
                                 					destination Tensor <samp class="ph codeph">C</samp> or must be equal to 1. In the latter case, the
                                 					same value from the input Tensor <samp class="ph codeph">B</samp> for those dimensions will be used
                                 					to blend into the <samp class="ph codeph">C</samp> Tensor.
                              </li>
                              <li class="li liexpand">The data types of the input Tensors <samp class="ph codeph">A</samp> and <samp class="ph codeph">B</samp>, and the destination
                                 					Tensor C, must satisfy the table <a class="xref" href="index.html#cudnnOpTensor__table_supported_datatypes" shape="rect">Table 14</a>.
                                 					
                              </li>
                           </ul>
                        </div>
                        <div class="p">
                           <div class="tablenoborder"><a name="cudnnOpTensor__table_supported_datatypes" shape="rect">
                                 <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnOpTensor__table_supported_datatypes" class="table" frame="border" border="1" rules="all">
                                 <caption><span class="tablecap">Table 14. Supported Datatypes</span></caption>
                                 <thead class="thead" align="left">
                                    <tr class="row">
                                       <th class="entry" align="center" valign="top" width="29.537953795379536%" id="d54e46441" rowspan="1" colspan="1"><samp class="ph codeph">opTensorCompType</samp> in <samp class="ph codeph">opTensorDesc</samp></th>
                                       <th class="entry" align="center" valign="top" width="19.966996699669963%" id="d54e46449" rowspan="1" colspan="1">A</th>
                                       <th class="entry" align="center" valign="top" width="16.5016501650165%" id="d54e46452" rowspan="1" colspan="1">B</th>
                                       <th class="entry" align="center" valign="top" width="33.993399339933994%" id="d54e46455" rowspan="1" colspan="1">C (destination)</th>
                                    </tr>
                                 </thead>
                                 <tbody class="tbody">
                                    <tr class="row">
                                       <td class="entry" align="center" valign="top" width="29.537953795379536%" headers="d54e46441" rowspan="1" colspan="1">FLOAT</td>
                                       <td class="entry" align="center" valign="top" width="19.966996699669963%" headers="d54e46449" rowspan="1" colspan="1">FLOAT</td>
                                       <td class="entry" align="center" valign="top" width="16.5016501650165%" headers="d54e46452" rowspan="1" colspan="1">FLOAT</td>
                                       <td class="entry" align="center" valign="top" width="33.993399339933994%" headers="d54e46455" rowspan="1" colspan="1">FLOAT</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" align="center" valign="top" width="29.537953795379536%" headers="d54e46441" rowspan="1" colspan="1">FLOAT</td>
                                       <td class="entry" align="center" valign="top" width="19.966996699669963%" headers="d54e46449" rowspan="1" colspan="1">INT8</td>
                                       <td class="entry" align="center" valign="top" width="16.5016501650165%" headers="d54e46452" rowspan="1" colspan="1">INT8</td>
                                       <td class="entry" align="center" valign="top" width="33.993399339933994%" headers="d54e46455" rowspan="1" colspan="1">FLOAT</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" align="center" valign="top" width="29.537953795379536%" headers="d54e46441" rowspan="1" colspan="1">FLOAT</td>
                                       <td class="entry" align="center" valign="top" width="19.966996699669963%" headers="d54e46449" rowspan="1" colspan="1">HALF</td>
                                       <td class="entry" align="center" valign="top" width="16.5016501650165%" headers="d54e46452" rowspan="1" colspan="1">HALF</td>
                                       <td class="entry" align="center" valign="top" width="33.993399339933994%" headers="d54e46455" rowspan="1" colspan="1">FLOAT</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" align="center" valign="top" width="29.537953795379536%" headers="d54e46441" rowspan="1" colspan="1">DOUBLE</td>
                                       <td class="entry" align="center" valign="top" width="19.966996699669963%" headers="d54e46449" rowspan="1" colspan="1">DOUBLE</td>
                                       <td class="entry" align="center" valign="top" width="16.5016501650165%" headers="d54e46452" rowspan="1" colspan="1">DOUBLE</td>
                                       <td class="entry" align="center" valign="top" width="33.993399339933994%" headers="d54e46455" rowspan="1" colspan="1">DOUBLE</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" align="center" valign="top" width="29.537953795379536%" headers="d54e46441" rowspan="1" colspan="1">FLOAT</td>
                                       <td class="entry" align="center" valign="top" width="19.966996699669963%" headers="d54e46449" rowspan="1" colspan="1">FLOAT</td>
                                       <td class="entry" align="center" valign="top" width="16.5016501650165%" headers="d54e46452" rowspan="1" colspan="1">FLOAT</td>
                                       <td class="entry" align="center" valign="top" width="33.993399339933994%" headers="d54e46455" rowspan="1" colspan="1">HALF</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" align="center" valign="top" width="29.537953795379536%" headers="d54e46441" rowspan="1" colspan="1">FLOAT</td>
                                       <td class="entry" align="center" valign="top" width="19.966996699669963%" headers="d54e46449" rowspan="1" colspan="1">HALF </td>
                                       <td class="entry" align="center" valign="top" width="16.5016501650165%" headers="d54e46452" rowspan="1" colspan="1">HALF</td>
                                       <td class="entry" align="center" valign="top" width="33.993399339933994%" headers="d54e46455" rowspan="1" colspan="1">HALF</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" align="center" valign="top" width="29.537953795379536%" headers="d54e46441" rowspan="1" colspan="1">FLOAT</td>
                                       <td class="entry" align="center" valign="top" width="19.966996699669963%" headers="d54e46449" rowspan="1" colspan="1">INT8</td>
                                       <td class="entry" align="center" valign="top" width="16.5016501650165%" headers="d54e46452" rowspan="1" colspan="1">INT8</td>
                                       <td class="entry" align="center" valign="top" width="33.993399339933994%" headers="d54e46455" rowspan="1" colspan="1">INT8</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" align="center" valign="top" width="29.537953795379536%" headers="d54e46441" rowspan="1" colspan="1">FLOAT</td>
                                       <td class="entry" align="center" valign="top" width="19.966996699669963%" headers="d54e46449" rowspan="1" colspan="1">FLOAT</td>
                                       <td class="entry" align="center" valign="top" width="16.5016501650165%" headers="d54e46452" rowspan="1" colspan="1">FLOAT</td>
                                       <td class="entry" align="center" valign="top" width="33.993399339933994%" headers="d54e46455" rowspan="1" colspan="1">INT8</td>
                                    </tr>
                                 </tbody>
                              </table>
                           </div>
                        </div>
                        <div class="note note"><span class="notetitle">Note:</span> All Tensor formats up to dimension five (5) are supported. This routine does not
                           			support Tensor formats beyond these dimensions.
                        </div>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">opTensorDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized op Tensor descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">alpha1, alpha2, beta </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointers to scaling factors (in host memory) used to blend the
                                 						source value with prior value in the destination Tensor as indicated by the above
                                 						op equation. <a class="xref" href="index.html#general-description" shape="rect">Refer to
                                    							this section for additional details.</a></p>
                           </dd>
                           <dt class="dt dlterm">aDesc, bDesc, cDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized Tensor descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">A, B </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointer to data of the Tensors described by the
                                 							<samp class="ph codeph">aDesc</samp> and <samp class="ph codeph">bDesc</samp> descriptors,
                                 						respectively.
                              </p>
                           </dd>
                           <dt class="dt dlterm">C </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input/Output</em>. Pointer to data of the Tensor described by the
                                 							<samp class="ph codeph">cDesc</samp> descriptor.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The function executed successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function does not support the provided configuration. See the following
                                 for some examples of non-supported configurations:
                              </p><a name="cudnnOpTensor__ul_qcb_qr1_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnOpTensor__ul_qcb_qr1_s1b">
                                 <li class="li">The dimensions of the bias Tensor and the output Tensor dimensions are
                                    							above 5.
                                 </li>
                                 <li class="li"><samp class="ph codeph">opTensorCompType</samp> is not set as stated above.
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">The data type of the destination Tensor <samp class="ph codeph">C</samp> is unrecognized,
                                 						or the restrictions on the input and destination Tensors, stated above, are not
                                 						met.
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function failed to launch on the GPU.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnPoolingBackward"><a name="cudnnPoolingBackward" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnPoolingBackward" name="cudnnPoolingBackward" shape="rect">4.154.&nbsp;cudnnPoolingBackward</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnPoolingBackward(
    cudnnHandle_t                       handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnPoolingDescriptor_t      poolingDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                         *alpha,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                         *y,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       dyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                         *dy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                         *xData,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                         *beta,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t       dxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                               *dx)</pre><p class="p">This function computes the gradient of a pooling operation.</p>
                        <p class="p">As of cuDNN version 6.0, a deterministic algorithm is implemented for max backwards
                           pooling. This algorithm can be chosen via the pooling mode enum of
                           <samp class="ph codeph">poolingDesc</samp>. The deterministic algorithm has been measured to be up
                           to 50% slower than the legacy max backwards pooling algorithm, or up to 20% faster,
                           depending upon the use case.
                        </p>
                        <div class="note note"><span class="notetitle">Note:</span> All tensor formats are supported, best performance is expected when using
                           <samp class="ph codeph">HW-packed</samp> tensors. Only 2 and 3 spatial dimensions are
                           allowed
                        </div>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">poolingDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized pooling descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">alpha, beta </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointers to scaling factors (in host memory) used to blend the
                                 computation result with prior value in the output layer as follows: dstValue
                                 = alpha[0]*result + beta[0]*priorDstValue. <a class="xref" href="index.html#general-description" shape="rect">Please refer to this
                                    section for additional details.</a></p>
                           </dd>
                           <dt class="dt dlterm">yDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized input tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">y </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">yDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dyDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized input differential tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dy </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">dyData</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">xDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized output tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">x </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the output tensor
                                 descriptor <samp class="ph codeph">xDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dxDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized output differential tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dx </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the output tensor
                                 descriptor <samp class="ph codeph">dxDesc</samp>.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The function launched successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnPoolingBackward__ul_zmt_yyh_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnPoolingBackward__ul_zmt_yyh_s1b">
                                 <li class="li">The dimensions <samp class="ph codeph">n,c,h,w</samp> of the <samp class="ph codeph">yDesc</samp>
                                    and <samp class="ph codeph">dyDesc</samp> tensors differ.
                                 </li>
                                 <li class="li">The strides <samp class="ph codeph">nStride, cStride, hStride, wStride</samp> of the
                                    <samp class="ph codeph">yDesc</samp> and <samp class="ph codeph">dyDesc</samp> tensors
                                    differ.
                                 </li>
                                 <li class="li">The dimensions <samp class="ph codeph">n,c,h,w</samp> of the <samp class="ph codeph">dxDesc</samp>
                                    and <samp class="ph codeph">dxDesc</samp> tensors differ.
                                 </li>
                                 <li class="li">The strides <samp class="ph codeph">nStride, cStride, hStride, wStride</samp> of the
                                    <samp class="ph codeph">xDesc</samp> and <samp class="ph codeph">dxDesc</samp> tensors
                                    differ.
                                 </li>
                                 <li class="li">The <samp class="ph codeph">datatype</samp> of the four tensors differ.
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function does not support the provided configuration. See the following
                                 for some examples of non-supported configurations:
                              </p><a name="cudnnPoolingBackward__ul_hnt_yyh_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnPoolingBackward__ul_hnt_yyh_s1b">
                                 <li class="li">The <samp class="ph codeph">wStride</samp> of input tensor or output tensor is not
                                    1.
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function failed to launch on the GPU.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnPoolingForward"><a name="cudnnPoolingForward" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnPoolingForward" name="cudnnPoolingForward" shape="rect">4.155.&nbsp;cudnnPoolingForward</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnPoolingForward(
    cudnnHandle_t                    handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnPoolingDescriptor_t   poolingDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *alpha,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *beta,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *y)</pre><p class="p">This function computes pooling of input values (i.e., the maximum or average of several
                           adjacent values) to produce an output with smaller height and/or width.
                        </p>
                        <div class="note note"><span class="notetitle">Note:</span> All tensor formats are supported, best performance is expected when using
                           <samp class="ph codeph">HW-packed</samp> tensors. Only 2 and 3 spatial dimensions are
                           allowed.
                        </div>
                        <div class="note note"><span class="notetitle">Note:</span> The dimensions of the output tensor <samp class="ph codeph">yDesc</samp> can be smaller or bigger
                           			than the dimensions advised by the routine
                           				<samp class="ph codeph">cudnnGetPooling2dForwardOutputDim</samp> or
                           				<samp class="ph codeph">cudnnGetPoolingNdForwardOutputDim</samp>.
                        </div>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">poolingDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized pooling descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">alpha, beta </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointers to scaling factors (in host memory) used to blend the
                                 						computation result with prior value in the output layer as follows: dstValue
                                 						= alpha[0]*result + beta[0]*priorDstValue. <a class="xref" href="index.html#scaling-parameters" shape="rect">Refer to this section for additional details.</a></p>
                           </dd>
                           <dt class="dt dlterm">xDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized input tensor descriptor.
                                 						Must be of type FLOAT, or DOUBLE, or HALF, or INT8. See <a class="xref" href="index.html#cudnnDataType_t" shape="rect">cudnnDataType_t.</a></p>
                           </dd>
                           <dt class="dt dlterm">x </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">xDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">yDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized output tensor descriptor.
                                 						Must be of type FLOAT, or DOUBLE, or HALF, or INT8. See <a class="xref" href="index.html#cudnnDataType_t" shape="rect">cudnnDataType_t.</a></p>
                           </dd>
                           <dt class="dt dlterm">y </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the output tensor
                                 descriptor <samp class="ph codeph">yDesc</samp>.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The function launched successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnPoolingForward__ul_e2z_5yh_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnPoolingForward__ul_e2z_5yh_s1b">
                                 <li class="li">The dimensions <samp class="ph codeph">n,c</samp> of the input tensor and output
                                    tensors differ.
                                 </li>
                                 <li class="li">The <samp class="ph codeph">datatype</samp> of the input tensor and output tensors
                                    differs.
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function does not support the provided configuration. </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function failed to launch on the GPU.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnQueryRuntimeError"><a name="cudnnQueryRuntimeError" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnQueryRuntimeError" name="cudnnQueryRuntimeError" shape="rect">4.156.&nbsp;cudnnQueryRuntimeError</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnQueryRuntimeError(
    cudnnHandle_t            handle,
    cudnnStatus_t           *rstatus,
    cudnnErrQueryMode_t      mode,
    cudnnRuntimeTag_t       *tag)</pre><p class="p">cuDNN library functions perform extensive input argument checking before launching GPU
                           kernels. The last step is to verify that the GPU kernel actually started. When a kernel
                           fails to start, CUDNN_STATUS_EXECUTION_FAILED is returned by the corresponding API call.
                           Typically, after a GPU kernel starts, no runtime checks are performed by the kernel
                           itself -- numerical results are simply written to output buffers. 
                        </p>
                        <p class="p">When the CUDNN_BATCHNORM_SPATIAL_PERSISTENT mode is selected in
                           cudnnBatchNormalizationForwardTraining or cudnnBatchNormalizationBackward, the algorithm
                           may encounter numerical overflows where CUDNN_BATCHNORM_SPATIAL performs just fine
                           albeit at a slower speed. The user can invoke cudnnQueryRuntimeError to make sure
                           numerical overflows did not occur during the kernel execution. Those issues are reported
                           by the kernel that performs computations. 
                        </p>
                        <p class="p">cudnnQueryRuntimeError can be used in polling and blocking software control flows. There
                           are two polling modes (CUDNN_ERRQUERY_RAWCODE, CUDNN_ERRQUERY_NONBLOCKING) and one
                           blocking mode CUDNN_ERRQUERY_BLOCKING. 
                        </p>
                        <p class="p">CUDNN_ERRQUERY_RAWCODE reads the error storage location regardless of the kernel
                           completion status. The kernel might not even started and the error storage (allocated
                           per cuDNN handle) might be used by an earlier call. 
                        </p>
                        <p class="p">CUDNN_ERRQUERY_NONBLOCKING checks if all tasks in the user stream completed. The
                           cudnnQueryRuntimeError function will return immediately and report
                           CUDNN_STATUS_RUNTIME_IN_PROGRESS in 'rstatus' if some tasks in the user stream are
                           pending. Otherwise, the function will copy the remote kernel error code to 'rstatus'. 
                        </p>
                        <p class="p">In the blocking mode (CUDNN_ERRQUERY_BLOCKING), the function waits for all tasks to drain
                           in the user stream before reporting the remote kernel error code. The blocking flavor
                           can be further adjusted by calling cudaSetDeviceFlags with the cudaDeviceScheduleSpin,
                           cudaDeviceScheduleYield, or cudaDeviceScheduleBlockingSync flag. 
                        </p>
                        <p class="p">CUDNN_ERRQUERY_NONBLOCKING and CUDNN_ERRQUERY_BLOCKING modes should not be used when the
                           user stream is changed in the cuDNN handle, i.e., cudnnSetStream is invoked between
                           functions that report runtime kernel errors and the cudnnQueryRuntimeError function. 
                        </p>
                        <p class="p">The remote error status reported in rstatus can be set to: CUDNN_STATUS_SUCCESS,
                           CUDNN_STATUS_RUNTIME_IN_PROGRESS, or CUDNN_STATUS_RUNTIME_FP_OVERFLOW. The remote kernel
                           error is automatically cleared by cudnnQueryRuntimeError. 
                        </p>
                        <div class="note note"><span class="notetitle">Note:</span> The cudnnQueryRuntimeError function should be used in conjunction with
                           cudnnBatchNormalizationForwardTraining and cudnnBatchNormalizationBackward when the
                           cudnnBatchNormMode_t argument is CUDNN_BATCHNORM_SPATIAL_PERSISTENT. 
                        </div>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">rstatus </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Pointer to the user's error code storage. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">mode </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Remote error query mode. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">tag </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input/Output</em>. Currently, this argument should be NULL. 
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">No errors detected (rstatus holds a valid value). </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">Invalid input argument. </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_INTERNAL_ERROR</samp></dt>
                           <dd class="dd">
                              <p class="p">A stream blocking synchronization or a non-blocking stream query failed. </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_MAPPING_ERROR</samp></dt>
                           <dd class="dd">
                              <p class="p">Device cannot access zero-copy memory to report kernel errors. </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnReduceTensor"><a name="cudnnReduceTensor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnReduceTensor" name="cudnnReduceTensor" shape="rect">4.157.&nbsp;cudnnReduceTensor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnReduceTensor(
    cudnnHandle_t                           handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnReduceTensorDescriptor_t     reduceTensorDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                   *indices,
    size_t                                  indicesSizeInBytes,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                   *workspace,
    size_t                                  workspaceSizeInBytes,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                             *alpha,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t           aDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                             *A,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                             *beta,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t           cDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                   *C)</pre><p class="p">This function reduces tensor A by implementing the equation C = alpha * reduce op ( A ) +
                           beta * C, given tensors A and C and scaling factors alpha and beta. The reduction op to
                           use is indicated by the descriptor <samp class="ph codeph">reduceTensorDesc</samp>.
                           Currently-supported ops are listed by the <samp class="ph codeph">cudnnReduceTensorOp_t</samp>
                           enum.
                        </p>
                        <p class="p">Each dimension of the output tensor <samp class="ph codeph">C</samp> must match the corresponding
                           dimension of the input tensor <samp class="ph codeph">A</samp> or must be equal to 1. The dimensions
                           equal to 1 indicate the dimensions of <samp class="ph codeph">A</samp> to be reduced.
                        </p>
                        <p class="p">The implementation will generate indices for the min and max ops only, as indicated by
                           the <samp class="ph codeph">cudnnReduceTensorIndices_t</samp> enum of the
                           <samp class="ph codeph">reduceTensorDesc</samp>. Requesting indices for the other reduction ops
                           results in an error. The data type of the indices is indicated by the
                           <samp class="ph codeph">cudnnIndicesType_t</samp> enum; currently only the 32-bit (unsigned int)
                           type is supported.
                        </p>
                        <p class="p">The indices returned by the implementation are not absolute indices but relative to the
                           dimensions being reduced. The indices are also flattened, i.e. not coordinate
                           tuples.
                        </p>
                        <p class="p">The data types of the tensors <samp class="ph codeph">A</samp> and <samp class="ph codeph">C</samp> must match if of
                           type double. In this case, <samp class="ph codeph">alpha</samp> and <samp class="ph codeph">beta</samp> and the
                           computation enum of <samp class="ph codeph">reduceTensorDesc</samp> are all assumed to be of type
                           double.
                        </p>
                        <p class="p">The half and int8 data types may be mixed with the float data types. In these cases, the
                           computation enum of <samp class="ph codeph">reduceTensorDesc</samp> is required to be of type
                           float.
                        </p>
                        <div class="note note"><span class="notetitle">Note:</span> Up to dimension 8, all tensor formats are supported. Beyond those dimensions, this
                           routine is not supported
                        </div>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">reduceTensorDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized reduce tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">indices </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Handle to a previously allocated space for writing
                                 indices.
                              </p>
                           </dd>
                           <dt class="dt dlterm">indicesSizeInBytes </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Size of the above previously allocated space.
                              </p>
                           </dd>
                           <dt class="dt dlterm">workspace </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously allocated space for the reduction
                                 implementation.
                              </p>
                           </dd>
                           <dt class="dt dlterm">workspaceSizeInBytes </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Size of the above previously allocated space.
                              </p>
                           </dd>
                           <dt class="dt dlterm">alpha, beta </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointers to scaling factors (in host memory) used to blend the
                                 source value with prior value in the destination tensor as indicated by the
                                 above op equation. <a class="xref" href="index.html#general-description" shape="rect">Please refer to this section for additional details.</a></p>
                           </dd>
                           <dt class="dt dlterm">aDesc, cDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">A </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointer to data of the tensor described by the
                                 <samp class="ph codeph">aDesc</samp> descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">C </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input/Output</em>. Pointer to data of the tensor described by the
                                 <samp class="ph codeph">cDesc</samp> descriptor.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The function executed successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function does not support the provided configuration. See the following
                                 for some examples of non-supported configurations:
                              </p><a name="cudnnReduceTensor__ul_orx_tr1_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnReduceTensor__ul_orx_tr1_s1b">
                                 <li class="li">The dimensions of the input tensor and the output tensor are above
                                    8.
                                 </li>
                                 <li class="li"><samp class="ph codeph">reduceTensorCompType</samp> is not set as stated above.
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">The corresponding dimensions of the input and output tensors all match, or
                                 the conditions in the above paragraphs are unmet.
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_INVALID_VALUE</samp></dt>
                           <dd class="dd">
                              <p class="p">The allocations for the indices or workspace are insufficient.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function failed to launch on the GPU.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnReorderFilterAndBias"><a name="cudnnReorderFilterAndBias" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnReorderFilterAndBias" name="cudnnReorderFilterAndBias" shape="rect">4.158.&nbsp;cudnnReorderFilterAndBias</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnReorderFilterAndBias(
	cudnnHandle_t handle,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t filterDesc,
	cudnnReorderType_t reorderType,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *filterData,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *reorderedFilterData,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> reorderBias,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *biasData,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *reorderedBiasData);		</pre><p dir="ltr" class="p" id="cudnnReorderFilterAndBias__docs-internal-guid-0eaa8c2b-7fff-7d3b-da2a-c0eee8303faf"><a name="cudnnReorderFilterAndBias__docs-internal-guid-0eaa8c2b-7fff-7d3b-da2a-c0eee8303faf" shape="rect">
                              <!-- --></a>This function
                           				<samp class="ph codeph">cudnnReorderFilterAndBias()</samp> reorders the filter and bias values. It can
                           			be used to enhance the inference time by separating the reordering operation from
                           			convolution. 
                        </p>
                        <p dir="ltr" class="p">For example, convolutions in a neural network of multiple layers can require
                           			reordering of kernels at every layer, which can take up a significant fraction of the total
                           			inference time. Using this function, the reordering can be done one time on the filter and
                           			bias data followed by the convolution operations at the multiple layers, thereby enhancing
                           			the inference time. 
                        </p>
                        <p class="p"><strong class="ph b">Parameters:</strong></p>
                        <div class="tablenoborder"><a name="cudnnReorderFilterAndBias__table_hpj_hcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnReorderFilterAndBias__table_hpj_hcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1"><strong class="ph b">Parameter</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1"><strong class="ph b">Input / Output</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">filterDesc</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Descriptor for the kernel dataset. </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">reorderType</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Setting to either perform reordering or not. See <a class="xref" href="index.html#cudnnReorderType_t" shape="rect">cudnnReorderType_t</a>.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">filterData</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Pointer to the filter (kernel) data location in the device
                                       							memory.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">reorderedFilterData</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Pointer to the location in the device memory where the reordered
                                       							filter data will be written to, by this function.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">reorderBias</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">If &gt; 0, then reorders the bias data also. If &lt;= 0 then does
                                       							not perform reordering operation on the bias data. 
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">biasData</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Pointer to the bias data location in the device memory.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">reorderedBiasData</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Pointer to the location in the device memory where the reordered
                                       							bias data will be written to, by this function.
                                    </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                        <p class="p"><strong class="ph b">Returns:</strong></p>
                        <div class="tablenoborder"><a name="cudnnReorderFilterAndBias__table_usk_kcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnReorderFilterAndBias__table_usk_kcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Return Value</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_SUCCESS</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">Reordering was successful.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_EXECUTION_FAILED</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">Either the reordering of the filter data or of the bias data
                                       							failed. 
                                    </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnRestoreAlgorithm"><a name="cudnnRestoreAlgorithm" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnRestoreAlgorithm" name="cudnnRestoreAlgorithm" shape="rect">4.159.&nbsp;cudnnRestoreAlgorithm</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnRestoreAlgorithm(
    cudnnHandle_t               handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>*                       algoSpace,
    size_t                      algoSpaceSizeInBytes,
    cudnnAlgorithmDescriptor_t  algoDesc)</pre><p class="p"><strong class="ph b">(New for 7.1)</strong></p>
                        <p class="p">This function reads algorithm metadata from the host memory space provided by the user in <samp class="ph codeph">algoSpace</samp>, allowing the user to use the results of RNN finds from previous cuDNN sessions.
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">algoDesc</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A previously created algorithm descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">algoSpace</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointer to the host memory to be read.
                              </p>
                           </dd>
                           <dt class="dt dlterm">algoSpaceSizeInBytes</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Amount of host memory needed as workspace to be able to hold the metadata from the specified <samp class="ph codeph">algoDesc</samp>.
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The function launched successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The metadata is from a different cudnn version.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions is met:</p>
                              <ul class="ul">
                                 <li class="li">One of the arguments is null.</li>
                                 <li class="li">The metadata is corrupted.</li>
                              </ul>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnRestoreDropoutDescriptor"><a name="cudnnRestoreDropoutDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnRestoreDropoutDescriptor" name="cudnnRestoreDropoutDescriptor" shape="rect">4.160.&nbsp;cudnnRestoreDropoutDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnRestoreDropoutDescriptor(
    cudnnDropoutDescriptor_t dropoutDesc,
    cudnnHandle_t            handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>                    dropout,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                    *states,
    size_t                   stateSizeInBytes,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span>       seed)</pre><p class="p">This function restores a dropout descriptor to a previously saved-off state.</p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">dropoutDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input/Output</em>. Previously created dropout descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dropout </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Probability with which the value from an input tensor is set to
                                 0 when performing dropout.
                              </p>
                           </dd>
                           <dt class="dt dlterm">states </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointer to GPU memory that holds random number generator states
                                 initialized by a prior call to
                                 <samp class="ph codeph">cudnnSetDropoutDescriptor.</samp></p>
                           </dd>
                           <dt class="dt dlterm">stateSizeInBytes </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Size in bytes of buffer holding random number generator
                                 states.
                              </p>
                           </dd>
                           <dt class="dt dlterm">seed </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Seed used in prior call to
                                 <samp class="ph codeph">cudnnSetDropoutDescriptor</samp> that initialized 'states'
                                 buffer. Using a different seed from this has no effect. A change of seed,
                                 and subsequent update to random number generator states can be achieved by
                                 calling <samp class="ph codeph">cudnnSetDropoutDescriptor</samp>. 
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The call was successful.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_INVALID_VALUE</samp></dt>
                           <dd class="dd">
                              <p class="p"> States buffer size (as indicated in stateSizeInBytes) is too small.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnRNNBackwardData"><a name="cudnnRNNBackwardData" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnRNNBackwardData" name="cudnnRNNBackwardData" shape="rect">4.161.&nbsp;cudnnRNNBackwardData</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnRNNBackwardData(
    cudnnHandle_t                   handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDescriptor_t      rnnDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                       seqLength,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t  *yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *y,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t  *dyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *dy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   dhyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *dhy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   dcyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *dcy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t   wDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *w,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   hxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *hx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   cxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *cx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t  *dxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *dx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   dhxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *dhx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   dcxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *dcx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *workspace,
    size_t                          workSpaceSizeInBytes,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *reserveSpace,
    size_t                          reserveSpaceSizeInBytes)</pre><p class="p">This routine executes the recurrent neural network described by <samp class="ph codeph">rnnDesc</samp>
                           with output gradients <samp class="ph codeph">dy, dhy, dhc</samp>, weights <samp class="ph codeph">w</samp> and
                           input gradients <samp class="ph codeph">dx, dhx, dcx</samp>. <samp class="ph codeph">workspace</samp> is required
                           for intermediate storage. The data in <samp class="ph codeph">reserveSpace</samp> must have previously
                           been generated by <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNForwardTraining" shape="rect">cudnnRNNForwardTraining</a></samp>. The same <samp class="ph codeph">reserveSpace</samp>
                           data must be used for future calls to <samp class="ph codeph"><a class="xref" href="index.html#cudnnRNNBackwardWeights" shape="rect">cudnnRNNBackwardWeights</a></samp> if they execute on the same input
                           data.
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context. See <a class="xref" href="index.html#cudnnHandle_t" shape="rect">cudnnHandle_t.</a></p>
                           </dd>
                           <dt class="dt dlterm">rnnDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A previously initialized RNN descriptor. See <a class="xref" href="index.html#cudnnRNNDescriptor_t" shape="rect">cudnnRNNDescriptor_t</a>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">seqLength </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Number of iterations to unroll over. The value of this
                                 							<samp class="ph codeph">seqLength</samp> must not exceed the value that was used in
                                 							<samp class="ph codeph">cudnnGetRNNWorkspaceSize() </samp>function for querying the
                                 						workspace size required to execute the RNN. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">yDesc </dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. An array of fully packed tensor descriptors describing the
                                 output from each recurrent iteration (one descriptor per iteration). See <a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a>. The
                                 second dimension of the tensor depends on the <samp class="ph codeph">direction</samp>
                                 argument passed to the <samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNDescriptor" shape="rect">cudnnSetRNNDescriptor</a></samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnRNNBackwardData__ul_xgb_1g3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnRNNBackwardData__ul_xgb_1g3_s1b">
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the second dimension
                                       should match the <samp class="ph codeph">hiddenSize</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the second dimension should
                                       match double the <samp class="ph codeph">hiddenSize</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                 </ul>
                                 
                                 The first dimension of the tensor <samp class="ph codeph">n</samp> must match the
                                 first dimension of the tensor <samp class="ph codeph">n</samp> in
                                 <samp class="ph codeph">dyDesc</samp>.
                              </div>
                           </dd>
                           <dt class="dt dlterm">y </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the output tensor
                                 descriptor <samp class="ph codeph">yDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dyDesc </dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. An array of fully packed tensor descriptors describing the
                                 gradient at the output from each recurrent iteration (one descriptor per
                                 iteration). The second dimension of the tensor depends on the
                                 <samp class="ph codeph">direction</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnRNNBackwardData__ul_zgb_1g3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnRNNBackwardData__ul_zgb_1g3_s1b">
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the second dimension
                                       should match the <samp class="ph codeph">hiddenSize</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the second dimension should
                                       match double the <samp class="ph codeph">hiddenSize</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                 </ul>
                                 
                                 The first dimension of the tensor <samp class="ph codeph">n</samp> must match the
                                 first dimension of the tensor <samp class="ph codeph">n</samp> in
                                 <samp class="ph codeph">dxDesc</samp>.
                              </div>
                           </dd>
                           <dt class="dt dlterm">dy </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptors in the array <samp class="ph codeph">dyDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dhyDesc </dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the gradients at
                                 the final hidden state of the RNN. The first dimension of the tensor depends
                                 on the <samp class="ph codeph">direction</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnRNNBackwardData__ul_bhb_1g3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnRNNBackwardData__ul_bhb_1g3_s1b">
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first dimension should
                                       match the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension should
                                       match double the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                 </ul>
                                 
                                 The second dimension must match the first dimension of the tensors
                                 described in <samp class="ph codeph">xDesc</samp>. The third dimension must match the
                                 <samp class="ph codeph">hiddenSize</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                              </div>
                           </dd>
                           <dt class="dt dlterm">dhy </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">dhyDesc</samp>. If a NULL pointer is passed, the
                                 gradients at the final hidden state of the network will be initialized to
                                 zero.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dcyDesc </dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the gradients at
                                 the final cell state of the RNN. The first dimension of the tensor depends
                                 on the <samp class="ph codeph">direction</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnRNNBackwardData__ul_chb_1g3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnRNNBackwardData__ul_chb_1g3_s1b">
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first dimension should
                                       match the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension should
                                       match double the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                 </ul>
                                 
                                 The second dimension must match the first dimension of the tensors
                                 described in <samp class="ph codeph">xDesc</samp>. The third dimension must match the
                                 <samp class="ph codeph">hiddenSize</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                              </div>
                           </dd>
                           <dt class="dt dlterm">dcy </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">dcyDesc</samp>. If a NULL pointer is passed, the
                                 gradients at the final cell state of the network will be initialized to
                                 zero.
                              </p>
                           </dd>
                           <dt class="dt dlterm">wDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor describing
                                 the weights for the RNN. See <a class="xref" href="index.html#cudnnFilterDescriptor_t" shape="rect">cudnnFilterDescriptor_t</a>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">w </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the filter
                                 descriptor <samp class="ph codeph">wDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">hxDesc </dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the initial hidden
                                 state of the RNN. The first dimension of the tensor depends on the
                                 <samp class="ph codeph">direction</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnRNNBackwardData__ul_ehb_1g3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnRNNBackwardData__ul_ehb_1g3_s1b">
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first dimension should
                                       match the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension should
                                       match double the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                 </ul>
                                 
                                 The second dimension must match the second dimension of the tensors
                                 described in <samp class="ph codeph">xDesc</samp>. The third dimension must match the
                                 <samp class="ph codeph">hiddenSize</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                              </div>
                           </dd>
                           <dt class="dt dlterm">hx </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">hxDesc</samp>. If a NULL pointer is passed, the initial
                                 hidden state of the network will be initialized to zero.
                              </p>
                           </dd>
                           <dt class="dt dlterm">cxDesc </dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the initial cell
                                 state for LSTM networks. The first dimension of the tensor depends on the
                                 <samp class="ph codeph">direction</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnRNNBackwardData__ul_fhb_1g3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnRNNBackwardData__ul_fhb_1g3_s1b">
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first dimension should
                                       match the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension should
                                       match double the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                 </ul>
                                 
                                 The second dimension must match the second dimension of the tensors
                                 described in <samp class="ph codeph">xDesc</samp>. The third dimension must match the
                                 <samp class="ph codeph">hiddenSize</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                              </div>
                           </dd>
                           <dt class="dt dlterm">cx </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">cxDesc</samp>. If a NULL pointer is passed, the initial
                                 cell state of the network will be initialized to zero.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dxDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. An array of fully packed tensor descriptors describing the
                                 gradient at the input of each recurrent iteration (one descriptor per
                                 iteration). The first dimension (batch size) of the tensors may decrease
                                 from element <samp class="ph codeph">n</samp> to element <samp class="ph codeph">n+1</samp> but may not
                                 increase. Each tensor descriptor must have the same second dimension (vector
                                 length).
                              </p>
                           </dd>
                           <dt class="dt dlterm">dx </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the tensor
                                 descriptors in the array <samp class="ph codeph">dxDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dhxDesc </dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the gradient at the
                                 initial hidden state of the RNN. The first dimension of the tensor depends
                                 on the <samp class="ph codeph">direction</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnRNNBackwardData__ul_hhb_1g3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnRNNBackwardData__ul_hhb_1g3_s1b">
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first dimension should
                                       match the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension should
                                       match double the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                 </ul>
                                 
                                 The second dimension must match the first dimension of the tensors
                                 described in <samp class="ph codeph">xDesc</samp>. The third dimension must match the
                                 <samp class="ph codeph">hiddenSize</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                              </div>
                           </dd>
                           <dt class="dt dlterm">dhx </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">dhxDesc</samp>. If a NULL pointer is passed, the
                                 gradient at the hidden input of the network will not be set.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dcxDesc </dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the gradient at the
                                 initial cell state of the RNN. The first dimension of the tensor depends on
                                 the <samp class="ph codeph">direction</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnRNNBackwardData__ul_jhb_1g3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnRNNBackwardData__ul_jhb_1g3_s1b">
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first dimension should
                                       match the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension should
                                       match double the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                 </ul>
                                 
                                 The second dimension must match the first dimension of the tensors
                                 described in <samp class="ph codeph">xDesc</samp>. The third dimension must match the
                                 <samp class="ph codeph">hiddenSize</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                              </div>
                           </dd>
                           <dt class="dt dlterm">dcx </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">dcxDesc</samp>. If a NULL pointer is passed, the
                                 gradient at the cell input of the network will not be set.
                              </p>
                           </dd>
                           <dt class="dt dlterm">workspace </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory to be used as a workspace for this
                                 call.
                              </p>
                           </dd>
                           <dt class="dt dlterm">workSpaceSizeInBytes </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                 <samp class="ph codeph">workspace</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">reserveSpace </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input/Output</em>. Data pointer to GPU memory to be used as a reserve space
                                 for this call.
                              </p>
                           </dd>
                           <dt class="dt dlterm">reserveSpaceSizeInBytes </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                 <samp class="ph codeph">reserveSpace</samp>.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The function launched successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function does not support the provided configuration.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnRNNBackwardData__ul_khb_1g3_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnRNNBackwardData__ul_khb_1g3_s1b">
                                 <li class="li">The descriptor <samp class="ph codeph">rnnDesc</samp> is invalid.
                                 </li>
                                 <li class="li">At least one of the descriptors <samp class="ph codeph">dhxDesc, wDesc, hxDesc, cxDesc,
                                       dcxDesc, dhyDesc, dcyDesc</samp> or one of the descriptors in
                                    <samp class="ph codeph">yDesc, dxdesc, dydesc</samp> is invalid.
                                 </li>
                                 <li class="li">The descriptors in one of <samp class="ph codeph">yDesc, dxDesc, dyDesc, dhxDesc, wDesc,
                                       hxDesc, cxDesc, dcxDesc, dhyDesc, dcyDesc</samp> has incorrect
                                    strides or dimensions.
                                 </li>
                                 <li class="li"><samp class="ph codeph">workSpaceSizeInBytes</samp> is too small.
                                 </li>
                                 <li class="li"><samp class="ph codeph">reserveSpaceSizeInBytes</samp> is too small.
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function failed to launch on the GPU.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function was unable to allocate memory.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnRNNBackwardDataEx"><a name="cudnnRNNBackwardDataEx" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnRNNBackwardDataEx" name="cudnnRNNBackwardDataEx" shape="rect">4.162.&nbsp;cudnnRNNBackwardDataEx</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">
cudnnStatus_t cudnnRNNBackwardDataEx(
    cudnnHandle_t                     handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDescriptor_t        rnnDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDataDescriptor_t    yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                        *y,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDataDescriptor_t    dyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                        *dy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDataDescriptor_t    dcDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                        *dcAttn,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t     dhyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                        *dhy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t     dcyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                        *dcy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t     wDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                        *w,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t     hxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                        *hx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t     cxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                        *cx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDataDescriptor_t    dxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                              *dx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t     dhxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                              *dhx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t     dcxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                              *dcx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDataDescriptor_t    dkDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                              *dkeys,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                              *workSpace,
    size_t                            workSpaceSizeInBytes,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                              *reserveSpace,
    size_t                            reserveSpaceSizeInBytes)
</pre><p class="p">This routine is the extended version of the function
                           <samp class="ph codeph">cudnnRNNBackwardData</samp>. This function
                           <samp class="ph codeph">cudnnRNNBackwardDataEx</samp> allows the user to use unpacked (padded)
                           layout for input <samp class="ph codeph">y</samp> and output <samp class="ph codeph">dx</samp>. 
                        </p>
                        <p class="p">In the unpacked layout, each sequence in the mini-batch is considered to be of fixed
                           length, specified by <samp class="ph codeph">maxSeqLength</samp> in its corresponding
                           <samp class="ph codeph">RNNDataDescriptor</samp>. Each fixed-length sequence, for example, the nth
                           sequence in the mini-batch, is composed of a valid segment specified by the
                           <samp class="ph codeph">seqLengthArray[n]</samp> in its corresponding
                           <samp class="ph codeph">RNNDataDescriptor</samp>; and a padding segment to make the combined
                           sequence length equal to <samp class="ph codeph">maxSeqLength</samp>. 
                        </p>
                        <p class="p">With the unpacked layout, both sequence major (i.e. time major) and batch major are
                           supported. For backward compatibility, the packed sequence major layout is supported.
                           However, similar to the non-extended function <samp class="ph codeph">cudnnRNNBackwardData</samp>, the
                           sequences in the mini-batch need to be sorted in descending order according to length. 
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">rnnDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A previously initialized RNN descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">yDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A previously initialized RNN data descriptor. Must match or be
                                 the exact same descriptor previously passed into
                                 <samp class="ph codeph">cudnnRNNForwardTrainingEx</samp>. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">y </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to the GPU memory associated with the RNN data
                                 descriptor <samp class="ph codeph">yDesc</samp>. The vectors are expected to be laid out
                                 in memory according to the layout specified by <samp class="ph codeph">yDesc</samp>. The
                                 elements in the tensor (including elements in the padding vector) must be
                                 densely packed, and no strides are supported. Must contain the exact same
                                 data previously produced by <samp class="ph codeph">cudnnRNNForwardTrainingEx</samp>. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">dyDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A previously initialized RNN data descriptor. The
                                 <samp class="ph codeph">dataType</samp>, <samp class="ph codeph">layout</samp>,
                                 <samp class="ph codeph">maxSeqLength</samp> , <samp class="ph codeph">batchSize</samp>,
                                 <samp class="ph codeph">vectorSize</samp> and <samp class="ph codeph">seqLengthArray</samp> need to
                                 match the <samp class="ph codeph">yDesc</samp> previously passed to
                                 <samp class="ph codeph">cudnnRNNForwardTrainingEx</samp>. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">dy </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>.Data pointer to the GPU memory associated with the RNN data
                                 descriptor <samp class="ph codeph">dyDesc</samp>. The vectors are expected to be laid out
                                 in memory according to the layout specified by <samp class="ph codeph">dyDesc</samp>. The
                                 elements in the tensor (including elements in the padding vector) must be
                                 densely packed, and no strides are supported. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">dhyDesc </dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the gradients at
                                 the final hidden state of the RNN. The first dimension of the tensor depends
                                 on the <samp class="ph codeph">direction</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>. Moreover: <a name="cudnnRNNBackwardDataEx__ul_bhb_1g3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnRNNBackwardDataEx__ul_bhb_1g3_s1b">
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first dimension should
                                       match the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension should
                                       match double the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                 </ul>
                              </div>
                              <p class="p">The second dimension must match the <samp class="ph codeph">batchSize</samp> parameter in
                                 <samp class="ph codeph">xDesc</samp>. 
                              </p>
                              <p class="p">The third dimension depends on whether RNN mode is CUDNN_LSTM and whether
                                 LSTM projection is enabled. Moreover:
                              </p>
                              <div class="p"><a name="cudnnRNNBackwardDataEx__ul_v5c_4xy_h2b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnRNNBackwardDataEx__ul_v5c_4xy_h2b">
                                    <li class="li">If RNN mode is <samp class="ph codeph">CUDNN_LSTM</samp> and LSTM projection is
                                       enabled, the third dimension must match the
                                       <samp class="ph codeph">recProjSize</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNProjectionLayers</samp> call used to set
                                       <samp class="ph codeph">rnnDesc</samp>. 
                                    </li>
                                    <li class="li">Otherwise, the third dimension must match the
                                       <samp class="ph codeph">hiddenSize</samp> argument passed to the
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                       <samp class="ph codeph">rnnDesc</samp>. 
                                    </li>
                                 </ul>
                              </div>
                           </dd>
                           <dt class="dt dlterm">dhy </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">dhyDesc</samp>. If a NULL pointer is passed, the
                                 gradients at the final hidden state of the network will be initialized to
                                 zero.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dcyDesc </dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the gradients at
                                 the final cell state of the RNN. The first dimension of the tensor depends
                                 on the <samp class="ph codeph">direction</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>. Moreover: <a name="cudnnRNNBackwardDataEx__ul_chb_1g3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnRNNBackwardDataEx__ul_chb_1g3_s1b">
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first dimension should
                                       match the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension should
                                       match double the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                 </ul>
                              </div>
                              <p class="p">The second dimension must match the first dimension of the tensors described
                                 in <samp class="ph codeph">xDesc</samp>. 
                              </p>
                              <p class="p">The third dimension must match the <samp class="ph codeph">hiddenSize</samp> argument
                                 passed to the <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dcy </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">dcyDesc</samp>. If a NULL pointer is passed, the
                                 gradients at the final cell state of the network will be initialized to
                                 zero.
                              </p>
                           </dd>
                           <dt class="dt dlterm">wDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor describing
                                 the weights for the RNN.
                              </p>
                           </dd>
                           <dt class="dt dlterm">w </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the filter
                                 descriptor <samp class="ph codeph">wDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">hxDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the initial hidden
                                 state of the RNN. Must match or be the exact same descriptor previously
                                 passed into <samp class="ph codeph">cudnnRNNForwardTrainingEx</samp>. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">hx </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">hxDesc</samp>. If a NULL pointer is passed, the initial
                                 hidden state of the network will be initialized to zero. Must contain the
                                 exact same data previously passed into
                                 <samp class="ph codeph">cudnnRNNForwardTrainingEx</samp>, or be <samp class="ph codeph">NULL</samp>
                                 if <samp class="ph codeph">NULL</samp> was previously passed to
                                 <samp class="ph codeph">cudnnRNNForwardTrainingEx</samp>. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">cxDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the initial cell
                                 state for LSTM networks. Must match or be the exact same descriptor
                                 previously passed into <samp class="ph codeph">cudnnRNNForwardTrainingEx</samp>. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">cx </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>.  Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">cxDesc</samp>. If a <samp class="ph codeph">NULL</samp> pointer is
                                 passed, the initial cell state of the network will be initialized to zero.
                                 Must contain the exact same data previously passed into
                                 <samp class="ph codeph">cudnnRNNForwardTrainingEx</samp>, or be <samp class="ph codeph">NULL</samp>
                                 if <samp class="ph codeph">NULL</samp> was previously passed to
                                 <samp class="ph codeph">cudnnRNNForwardTrainingEx</samp>. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">dxDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A previously initialized RNN data descriptor. The
                                 <samp class="ph codeph">dataType</samp>, <samp class="ph codeph">layout</samp>,
                                 <samp class="ph codeph">maxSeqLength</samp>, <samp class="ph codeph">batchSize</samp>,
                                 <samp class="ph codeph">vectorSize</samp> and <samp class="ph codeph">seqLengthArray</samp> need to
                                 match that of <samp class="ph codeph">xDesc</samp> previously passed to
                                 <samp class="ph codeph">cudnnRNNForwardtrainingEx</samp>. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">dx </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Data pointer to the GPU memory associated with the RNN data
                                 descriptor <samp class="ph codeph">dxDesc</samp>. The vectors are expected to be laid out
                                 in memory according to the layout specified by <samp class="ph codeph">dxDesc</samp>. The
                                 elements in the tensor (including elements in the padding vector) must be
                                 densely packed, and no strides are supported. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">dhxDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the gradient at the
                                 initial hidden state of the RNN. The descriptor must be set exactly the same
                                 way as <samp class="ph codeph">dhyDesc</samp>. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">dhx </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">dhxDesc</samp>. If a NULL pointer is passed, the
                                 gradient at the hidden input of the network will not be set.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dcxDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the gradient at the
                                 initial cell state of the RNN. The descriptor must be set exactly the same
                                 way as <samp class="ph codeph">dcyDesc</samp>. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">dcx </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">dcxDesc</samp>. If a NULL pointer is passed, the
                                 gradient at the cell input of the network will not be set.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dkDesc </dt>
                           <dd class="dd">
                              <p class="p">Reserved. User may pass in NULL. </p>
                           </dd>
                           <dt class="dt dlterm">dkeys </dt>
                           <dd class="dd">
                              <p class="p">Reserved. User may pass in NULL. </p>
                           </dd>
                           <dt class="dt dlterm">workspace </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory to be used as a workspace for this
                                 call.
                              </p>
                           </dd>
                           <dt class="dt dlterm">workSpaceSizeInBytes </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                 <samp class="ph codeph">workspace</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">reserveSpace </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input/Output</em>. Data pointer to GPU memory to be used as a reserve space
                                 for this call.
                              </p>
                           </dd>
                           <dt class="dt dlterm">reserveSpaceSizeInBytes </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                 <samp class="ph codeph">reserveSpace</samp>.
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The function launched successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnRNNBackwardDataEx__ul_j3f_hzy_h2b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnRNNBackwardDataEx__ul_j3f_hzy_h2b">
                                 <li class="li">Variable sequence length input is passed in while
                                    <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_STATIC</samp>
                                    or<samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_DYNAMIC</samp> is used. 
                                 </li>
                                 <li class="li"><samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_STATIC</samp> or
                                    <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_DYNAMIC</samp> is used on
                                    pre-Pascal devices. 
                                 </li>
                                 <li class="li">Double input/output is used for
                                    <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_STATIC</samp>.
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnRNNBackwardDataEx__ul_khb_1g3_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnRNNBackwardDataEx__ul_khb_1g3_s1b">
                                 <li class="li">The descriptor <samp class="ph codeph">rnnDesc</samp> is invalid.
                                 </li>
                                 <li class="li">At least one of the descriptors <samp class="ph codeph">yDesc</samp>,
                                    <samp class="ph codeph">dxdesc</samp>, <samp class="ph codeph">dydesc</samp>,
                                    <samp class="ph codeph">dhxDesc</samp>, <samp class="ph codeph">wDesc</samp>,
                                    <samp class="ph codeph">hxDesc</samp>, <samp class="ph codeph">cxDesc</samp>,
                                    <samp class="ph codeph">dcxDesc</samp>, <samp class="ph codeph">dhyDesc</samp>,
                                    <samp class="ph codeph">dcyDesc</samp> is invalid or has incorrect strides or
                                    dimensions. 
                                 </li>
                                 <li class="li"><samp class="ph codeph">workSpaceSizeInBytes</samp> is too small.
                                 </li>
                                 <li class="li"><samp class="ph codeph">reserveSpaceSizeInBytes</samp> is too small.
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function failed to launch on the GPU.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function was unable to allocate memory.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnRNNBackwardWeights"><a name="cudnnRNNBackwardWeights" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnRNNBackwardWeights" name="cudnnRNNBackwardWeights" shape="rect">4.163.&nbsp;cudnnRNNBackwardWeights</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnRNNBackwardWeights(
    cudnnHandle_t                   handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDescriptor_t      rnnDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                       seqLength,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t  *xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   hxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *hx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t  *yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *y,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *workspace,
    size_t                          workSpaceSizeInBytes,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t   dwDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *dw,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *reserveSpace,
    size_t                          reserveSpaceSizeInBytes)</pre><p class="p">This routine accumulates weight gradients <samp class="ph codeph">dw</samp> from the recurrent neural
                           network described by <samp class="ph codeph">rnnDesc</samp> with inputs <samp class="ph codeph">x, hx</samp>, and
                           outputs <samp class="ph codeph">y</samp>. The mode of operation in this case is additive, the weight
                           gradients calculated will be added to those already existing in <samp class="ph codeph">dw</samp>.
                           <samp class="ph codeph">workspace</samp> is required for intermediate storage. The data in
                           <samp class="ph codeph">reserveSpace</samp> must have previously been generated by
                           <samp class="ph codeph">cudnnRNNBackwardData</samp>.
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">rnnDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A previously initialized RNN descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">seqLength </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Number of iterations to unroll over. The value of this
                                 							<samp class="ph codeph">seqLength</samp> must not exceed the value that was used in
                                 							<samp class="ph codeph">cudnnGetRNNWorkspaceSize() </samp>function for querying the
                                 						workspace size required to execute the RNN. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">xDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. An array of fully packed tensor descriptors describing the
                                 input to each recurrent iteration (one descriptor per iteration). The first
                                 dimension (batch size) of the tensors may decrease from element
                                 <samp class="ph codeph">n</samp> to element <samp class="ph codeph">n+1</samp> but may not increase.
                                 Each tensor descriptor must have the same second dimension (vector
                                 length).
                              </p>
                           </dd>
                           <dt class="dt dlterm">x </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptors in the array <samp class="ph codeph">xDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">hxDesc </dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the initial hidden
                                 state of the RNN. The first dimension of the tensor depends on the
                                 <samp class="ph codeph">direction</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnRNNBackwardWeights__ul_qjf_2g3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnRNNBackwardWeights__ul_qjf_2g3_s1b">
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first dimension should
                                       match the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension should
                                       match double the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                 </ul>
                                 
                                 The second dimension must match the first dimension of the tensors
                                 described in <samp class="ph codeph">xDesc</samp>. The third dimension must match the
                                 <samp class="ph codeph">hiddenSize</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                              </div>
                           </dd>
                           <dt class="dt dlterm">hx </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">hxDesc</samp>. If a NULL pointer is passed, the initial
                                 hidden state of the network will be initialized to zero.
                              </p>
                           </dd>
                           <dt class="dt dlterm">yDesc </dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. An array of fully packed tensor descriptors describing the
                                 output from each recurrent iteration (one descriptor per iteration). The
                                 second dimension of the tensor depends on the <samp class="ph codeph">direction</samp>
                                 argument passed to the <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to
                                 initialize <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnRNNBackwardWeights__ul_ujf_2g3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnRNNBackwardWeights__ul_ujf_2g3_s1b">
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the second dimension
                                       should match the <samp class="ph codeph">hiddenSize</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the second dimension should
                                       match double the <samp class="ph codeph">hiddenSize</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                 </ul>
                                 
                                 The first dimension of the tensor <samp class="ph codeph">n</samp> must match the
                                 first dimension of the tensor <samp class="ph codeph">n</samp> in
                                 <samp class="ph codeph">dyDesc</samp>.
                              </div>
                           </dd>
                           <dt class="dt dlterm">y </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the output tensor
                                 descriptor <samp class="ph codeph">yDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">workspace </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory to be used as a workspace for this
                                 call.
                              </p>
                           </dd>
                           <dt class="dt dlterm">workSpaceSizeInBytes </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                 <samp class="ph codeph">workspace</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dwDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor describing
                                 the gradients of the weights for the RNN.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dw </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input/Output</em>. Data pointer to GPU memory associated with the filter
                                 descriptor <samp class="ph codeph">dwDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">reserveSpace </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory to be used as a reserve space for
                                 this call.
                              </p>
                           </dd>
                           <dt class="dt dlterm">reserveSpaceSizeInBytes </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                 <samp class="ph codeph">reserveSpace</samp></p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The function launched successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function does not support the provided configuration.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnRNNBackwardWeights__ul_yjf_2g3_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnRNNBackwardWeights__ul_yjf_2g3_s1b">
                                 <li class="li">The descriptor <samp class="ph codeph">rnnDesc</samp> is invalid.
                                 </li>
                                 <li class="li">At least one of the descriptors <samp class="ph codeph">hxDesc, dwDesc</samp> or one
                                    of the descriptors in <samp class="ph codeph">xDesc, yDesc</samp> is invalid.
                                 </li>
                                 <li class="li">The descriptors in one of <samp class="ph codeph">xDesc, hxDesc, yDesc, dwDesc</samp>
                                    has incorrect strides or dimensions.
                                 </li>
                                 <li class="li"><samp class="ph codeph">workSpaceSizeInBytes</samp> is too small.
                                 </li>
                                 <li class="li"><samp class="ph codeph">reserveSpaceSizeInBytes</samp> is too small.
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function failed to launch on the GPU.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function was unable to allocate memory.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnRNNBackwardWeightsEx"><a name="cudnnRNNBackwardWeightsEx" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnRNNBackwardWeightsEx" name="cudnnRNNBackwardWeightsEx" shape="rect">4.164.&nbsp;cudnnRNNBackwardWeightsEx</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">
cudnnStatus_t cudnnRNNBackwardWeightsEx(
    cudnnHandle_t                    handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDescriptor_t       rnnDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDataDescriptor_t   xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    hxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *hx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDataDescriptor_t   yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *y,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                             *workSpace,
    size_t                           workSpaceSizeInBytes,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t    dwDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                             *dw,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                             *reserveSpace,
    size_t                           reserveSpaceSizeInBytes)
</pre><p class="p">This routine is the extended version of the function
                           <samp class="ph codeph">cudnnRNNBackwardWeights</samp>. This function
                           <samp class="ph codeph">cudnnRNNBackwardWeightsEx</samp> allows the user to use unpacked (padded)
                           layout for input <samp class="ph codeph">x</samp> and output <samp class="ph codeph">dw</samp>. 
                        </p>
                        <p class="p">In the unpacked layout, each sequence in the mini-batch is considered to be of fixed
                           length, specified by <samp class="ph codeph">maxSeqLength</samp> in its corresponding
                           <samp class="ph codeph">RNNDataDescriptor</samp>. Each fixed-length sequence, for example, the nth
                           sequence in the mini-batch, is composed of a valid segment specified by the
                           <samp class="ph codeph">seqLengthArray[n] </samp>in its corresponding
                           <samp class="ph codeph">RNNDataDescriptor</samp>; and a padding segment to make the combined
                           sequence length equal to <samp class="ph codeph">maxSeqLength</samp>. 
                        </p>
                        <p class="p">With the unpacked layout, both sequence major (i.e. time major) and batch major are
                           supported. For backward compatibility, the packed sequence major layout is supported.
                           However, similar to the non-extended function <samp class="ph codeph">cudnnRNNBackwardWeights</samp>,
                           the sequences in the mini-batch need to be sorted in descending order according to
                           length. 
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">rnnDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A previously initialized RNN descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">xDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A previously initialized RNN data descriptor. Must match or be
                                 the exact same descriptor previously passed into
                                 <samp class="ph codeph">cudnnRNNForwardTrainingEx</samp>. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">x </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptors in the array <samp class="ph codeph">xDesc</samp>. Must contain the exact same
                                 data previously passed into <samp class="ph codeph">cudnnRNNForwardTrainingEx</samp>. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">hxDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the initial hidden
                                 state of the RNN. Must match or be the exact same descriptor previously
                                 passed into <samp class="ph codeph">cudnnRNNForwardTrainingEx</samp>. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">hx </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">hxDesc</samp>. If a NULL pointer is passed, the initial
                                 hidden state of the network will be initialized to zero. Must contain the
                                 exact same data previously passed into
                                 <samp class="ph codeph">cudnnRNNForwardTrainingEx</samp>, or be <samp class="ph codeph">NULL</samp>
                                 if <samp class="ph codeph">NULL</samp> was previously passed to
                                 <samp class="ph codeph">cudnnRNNForwardTrainingEx</samp>.  
                              </p>
                           </dd>
                           <dt class="dt dlterm">yDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A previously initialized RNN data descriptor. Must match or be
                                 the exact same descriptor previously passed into
                                 <samp class="ph codeph">cudnnRNNForwardTrainingEx</samp>. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">y </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the output tensor
                                 descriptor <samp class="ph codeph">yDesc</samp>. Must contain the exact same data
                                 previously produced by <samp class="ph codeph">cudnnRNNForwardTrainingEx</samp>. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">workspace </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory to be used as a workspace for this
                                 call.
                              </p>
                           </dd>
                           <dt class="dt dlterm">workSpaceSizeInBytes </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                 <samp class="ph codeph">workspace</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dwDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor describing
                                 the gradients of the weights for the RNN.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dw </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input/Output</em>. Data pointer to GPU memory associated with the filter
                                 descriptor <samp class="ph codeph">dwDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">reserveSpace </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory to be used as a reserve space for
                                 this call.
                              </p>
                           </dd>
                           <dt class="dt dlterm">reserveSpaceSizeInBytes </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                 <samp class="ph codeph">reserveSpace</samp></p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The function launched successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function does not support the provided configuration.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnRNNBackwardWeightsEx__ul_yjf_2g3_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnRNNBackwardWeightsEx__ul_yjf_2g3_s1b">
                                 <li class="li">The descriptor <samp class="ph codeph">rnnDesc</samp> is invalid.
                                 </li>
                                 <li class="li">At least one of the descriptors <samp class="ph codeph">xDesc, yDesc, hxDesc,
                                       dwDesc</samp> is invalud, or has incorrect strides or dimensions. 
                                 </li>
                                 <li class="li"><samp class="ph codeph">workSpaceSizeInBytes</samp> is too small.
                                 </li>
                                 <li class="li"><samp class="ph codeph">reserveSpaceSizeInBytes</samp> is too small.
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function failed to launch on the GPU.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function was unable to allocate memory.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnRNNForwardInference"><a name="cudnnRNNForwardInference" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnRNNForwardInference" name="cudnnRNNForwardInference" shape="rect">4.165.&nbsp;cudnnRNNForwardInference</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnRNNForwardInference(
    cudnnHandle_t                   handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDescriptor_t      rnnDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                       seqLength,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t  *xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   hxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *hx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   cxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *cx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t   wDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *w,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   *yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *y,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   hyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *hy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   cyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *cy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *workspace,
    size_t                          workSpaceSizeInBytes)</pre><p class="p">This routine executes the recurrent neural network described by <samp class="ph codeph">rnnDesc</samp>
                           with inputs <samp class="ph codeph">x, hx, cx</samp>, weights <samp class="ph codeph">w</samp> and outputs
                           <samp class="ph codeph">y, hy, cy</samp>. <samp class="ph codeph">workspace</samp> is required for intermediate
                           storage. This function does not store intermediate data required for training;
                           <samp class="ph codeph">cudnnRNNForwardTraining</samp> should be used for that purpose.
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">rnnDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A previously initialized RNN descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">seqLength </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Number of iterations to unroll over. The value of this
                                 							<samp class="ph codeph">seqLength</samp> must not exceed the value that was used in
                                 							<samp class="ph codeph">cudnnGetRNNWorkspaceSize() </samp>function for querying the
                                 						workspace size required to execute the RNN. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">xDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. An array of 'seqLength' fully packed tensor descriptors. 
                                 Each descriptor in the array should have three dimensions that describe the input data 
                                 format to one recurrent iteration (one descriptor per RNN time-step). The first
                                 dimension (batch size) of the tensors may decrease from iteration 
                                 <samp class="ph codeph">n</samp> to iteration <samp class="ph codeph">n+1</samp> but may not increase.
                                 Each tensor descriptor must have the same second dimension (RNN input vector length, inputSize). 
                                 The third dimension of each tensor should be 1. Input data are expected to be arranged in the 
                                 column-major order so strides in <samp class="ph codeph">xDesc</samp> should be set as follows: strideA[0]=inputSize, 
                                 strideA[1]=1, strideA[2]=1.
                              </p>
                           </dd>
                           <dt class="dt dlterm">x </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the array of tensor descriptors <samp class="ph codeph">xDesc</samp>. 
                                 The input vectors are expected to be packed contiguously with the first vector of 
                                 iteration (time-step) <samp class="ph codeph">n+1</samp> following directly from the last vector of iteration <samp class="ph codeph">n</samp>. 
                                 In other words, input vectors for all RNN time-steps should be packed in the contiguous 
                                 block of GPU memory with no gaps between the vectors.
                              </p>
                           </dd>
                           <dt class="dt dlterm">hxDesc </dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the initial hidden
                                 state of the RNN. The first dimension of the tensor depends on the
                                 <samp class="ph codeph">direction</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnRNNForwardInference__ul_bsf_sf3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnRNNForwardInference__ul_bsf_sf3_s1b">
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first dimension should
                                       match the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension should
                                       match double the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                 </ul>
                                 
                                 The second dimension must match the first dimension of the tensors
                                 described in <samp class="ph codeph">xDesc</samp>. The third dimension must match the
                                 <samp class="ph codeph">hiddenSize</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                              </div>
                           </dd>
                           <dt class="dt dlterm">hx </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">hxDesc</samp>. If a NULL pointer is passed, the initial
                                 hidden state of the network will be initialized to zero.
                              </p>
                           </dd>
                           <dt class="dt dlterm">cxDesc </dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the initial cell
                                 state for LSTM networks. The first dimension of the tensor depends on the
                                 <samp class="ph codeph">direction</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnRNNForwardInference__ul_dsf_sf3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnRNNForwardInference__ul_dsf_sf3_s1b">
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first dimension should
                                       match the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension should
                                       match double the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                 </ul>
                                 
                                 The second dimension must match the first dimension of the tensors
                                 described in <samp class="ph codeph">xDesc</samp>. The third dimension must match the
                                 <samp class="ph codeph">hiddenSize</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                              </div>
                           </dd>
                           <dt class="dt dlterm">cx </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">cxDesc</samp>. If a NULL pointer is passed, the initial
                                 cell state of the network will be initialized to zero.
                              </p>
                           </dd>
                           <dt class="dt dlterm">wDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor describing
                                 the weights for the RNN.
                              </p>
                           </dd>
                           <dt class="dt dlterm">w </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the filter
                                 descriptor <samp class="ph codeph">wDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">yDesc </dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. An array of fully packed tensor descriptors describing the
                                 output from each recurrent iteration (one descriptor per iteration). The
                                 second dimension of the tensor depends on the <samp class="ph codeph">direction</samp>
                                 argument passed to the <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to
                                 initialize <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnRNNForwardInference__ul_fsf_sf3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnRNNForwardInference__ul_fsf_sf3_s1b">
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the second dimension
                                       should match the <samp class="ph codeph">hiddenSize</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the second dimension should
                                       match double the <samp class="ph codeph">hiddenSize</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                 </ul>
                                 
                                 The first dimension of the tensor <samp class="ph codeph">n</samp> must match the
                                 first dimension of the tensor <samp class="ph codeph">n</samp> in
                                 <samp class="ph codeph">xDesc</samp>.
                              </div>
                           </dd>
                           <dt class="dt dlterm">y </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the output tensor
                                 descriptor <samp class="ph codeph">yDesc</samp>. The data are expected to be packed
                                 contiguously with the first element of iteration <samp class="ph codeph">n+1</samp> following directly from
                                 the last element of iteration <samp class="ph codeph">n</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">hyDesc </dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the final hidden
                                 state of the RNN. The first dimension of the tensor depends on the
                                 <samp class="ph codeph">direction</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnRNNForwardInference__ul_gsf_sf3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnRNNForwardInference__ul_gsf_sf3_s1b">
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first dimension should
                                       match the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension should
                                       match double the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                 </ul>
                                 
                                 The second dimension must match the first dimension of the tensors
                                 described in <samp class="ph codeph">xDesc</samp>. The third dimension must match the
                                 <samp class="ph codeph">hiddenSize</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                              </div>
                           </dd>
                           <dt class="dt dlterm">hy </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">hyDesc</samp>. If a NULL pointer is passed, the final
                                 hidden state of the network will not be saved.
                              </p>
                           </dd>
                           <dt class="dt dlterm">cyDesc </dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the final cell
                                 state for LSTM networks. The first dimension of the tensor depends on the
                                 <samp class="ph codeph">direction</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnRNNForwardInference__ul_isf_sf3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnRNNForwardInference__ul_isf_sf3_s1b">
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first dimension should
                                       match the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension should
                                       match double the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                 </ul>
                                 
                                 The second dimension must match the first dimension of the tensors
                                 described in <samp class="ph codeph">xDesc</samp>. The third dimension must match the
                                 <samp class="ph codeph">hiddenSize</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                              </div>
                           </dd>
                           <dt class="dt dlterm">cy </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">cyDesc</samp>. If a NULL pointer is passed, the final
                                 cell state of the network will be not be saved.
                              </p>
                           </dd>
                           <dt class="dt dlterm">workspace </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory to be used as a workspace for this
                                 call.
                              </p>
                           </dd>
                           <dt class="dt dlterm">workSpaceSizeInBytes </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                 <samp class="ph codeph">workspace</samp>.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The function launched successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function does not support the provided configuration.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnRNNForwardInference__ul_ksf_sf3_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnRNNForwardInference__ul_ksf_sf3_s1b">
                                 <li class="li">The descriptor <samp class="ph codeph">rnnDesc</samp> is invalid.
                                 </li>
                                 <li class="li">At least one of the descriptors <samp class="ph codeph">hxDesc, cxDesc, wDesc, hyDesc,
                                       cyDesc</samp> or one of the descriptors in <samp class="ph codeph">xDesc,
                                       yDesc</samp> is invalid.
                                 </li>
                                 <li class="li">The descriptors in one of <samp class="ph codeph">xDesc, hxDesc, cxDesc, wDesc, yDesc,
                                       hyDesc, cyDesc</samp> have incorrect strides or dimensions.
                                 </li>
                                 <li class="li"><samp class="ph codeph">workSpaceSizeInBytes</samp> is too small.
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function failed to launch on the GPU.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function was unable to allocate memory.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnRNNForwardInferenceEx"><a name="cudnnRNNForwardInferenceEx" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnRNNForwardInferenceEx" name="cudnnRNNForwardInferenceEx" shape="rect">4.166.&nbsp;cudnnRNNForwardInferenceEx</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">
cudnnStatus_t cudnnRNNForwardInferenceEx(
    cudnnHandle_t                   handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDescriptor_t      rnnDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDataDescriptor_t  xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   hxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *hx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   cxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *cx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t   wDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *w,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDataDescriptor_t  yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *y,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   hyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *hy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   cyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *cy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDataDescriptor_t  kDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *keys,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDataDescriptor_t  cDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *cAttn,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDataDescriptor_t  iDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *iAttn,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDataDescriptor_t  qDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *queries,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *workSpace,
    size_t                          workSpaceSizeInBytes)
</pre><p class="p">This routine is the extended version of the <samp class="ph codeph">cudnnRNNForwardInference</samp>
                           function. The <samp class="ph codeph">cudnnRNNForwardTrainingEx</samp> allows the user to use unpacked
                           (padded) layout for input <samp class="ph codeph">x</samp> and output <samp class="ph codeph">y</samp>. In the
                           unpacked layout, each sequence in the mini-batch is considered to be of fixed length,
                           specified by <samp class="ph codeph">maxSeqLength</samp> in its corresponding
                           <samp class="ph codeph">RNNDataDescriptor</samp>. Each fixed-length sequence, for example, the nth
                           sequence in the mini-batch, is composed of a valid segment, specified by the
                           <samp class="ph codeph">seqLengthArray[n]</samp> in its corresponding
                           <samp class="ph codeph">RNNDataDescriptor</samp>, and a padding segment to make the combined
                           sequence length equal to <samp class="ph codeph">maxSeqLength</samp>. 
                        </p>
                        <p class="p">With unpacked layout, both sequence major (i.e. time major) and batch major are
                           supported. For backward compatibility, the packed sequence major layout is supported.
                           However, similar to the non-extended function <samp class="ph codeph">cudnnRNNForwardInference</samp>,
                           the sequences in the mini-batch need to be sorted in descending order according to
                           length.
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">rnnDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A previously initialized RNN descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">xDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A previously initialized RNN Data descriptor. The
                                 <samp class="ph codeph">dataType</samp>, <samp class="ph codeph">layout</samp>,
                                 <samp class="ph codeph">maxSeqLength</samp> , <samp class="ph codeph">batchSize</samp>, and
                                 <samp class="ph codeph">seqLengthArray</samp> need to match that of
                                 <samp class="ph codeph">yDesc</samp>. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">x </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to the GPU memory associated with the RNN data
                                 descriptor <samp class="ph codeph">xDesc</samp>. The vectors are expected to be laid out
                                 in memory according to the layout specified by <samp class="ph codeph">xDesc</samp>. The
                                 elements in the tensor (including elements in the padding vector) must be
                                 densely packed, and no strides are supported. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">hxDesc </dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the initial hidden
                                 state of the RNN. The first dimension of the tensor depends on the
                                 <samp class="ph codeph">direction</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnRNNForwardInferenceEx__ul_bsf_sf3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnRNNForwardInferenceEx__ul_bsf_sf3_s1b">
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first dimension should
                                       match the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension should
                                       match double the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                 </ul>
                              </div>
                              <p class="p"> The second dimension must match the <samp class="ph codeph">batchSize</samp> parameter
                                 described in <samp class="ph codeph">xDesc</samp>. 
                              </p>
                              <p class="p">The third dimension depends on whether RNN mode is CUDNN_LSTM and whether
                                 LSTM projection is enabled. In specific:
                              </p>
                              <div class="p"><a name="cudnnRNNForwardInferenceEx__ul_mgv_1px_h2b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnRNNForwardInferenceEx__ul_mgv_1px_h2b">
                                    <li class="li">If RNN mode is <samp class="ph codeph">CUDNN_LSTM</samp> and LSTM projection is
                                       enabled, the third dimension must match the
                                       <samp class="ph codeph">recProjSize</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNProjectionLayers</samp> call used to set
                                       <samp class="ph codeph">rnnDesc</samp>. 
                                    </li>
                                    <li class="li">Otherwise, the third dimension must match the
                                       <samp class="ph codeph">hiddenSize</samp> argument passed to the
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                       <samp class="ph codeph">rnnDesc</samp>.
                                    </li>
                                 </ul>
                              </div>
                           </dd>
                           <dt class="dt dlterm">hx </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">hxDesc</samp>. If a NULL pointer is passed, the initial
                                 hidden state of the network will be initialized to zero.
                              </p>
                           </dd>
                           <dt class="dt dlterm">cxDesc </dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the initial cell
                                 state for LSTM networks. The first dimension of the tensor depends on the
                                 <samp class="ph codeph">direction</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnRNNForwardInferenceEx__ul_dsf_sf3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnRNNForwardInferenceEx__ul_dsf_sf3_s1b">
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first dimension should
                                       match the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension should
                                       match double the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                 </ul>
                              </div>
                              <p class="p">The second dimension must match the <samp class="ph codeph">batchSize</samp> parameter in
                                 <samp class="ph codeph">xDesc</samp>. The third dimension must match the
                                 <samp class="ph codeph">hiddenSize</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">cx </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">cxDesc</samp>. If a NULL pointer is passed, the initial
                                 cell state of the network will be initialized to zero.
                              </p>
                           </dd>
                           <dt class="dt dlterm">wDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor describing
                                 the weights for the RNN.
                              </p>
                           </dd>
                           <dt class="dt dlterm">w </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the filter
                                 descriptor <samp class="ph codeph">wDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">yDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A previously initialized RNN data descriptor. The
                                 <samp class="ph codeph">dataType</samp>, <samp class="ph codeph">layout</samp>,
                                 <samp class="ph codeph">maxSeqLength</samp> , <samp class="ph codeph">batchSize</samp>, and
                                 <samp class="ph codeph">seqLengthArray</samp> must match that of
                                 <samp class="ph codeph">dyDesc</samp> and <samp class="ph codeph">dxDesc</samp>. The parameter
                                 <samp class="ph codeph">vectorSize</samp> depends on whether RNN mode is
                                 <samp class="ph codeph">CUDNN_LSTM</samp> and whether LSTM projection is enabled and
                                 whether the network is bidirectional. In specific: 
                              </p>
                              <div class="p"><a name="cudnnRNNForwardInferenceEx__ul_jrn_wpx_h2b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnRNNForwardInferenceEx__ul_jrn_wpx_h2b">
                                    <li class="li">For uni-directional network, if RNN mode is
                                       <samp class="ph codeph">CUDNN_LSTM</samp> and LSTM projection is enabled, the
                                       parameter <samp class="ph codeph">vectorSize</samp> must match the
                                       <samp class="ph codeph">recProjSize</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNProjectionLayers</samp> call used to set
                                       <samp class="ph codeph">rnnDesc</samp>. If the network is bidirectional, then
                                       multiply the value by 2. 
                                    </li>
                                    <li class="li">Otherwise, for uni-directional network, the parameter
                                       <samp class="ph codeph">vectorSize</samp> must match the
                                       <samp class="ph codeph">hiddenSize</samp> argument passed to the
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                       <samp class="ph codeph">rnnDesc</samp>. If the network is bidirectional, then
                                       multiply the value by 2.
                                    </li>
                                 </ul>
                              </div>
                           </dd>
                           <dt class="dt dlterm">y </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Data pointer to the GPU memory associated with the RNN data
                                 descriptor <samp class="ph codeph">yDesc</samp>. The vectors are expected to be laid out
                                 in memory according to the layout specified by <samp class="ph codeph">yDesc</samp>. The
                                 elements in the tensor (including elements in the padding vector) must be
                                 densely packed, and no strides are supported. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">hyDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the final hidden
                                 state of the RNN. The descriptor must be set exactly the same way as
                                 <samp class="ph codeph">hxDesc</samp>. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">hy </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">hyDesc</samp>. If a NULL pointer is passed, the final
                                 hidden state of the network will not be saved.
                              </p>
                           </dd>
                           <dt class="dt dlterm">cyDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the final cell
                                 state for LSTM networks. The descriptor must be set exactly the same way as
                                 <samp class="ph codeph">cxDesc</samp>. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">cy </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">cyDesc</samp>. If a NULL pointer is passed, the final
                                 cell state of the network will be not be saved.
                              </p>
                           </dd>
                           <dt class="dt dlterm">kDesc </dt>
                           <dd class="dd">
                              <p class="p">Reserved. User may pass in NULL.</p>
                           </dd>
                           <dt class="dt dlterm">Keys </dt>
                           <dd class="dd">
                              <p class="p">Reserved. User may pass in NULL.</p>
                           </dd>
                           <dt class="dt dlterm">cDesc </dt>
                           <dd class="dd">
                              <p class="p">Reserved. User may pass in NULL.</p>
                           </dd>
                           <dt class="dt dlterm">cAttn </dt>
                           <dd class="dd">
                              <p class="p">Reserved. User may pass in NULL.</p>
                           </dd>
                           <dt class="dt dlterm">iDesc </dt>
                           <dd class="dd">
                              <p class="p">Reserved. User may pass in NULL.</p>
                           </dd>
                           <dt class="dt dlterm">iAttn </dt>
                           <dd class="dd">
                              <p class="p">Reserved. User may pass in NULL.</p>
                           </dd>
                           <dt class="dt dlterm">qDesc </dt>
                           <dd class="dd">
                              <p class="p">Reserved. User may pass in NULL.</p>
                           </dd>
                           <dt class="dt dlterm">Queries </dt>
                           <dd class="dd">
                              <p class="p">Reserved. User may pass in NULL.</p>
                           </dd>
                           <dt class="dt dlterm">workspace </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory to be used as a workspace for this
                                 call.
                              </p>
                           </dd>
                           <dt class="dt dlterm">workSpaceSizeInBytes </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                 <samp class="ph codeph">workspace</samp>.
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The function launched successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met: </p>
                              <div class="p"><a name="cudnnRNNForwardInferenceEx__ul_jkd_wrx_h2b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnRNNForwardInferenceEx__ul_jkd_wrx_h2b">
                                    <li class="li">Variable sequence length input is passed in while
                                       <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_STATIC</samp> or
                                       <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_DYNAMIC</samp> is used. 
                                    </li>
                                    <li class="li"><samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_STATIC</samp> or
                                       <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_DYNAMIC</samp> is used on
                                       pre-Pascal devices. 
                                    </li>
                                    <li class="li">Double input/output is used for
                                       <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_STATIC</samp>. 
                                    </li>
                                 </ul>
                              </div>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnRNNForwardInferenceEx__ul_ksf_sf3_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnRNNForwardInferenceEx__ul_ksf_sf3_s1b">
                                 <li class="li">The descriptor <samp class="ph codeph">rnnDesc</samp> is invalid.
                                 </li>
                                 <li class="li">At least one of the descriptors in <samp class="ph codeph">xDesc</samp>,
                                    <samp class="ph codeph">yDesc</samp>, <samp class="ph codeph">hxDesc</samp>,
                                    <samp class="ph codeph">cxDesc</samp>, <samp class="ph codeph">wDesc</samp>,
                                    <samp class="ph codeph">hyDesc</samp>, <samp class="ph codeph">cyDesc</samp> is invalid, or have
                                    incorrect strides or dimensions. 
                                 </li>
                                 <li class="li"><samp class="ph codeph">reserveSpaceSizeInBytes</samp> is too small.
                                 </li>
                                 <li class="li"><samp class="ph codeph">workSpaceSizeInBytes</samp> is too small.
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function failed to launch on the GPU.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function was unable to allocate memory.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnRNNForwardTraining"><a name="cudnnRNNForwardTraining" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnRNNForwardTraining" name="cudnnRNNForwardTraining" shape="rect">4.167.&nbsp;cudnnRNNForwardTraining</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnRNNForwardTraining(
    cudnnHandle_t                   handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDescriptor_t      rnnDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                       seqLength,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t  *xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   hxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *hx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   cxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *cx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t   wDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *w,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t  *yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *y,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   hyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *hy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   cyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *cy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *workspace,
    size_t                          workSpaceSizeInBytes,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *reserveSpace,
    size_t                          reserveSpaceSizeInBytes)</pre><p class="p">This routine executes the recurrent neural network described by <samp class="ph codeph">rnnDesc</samp>
                           with inputs <samp class="ph codeph">x, hx, cx</samp>, weights <samp class="ph codeph">w</samp> and outputs
                           <samp class="ph codeph">y, hy, cy</samp>. <samp class="ph codeph">workspace</samp> is required for intermediate
                           storage. <samp class="ph codeph">reserveSpace</samp> stores data required for training. The same
                           reserveSpace data must be used for future calls to <samp class="ph codeph">cudnnRNNBackwardData</samp>
                           and <samp class="ph codeph">cudnnRNNBackwardWeights</samp> if these execute on the same input
                           data.
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">rnnDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A previously initialized RNN descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">seqLength </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Number of iterations to unroll over. The value of this
                                 							<samp class="ph codeph">seqLength</samp> must not exceed the value that was used in
                                 							<samp class="ph codeph">cudnnGetRNNWorkspaceSize() </samp>function for querying the
                                 						workspace size required to execute the RNN. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">xDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. An array of 'seqLength' fully packed tensor descriptors. Each descriptor in the array 
                                 should have three dimensions that describe the input data format to one recurrent iteration 
                                 (one descriptor per RNN time-step). The first dimension 
                                 (batch size) of the tensors may decrease from iteration element n to iteration element <samp class="ph codeph">n+1</samp> but 
                                 may not increase. Each tensor descriptor must have the same second dimension (RNN input vector 
                                 length, inputSize). The third dimension of each tensor should be 1. Input vectors are 
                                 expected to be arranged in the column-major order so strides in <samp class="ph codeph">xDesc</samp> should 
                                 be set as follows: strideA[0]=inputSize, strideA[1]=1, strideA[2]=1.
                              </p>
                           </dd>
                           <dt class="dt dlterm">x</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the array of tensor descriptors <samp class="ph codeph">xDesc</samp>. The input vectors are expected to be packed contiguously with the first 
                                 vector of iteration (time-step) <samp class="ph codeph">n+1</samp> following directly the last vector 
                                 of iteration <samp class="ph codeph">n</samp>. In other words, input vectors for all RNN time-steps should be packed 
                                 in the contiguous block of GPU memory with no gaps between the vectors.
                              </p>
                           </dd>
                           <dt class="dt dlterm">hxDesc </dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the initial hidden
                                 state of the RNN. The first dimension of the tensor depends on the
                                 <samp class="ph codeph">direction</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnRNNForwardTraining__ul_hqb_wf3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnRNNForwardTraining__ul_hqb_wf3_s1b">
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first dimension should
                                       match the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension should
                                       match double the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                 </ul>
                                 
                                 The second dimension must match the first dimension of the tensors
                                 described in <samp class="ph codeph">xDesc</samp>. The third dimension must match the
                                 <samp class="ph codeph">hiddenSize</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                              </div>
                           </dd>
                           <dt class="dt dlterm">hx </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">hxDesc</samp>. If a NULL pointer is passed, the initial
                                 hidden state of the network will be initialized to zero.
                              </p>
                           </dd>
                           <dt class="dt dlterm">cxDesc </dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the initial cell
                                 state for LSTM networks. The first dimension of the tensor depends on the
                                 <samp class="ph codeph">direction</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnRNNForwardTraining__ul_kqb_wf3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnRNNForwardTraining__ul_kqb_wf3_s1b">
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first dimension should
                                       match the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension should
                                       match double the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                 </ul>
                                 
                                 The second dimension must match the first dimension of the tensors
                                 described in <samp class="ph codeph">xDesc</samp>. The third dimension must match the
                                 <samp class="ph codeph">hiddenSize</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                              </div>
                           </dd>
                           <dt class="dt dlterm">cx </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">cxDesc</samp>. If a NULL pointer is passed, the initial
                                 cell state of the network will be initialized to zero.
                              </p>
                           </dd>
                           <dt class="dt dlterm">wDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor describing
                                 the weights for the RNN.
                              </p>
                           </dd>
                           <dt class="dt dlterm">w </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the filter
                                 descriptor <samp class="ph codeph">wDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">yDesc </dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. An array of fully packed tensor descriptors describing the
                                 output from each recurrent iteration (one descriptor per iteration). The
                                 second dimension of the tensor depends on the <samp class="ph codeph">direction</samp>
                                 argument passed to the <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to
                                 initialize <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnRNNForwardTraining__ul_mqb_wf3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnRNNForwardTraining__ul_mqb_wf3_s1b">
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the second dimension
                                       should match the <samp class="ph codeph">hiddenSize</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the second dimension should
                                       match double the <samp class="ph codeph">hiddenSize</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                 </ul>
                                 
                                 The first dimension of the tensor <samp class="ph codeph">n</samp> must match the
                                 first dimension of the tensor <samp class="ph codeph">n</samp> in
                                 <samp class="ph codeph">xDesc</samp>.
                              </div>
                           </dd>
                           <dt class="dt dlterm">y </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the output tensor
                                 descriptor <samp class="ph codeph">yDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">hyDesc </dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the final hidden
                                 state of the RNN. The first dimension of the tensor depends on the
                                 <samp class="ph codeph">direction</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnRNNForwardTraining__ul_oqb_wf3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnRNNForwardTraining__ul_oqb_wf3_s1b">
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first dimension should
                                       match the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension should
                                       match double the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                 </ul>
                                 
                                 The second dimension must match the first dimension of the tensors
                                 described in <samp class="ph codeph">xDesc</samp>. The third dimension must match the
                                 <samp class="ph codeph">hiddenSize</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                              </div>
                           </dd>
                           <dt class="dt dlterm">hy </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">hyDesc</samp>. If a NULL pointer is passed, the final
                                 hidden state of the network will not be saved.
                              </p>
                           </dd>
                           <dt class="dt dlterm">cyDesc </dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the final cell
                                 state for LSTM networks. The first dimension of the tensor depends on the
                                 <samp class="ph codeph">direction</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>: <a name="cudnnRNNForwardTraining__ul_qqb_wf3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnRNNForwardTraining__ul_qqb_wf3_s1b">
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first dimension should
                                       match the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension should
                                       match double the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                 </ul>
                                 
                                 The second dimension must match the first dimension of the tensors
                                 described in <samp class="ph codeph">xDesc</samp>. The third dimension must match the
                                 <samp class="ph codeph">hiddenSize</samp> argument passed to the
                                 <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                              </div>
                           </dd>
                           <dt class="dt dlterm">cy </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">cyDesc</samp>. If a NULL pointer is passed, the final
                                 cell state of the network will be not be saved.
                              </p>
                           </dd>
                           <dt class="dt dlterm">workspace </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory to be used as a workspace for this
                                 call.
                              </p>
                           </dd>
                           <dt class="dt dlterm">workSpaceSizeInBytes </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                 <samp class="ph codeph">workspace</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">reserveSpace </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input/Output</em>. Data pointer to GPU memory to be used as a reserve space
                                 for this call.
                              </p>
                           </dd>
                           <dt class="dt dlterm">reserveSpaceSizeInBytes </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                 <samp class="ph codeph">reserveSpace</samp></p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The function launched successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnRNNForwardTraining__ul_rqb_wf3_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnRNNForwardTraining__ul_rqb_wf3_s1b">
                                 <li class="li">The descriptor <samp class="ph codeph">rnnDesc</samp> is invalid.
                                 </li>
                                 <li class="li">At least one of the descriptors <samp class="ph codeph">hxDesc, cxDesc, wDesc, hyDesc,
                                       cyDesc</samp> or one of the descriptors in <samp class="ph codeph">xDesc,
                                       yDesc</samp> is invalid.
                                 </li>
                                 <li class="li">The descriptors in one of <samp class="ph codeph">xDesc, hxDesc, cxDesc, wDesc, yDesc,
                                       hyDesc, cyDesc</samp> have incorrect strides or dimensions.
                                 </li>
                                 <li class="li"><samp class="ph codeph">workSpaceSizeInBytes</samp> is too small.
                                 </li>
                                 <li class="li"><samp class="ph codeph">reserveSpaceSizeInBytes</samp> is too small.
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function failed to launch on the GPU.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function was unable to allocate memory.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnRNNForwardTrainingEx"><a name="cudnnRNNForwardTrainingEx" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnRNNForwardTrainingEx" name="cudnnRNNForwardTrainingEx" shape="rect">4.168.&nbsp;cudnnRNNForwardTrainingEx</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">
cudnnStatus_t cudnnRNNForwardTrainingEx(
    cudnnHandle_t                        handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDescriptor_t           rnnDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDataDescriptor_t       xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t        hxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *hx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t        cxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *cx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFilterDescriptor_t        wDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *w,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDataDescriptor_t       yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                 *y,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t        hyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                 *hy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t        cyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                 *cy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDataDescriptor_t       kDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *keys,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDataDescriptor_t       cDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                 *cAttn,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDataDescriptor_t       iDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                 *iAttn,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnRNNDataDescriptor_t       qDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                 *queries,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                 *workSpace,
    size_t                               workSpaceSizeInBytes,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                 *reserveSpace,
    size_t                               reserveSpaceSizeInBytes);
</pre><p class="p">This routine is the extended version of the <samp class="ph codeph">cudnnRNNForwardTraining</samp>
                           function. The <samp class="ph codeph">cudnnRNNForwardTrainingEx</samp> allows the user to use unpacked
                           (padded) layout for input <samp class="ph codeph">x</samp> and output <samp class="ph codeph">y</samp>. 
                        </p>
                        <p class="p">In the unpacked layout, each sequence in the mini-batch is considered to be of fixed
                           length, specified by <samp class="ph codeph">maxSeqLength</samp> in its corresponding
                           <samp class="ph codeph">RNNDataDescriptor</samp>. Each fixed-length sequence, for example, the
                           <samp class="ph codeph">n</samp>th sequence in the mini-batch, is composed of a valid segment
                           specified by the <samp class="ph codeph">seqLengthArray[n]</samp> in its corresponding
                           <samp class="ph codeph">RNNDataDescriptor</samp>; and a padding segment to make the combined
                           sequence length equal to <samp class="ph codeph">maxSeqLength</samp>. 
                        </p>
                        <p class="p">With the unpacked layout, both sequence major (i.e. time major) and batch major are
                           supported. For backward compatibility, the packed sequence major layout is supported.
                           However, similar to the non-extended function <samp class="ph codeph">cudnnRNNForwardTraining</samp>,
                           the sequences in the mini-batch need to be sorted in descending order according to
                           length. 
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">rnnDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A previously initialized RNN descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">xDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A previously initialized RNN Data descriptor. The
                                 <samp class="ph codeph">dataType</samp>, <samp class="ph codeph">layout</samp>,
                                 <samp class="ph codeph">maxSeqLength</samp> , <samp class="ph codeph">batchSize</samp>, and
                                 <samp class="ph codeph">seqLengthArray</samp> need to match that of
                                 <samp class="ph codeph">yDesc</samp>. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">x</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to the GPU memory associated with the RNN data
                                 descriptor <samp class="ph codeph">xDesc</samp>. The input vectors are expected to be laid
                                 out in memory according to the layout specified by <samp class="ph codeph">xDesc</samp>.
                                 The elements in the tensor (including elements in the padding vector) must
                                 be densely packed, and no strides are supported. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">hxDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the initial hidden
                                 state of the RNN. 
                              </p>
                              <div class="p">The first dimension of the tensor depends on the <samp class="ph codeph">direction</samp>
                                 argument passed to the <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to
                                 initialize <samp class="ph codeph">rnnDesc</samp>. Moreover: <a name="cudnnRNNForwardTrainingEx__ul_hqb_wf3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnRNNForwardTrainingEx__ul_hqb_wf3_s1b">
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> then the first dimension
                                       should match the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> then the first dimension
                                       should match double the <samp class="ph codeph">numLayers</samp> argument passed
                                       to <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                 </ul>
                              </div>
                              <p class="p">The second dimension must match the <samp class="ph codeph">batchSize</samp> parameter in
                                 <samp class="ph codeph">xDesc</samp>. 
                              </p>
                              <p class="p">The third dimension depends on whether RNN mode is
                                 <samp class="ph codeph">CUDNN_LSTM</samp> and whether <samp class="ph codeph">LSTM</samp> projection
                                 is enabled. Moreover: 
                              </p>
                              <div class="p"><a name="cudnnRNNForwardTrainingEx__ul_n2s_vfs_h2b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnRNNForwardTrainingEx__ul_n2s_vfs_h2b">
                                    <li class="li">If RNN mode is <samp class="ph codeph">CUDNN_LSTM</samp> and <samp class="ph codeph">LSTM</samp>
                                       projection is enabled, the third dimension must match the
                                       <samp class="ph codeph">recProjSize</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNProjectionLayers</samp> call used to set
                                       <samp class="ph codeph">rnnDesc</samp>. 
                                    </li>
                                    <li class="li">Otherwise, the third dimension must match the
                                       <samp class="ph codeph">hiddenSize</samp> argument passed to the
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                       <samp class="ph codeph">rnnDesc</samp> .
                                    </li>
                                 </ul>
                              </div>
                           </dd>
                           <dt class="dt dlterm">hx </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">hxDesc</samp>. If a NULL pointer is passed, the initial
                                 hidden state of the network will be initialized to zero.
                              </p>
                           </dd>
                           <dt class="dt dlterm">cxDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the initial cell
                                 state for LSTM networks. 
                              </p>
                              <div class="p">The first dimension of the tensor depends on the <samp class="ph codeph">direction</samp>
                                 argument passed to the <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to
                                 initialize <samp class="ph codeph">rnnDesc</samp>. Moreover: <a name="cudnnRNNForwardTrainingEx__ul_kqb_wf3_s1b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnRNNForwardTrainingEx__ul_kqb_wf3_s1b">
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_UNIDIRECTIONAL</samp> the first dimension should
                                       match the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                    <li class="li">If <samp class="ph codeph">direction</samp> is
                                       <samp class="ph codeph">CUDNN_BIDIRECTIONAL</samp> the first dimension should
                                       match double the <samp class="ph codeph">numLayers</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp>.
                                    </li>
                                 </ul>
                              </div>
                              <p class="p">The second dimension must match the first dimension of the tensors described
                                 in <samp class="ph codeph">xDesc</samp>. 
                              </p>
                              <p class="p">The third dimension must match the <samp class="ph codeph">hiddenSize</samp> argument
                                 passed to the <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                 <samp class="ph codeph">rnnDesc</samp>. The tensor must be fully packed.
                              </p>
                           </dd>
                           <dt class="dt dlterm">cx </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">cxDesc</samp>. If a NULL pointer is passed, the initial
                                 cell state of the network will be initialized to zero.
                              </p>
                           </dd>
                           <dt class="dt dlterm">wDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized filter descriptor describing
                                 the weights for the RNN.
                              </p>
                           </dd>
                           <dt class="dt dlterm">w </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the filter
                                 descriptor <samp class="ph codeph">wDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">yDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A previously initialized RNN data descriptor. The
                                 <samp class="ph codeph">dataType</samp>, <samp class="ph codeph">layout</samp>,
                                 <samp class="ph codeph">maxSeqLength</samp> , <samp class="ph codeph">batchSize</samp>, and
                                 <samp class="ph codeph">seqLengthArray</samp> need to match that of
                                 <samp class="ph codeph">dyDesc</samp> and <samp class="ph codeph">dxDesc</samp>. The parameter
                                 <samp class="ph codeph">vectorSize</samp> depends on whether RNN mode is
                                 <samp class="ph codeph">CUDNN_LSTM</samp> and whether LSTM projection is enabled and
                                 whether the network is bidirectional. In specific: 
                              </p>
                              <div class="p"><a name="cudnnRNNForwardTrainingEx__ul_zsr_v1y_h2b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnRNNForwardTrainingEx__ul_zsr_v1y_h2b">
                                    <li class="li">For uni-directional network, if RNN mode is
                                       <samp class="ph codeph">CUDNN_LSTM</samp> and LSTM projection is enabled, the
                                       parameter <samp class="ph codeph">vectorSize</samp> must match the
                                       <samp class="ph codeph">recProjSize</samp> argument passed to
                                       <samp class="ph codeph">cudnnSetRNNProjectionLayers</samp> call used to set
                                       <samp class="ph codeph">rnnDesc</samp>. If the network is bidirectional, then
                                       multiply the value by 2. 
                                    </li>
                                    <li class="li">Otherwise, for uni-directional network, the parameter
                                       <samp class="ph codeph">vectorSize</samp> must match the
                                       <samp class="ph codeph">hiddenSize</samp> argument passed to the
                                       <samp class="ph codeph">cudnnSetRNNDescriptor</samp> call used to initialize
                                       <samp class="ph codeph">rnnDesc</samp>. If the network is bidirectional, then
                                       multiply the value by 2. 
                                    </li>
                                 </ul>
                              </div>
                           </dd>
                           <dt class="dt dlterm">y </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the RNN data
                                 descriptor yDesc. The input vectors are expected to be laid out in memory
                                 according to the layout specified by <samp class="ph codeph">yDesc</samp>. The elements in
                                 the tensor (including elements in the padding vector) must be densely
                                 packed, and no strides are supported.
                              </p>
                           </dd>
                           <dt class="dt dlterm">hyDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the final hidden
                                 state of the RNN. The descriptor must be set exactly the same as
                                 <samp class="ph codeph">hxDesc</samp>. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">hy </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">hyDesc</samp>. If a NULL pointer is passed, the final
                                 hidden state of the network will not be saved.
                              </p>
                           </dd>
                           <dt class="dt dlterm">cyDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A fully packed tensor descriptor describing the final cell
                                 state for LSTM networks. The descriptor must be set exactly the same as
                                 <samp class="ph codeph">cxDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">cy </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">cyDesc</samp>. If a NULL pointer is passed, the final
                                 cell state of the network will be not be saved.
                              </p>
                           </dd>
                           <dt class="dt dlterm">kDesc </dt>
                           <dd class="dd">
                              <p class="p">Reserved. User may pass in NULL.</p>
                           </dd>
                           <dt class="dt dlterm">Keys </dt>
                           <dd class="dd">
                              <p class="p">Reserved. User may pass in NULL.</p>
                           </dd>
                           <dt class="dt dlterm">cDesc </dt>
                           <dd class="dd">
                              <p class="p">Reserved. User may pass in NULL.</p>
                           </dd>
                           <dt class="dt dlterm">cAttn </dt>
                           <dd class="dd">
                              <p class="p">Reserved. User may pass in NULL.</p>
                           </dd>
                           <dt class="dt dlterm">iDesc </dt>
                           <dd class="dd">
                              <p class="p">Reserved. User may pass in NULL.</p>
                           </dd>
                           <dt class="dt dlterm">iAttn </dt>
                           <dd class="dd">
                              <p class="p">Reserved. User may pass in NULL.</p>
                           </dd>
                           <dt class="dt dlterm">qDesc </dt>
                           <dd class="dd">
                              <p class="p">Reserved. User may pass in NULL.</p>
                           </dd>
                           <dt class="dt dlterm">Queries </dt>
                           <dd class="dd">
                              <p class="p">Reserved. User may pass in NULL.</p>
                           </dd>
                           <dt class="dt dlterm">workspace </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory to be used as a workspace for this
                                 call.
                              </p>
                           </dd>
                           <dt class="dt dlterm">workSpaceSizeInBytes </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                 <samp class="ph codeph">workspace</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">reserveSpace </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input/Output</em>. Data pointer to GPU memory to be used as a reserve space
                                 for this call.
                              </p>
                           </dd>
                           <dt class="dt dlterm">reserveSpaceSizeInBytes </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Specifies the size in bytes of the provided
                                 <samp class="ph codeph">reserveSpace</samp></p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The function launched successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnRNNForwardTrainingEx__ul_v1c_d3s_h2b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnRNNForwardTrainingEx__ul_v1c_d3s_h2b">
                                 <li class="li">Variable sequence length input is passed in while<samp class="ph codeph">
                                       CUDNN_RNN_ALGO_PERSIST_STATIC</samp> or
                                    <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_DYNAMIC</samp> is used. 
                                 </li>
                                 <li class="li"><samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_STATIC</samp> or
                                    <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_DYNAMIC</samp> is used on
                                    pre-Pascal devices. 
                                 </li>
                                 <li class="li">Double input/output is used for
                                    <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_STATIC</samp>. 
                                 </li>
                              </ul>
                           </dd>
                        </dl>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnRNNForwardTrainingEx__ul_rqb_wf3_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnRNNForwardTrainingEx__ul_rqb_wf3_s1b">
                                 <li class="li">The descriptor <samp class="ph codeph">rnnDesc</samp> is invalid.
                                 </li>
                                 <li class="li">At least one of the descriptors <samp class="ph codeph">xDesc, yDesc, hxDesc, cxDesc,
                                       wDesc, hyDesc, cyDesc</samp> is invalid, or have incorrect strides
                                    or dimensions. 
                                 </li>
                                 <li class="li"><samp class="ph codeph">workSpaceSizeInBytes</samp> is too small.
                                 </li>
                                 <li class="li"><samp class="ph codeph">reserveSpaceSizeInBytes</samp> is too small.
                                 </li>
                              </ul>
                           </dd>
                        </dl>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function failed to launch on the GPU.</p>
                           </dd>
                        </dl>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function was unable to allocate memory.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnRNNGetClip"><a name="cudnnRNNGetClip" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnRNNGetClip" name="cudnnRNNGetClip" shape="rect">4.169.&nbsp;cudnnRNNGetClip</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">
cudnnStatus_t cudnnRNNGetClip(
    cudnnHandle_t               handle,
    cudnnRNNDescriptor_t        rnnDesc,
    cudnnRNNClipMode_t          *clipMode,
    cudnnNanPropagation_t       *clipNanOpt,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>                      *lclip,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>                      *rclip);
</pre><p class="p">Retrieves the current LSTM cell clipping parameters, and stores them in the arguments
                           provided. 
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">*clipMode </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Pointer to the location where the retrieved
                                 <samp class="ph codeph">clipMode</samp> is stored. The <samp class="ph codeph">clipMode</samp> can
                                 be CUDNN_RNN_CLIP_NONE in which case no LSTM cell state clipping is being
                                 performed; or CUDNN_RNN_CLIP_MINMAX, in which case the cell state activation
                                 to other units are being clipped. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">*lclip, *rclip </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Pointers to the location where the retrieved LSTM cell
                                 clipping range [lclip, rclip] is stored. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">*clipNanOpt </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>.  Pointer to the location where the retrieved
                                 <samp class="ph codeph">clipNanOpt</samp> is stored. 
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The function launched successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">If any of the pointer arguments provided are NULL. </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnRNNSetClip"><a name="cudnnRNNSetClip" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnRNNSetClip" name="cudnnRNNSetClip" shape="rect">4.170.&nbsp;cudnnRNNSetClip</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">
cudnnStatus_t cudnnRNNSetClip(
    cudnnHandle_t               handle,
    cudnnRNNDescriptor_t        rnnDesc,
    cudnnRNNClipMode_t          clipMode,
    cudnnNanPropagation_t       clipNanOpt,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>                      lclip,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>                      rclip);
</pre><p class="p">Sets the LSTM cell clipping mode. The LSTM clipping is disabled by default. When enabled,
                           clipping is applied to all layers. This <samp class="ph codeph">cudnnRNNSetClip()</samp> function may
                           be called multiple times.  
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">clipMode </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Enables or disables the LSTM cell clipping. When
                                 <samp class="ph codeph">clipMode</samp> is set to CUDNN_RNN_CLIP_NONE no LSTM cell
                                 state clipping is performed. When <samp class="ph codeph">clipMode</samp> is
                                 CUDNN_RNN_CLIP_MINMAX the cell state activation to other units are clipped. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">lclip, rclip </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. The range [lclip, rclip] to which the LSTM cell clipping should
                                 be set. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">clipNanOpt </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. When set to CUDNN_PROPAGATE_NAN (See the description for
                                 <samp class="ph codeph">cudnnNanPropagation_t</samp>), NaN is propagated from the LSTM
                                 cell, or it can be set to one of the clipping range boundary values, instead
                                 of propagating. 
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The function launched successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">Returns this value if <samp class="ph codeph">lclip</samp> &gt; <samp class="ph codeph">rclip</samp>; or if
                                 either <samp class="ph codeph">lclip</samp> or <samp class="ph codeph">rclip</samp> is NaN. 
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSaveAlgorithm"><a name="cudnnSaveAlgorithm" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSaveAlgorithm" name="cudnnSaveAlgorithm" shape="rect">4.171.&nbsp;cudnnSaveAlgorithm</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSaveAlgorithm(
    cudnnHandle_t          		handle,
    cudnnAlgorithmDescriptor_t 	algoDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>*                  		algoSpace
    size_t                 		algoSpaceSizeInBytes)</pre><p class="p"><strong class="ph b">(New for 7.1)</strong></p>
                        <p class="p">This function writes algorithm metadata into the host memory space provided by the user in <samp class="ph codeph">algoSpace</samp>, allowing the user to preserve the results of RNN finds after cuDNN exits.
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">algoDesc</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A previously created algorithm descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">algoSpace</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointer to the host memory to be written.
                              </p>
                           </dd>
                           <dt class="dt dlterm">algoSpaceSizeInBytes</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Amount of host memory needed as workspace to be able to save the metadata from the specified <samp class="ph codeph">algoDesc</samp>.
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The function launched successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions is met:</p>
                              <ul class="ul">
                                 <li class="li">One of the arguments is null.</li>
                                 <li class="li"><samp class="ph codeph">algoSpaceSizeInBytes</samp> is too small.
                                 </li>
                              </ul>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnScaleTensor"><a name="cudnnScaleTensor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnScaleTensor" name="cudnnScaleTensor" shape="rect">4.172.&nbsp;cudnnScaleTensor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnScaleTensor(
    cudnnHandle_t                   handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *y,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *alpha)</pre><p class="p">This function scale all the elements of a tensor by a given factor. </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">yDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">y </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input/Output</em>. Pointer to data of the tensor described by the
                                 <samp class="ph codeph">yDesc</samp> descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">alpha </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointer in Host memory to a single value that all elements of
                                 the tensor will be scaled with. <a class="xref" href="index.html#general-description" shape="rect">Please refer to this
                                    section for additional details.</a></p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The function launched successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function does not support the provided configuration.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">one of the provided pointers is nil</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function failed to launch on the GPU.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSetActivationDescriptor"><a name="cudnnSetActivationDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetActivationDescriptor" name="cudnnSetActivationDescriptor" shape="rect">4.173.&nbsp;cudnnSetActivationDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetActivationDescriptor(
    cudnnActivationDescriptor_t         activationDesc,
    cudnnActivationMode_t               mode,
    cudnnNanPropagation_t               reluNanOpt,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>                              coef)</pre><p class="p">This function initializes a previously created generic activation descriptor object. </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">activationDesc</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input/Output</em>. Handle to a previously created pooling descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">mode </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Enumerant to specify the activation mode.
                              </p>
                           </dd>
                           <dt class="dt dlterm">reluNanOpt </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Enumerant to specify the <samp class="ph codeph">Nan</samp> propagation
                                 mode.
                              </p>
                           </dd>
                           <dt class="dt dlterm">coef </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. floating point number to specify the clipping threashold when
                                 						the activation mode is set to <samp class="ph codeph">CUDNN_ACTIVATION_CLIPPED_RELU</samp> or to
                                 						specify the alpha coefficient when the activation mode is set to
                                 							<samp class="ph codeph">CUDNN_ACTIVATION_RELU</samp>. 
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was set successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p"><samp class="ph codeph">mode</samp> or <samp class="ph codeph">reluNanOpt</samp> has an invalid
                                 enumerant value.
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSetAlgorithmDescriptor"><a name="cudnnSetAlgorithmDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetAlgorithmDescriptor" name="cudnnSetAlgorithmDescriptor" shape="rect">4.174.&nbsp;cudnnSetAlgorithmDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetAlgorithmDescriptor(
    cudnnAlgorithmDescriptor_t      algorithmDesc,
    cudnnAlgorithm_t                algorithm)</pre><p class="p"><strong class="ph b">(New for 7.1)</strong></p>
                        <p class="p">This function initializes a previously created generic algorithm descriptor object.</p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">algorithmDesc</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input/Output</em>. Handle to a previously created algorithm descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">algorithm</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Struct to specify the algorithm.
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was set successfully.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSetAlgorithmPerformance"><a name="cudnnSetAlgorithmPerformance" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetAlgorithmPerformance" name="cudnnSetAlgorithmPerformance" shape="rect">4.175.&nbsp;cudnnSetAlgorithmPerformance</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetAlgorithmPerformance(
    cudnnAlgorithmPerformance_t	    algoPerf,
    cudnnAlgorithmDescriptor_t      algoDesc,
    cudnnStatus_t                   status,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>                           time,
    size_t                          memory)</pre><p class="p"><strong class="ph b">(New for 7.1)</strong></p>
                        <p class="p">This function initializes a previously created generic algorithm performance object.</p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">algoPerf</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input/Output</em>. Handle to a previously created algorithm performance object.
                              </p>
                           </dd>
                           <dt class="dt dlterm">algoDesc</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. The algorithm descriptor which the performance results describe.
                              </p>
                           </dd>
                           <dt class="dt dlterm">status</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. The cudnn status returned from running the algoDesc algorithm.
                              </p>
                           </dd>
                           <dt class="dt dlterm">time</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. The GPU time spent running the algoDesc algorithm.
                              </p>
                           </dd>
                           <dt class="dt dlterm">memory</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. The GPU memory needed to run the algoDesc algorithm.
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was set successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p"><samp class="ph codeph">mode</samp> or <samp class="ph codeph">reluNanOpt</samp> has an invalid
                                 enumerant value.
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSetAttnDescriptor"><a name="cudnnSetAttnDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetAttnDescriptor" name="cudnnSetAttnDescriptor" shape="rect">4.176.&nbsp;cudnnSetAttnDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetAttnDescriptor(
cudnnAttnDescriptor_t attnDesc,
	cudnnAttnQueryMap_t queryMap,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> nHeads,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span> smScaler,
	cudnnDataType_t dataType,
	cudnnDataType_t computePrec,
	cudnnMathType_t mathType,
	cudnnDropoutDescriptor_t attnDropoutDesc,
	cudnnDropoutDescriptor_t postDropoutDesc,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> qSize,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> kSize,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> vSize,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> qProjSize,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> kProjSize,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> vProjSize,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> oProjSize,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> qoMaxSeqLength,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> kvMaxSeqLength,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> maxBatchSize,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> maxBeamSize);</pre><p dir="ltr" class="p" id="cudnnSetAttnDescriptor__docs-internal-guid-87763921-7fff-67bc-4609-cd6018ef2ef4"><a name="cudnnSetAttnDescriptor__docs-internal-guid-87763921-7fff-67bc-4609-cd6018ef2ef4" shape="rect">
                              <!-- --></a></p>
                        <p dir="ltr" class="p" id="cudnnSetAttnDescriptor__docs-internal-guid-08c06b68-7fff-0edc-6dc3-1440cb81bf4e"><a name="cudnnSetAttnDescriptor__docs-internal-guid-08c06b68-7fff-0edc-6dc3-1440cb81bf4e" shape="rect">
                              <!-- --></a>This function
                           			initializes a multi-head attention descriptor that was previously created using the
                           				<a class="xref" href="index.html#cudnnCreateAttnDescriptor" shape="rect">cudnnCreateAttnDescriptor</a> function. 
                        </p>
                        <p dir="ltr" class="p">For query, key, and value input data, the effective projection size is equal to
                           			the respective <samp class="ph codeph">[qkv]ProjSize</samp> when the value is positive, and is equal to
                           				<samp class="ph codeph">[qkv]Size</samp> otherwise. 
                        </p>
                        <p dir="ltr" class="p">The output projection size decides the hidden vector size of the forward output
                           			sequence data. It is equal to <samp class="ph codeph">oProjSize</samp> when the value is positive,
                           			otherwise is equal to <samp class="ph codeph">nHeads</samp> times effective value-projection size.
                        </p>
                        <p class="p"><strong class="ph b">Parameters:</strong></p>
                        <div class="tablenoborder"><a name="cudnnSetAttnDescriptor__table_hpj_hcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnSetAttnDescriptor__table_hpj_hcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1"><strong class="ph b">Parameter</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1"><strong class="ph b">Input / Output</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">attnDesc</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Attention descriptor whose values are to be initialized. </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">queryMap</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Query mapping mode.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">nHeads</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Number of attention heads.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">smScaler</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Softmax smoothing, or sharpening, coefficient.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">dataType</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Data type for Q,K,V inputs, weights, and the output.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">computePrec</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Compute data type (precision).</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">mathType</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">The Tensor Core Operations settings.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">attnDropoutDesc</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Dropout descriptor for the dropout at the attention
                                       							layer.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">postDropoutDesc</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Dropout descriptor for the dropout at the output.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">qSize, kSize, vSize</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Hidden size of Q, K, and V input sequence data.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">qProjSize, kProjSize, vProjSize</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Hidden size of projected Q, K and V sequence data; 0 if no
                                       							projection.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">oProjSize</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Output projection size.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">qoMaxSeqLength</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Largest sequence length allowed in sequence data Q and O.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">kvMaxSeqLength</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Largest sequence length allowed in sequence data K and V.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">maxBatchSize</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Largest batch size allowed in sequence data.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">maxBeamSize</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Largest beam size allowed in sequence data.</td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                        <p class="p"><strong class="ph b">Returns:</strong></p>
                        <div class="tablenoborder"><a name="cudnnSetAttnDescriptor__table_usk_kcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnSetAttnDescriptor__table_usk_kcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Return Value</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_SUCCESS </td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">The <samp class="ph codeph">attnDesc</samp> field values are updated
                                       							successfully.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_BAD_PARAM </td>
                                    <td class="entry" valign="top" width="50%" rowspan="1" colspan="1">
                                       <p dir="ltr" class="p">An invalid input value is encountered. For example:</p>
                                       <p dir="ltr" class="p">- <samp class="ph codeph">attnDesc</samp> is NULL 
                                       </p>
                                       <p dir="ltr" class="p">- <samp class="ph codeph">queryMap</samp> is not one of enumerated labels of
                                          									<samp class="ph codeph">cudnnAttnQueryMap_t</samp></p>
                                       <p dir="ltr" class="p">- Effective Q, K projection size are not equal (see remark below) </p>
                                       <p dir="ltr" class="p">- <samp class="ph codeph">dataType</samp>, <samp class="ph codeph">computePrec</samp>,
                                          									<samp class="ph codeph">mathType</samp> are invalid
                                       </p>
                                       <p dir="ltr" class="p">Any of the following valid ranges are violated: </p>
                                       <p dir="ltr" class="p"> - <samp class="ph codeph">nHeads, qSize, kSize, vSize, qoMaxSeqLength,
                                             									kvMaxSeqLength, maxBatchSize, maxBeamSize</samp> &gt;= 1 
                                       </p>
                                       <p dir="ltr" class="p"> - <samp class="ph codeph">qProjSize, kProjSize, vProjSize</samp> &gt;= 0 
                                       </p>
                                       <p dir="ltr" class="p"> - <samp class="ph codeph">smScaler</samp> &gt;= 0.0 
                                       </p>
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_NOT_SUPPORTED </td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">An unsupported value is encountered.</td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSetCallback"><a name="cudnnSetCallback" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetCallback" name="cudnnSetCallback" shape="rect">4.177.&nbsp;cudnnSetCallback</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetCallback(
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span>            mask,
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                *udata,
        cudnnCallback_t     fptr)</pre><p class="p"><strong class="ph b">(New for 7.1)</strong></p>
                        <p class="p">This function sets the internal states of cuDNN error reporting functionality.</p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">mask</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. An unsigned integer. The four least significant bits (LSBs) of
                                 this unsigned integer are used for switching on and off the different levels
                                 of error reporting messages. This applies for both the default callbacks,
                                 and for the customized callbacks. The bit position is in correspondence with
                                 the enum of <samp class="ph codeph">cudnnSeverity_t</samp>. The user may utilize the
                                 predefined macros CUDNN_SEV_ERROR_EN, CUDNN_SEV_WARNING_EN, and
                                 CUDNN_SEV_INFO_EN to form the bit mask. When a bit is set to 1, the
                                 corresponding message channel is enabled. 
                              </p>
                              <p class="p">For example, when bit 3 is set to 1, the API logging is enabled. Currently
                                 only the log output of level CUDNN_SEV_INFO is functional; the others are
                                 not yet implemented. When used for turning on and off the logging with the
                                 default callback, the user may pass NULL to <samp class="ph codeph">udata</samp> and
                                 <samp class="ph codeph">fptr</samp>. In addition, the environment variable
                                 CUDNN_LOGDEST_DBG must be set (see Section 2.11). 
                              </p>
                              <p class="p"><samp class="ph codeph">CUDNN_SEV_INFO_EN</samp> = 0b1000 (functional).
                              </p>
                              <p class="p"><samp class="ph codeph">CUDNN_SEV_ERROR_EN</samp> = 0b0010 (not yet functional).
                              </p>
                              <p class="p"><samp class="ph codeph">CUDNN_SEV_WARNING_EN</samp> = 0b0100 (not yet functional).
                              </p>
                              <p class="p">The output of CUDNN_SEV_FATAL is always enabled, and cannot be disabled.</p>
                           </dd>
                           <dt class="dt dlterm">udata</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A pointer provided by the user. This pointer will be passed to
                                 the user’s custom logging callback function. The data it points to will not
                                 be read, nor be changed by cuDNN. This pointer may be used in many ways,
                                 such as in a mutex or in a communication socket for the user’s callback
                                 function for logging. If the user is utilizing the default callback
                                 function, or doesn’t want to use this input in the customized callback
                                 function, they may pass in NULL. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">fptr</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A pointer to a user-supplied callback function. When NULL is
                                 passed to this pointer, then cuDNN switches back to the built-in default
                                 callback function. The user-supplied callback function prototype must be
                                 similar to the following (also defined in the header file):
                              </p>
                              <p class="p"><samp class="ph codeph">void customizedLoggingCallback (cudnnSeverity_t sev, void *udata,
                                    const cudnnDebug_t *dbg, const char *msg);</samp></p>
                              <div class="p"><a name="cudnnSetCallback__ul_zfm_jn5_k2b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnSetCallback__ul_zfm_jn5_k2b">
                                    <li class="li">The structure <samp class="ph codeph">cudnnDebug_t</samp> is defined in the header
                                       file. It provides the metadata, such as time, time since start,
                                       stream ID, process and thread ID, that the user may choose to print
                                       or store in their customized callback. 
                                    </li>
                                    <li class="li">The variable <samp class="ph codeph">msg</samp> is the logging message generated
                                       by cuDNN. Each line of this message is terminated by
                                       <samp class="ph codeph">“\0”</samp>, and the end of message is terminated by
                                       <samp class="ph codeph">“\0\0”</samp>. User may select what is necessary to
                                       show in the log, and may reformat the string. 
                                    </li>
                                 </ul>
                              </div>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The function launched successfully.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSetConvolution2dDescriptor"><a name="cudnnSetConvolution2dDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetConvolution2dDescriptor" name="cudnnSetConvolution2dDescriptor" shape="rect">4.178.&nbsp;cudnnSetConvolution2dDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetConvolution2dDescriptor(
    cudnnConvolutionDescriptor_t    convDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                             pad_h,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                             pad_w,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                             u,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                             v,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                             dilation_h,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                             dilation_w,
    cudnnConvolutionMode_t          mode,
    cudnnDataType_t                 computeType)</pre><p class="p">This function initializes a previously created convolution descriptor object into a 2D
                           correlation. This function assumes that the tensor and filter descriptors corresponds to
                           the formard convolution path and checks if their settings are valid. That same
                           convolution descriptor can be reused in the backward path provided it corresponds to the
                           same layer. 
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">convDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input/Output</em>. Handle to a previously created convolution
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">pad_h </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. zero-padding height: number of rows of zeros implicitly
                                 concatenated onto the top and onto the bottom of input images.
                              </p>
                           </dd>
                           <dt class="dt dlterm">pad_w </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. zero-padding width: number of columns of zeros implicitly
                                 concatenated onto the left and onto the right of input images.
                              </p>
                           </dd>
                           <dt class="dt dlterm">u </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Vertical filter stride.
                              </p>
                           </dd>
                           <dt class="dt dlterm">v </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Horizontal filter stride.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dilation_h </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Filter height dilation.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dilation_w </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Filter width dilation.
                              </p>
                           </dd>
                           <dt class="dt dlterm">mode </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Selects between <samp class="ph codeph">CUDNN_CONVOLUTION</samp> and
                                 <samp class="ph codeph">CUDNN_CROSS_CORRELATION</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">computeType </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. compute precision.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was set successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnSetConvolution2dDescriptor__ul_a54_yfb_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnSetConvolution2dDescriptor__ul_a54_yfb_s1b">
                                 <li class="li">The descriptor <samp class="ph codeph">convDesc</samp> is nil.
                                 </li>
                                 <li class="li">One of the parameters <samp class="ph codeph">pad_h,pad_w</samp> is strictly
                                    negative.
                                 </li>
                                 <li class="li">One of the parameters <samp class="ph codeph">u,v</samp> is negative or zero.
                                 </li>
                                 <li class="li">One of the parameters <samp class="ph codeph">dilation_h,dilation_w</samp> is negative
                                    or zero.
                                 </li>
                                 <li class="li">The parameter <samp class="ph codeph">mode</samp> has an invalid enumerant value.
                                 </li>
                              </ul>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSetConvolutionGroupCount"><a name="cudnnSetConvolutionGroupCount" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetConvolutionGroupCount" name="cudnnSetConvolutionGroupCount" shape="rect">4.179.&nbsp;cudnnSetConvolutionGroupCount</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetConvolutionGroupCount(
    cudnnConvolutionDescriptor_t    convDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                             groupCount)</pre><p class="p">This function allows the user to specify the number of groups to be used in the
                           associated convolution. 
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The group count was set successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">An invalid convolution descriptor was provided</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSetConvolutionMathType"><a name="cudnnSetConvolutionMathType" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetConvolutionMathType" name="cudnnSetConvolutionMathType" shape="rect">4.180.&nbsp;cudnnSetConvolutionMathType</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetConvolutionMathType(
    cudnnConvolutionDescriptor_t    convDesc,
    cudnnMathType_t                 mathType)</pre><p class="p">This function allows the user to specify whether or not the use of tensor op is permitted
                           in library routines associated with a given convolution descriptor. 
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The math type was was set successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p"> Either an invalid convolution descriptor was provided or an invalid math
                                 type was specified.
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSetConvolutionNdDescriptor"><a name="cudnnSetConvolutionNdDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetConvolutionNdDescriptor" name="cudnnSetConvolutionNdDescriptor" shape="rect">4.181.&nbsp;cudnnSetConvolutionNdDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetConvolutionNdDescriptor(
    cudnnConvolutionDescriptor_t    convDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                             arrayLength,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                       padA[],
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                       filterStrideA[],
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                       dilationA[],
    cudnnConvolutionMode_t          mode,
    cudnnDataType_t                 dataType)</pre><p class="p">This function initializes a previously created generic convolution descriptor object into
                           a n-D correlation. That same convolution descriptor can be reused in the backward path
                           provided it corresponds to the same layer. The convolution computation will done in the
                           specified <samp class="ph codeph">dataType</samp>, which can be potentially different from the
                           input/output tensors. 
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">convDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input/Output</em>. Handle to a previously created convolution
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">arrayLength </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Dimension of the convolution.
                              </p>
                           </dd>
                           <dt class="dt dlterm">padA </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Array of dimension <samp class="ph codeph">arrayLength</samp> containing the
                                 zero-padding size for each dimension. For every dimension, the padding
                                 represents the number of extra zeros implicitly concatenated at the start
                                 and at the end of every element of that dimension .
                              </p>
                           </dd>
                           <dt class="dt dlterm">filterStrideA </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Array of dimension <samp class="ph codeph">arrayLength</samp> containing the
                                 filter stride for each dimension. For every dimension, the fitler stride
                                 represents the number of elements to slide to reach the next start of the
                                 filtering window of the next point.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dilationA </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Array of dimension <samp class="ph codeph">arrayLength</samp> containing the
                                 dilation factor for each dimension. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">mode </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Selects between <samp class="ph codeph">CUDNN_CONVOLUTION</samp> and
                                 <samp class="ph codeph">CUDNN_CROSS_CORRELATION</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">datatype </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Selects the datatype in which the computation will be done.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was set successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnSetConvolutionNdDescriptor__ul_idc_lgb_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnSetConvolutionNdDescriptor__ul_idc_lgb_s1b">
                                 <li class="li">The descriptor <samp class="ph codeph">convDesc</samp> is nil.
                                 </li>
                                 <li class="li">The <samp class="ph codeph">arrayLengthRequest</samp> is negative.
                                 </li>
                                 <li class="li">The enumerant <samp class="ph codeph">mode</samp> has an invalid value.
                                 </li>
                                 <li class="li">The enumerant <samp class="ph codeph">datatype</samp> has an invalid value.
                                 </li>
                                 <li class="li">One of the elements of <samp class="ph codeph">padA</samp> is strictly negative.
                                 </li>
                                 <li class="li">One of the elements of <samp class="ph codeph">strideA</samp> is negative or
                                    zero.
                                 </li>
                                 <li class="li">One of the elements of <samp class="ph codeph">dilationA</samp> is negative or
                                    zero.
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnSetConvolutionNdDescriptor__ul_tdc_lgb_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnSetConvolutionNdDescriptor__ul_tdc_lgb_s1b">
                                 <li class="li">The <samp class="ph codeph">arrayLengthRequest</samp> is greater than
                                    CUDNN_DIM_MAX.
                                 </li>
                              </ul>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSetConvolutionReorderType"><a name="cudnnSetConvolutionReorderType" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetConvolutionReorderType" name="cudnnSetConvolutionReorderType" shape="rect">4.182.&nbsp;cudnnSetConvolutionReorderType</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetConvolutionReorderType(
	cudnnConvolutionDescriptor_t convDesc, 
	cudnnReorderType_t reorderType);		</pre><p dir="ltr" class="p" id="cudnnSetConvolutionReorderType__docs-internal-guid-0eaa8c2b-7fff-7d3b-da2a-c0eee8303faf"><a name="cudnnSetConvolutionReorderType__docs-internal-guid-0eaa8c2b-7fff-7d3b-da2a-c0eee8303faf" shape="rect">
                              <!-- --></a>This function sets the
                           			convolution reorder type for the given convolution descriptor. 
                        </p>
                        <p class="p"><strong class="ph b">Parameters:</strong></p>
                        <div class="tablenoborder"><a name="cudnnSetConvolutionReorderType__table_hpj_hcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnSetConvolutionReorderType__table_hpj_hcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1"><strong class="ph b">Parameter</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1"><strong class="ph b">Input / Output</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">convDesc</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">The convolution descriptor for which the reorder type should be
                                       							set. 
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">reorderType</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Set the reorder type to this value. See <a class="xref" href="index.html#cudnnReorderType_t" shape="rect">cudnnReorderType_t</a>.
                                    </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                        <p class="p"><strong class="ph b">Returns:</strong></p>
                        <div class="tablenoborder"><a name="cudnnSetConvolutionReorderType__table_usk_kcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnSetConvolutionReorderType__table_usk_kcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Return Value</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_BAD_PARAM</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">The reorder type supplied is not supported. </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_SUCCESS</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">Reorder type is set successfully.</td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSetCTCLossDescriptor"><a name="cudnnSetCTCLossDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetCTCLossDescriptor" name="cudnnSetCTCLossDescriptor" shape="rect">4.183.&nbsp;cudnnSetCTCLossDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetCTCLossDescriptor(
    cudnnCTCLossDescriptor_t        ctcLossDesc,
    cudnnDataType_t                 compType)</pre><p class="p">This function sets a CTC loss function descriptor. See also the extended version <a class="xref" href="index.html#cudnnSetCTCLossDescriptorEx" shape="rect">cudnnSetCTCLossDescriptorEx</a> to set the input normalization mode. 
                        </p>
                        <div class="p">When the extended version <samp class="ph codeph">cudnnSetCTCLossDescriptorEx</samp> is used with
                           				<samp class="ph codeph">normMode</samp> set to CUDNN_LOSS_NORMALIZATION_NONE and the
                           				<samp class="ph codeph">gradMode</samp> set to CUDNN_NOT_PROPAGATE_NAN, then it is the same as the
                           			current function <samp class="ph codeph">cudnnSetCTCLossDescriptor</samp>, i.e.,
                           			<pre xml:space="preserve">cudnnSetCtcLossDescriptor(*) = cudnnSetCtcLossDescriptorEx(*, normMode=CUDNN_LOSS_NORMALIZATION_NONE, gradMode=CUDNN_NOT_PROPAGATE_NAN)</pre></div>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">ctcLossDesc</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. CTC loss descriptor to be set.
                              </p>
                           </dd>
                           <dt class="dt dlterm">compType</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Compute type for this CTC loss function.
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The function returned successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of input parameters passed is invalid.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSetCTCLossDescriptorEx"><a name="cudnnSetCTCLossDescriptorEx" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetCTCLossDescriptorEx" name="cudnnSetCTCLossDescriptorEx" shape="rect">4.184.&nbsp;cudnnSetCTCLossDescriptorEx</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetCTCLossDescriptorEx(
    cudnnCTCLossDescriptor_t        ctcLossDesc,
    cudnnDataType_t                 compType,
    cudnnLossNormalizationMode_t    normMode,
    cudnnNanPropagation_t           gradMode)</pre><p class="p">This function is an extension of <a class="xref" href="index.html#cudnnSetCTCLossDescriptor" shape="rect">cudnnSetCTCLossDescriptor</a>. This
                           			function provides an additional interface <samp class="ph codeph">normMode</samp> to set the input
                           			normaliztion mode for the CTC loss function,  and <samp class="ph codeph">gradMode</samp> to control the
                           			NaN propagation type.
                        </p>
                        <div class="p">When this function <samp class="ph codeph">cudnnSetCTCLossDescriptorEx</samp> is used with
                           				<samp class="ph codeph">normMode</samp> set to CUDNN_LOSS_NORMALIZATION_NONE and the
                           				<samp class="ph codeph">gradMode</samp> set to CUDNN_NOT_PROPAGATE_NAN, then it is the same as
                           				<samp class="ph codeph">cudnnSetCTCLossDescriptor</samp>, i.e.,
                           			<pre xml:space="preserve">cudnnSetCtcLossDescriptor(*) = cudnnSetCtcLossDescriptorEx(*, normMode=CUDNN_LOSS_NORMALIZATION_NONE, gradMode=CUDNN_NOT_PROPAGATE_NAN)</pre></div>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">ctcLossDesc</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. CTC loss descriptor to be set.
                              </p>
                           </dd>
                           <dt class="dt dlterm">compType</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Compute type for this CTC loss function.
                              </p>
                           </dd>
                           <dt class="dt dlterm">normMode</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Input normalization type for this CTC loss function. See also <a class="xref" href="index.html#cudnnLossNormalizationMode_t" shape="rect">cudnnLossNormalizationMode_t</a>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">gradMode</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. NaN propagation type for this CTC loss function. For L the sequence
                                 						length, R the number of repeated letters in the sequence, and T the length of
                                 						sequential data, the following applies: When a sample with <samp class="ph codeph">L+R &gt;
                                    							T</samp> is encountered during the gradient calcuation, if
                                 							<samp class="ph codeph">gradMode</samp> is set to CUDNN_PROPAGATE_NAN (see <a class="xref" href="index.html#cudnnNanPropagation_t" shape="rect">cudnnNanPropagation_t</a>), then the CTC loss function does not write to
                                 						the gradient buffer for that sample. Instead, the current values, even not finite,
                                 						are retained. If <samp class="ph codeph">gradMode</samp> is set to CUDNN_NOT_PROPAGATE_NAN, then
                                 						the gradient for that sample is set to zero. This guarantees finite gradient. 
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The function returned successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of input parameters passed is invalid.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSetDropoutDescriptor"><a name="cudnnSetDropoutDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetDropoutDescriptor" name="cudnnSetDropoutDescriptor" shape="rect">4.185.&nbsp;cudnnSetDropoutDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetDropoutDescriptor(
    cudnnDropoutDescriptor_t    dropoutDesc,
    cudnnHandle_t               handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>                       dropout,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                       *states,
    size_t                      stateSizeInBytes,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span>          seed)</pre><p class="p">This function initializes a previously created dropout descriptor object. If
                           <samp class="ph codeph">states</samp> argument is equal to NULL, random number generator states
                           won't be initialized, and only <samp class="ph codeph">dropout</samp> value will be set. No other
                           function should be writing to the memory pointed at by <samp class="ph codeph">states</samp> argument
                           while this function is running. The user is expected not to change memory pointed at by
                           <samp class="ph codeph">states</samp> for the duration of the computation.
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">dropoutDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input/Output</em>. Previously created dropout descriptor object.
                              </p>
                           </dd>
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dropout </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. The probability with which the value from input is set to zero
                                 during the dropout layer.
                              </p>
                           </dd>
                           <dt class="dt dlterm">states </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Pointer to user-allocated GPU memory that will hold random
                                 number generator states.
                              </p>
                           </dd>
                           <dt class="dt dlterm">stateSizeInBytes </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Specifies size in bytes of the provided memory for the
                                 states
                              </p>
                           </dd>
                           <dt class="dt dlterm">seed </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Seed used to initialize random number generator states.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The call was successful.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_INVALID_VALUE</samp></dt>
                           <dd class="dd">
                              <p class="p"><samp class="ph codeph">sizeInBytes</samp> is less than the value returned by
                                 <samp class="ph codeph">cudnnDropoutGetStatesSize</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function failed to launch on the GPU</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSetFilter4dDescriptor"><a name="cudnnSetFilter4dDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetFilter4dDescriptor" name="cudnnSetFilter4dDescriptor" shape="rect">4.186.&nbsp;cudnnSetFilter4dDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetFilter4dDescriptor(
    cudnnFilterDescriptor_t    filterDesc,
    cudnnDataType_t            dataType,
    cudnnTensorFormat_t        format,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                        k,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                        c,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                        h,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                        w)</pre><p class="p">This function initializes a previously created filter descriptor object into a 4D filter.
                           The layout of the filters must be contiguous in memory. 
                        </p>
                        <p class="p">Tensor format CUDNN_TENSOR_NHWC has limited support in
                           <samp class="ph codeph">cudnnConvolutionForward</samp>,
                           <samp class="ph codeph">cudnnConvolutionBackwardData</samp> and
                           <samp class="ph codeph">cudnnConvolutionBackwardFilter</samp>; please refer to the documentation
                           for each function for more information. 
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">filterDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input/Output</em>. Handle to a previously created filter descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">datatype </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data type.
                              </p>
                           </dd>
                           <dt class="dt dlterm">format </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>.Type of the filter layout format. If this input is set to
                                 CUDNN_TENSOR_NCHW, which is one of the enumerated values allowed by
                                 <samp class="ph codeph">cudnnTensorFormat_t</samp> descriptor, then the layout of the
                                 filter is in the form of KCRS (K represents the number of output feature
                                 maps, C the number of input feature maps, R the number of rows per filter,
                                 and S the number of columns per filter.) 
                              </p>
                              <p class="p">If this input is set to CUDNN_TENSOR_NHWC, then the layout of the filter is
                                 in the form of KRSC. See also the description for
                                 <samp class="ph codeph">cudnnTensorFormat_t</samp>. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">k </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Number of output feature maps.
                              </p>
                           </dd>
                           <dt class="dt dlterm">c </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Number of input feature maps.
                              </p>
                           </dd>
                           <dt class="dt dlterm">h </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Height of each filter.
                              </p>
                           </dd>
                           <dt class="dt dlterm">w </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Width of each filter.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was set successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the parameters <samp class="ph codeph">k,c,h,w</samp> is negative or
                                 <samp class="ph codeph">dataType</samp> or <samp class="ph codeph">format</samp> has an invalid
                                 enumerant value. 
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSetFilterNdDescriptor"><a name="cudnnSetFilterNdDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetFilterNdDescriptor" name="cudnnSetFilterNdDescriptor" shape="rect">4.187.&nbsp;cudnnSetFilterNdDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetFilterNdDescriptor(
    cudnnFilterDescriptor_t filterDesc,
    cudnnDataType_t         dataType,
    cudnnTensorFormat_t     format,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                     nbDims,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>               filterDimA[])</pre><p class="p">This function initializes a previously created filter descriptor object.  The layout of
                           the filters must be contiguous in memory. 
                        </p>
                        <p class="p">The tensor format CUDNN_TENSOR_NHWC has limited support in
                           <samp class="ph codeph">cudnnConvolutionForward</samp>,
                           <samp class="ph codeph">cudnnConvolutionBackwardData</samp> and
                           <samp class="ph codeph">cudnnConvolutionBackwardFilter</samp>; please refer to the documentation
                           for each function for more information.
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">filterDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input/Output</em>. Handle to a previously created filter descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">datatype </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data type.
                              </p>
                           </dd>
                           <dt class="dt dlterm">format </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>.Type of the filter layout format. If this input is set to
                                 CUDNN_TENSOR_NCHW, which is one of the enumerated values allowed by
                                 <samp class="ph codeph">cudnnTensorFormat_t</samp> descriptor, then the layout of the
                                 filter is as follows: 
                              </p>
                              <div class="p"><a name="cudnnSetFilterNdDescriptor__ul_qyq_1h5_k2b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnSetFilterNdDescriptor__ul_qyq_1h5_k2b">
                                    <li class="li">For N=4, i.e., for a 4D filter descriptor, the filter layout is in
                                       the form of KCRS (K represents the number of output feature maps, C
                                       the number of input feature maps, R the number of rows per filter,
                                       and S the number of columns per filter.) 
                                    </li>
                                    <li class="li">For N=3, i.e., for a 3D filter descriptor, the number S (number of
                                       columns per filter) is omitted. 
                                    </li>
                                    <li class="li">For N=5 and greater, the layout of the higher dimensions immediately
                                       follow RS. 
                                    </li>
                                 </ul>
                              </div>
                              <p class="p">On the other hand, if this input is set to CUDNN_TENSOR_NHWC, then the layout
                                 of the filter is as follows: 
                              </p>
                              <div class="p"><a name="cudnnSetFilterNdDescriptor__ul_txm_jh5_k2b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnSetFilterNdDescriptor__ul_txm_jh5_k2b">
                                    <li class="li">For N=4, i.e., for a 4D filter descriptor, the filter layout is in
                                       the form of KRSC. 
                                    </li>
                                    <li class="li">For N=3, i.e., for a 3D filter descriptor, the number S (number of
                                       columns per filter) is omitted, and the layout of C immediately
                                       follows R. 
                                    </li>
                                    <li class="li">For N=5 and greater, the layout of the higher dimensions are
                                       inserted between S and C. See also the description for
                                       <samp class="ph codeph">cudnnTensorFormat_t</samp>.
                                    </li>
                                 </ul>
                              </div>
                           </dd>
                           <dt class="dt dlterm">nbDims </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Dimension of the filter.
                              </p>
                           </dd>
                           <dt class="dt dlterm">filterDimA </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Array of dimension <samp class="ph codeph">nbDims</samp> containing the size
                                 of the filter for each dimension.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was set successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the elements of the array <samp class="ph codeph">filterDimA</samp> is
                                 negative or <samp class="ph codeph">dataType</samp> or <samp class="ph codeph">format</samp> has an
                                 invalid enumerant value. 
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The parameter <samp class="ph codeph">nbDims</samp> exceeds CUDNN_DIM_MAX. 
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSetFusedOpsConstParamPackAttribute"><a name="cudnnSetFusedOpsConstParamPackAttribute" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetFusedOpsConstParamPackAttribute" name="cudnnSetFusedOpsConstParamPackAttribute" shape="rect">4.188.&nbsp;cudnnSetFusedOpsConstParamPackAttribute</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetFusedOpsConstParamPackAttribute(
	cudnnFusedOpsConstParamPack_t constPack,
	cudnnFusedOpsConstParamLabel_t paramLabel,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *param);		</pre><p class="p">This function sets the descriptor pointed to by the param pointer input. The type of the
                           			descriptor to be set is indicated by the enum value of <span class="keyword apiname">paramLabel</span> input. 
                        </p>
                        <p class="p"><strong class="ph b">Parameters:</strong></p>
                        <div class="tablenoborder"><a name="cudnnSetFusedOpsConstParamPackAttribute__table_hpj_hcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnSetFusedOpsConstParamPackAttribute__table_hpj_hcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1"><strong class="ph b">Parameter</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1"><strong class="ph b">Input / Output</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">constPack</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">The opaque <a class="xref" href="index.html#cudnnFusedOpsConstParamPack_t" shape="rect">cudnnFusedOpsConstParamPack_t</a> structure that
                                       							contains the various problem size information, such as the shape, layout and
                                       							the type of Tensors, the descriptors for convolution and activation, and
                                       							settings for operations such as convolution and activation. 
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">paramLabel</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Several types of descriptors can be set by this setter function. The param
                                       							input points to the descriptor itself, and this input indicates the type of the
                                       							descriptor pointed to by the param input. The <a class="xref" href="index.html#cudnnFusedOpsConstParamLabel_t" shape="rect">cudnnFusedOpsConstParamLabel_t</a>  enumerated type enables the
                                       							selection of the type of the descriptor. See the <span class="keyword apiname">param</span>
                                       							description below.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">param</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">
                                       <p dir="ltr" class="p">Data pointer, to the host memory, associated with the specific descriptor. The
                                          								type of the descriptor depends on the value of
                                          								<span class="keyword apiname">paramLabel</span>. See the table in <a class="xref" href="index.html#cudnnFusedOpsConstParamLabel_t" shape="rect">cudnnFusedOpsConstParamLabel_t</a>. 
                                       </p>
                                       <p dir="ltr" class="p">If this pointer is set to NULL, then the cuDNN library will record as such. If
                                          								not, then the values pointed to by this pointer (i.e., the value or the
                                          								opaque structure underneath) will be copied into the constPack during ​
                                          									<samp class="ph codeph">cudnnSetFusedOpsConstParamPackAttribute()</samp> operation.
                                       </p>
                                    </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                        <p class="p"><strong class="ph b">Returns:</strong></p>
                        <div class="tablenoborder"><a name="cudnnSetFusedOpsConstParamPackAttribute__table_usk_kcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnSetFusedOpsConstParamPackAttribute__table_usk_kcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Return Value</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_SUCCESS</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">The descriptor is set successfully. </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_BAD_PARAM</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">If <samp class="ph codeph">constPack</samp> is NULL, or if
                                       								<samp class="ph codeph">paramLabel</samp> or the <samp class="ph codeph">ops</samp> setting for
                                       								<samp class="ph codeph">constPack</samp> is invalid. 
                                    </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSetFusedOpsVariantParamPackAttribute"><a name="cudnnSetFusedOpsVariantParamPackAttribute" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetFusedOpsVariantParamPackAttribute" name="cudnnSetFusedOpsVariantParamPackAttribute" shape="rect">4.189.&nbsp;cudnnSetFusedOpsVariantParamPackAttribute</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetFusedOpsVariantParamPackAttribute(
	cudnnFusedOpsVariantParamPack_t varPack,
	cudnnFusedOpsVariantParamLabel_t paramLabel,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *ptr);		</pre><p class="p">This function sets the variable parameter pack descriptor. </p>
                        <p class="p"><strong class="ph b">Parameters:</strong></p>
                        <div class="tablenoborder"><a name="cudnnSetFusedOpsVariantParamPackAttribute__table_hpj_hcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnSetFusedOpsVariantParamPackAttribute__table_hpj_hcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1"><strong class="ph b">Parameter</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1"><strong class="ph b">Input / Output</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">varPack</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Pointer to the cudnnFusedOps variant parameter pack
                                       								(<samp class="ph codeph">varPack</samp>) descriptor. 
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">paramLabel</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Type to which the buffer pointer parameter (in the <samp class="ph codeph">varPack</samp>
                                       							descriptor) is set by this function. See <a class="xref" href="index.html#cudnnFusedOpsConstParamLabel_t" shape="rect">cudnnFusedOpsConstParamLabel_t</a>.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">ptr</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Pointer, to the host or device memory, to the value to which the descriptor
                                       							parameter is set. The data type of the pointer, and the host/device memory
                                       							location, depend on the <samp class="ph codeph">paramLabel</samp> input selection. See
                                       								<span class="keyword apiname">cudnnFusedOpsVariantParamLabel_t</span>. 
                                    </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                        <p class="p"><strong class="ph b">Returns:</strong></p>
                        <div class="tablenoborder"><a name="cudnnSetFusedOpsVariantParamPackAttribute__table_usk_kcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnSetFusedOpsVariantParamPackAttribute__table_usk_kcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Return Value</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_BAD_PARAM</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">If <samp class="ph codeph">varPack</samp> is NULL or if
                                       								<samp class="ph codeph">paramLabel</samp> is set to an unsupported value. 
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_SUCCESS</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">The descriptor was set successfully.</td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSetLRNDescriptor"><a name="cudnnSetLRNDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetLRNDescriptor" name="cudnnSetLRNDescriptor" shape="rect">4.190.&nbsp;cudnnSetLRNDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetLRNDescriptor(
    cudnnLRNDescriptor_t   normDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span>               lrnN,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>                 lrnAlpha,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>                 lrnBeta,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>                 lrnK)</pre><p class="p">This function initializes a previously created LRN descriptor object. </p>
                        <div class="note note"><span class="notetitle">Note:</span> Macros CUDNN_LRN_MIN_N, CUDNN_LRN_MAX_N, CUDNN_LRN_MIN_K, CUDNN_LRN_MIN_BETA defined
                           in cudnn.h specify valid ranges for parameters.
                        </div>
                        <div class="note note"><span class="notetitle">Note:</span> Values of double parameters will be cast down to the tensor datatype during
                           computation.
                        </div>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">normDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Handle to a previously created LRN descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">lrnN </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Normalization window width in elements. LRN layer uses a window
                                 [center-lookBehind, center+lookAhead], where lookBehind = floor( (lrnN-1)/2
                                 ), lookAhead = lrnN-lookBehind-1. So for n=10, the window is [k-4...k...k+5]
                                 with a total of 10 samples. For DivisiveNormalization layer the window has
                                 the same extents as above in all 'spatial' dimensions (dimA[2], dimA[3],
                                 dimA[4]). By default lrnN is set to 5 in cudnnCreateLRNDescriptor. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">lrnAlpha </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Value of the alpha variance scaling parameter in the
                                 normalization formula. Inside the library code this value is divided by the
                                 window width for LRN and by (window width)^#spatialDimensions for
                                 DivisiveNormalization. By default this value is set to 1e-4 in
                                 cudnnCreateLRNDescriptor. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">lrnBeta </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Value of the beta power parameter in the normalization formula.
                                 By default this value is set to 0.75 in cudnnCreateLRNDescriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">lrnK </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Value of the k parameter in normalization formula. By default
                                 this value is set to 2.0.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">Possible error values returned by this function and their meanings are listed below.</p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was set successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">One of the input parameters was out of valid range as described above. </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSetOpTensorDescriptor"><a name="cudnnSetOpTensorDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetOpTensorDescriptor" name="cudnnSetOpTensorDescriptor" shape="rect">4.191.&nbsp;cudnnSetOpTensorDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetOpTensorDescriptor(
    cudnnOpTensorDescriptor_t   opTensorDesc,
    cudnnOpTensorOp_t           opTensorOp,
    cudnnDataType_t             opTensorCompType,
    cudnnNanPropagation_t       opTensorNanOpt)</pre><p class="p">This function initializes a Tensor Pointwise math descriptor.</p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">opTensorDesc</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Pointer to the structure holding the description of the Tensor Pointwise math descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">opTensorOp</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Tensor Pointwise math operation for this Tensor Pointwise math descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">opTensorCompType</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Computation datatype for this Tensor Pointwise math descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">opTensorNanOpt</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. NAN propagation policy
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The function returned successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of input parameters passed is invalid.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSetPersistentRNNPlan"><a name="cudnnSetPersistentRNNPlan" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetPersistentRNNPlan" name="cudnnSetPersistentRNNPlan" shape="rect">4.192.&nbsp;cudnnSetPersistentRNNPlan</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetPersistentRNNPlan(
    cudnnRNNDescriptor_t        rnnDesc,
    cudnnPersistentRNNPlan_t    plan)</pre><p class="p">This function sets the persistent RNN plan to be executed when using
                           <samp class="ph codeph">rnnDesc</samp> and <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_DYNAMIC</samp>
                           algo.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The plan was set successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">The algo selected in <samp class="ph codeph">rnnDesc</samp> is not
                                 <samp class="ph codeph">CUDNN_RNN_ALGO_PERSIST_DYNAMIC</samp>.
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSetPooling2dDescriptor"><a name="cudnnSetPooling2dDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetPooling2dDescriptor" name="cudnnSetPooling2dDescriptor" shape="rect">4.193.&nbsp;cudnnSetPooling2dDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetPooling2dDescriptor(
    cudnnPoolingDescriptor_t    poolingDesc,
    cudnnPoolingMode_t          mode,
    cudnnNanPropagation_t       maxpoolingNanOpt,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                         windowHeight,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                         windowWidth,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                         verticalPadding,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                         horizontalPadding,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                         verticalStride,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                         horizontalStride)</pre><p class="p">This function initializes a previously created generic pooling descriptor object into a
                           2D description. 
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">poolingDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input/Output</em>. Handle to a previously created pooling descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">mode </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Enumerant to specify the pooling mode.
                              </p>
                           </dd>
                           <dt class="dt dlterm">maxpoolingNanOpt </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Enumerant to specify the Nan propagation mode.
                              </p>
                           </dd>
                           <dt class="dt dlterm">windowHeight </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Height of the pooling window.
                              </p>
                           </dd>
                           <dt class="dt dlterm">windowWidth </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Width of the pooling window.
                              </p>
                           </dd>
                           <dt class="dt dlterm">verticalPadding </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Size of vertical padding.
                              </p>
                           </dd>
                           <dt class="dt dlterm">horizontalPadding </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Size of horizontal padding
                              </p>
                           </dd>
                           <dt class="dt dlterm">verticalStride </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pooling vertical stride.
                              </p>
                           </dd>
                           <dt class="dt dlterm">horizontalStride </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pooling horizontal stride.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was set successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the parameters <samp class="ph codeph">windowHeight, windowWidth,
                                    verticalStride, horizontalStride</samp> is negative or
                                 <samp class="ph codeph">mode</samp> or <samp class="ph codeph">maxpoolingNanOpt</samp> has an
                                 invalid enumerant value.
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSetPoolingNdDescriptor"><a name="cudnnSetPoolingNdDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetPoolingNdDescriptor" name="cudnnSetPoolingNdDescriptor" shape="rect">4.194.&nbsp;cudnnSetPoolingNdDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetPoolingNdDescriptor(
    cudnnPoolingDescriptor_t     poolingDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnPoolingMode_t     mode,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnNanPropagation_t  maxpoolingNanOpt,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                          nbDims,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                    windowDimA[],
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                    paddingA[],
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                    strideA[])</pre><p class="p">This function initializes a previously created generic pooling descriptor object. </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">poolingDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input/Output</em>. Handle to a previously created pooling descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">mode </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Enumerant to specify the pooling mode.
                              </p>
                           </dd>
                           <dt class="dt dlterm">maxpoolingNanOpt </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Enumerant to specify the Nan propagation mode.
                              </p>
                           </dd>
                           <dt class="dt dlterm">nbDims </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Dimension of the pooling operation. Must be greater than zero. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">windowDimA </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Array of dimension <samp class="ph codeph">nbDims</samp> containing the
                                 						window size for each dimension. The value of array elements must be greater
                                 						than zero. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">paddingA </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Array of dimension <samp class="ph codeph">nbDims</samp> containing the
                                 						padding size for each dimension. Negative padding is allowed. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">strideA </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Array of dimension <samp class="ph codeph">nbDims</samp> containing the
                                 						striding size for each dimension. The value of array elements must be
                                 						greater than zero (i.e., negative striding size is not allowed). 
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was initialized successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">If (nbDims &gt; CUDNN_DIM_MAX - 2). </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">Either nbDims, or at least one of the elements of the arrays
                                 							<samp class="ph codeph">windowDimA, or strideA</samp> is negative, or
                                 							<samp class="ph codeph">mode</samp> or <samp class="ph codeph">maxpoolingNanOpt</samp> has an
                                 						invalid enumerant value.
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSetReduceTensorDescriptor"><a name="cudnnSetReduceTensorDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetReduceTensorDescriptor" name="cudnnSetReduceTensorDescriptor" shape="rect">4.195.&nbsp;cudnnSetReduceTensorDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetReduceTensorDescriptor(
    cudnnReduceTensorDescriptor_t   reduceTensorDesc,
    cudnnReduceTensorOp_t           reduceTensorOp,
    cudnnDataType_t                 reduceTensorCompType,
    cudnnNanPropagation_t           reduceTensorNanOpt,
    cudnnReduceTensorIndices_t      reduceTensorIndices,
    cudnnIndicesType_t              reduceTensorIndicesType)</pre><p class="p">This function initializes a previously created reduce tensor descriptor object.</p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">reduceTensorDesc</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input/Output</em>. Handle to a previously created reduce tensor descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">reduceTensorOp</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Enumerant to specify the reduce tensor operation.
                              </p>
                           </dd>
                           <dt class="dt dlterm">reduceTensorCompType</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Enumerant to specify the computation datatype of the reduction.
                              </p>
                           </dd>
                           <dt class="dt dlterm">reduceTensorNanOpt</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Enumerant to specify the Nan propagation mode.
                              </p>
                           </dd>
                           <dt class="dt dlterm">reduceTensorIndices</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Enumerant to specify the reduce tensor indices.
                              </p>
                           </dd>
                           <dt class="dt dlterm">reduceTensorIndicesType</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Enumerant to specify the reduce tensor indices type.
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was set successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">reduceTensorDesc is NULL (reduceTensorOp, reduceTensorCompType, reduceTensorNanOpt, reduceTensorIndices or reduceTensorIndicesType
                                 has an invalid enumerant value).
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSetRNNBiasMode"><a name="cudnnSetRNNBiasMode" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetRNNBiasMode" name="cudnnSetRNNBiasMode" shape="rect">4.196.&nbsp;cudnnSetRNNBiasMode</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">
cudnnStatus_t cudnnSetRNNBiasMode(
   cudnnRNNDescriptor_t   rnnDesc, 
   cudnnRNNBiasMode_t     biasMode)</pre><p class="p">The <samp class="ph codeph">cudnnSetRNNBiasMode()</samp> function sets the number of bias vectors for a
                           			previously created and initialized RNN descriptor. This function should be called after
                           					<samp class="ph codeph"><a class="xref" href="index.html#cudnnSetRNNDescriptor" shape="rect">cudnnSetRNNDescriptor()</a></samp> to
                           			enable the specified bias mode in an RNN. The default value of <samp class="ph codeph">biasMode</samp> in
                           				<samp class="ph codeph">rnnDesc</samp> after <samp class="ph codeph">cudnnCreateRNNDescriptor()</samp> is
                           			CUDNN_RNN_DOUBLE_BIAS.
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">rnnDesc</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input/Output.</em> A previously created RNN descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">biasMode</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Sets the number of bias vectors. See
                                 	<a class="xref" href="index.html#cudnnRNNBiasMode_t" shape="rect">cudnnRNNBiasMode_t</a>.
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">Either the <strong class="ph b"><samp class="ph codeph">rnnDesc</samp></strong> is NULL, or
                                 								<strong class="ph b"><samp class="ph codeph">biasMode</samp></strong> has an invalid enumerant value.
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The <strong class="ph b"><samp class="ph codeph">biasMode</samp></strong> was set successfully.
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">Non-default bias mode (an enumerated type besides
                                 							<samp class="ph codeph">CUDNN_RNN_DOUBLE_BIAS</samp>) applied to RNN algo other than
                                 							<samp class="ph codeph">CUDNN_RNN_ALGO_STANDARD</samp>.
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSetRNNDataDescriptor"><a name="cudnnSetRNNDataDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetRNNDataDescriptor" name="cudnnSetRNNDataDescriptor" shape="rect">4.197.&nbsp;cudnnSetRNNDataDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">
cudnnStatus_t cudnnSetRNNDataDescriptor(
    cudnnRNNDataDescriptor_t       RNNDataDesc,
    cudnnDataType_t                dataType,
    cudnnRNNDataLayout_t           layout,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                            maxSeqLength,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                            batchSize,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                            vectorSize,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                      seqLengthArray[],
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *paddingFill);</pre><p class="p">This function initializes a previously created RNN data descriptor object. This data
                           structure is intended to support the unpacked (padded) layout for input and output of
                           extended RNN inference and training functions. A packed (unpadded) layout is also
                           supported for backward compatibility.
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">RNNDataDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input/Output</em>. A previously created RNN descriptor. See <a class="xref" href="index.html#cudnnRNNDataDescriptor_t" shape="rect">cudnnRNNDataDescriptor_t</a>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dataType </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. The datatype of the RNN data tensor. See <a class="xref" href="index.html#cudnnDataType_t" shape="rect">cudnnDataType_t</a>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">layout </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. The memory layout of the RNN data tensor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">maxSeqLength </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. The maximum sequence length within this RNN data tensor. In the
                                 unpacked (padded) layout, this should include the padding vectors in each
                                 sequence. In the packed (unpadded) layout, this should be equal to the
                                 greatest element in <samp class="ph codeph">seqLengthArray</samp>. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">batchSize </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. The number of sequences within the mini-batch. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">vectorSize </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. The vector length (i.e. embedding size) of the input or output
                                 tensor at each timestep. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">seqLengthArray </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. An integer array with <samp class="ph codeph">batchSize</samp> number of
                                 elements. Describes the length (i.e. number of timesteps) of each sequence.
                                 Each element in <samp class="ph codeph">seqLengthArray</samp> must be greater than 0 but
                                 less than or equal to <samp class="ph codeph">maxSeqLength</samp>. In the packed layout,
                                 the elements should be sorted in descending order, similar to the layout
                                 required by the non-extended RNN compute functions.
                              </p>
                           </dd>
                           <dt class="dt dlterm">paddingFill </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A user-defined symbol for filling the padding position in RNN
                                 output. This is only effective when the descriptor is describing the RNN
                                 output, and the unpacked layout is specified. The symbol should be in the
                                 host memory, and is interpreted as the same data type as that of the RNN
                                 data tensor. If NULL pointer is passed in, then the padding position in the
                                 output will be undefined. 
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was set successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p"><samp class="ph codeph">dataType</samp> is not one of <samp class="ph codeph">CUDNN_DATA_HALF</samp>,
                                 <samp class="ph codeph">CUDNN_DATA_FLOAT</samp>, <samp class="ph codeph">CUDNN_DATA_DOUBLE</samp>. 
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">Any one of these have occurred: </p>
                              <div class="p"><a name="cudnnSetRNNDataDescriptor__ul_g4k_bsr_h2b" shape="rect">
                                    <!-- --></a><ul class="ul" id="cudnnSetRNNDataDescriptor__ul_g4k_bsr_h2b">
                                    <li class="li">RNNDataDesc is NULL. </li>
                                    <li class="li">Any one of <samp class="ph codeph">maxSeqLength</samp>,
                                       <samp class="ph codeph">batchSize</samp>, or <samp class="ph codeph">vectorSize</samp> is less
                                       than or equal to zero. 
                                    </li>
                                    <li class="li">An element of <samp class="ph codeph">seqLengthArray</samp> is less than or equal
                                       to zero or greater than <samp class="ph codeph">maxSeqLength</samp>. 
                                    </li>
                                    <li class="li">Layout is not one of
                                       <samp class="ph codeph">CUDNN_RNN_DATA_LAYOUT_SEQ_MAJOR_UNPACKED</samp>,<samp class="ph codeph">
                                          CUDNN_RNN_DATA_LAYOUT_SEQ_MAJOR_PACKED</samp>, or
                                       <samp class="ph codeph">CUDNN_RNN_DATA_LAYOUT_BATCH_MAJOR_UNPACKED</samp>.
                                       
                                    </li>
                                 </ul>
                              </div>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_ALLOC_FAILED</samp></dt>
                           <dd class="dd">The allocation of internal array storage has failed. </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSetRNNDescriptor"><a name="cudnnSetRNNDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetRNNDescriptor" name="cudnnSetRNNDescriptor" shape="rect">4.198.&nbsp;cudnnSetRNNDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetRNNDescriptor(
    cudnnHandle_t               handle,
    cudnnRNNDescriptor_t        rnnDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                         hiddenSize,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                         numLayers,
    cudnnDropoutDescriptor_t    dropoutDesc,
    cudnnRNNInputMode_t         inputMode,
    cudnnDirectionMode_t        direction,
    cudnnRNNMode_t              mode,
    cudnnRNNAlgo_t              algo,
    cudnnDataType_t             mathPrec)</pre><p class="p">This function initializes a previously created RNN descriptor object.</p>
                        <div class="note note"><span class="notetitle">Note:</span> Larger networks (e.g., longer sequences, more layers) are expected to be more
                           efficient than smaller networks.
                        </div>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">rnnDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input/Output</em>. A previously created RNN descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">hiddenSize </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Size of the internal hidden state for each layer.
                              </p>
                           </dd>
                           <dt class="dt dlterm">numLayers </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Number of stacked layers.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dropoutDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created and initialized dropout
                                 descriptor. Dropout will be applied between layers; a single layer network
                                 will have no dropout applied.
                              </p>
                           </dd>
                           <dt class="dt dlterm">inputMode </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Specifies the behavior at the input to the first layer.
                              </p>
                           </dd>
                           <dt class="dt dlterm">direction </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Specifies the recurrence pattern. (e.g., bidirectional).
                              </p>
                           </dd>
                           <dt class="dt dlterm">mode </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Specifies the type of RNN to compute.
                              </p>
                           </dd>
                           <dt class="dt dlterm">mathPrec </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Math precision. This parameter is used for controlling the math
                                 						precision in RNN. The following applies:
                              </p><a name="cudnnSetRNNDescriptor__ul_szh_4cr_vgb" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnSetRNNDescriptor__ul_szh_4cr_vgb">
                                 <li dir="ltr" class="li">
                                    <p dir="ltr" class="p">For the input/output in FP16, the parameter
                                       									<samp class="ph codeph">mathPrec</samp> can be CUDNN_DATA_HALF or CUDNN_DATA_FLOAT.
                                    </p>
                                 </li>
                                 <li dir="ltr" class="li">
                                    <p dir="ltr" class="p">For the input/output in FP32, the parameter
                                       									<samp class="ph codeph">mathPrec</samp> can only be CUDNN_DATA_FLOAT, and
                                    </p>
                                 </li>
                                 <li class="li">For the input/output in FP64, double type, the parameter
                                    								<samp class="ph codeph">mathPrec</samp> can only be CUDNN_DATA_DOUBLE.
                                 </li>
                              </ul>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was set successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">Either at least one of the parameters <samp class="ph codeph">hiddenSize, numLayers</samp>
                                 was zero or negative, one of <samp class="ph codeph">inputMode, direction, mode,
                                    dataType</samp> has an invalid enumerant value,
                                 <samp class="ph codeph">dropoutDesc</samp> is an invalid dropout descriptor or
                                 <samp class="ph codeph">rnnDesc</samp> has not been created correctly. 
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSetRNNDescriptor_v5"><a name="cudnnSetRNNDescriptor_v5" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetRNNDescriptor_v5" name="cudnnSetRNNDescriptor_v5" shape="rect">4.199.&nbsp;cudnnSetRNNDescriptor_v5</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetRNNDescriptor_v5(
    cudnnRNNDescriptor_t     rnnDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                      hiddenSize,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                      numLayers,
    cudnnDropoutDescriptor_t dropoutDesc,
    cudnnRNNInputMode_t      inputMode,
    cudnnDirectionMode_t     direction,
    cudnnRNNMode_t           mode,
    cudnnDataType_t          mathPrec)</pre><p class="p">This function initializes a previously created RNN descriptor object.</p>
                        <div class="note note"><span class="notetitle">Note:</span> Larger networks (e.g., longer sequences, more layers) are expected to be more
                           efficient than smaller networks.
                        </div>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">rnnDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input/Output</em>. A previously created RNN descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">hiddenSize </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Size of the internal hidden state for each layer.
                              </p>
                           </dd>
                           <dt class="dt dlterm">numLayers </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Number of stacked layers.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dropoutDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created and initialized dropout
                                 descriptor. Dropout will be applied between layers (e.g., a single layer
                                 network will have no dropout applied).
                              </p>
                           </dd>
                           <dt class="dt dlterm">inputMode </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Specifies the behavior at the input to the first layer
                              </p>
                           </dd>
                           <dt class="dt dlterm">direction </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Specifies the recurrence pattern. (e.g., bidirectional)
                              </p>
                           </dd>
                           <dt class="dt dlterm">mode </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Specifies the type of RNN to compute.
                              </p>
                           </dd>
                           <dt class="dt dlterm">mathPrec </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Math precision. This parameter is used for controlling the math
                                 						precision in RNN. The following applies:
                              </p><a name="cudnnSetRNNDescriptor_v5__ul_szh_4cr_vgb" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnSetRNNDescriptor_v5__ul_szh_4cr_vgb">
                                 <li dir="ltr" class="li">
                                    <p dir="ltr" class="p">For the input/output in FP16, the parameter
                                       									<samp class="ph codeph">mathPrec</samp> can be CUDNN_DATA_HALF or CUDNN_DATA_FLOAT.
                                    </p>
                                 </li>
                                 <li dir="ltr" class="li">
                                    <p dir="ltr" class="p">For the input/output in FP32, the parameter
                                       									<samp class="ph codeph">mathPrec</samp> can only be CUDNN_DATA_FLOAT, and
                                    </p>
                                 </li>
                                 <li class="li">For the input/output in FP64, double type, the parameter
                                    								<samp class="ph codeph">mathPrec</samp> can only be CUDNN_DATA_DOUBLE.
                                 </li>
                              </ul>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was set successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">Either at least one of the parameters <samp class="ph codeph">hiddenSize, numLayers</samp>
                                 was zero or negative, one of <samp class="ph codeph">inputMode, direction, mode, algo,
                                    dataType</samp> has an invalid enumerant value,
                                 <samp class="ph codeph">dropoutDesc</samp> is an invalid dropout descriptor or
                                 <samp class="ph codeph">rnnDesc</samp> has not been created correctly. 
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSetRNNDescriptor_v6"><a name="cudnnSetRNNDescriptor_v6" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetRNNDescriptor_v6" name="cudnnSetRNNDescriptor_v6" shape="rect">4.200.&nbsp;cudnnSetRNNDescriptor_v6</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetRNNDescriptor_v6(
	cudnnHandle_t                    handle,
	cudnnRNNDescriptor_t             rnnDesc,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                        hiddenSize,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                        numLayers,
	cudnnDropoutDescriptor_t         dropoutDesc,
	cudnnRNNInputMode_t              inputMode,
	cudnnDirectionMode_t             direction,
	cudnnRNNMode_t                   mode,
	cudnnRNNAlgo_t                   algo,
	cudnnDataType_t                  mathPrec)</pre><p class="p">This function initializes a previously created RNN descriptor object.</p>
                        <div class="note note"><span class="notetitle">Note:</span> Larger networks (e.g., longer sequences, more layers) are expected to be more
                           efficient than smaller networks.
                        </div>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN library descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">rnnDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input/Output</em>. A previously created RNN descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">hiddenSize </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Size of the internal hidden state for each layer.
                              </p>
                           </dd>
                           <dt class="dt dlterm">numLayers </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Number of stacked layers.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dropoutDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created and initialized dropout
                                 descriptor. Dropout will be applied between layers (e.g., a single layer
                                 network will have no dropout applied).
                              </p>
                           </dd>
                           <dt class="dt dlterm">inputMode </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Specifies the behavior at the input to the first layer
                              </p>
                           </dd>
                           <dt class="dt dlterm">direction </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Specifies the recurrence pattern. (e.g., bidirectional)
                              </p>
                           </dd>
                           <dt class="dt dlterm">mode </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Specifies the type of RNN to compute.
                              </p>
                           </dd>
                           <dt class="dt dlterm">algo </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Specifies which RNN algorithm should be used to compute the
                                 results.
                              </p>
                           </dd>
                           <dt class="dt dlterm">mathPrec </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Math precision. This parameter is used for controlling the math
                                 						precision in RNN. The following applies:
                              </p><a name="cudnnSetRNNDescriptor_v6__ul_szh_4cr_vgb" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnSetRNNDescriptor_v6__ul_szh_4cr_vgb">
                                 <li dir="ltr" class="li">
                                    <p dir="ltr" class="p">For the input/output in FP16, the parameter
                                       									<samp class="ph codeph">mathPrec</samp> can be CUDNN_DATA_HALF or CUDNN_DATA_FLOAT.
                                    </p>
                                 </li>
                                 <li dir="ltr" class="li">
                                    <p dir="ltr" class="p">For the input/output in FP32, the parameter
                                       									<samp class="ph codeph">mathPrec</samp> can only be CUDNN_DATA_FLOAT, and
                                    </p>
                                 </li>
                                 <li class="li">For the input/output in FP64, double type, the parameter
                                    								<samp class="ph codeph">mathPrec</samp> can only be CUDNN_DATA_DOUBLE.
                                 </li>
                              </ul>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was set successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">Either at least one of the parameters <samp class="ph codeph">hiddenSize, numLayers</samp>
                                 was zero or negative, one of <samp class="ph codeph">inputMode, direction, mode, algo,
                                    dataType</samp> has an invalid enumerant value,
                                 <samp class="ph codeph">dropoutDesc</samp> is an invalid dropout descriptor or
                                 <samp class="ph codeph">rnnDesc</samp> has not been created correctly. 
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSetRNNMatrixMathType"><a name="cudnnSetRNNMatrixMathType" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetRNNMatrixMathType" name="cudnnSetRNNMatrixMathType" shape="rect">4.201.&nbsp;cudnnSetRNNMatrixMathType</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetRNNMatrixMathType(
    cudnnRNNDescriptor_t    rnnDesc,
    cudnnMathType_t         mType)</pre><p class="p">This function sets the preferred option to use NVIDIA Tensor Cores accelerators on Volta GPU-s (SM 7.0 or higher). 
                           When the mType parameter is CUDNN_TENSOR_OP_MATH, inference and training RNN API-s will attempt use Tensor Cores when weights/biases
                           are of type CUDNN_DATA_HALF or CUDNN_DATA_FLOAT. 
                           When RNN weights/biases are stored in the CUDNN_DATA_FLOAT format, the original weights and intermediate results will be down-converted
                           to CUDNN_DATA_HALF before they are used in another recursive iteration.
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">rnnDesc</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A previously created and initialized RNN descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">mType</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A preferred compute option when performing RNN GEMM-s (general matrix-matrix multiplications). 
                                 This option has an “advisory” status meaning that Tensor Cores may not be utilized, e.g., due to specific GEMM dimensions.
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The preferred compute option for the RNN network was set successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">An invalid input parameter was detected.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSetRNNPaddingMode"><a name="cudnnSetRNNPaddingMode" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetRNNPaddingMode" name="cudnnSetRNNPaddingMode" shape="rect">4.202.&nbsp;cudnnSetRNNPaddingMode</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetRNNPaddingMode(
    cudnnRNNDescriptor_t        rnnDesc,
    cudnnRNNPaddingMode_t       paddingMode)</pre><p class="p">This function
                           enables or disables the padded RNN input/output for a previously created and initialized
                           RNN descriptor. This information is required before calling the
                           <samp class="ph codeph">cudnnGetRNNWorkspaceSize</samp> and
                           <samp class="ph codeph">cudnnGetRNNTrainingReserveSize</samp> functions, to determine whether
                           additional workspace and training reserve space is needed. By default the padded RNN
                           input/output is not enabled.
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">rnnDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input/Output</em>. A previously created RNN descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">paddingMode </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Enables or disables the padded input/output. See the
                                 description for <samp class="ph codeph">cudnnRNNPaddingMode_t</samp>.
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The <samp class="ph codeph">paddingMode</samp>  was set successfully.
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">Either the <samp class="ph codeph">rnnDesc</samp> is NULL, or <samp class="ph codeph">paddingMode</samp>
                                 has an invalid enumerant value. 
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSetRNNProjectionLayers"><a name="cudnnSetRNNProjectionLayers" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetRNNProjectionLayers" name="cudnnSetRNNProjectionLayers" shape="rect">4.203.&nbsp;cudnnSetRNNProjectionLayers</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetRNNProjectionLayers(
    cudnnHandle_t           handle,
    cudnnRNNDescriptor_t    rnnDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                     recProjSize,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                     outProjSize)</pre><p class="p"><strong class="ph b">(New for 7.1)</strong></p>
                        <p class="p">The <samp class="ph codeph">cudnnSetRNNProjectionLayers()</samp> function should be called after <samp class="ph codeph">cudnnSetRNNDescriptor()</samp> to enable the "recurrent" and/or "output" projection in a recursive neural network. 
                           The "recurrent" projection is an additional matrix multiplication in the LSTM cell to project hidden state vectors h<sub class="ph sub">t</sub> into smaller 
                           vectors r<sub class="ph sub">t</sub> = W<sub class="ph sub">r</sub>h<sub class="ph sub">t</sub>, where W<sub class="ph sub">r</sub> is a rectangular matrix with recProjSize rows and hiddenSize columns. 
                           When the recurrent projection is enabled, the output of the LSTM cell (both to the next layer and unrolled in-time) is r<sub class="ph sub">t</sub> instead of h<sub class="ph sub">t</sub>. 
                           The dimensionality of i<sub class="ph sub">t</sub>, f<sub class="ph sub">t</sub>, o<sub class="ph sub">t</sub>, and c<sub class="ph sub">t</sub> vectors used in conjunction with non-linear functions remains the same as in the canonical LSTM cell. 
                           To make this possible, the shapes of matrices in the LSTM formulas (see the chapter describing the <samp class="ph codeph">cudnnRNNMode_t</samp> type), such as W<sub class="ph sub">i</sub> in hidden RNN 
                           layers or R<sub class="ph sub">i</sub> in the entire network, become rectangular versus square in the canonical LSTM mode. 
                           Obviously, the result of "R<sub class="ph sub">i</sub>* W<sub class="ph sub">r</sub>" is a square matrix but it is rank deficient, reflecting the "compression" of LSTM output. 
                           The recurrent projection is typically employed when the number of independent (adjustable) weights in the RNN network with
                           projection 
                           is smaller in comparison to canonical LSTM for the same hiddenSize value.
                        </p>
                        <p class="p">The "recurrent" projection can be enabled for LSTM cells and <samp class="ph codeph">CUDNN_RNN_ALGO_STANDARD</samp> only. 
                           The recProjSize parameter should be smaller than the hiddenSize value programmed in the <samp class="ph codeph">cudnnSetRNNDescriptor()</samp> call. 
                           It is legal to set recProjSize equal to hiddenSize but in that case the recurrent projection feature is disabled.
                        </p>
                        <p class="p">The "output" projection is currently not implemented.</p>
                        <p class="p">For more information on the "recurrent" and "output" RNN projections see the paper by Hasim Sak, <em class="ph i">et al.</em>: Long Short-Term Memory Based Recurrent 
                           Neural Network Architectures For Large Vocabulary Speech Recognition.
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN library descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">rnnDesc</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A previously created and initialized RNN descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">recProjSize</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. The size of the LSTM cell output after the “recurrent” projection. 
                                 This value should not be larger than hiddenSize programmed via cudnnSetRNNDescriptor().
                              </p>
                           </dd>
                           <dt class="dt dlterm">outProjSize</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. This parameter should be zero.
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">RNN projection parameters were set successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">An invalid input argument was detected (e.g., NULL handles, negative values for projection parameters).</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">Projection applied to RNN algo other than <samp class="ph codeph">CUDNN_RNN_ALGO_STANDARD</samp>, cell type other than <samp class="ph codeph">CUDNN_LSTM</samp>, recProjSize larger than hiddenSize.
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSetSeqDataDescriptor"><a name="cudnnSetSeqDataDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetSeqDataDescriptor" name="cudnnSetSeqDataDescriptor" shape="rect">4.204.&nbsp;cudnnSetSeqDataDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetSeqDataDescriptor(
	cudnnSeqDataDescriptor_t seqDataDesc,
	cudnnDataType_t dataType,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> nbDims,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> dimA[],
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnSeqDataAxis_t axes[],
	size_t seqLengthArraySize,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> seqLengthArray[],
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *paddingFill);</pre><p dir="ltr" class="p" id="cudnnSetSeqDataDescriptor__docs-internal-guid-bfc6bcff-7fff-8c1b-6226-2161598bbc7d"><a name="cudnnSetSeqDataDescriptor__docs-internal-guid-bfc6bcff-7fff-8c1b-6226-2161598bbc7d" shape="rect">
                              <!-- --></a>This function
                           			initializes a previously created sequence data descriptor object. This descriptor points to
                           			a buffer that holds a batch of sequence samples. Each sample consists of a fixed beam size
                           			number of sequences. 
                        </p>
                        <p dir="ltr" class="p">Sequence data are regularly strided in memory with the order of time, batch, beam,
                           			and vector axes specified by the array <samp class="ph codeph">axes[]</samp>.
                        </p>
                        <p class="p">Each sequence has different sequence length and is specified in
                           				<samp class="ph codeph">seqLengthArray</samp>, an array of size <samp class="ph codeph">seqLengthArraySize</samp>. 
                        </p>
                        <p class="p">The value of <samp class="ph codeph">seqLengthArraySize</samp> is &lt;
                           				<samp class="ph codeph">dimA[CUDNN_SEQDATA_TIME_DIM]</samp>.
                        </p>
                        <p class="p"><strong class="ph b">Parameters:</strong></p>
                        <div class="tablenoborder"><a name="cudnnSetSeqDataDescriptor__table_hpj_hcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnSetSeqDataDescriptor__table_hpj_hcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1"><strong class="ph b">Parameter</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1"><strong class="ph b">Input / Output</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">seqDataDesc</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Pointer to a previously created
                                       								<samp class="ph codeph">cudnnSeqDataDescriptor</samp> structure to initialize. 
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">dataType</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Data type of the sequence data. </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">nbDims</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Number of sequence data dimensions. </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">dimA[]</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">
                                       <p dir="ltr" class="p">Size of each axes dimension. Array that contains the dimensions of
                                          								the buffer that holds a batch of sequence samples. This
                                          									<samp class="ph codeph">dimA</samp> is an array of 4 positive integers, where:
                                       </p>
                                       <p dir="ltr" class="p"> - <samp class="ph codeph">dimA[CUDNN_SEQDATA_TIME_DIM] </samp>is the maximum
                                          								allowed sequence length
                                       </p>
                                       <p dir="ltr" class="p"> - <samp class="ph codeph">dimA[CUDNN_SEQDATA_BATCH_DIM] </samp>is the maximum
                                          								allowed batch size
                                       </p>
                                       <p dir="ltr" class="p"> - <samp class="ph codeph">dimA[CUDNN_SEQDATA_BEAM_DIM]</samp> is the number of
                                          								beam in each sample
                                       </p>
                                       <p dir="ltr" class="p"> - <samp class="ph codeph">dimA[CUDNN_SEQDATA_VECT_DIM]</samp> is the vector
                                          								length.
                                       </p>
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">axes[]</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Array of axes, sorted from outermost to innermost dimension. The
                                       							array size is CUDNN_SEQDATA_DIM_COUNT. The elements of <samp class="ph codeph">axes[]</samp>
                                       							array is a valid permutation of enumerated labels of
                                       								<a class="xref" href="index.html#cudnnSeqDataAxis_t" shape="rect">cudnnSeqDataAxis_t</a> (in the order from the outermost to the
                                       							innermost axes in memory.)
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">seqLengthArraySize</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Number of elements in, i.e., the length of, the
                                       								<samp class="ph codeph">seqLengthArray</samp>. The value of this
                                       								<samp class="ph codeph">seqLengthArraySize</samp> is &lt;
                                       								<samp class="ph codeph">dimA[CUDNN_SEQDATA_TIME_DIM]</samp>.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">seqLengthArray[]</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Array that holds the sequence lengths of each sequence. </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">paddingFill</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Points to a value, of <samp class="ph codeph">dataType</samp>, that is used to fill up the
                                       							buffer beyond the sequence length of each sequence. The only supported value
                                       							for <span class="keyword apiname">paddingFill</span> is 0.
                                    </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                        <p class="p"><strong class="ph b">Returns:</strong></p>
                        <div class="tablenoborder"><a name="cudnnSetSeqDataDescriptor__table_usk_kcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnSetSeqDataDescriptor__table_usk_kcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Return Value</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_SUCCESS</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">All input values are validated and the descriptor value updated
                                       							successfully.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_BAD_PARAM</td>
                                    <td class="entry" valign="top" width="50%" rowspan="1" colspan="1">
                                       <p dir="ltr" class="p">Any of the below invalid inputs has occurred:</p>
                                       <p dir="ltr" class="p">- <samp class="ph codeph">seqDataDesc == NULL</samp></p>
                                       <p dir="ltr" class="p">- <samp class="ph codeph">dateType</samp> is not a valid data type 
                                       </p>
                                       <p dir="ltr" class="p">- <samp class="ph codeph">nbDims</samp> is not positive. 
                                       </p>
                                       <p dir="ltr" class="p">- Any element of dimA is not positive </p>
                                       <p dir="ltr" class="p">- <samp class="ph codeph">seqLengthArraySize</samp> is not equal to
                                          									<samp class="ph codeph">dimA[CUDNN_SEQDATA_BATCH_DIM] *
                                             									dimA[CUDNN_SEQDATA_BEAM_DIM]</samp></p>
                                       <p dir="ltr" class="p">- Any element of <samp class="ph codeph">seqLengthArray</samp> is not positive 
                                       </p>
                                       <p dir="ltr" class="p">- Any element of <samp class="ph codeph">seqLengthArray</samp> is larger than
                                          									<samp class="ph codeph">dimA[CUDNN_SEQDATA_TIME_DIM]</samp></p>
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_NOT_SUPPORTED</td>
                                    <td class="entry" valign="top" width="50%" rowspan="1" colspan="1">
                                       <p dir="ltr" class="p">Encountered any of the below unsupported values:</p>
                                       <p dir="ltr" class="p">- <samp class="ph codeph">nbDims</samp> is not equal to CUDNN_SEQDATA_DIM_COUNT
                                          								(4) 
                                       </p>
                                       <p dir="ltr" class="p">- <samp class="ph codeph">paddingFill</samp> is not a NULL pointer, and the
                                          								value pointed to is not of the <samp class="ph codeph">dataType</samp>.
                                       </p>
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_ALLOC_FAILED </td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">Failed to allocate storage for some field of the descriptor
                                       							structure.
                                    </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSetSpatialTransformerNdDescriptor"><a name="cudnnSetSpatialTransformerNdDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetSpatialTransformerNdDescriptor" name="cudnnSetSpatialTransformerNdDescriptor" shape="rect">4.205.&nbsp;cudnnSetSpatialTransformerNdDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetSpatialTransformerNdDescriptor(
    cudnnSpatialTransformerDescriptor_t     stDesc,
    cudnnSamplerType_t                      samplerType,
    cudnnDataType_t                         dataType,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                               nbDims,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                               dimA[])</pre><p class="p">This function initializes a previously created generic spatial transformer descriptor
                           object.
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">stDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input/Output</em>. Previously created spatial transformer descriptor
                                 object.
                              </p>
                           </dd>
                           <dt class="dt dlterm">samplerType </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Enumerant to specify the sampler type.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dataType </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data type.
                              </p>
                           </dd>
                           <dt class="dt dlterm">nbDims </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Dimension of the transformed tensor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dimA </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Array of dimension <samp class="ph codeph">nbDims</samp> containing the size
                                 of the transformed tensor for every dimension. 
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The call was successful.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnSetSpatialTransformerNdDescriptor__ul_pqt_333_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnSetSpatialTransformerNdDescriptor__ul_pqt_333_s1b">
                                 <li class="li"> Either <samp class="ph codeph">stDesc</samp> or <samp class="ph codeph">dimA</samp> is NULL.
                                 </li>
                                 <li class="li"> Either <samp class="ph codeph">dataType</samp> or <samp class="ph codeph">samplerType</samp> has an
                                    invalid enumerant value
                                 </li>
                              </ul>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSetStream"><a name="cudnnSetStream" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetStream" name="cudnnSetStream" shape="rect">4.206.&nbsp;cudnnSetStream</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetStream(
    cudnnHandle_t   handle,
    cudaStream_t    streamId)</pre><p class="p">This function sets the user's CUDA stream in the cuDNN handle. The new stream will be
                           used to launch cuDNN GPU kernels or to synchronize to this stream when cuDNN kernels are
                           launched in the internal streams. If the cuDNN library stream is not set, all kernels
                           use the default (NULL) stream. Setting the user stream in the cuDNN handle guarantees
                           the issue-order execution of cuDNN calls and other GPU kernels launched in the same
                           stream.
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointer to the cuDNN handle.
                              </p>
                           </dd>
                           <dt class="dt dlterm">streamID</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. New CUDA stream to be written to the cuDNN handle.
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">Invalid (NULL) handle.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_MAPPING_ERROR</samp></dt>
                           <dd class="dd">
                              <p class="p">Mismatch between the user stream and the cuDNN handle context.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The new stream was set successfully.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSetTensor4dDescriptor"><a name="cudnnSetTensor4dDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetTensor4dDescriptor" name="cudnnSetTensor4dDescriptor" shape="rect">4.207.&nbsp;cudnnSetTensor4dDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetTensor4dDescriptor(
    cudnnTensorDescriptor_t tensorDesc,
    cudnnTensorFormat_t     format,
    cudnnDataType_t         dataType,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                     n,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                     c,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                     h,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                     w)</pre><p class="p">This function initializes a previously created generic Tensor descriptor object into a 4D
                           tensor. The strides of the four dimensions are inferred from the format parameter and
                           set in such a way that the data is contiguous in memory with no padding between
                           dimensions. 
                        </p>
                        <div class="note note"><span class="notetitle">Note:</span> The total size of a tensor including the potential padding between dimensions is
                           limited to 2 Giga-elements of type <samp class="ph codeph">datatype</samp>.
                        </div>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">tensorDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input/Output</em>. Handle to a previously created tensor descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">format </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Type of format.
                              </p>
                           </dd>
                           <dt class="dt dlterm">datatype </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data type.
                              </p>
                           </dd>
                           <dt class="dt dlterm">n </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Number of images.
                              </p>
                           </dd>
                           <dt class="dt dlterm">c </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Number of feature maps per image.
                              </p>
                           </dd>
                           <dt class="dt dlterm">h </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Height of each feature map.
                              </p>
                           </dd>
                           <dt class="dt dlterm">w </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Width of each feature map.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was set successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the parameters <samp class="ph codeph">n,c,h,w</samp> was negative or
                                 <samp class="ph codeph">format</samp> has an invalid enumerant value or
                                 <samp class="ph codeph">dataType</samp> has an invalid enumerant value. 
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The total size of the tensor descriptor exceeds the maximim limit of 2
                                 Giga-elements.
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSetTensor4dDescriptorEx"><a name="cudnnSetTensor4dDescriptorEx" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetTensor4dDescriptorEx" name="cudnnSetTensor4dDescriptorEx" shape="rect">4.208.&nbsp;cudnnSetTensor4dDescriptorEx</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetTensor4dDescriptorEx(
    cudnnTensorDescriptor_t     tensorDesc,
    cudnnDataType_t             dataType,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                         n,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                         c,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                         h,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                         w,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                         nStride,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                         cStride,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                         hStride,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                         wStride)</pre><p class="p">This function initializes a previously created generic Tensor descriptor object into a 4D
                           tensor, similarly to <samp class="ph codeph">cudnnSetTensor4dDescriptor</samp> but with the strides
                           explicitly passed as parameters. This can be used to lay out the 4D tensor in any order
                           or simply to define gaps between dimensions. 
                        </p>
                        <div class="note note"><span class="notetitle">Note:</span> At present, some cuDNN routines have limited support for strides; Those routines will
                           return CUDNN_STATUS_NOT_SUPPORTED if a Tensor4D object with an unsupported stride is
                           used. <samp class="ph codeph">cudnnTransformTensor</samp> can be used to convert the data to a
                           supported layout.
                        </div>
                        <div class="note note"><span class="notetitle">Note:</span> The total size of a tensor including the potential padding between dimensions is
                           limited to 2 Giga-elements of type <samp class="ph codeph">datatype</samp>.
                        </div>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">tensorDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input/Output</em>. Handle to a previously created tensor descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">datatype </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data type.
                              </p>
                           </dd>
                           <dt class="dt dlterm">n </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Number of images.
                              </p>
                           </dd>
                           <dt class="dt dlterm">c </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Number of feature maps per image.
                              </p>
                           </dd>
                           <dt class="dt dlterm">h </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Height of each feature map.
                              </p>
                           </dd>
                           <dt class="dt dlterm">w </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Width of each feature map.
                              </p>
                           </dd>
                           <dt class="dt dlterm">nStride </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Stride between two consecutive images.
                              </p>
                           </dd>
                           <dt class="dt dlterm">cStride </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Stride between two consecutive feature maps.
                              </p>
                           </dd>
                           <dt class="dt dlterm">hStride </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Stride between two consecutive rows.
                              </p>
                           </dd>
                           <dt class="dt dlterm">wStride </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Stride between two consecutive columns.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was set successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the parameters <samp class="ph codeph">n,c,h,w</samp> or
                                 <samp class="ph codeph">nStride,cStride,hStride,wStride</samp> is negative or
                                 <samp class="ph codeph">dataType</samp> has an invalid enumerant value. 
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The total size of the tensor descriptor exceeds the maximim limit of 2
                                 Giga-elements.
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSetTensor"><a name="cudnnSetTensor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetTensor" name="cudnnSetTensor" shape="rect">4.209.&nbsp;cudnnSetTensor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetTensor(
    cudnnHandle_t                   handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t   yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                           *y,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                     *valuePtr)</pre><p class="p">This function sets all the elements of a tensor to a given value. </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">yDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">y </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input/Output</em>. Pointer to data of the tensor described by the
                                 <samp class="ph codeph">yDesc</samp> descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">valuePtr </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointer in Host memory to a single value. All elements of the y
                                 tensor will be set to value[0]. The data type of the element in value[0] has
                                 to match the data type of tensor <samp class="ph codeph">y</samp>.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The function launched successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function does not support the provided configuration.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">one of the provided pointers is nil</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function failed to launch on the GPU.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSetTensorNdDescriptor"><a name="cudnnSetTensorNdDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetTensorNdDescriptor" name="cudnnSetTensorNdDescriptor" shape="rect">4.210.&nbsp;cudnnSetTensorNdDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetTensorNdDescriptor(
    cudnnTensorDescriptor_t tensorDesc,
    cudnnDataType_t         dataType,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                     nbDims,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>               dimA[],
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>               strideA[])</pre><p class="p">This function initializes a previously created generic Tensor descriptor object. </p>
                        <div class="note note"><span class="notetitle">Note:</span> The total size of a tensor including the potential padding between dimensions is
                           limited to 2 Giga-elements of type <samp class="ph codeph">datatype</samp>. Tensors are restricted to
                           having at least 4 dimensions, and at most CUDNN_DIM_MAX dimensions (defined in cudnn.h).
                           When working with lower dimensional data, it is recommended that the user create a 4D
                           tensor, and set the size along unused dimensions to 1.
                        </div>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">tensorDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input/Output</em>. Handle to a previously created tensor descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">datatype </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data type.
                              </p>
                           </dd>
                           <dt class="dt dlterm">nbDims </dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. Dimension of the tensor. 
                                 <div class="note note"><span class="notetitle">Note:</span> Do not use 2 dimensions. Due to
                                    historical reasons, the minimum number of dimensions in the filter
                                    descriptor is three. See also the <a class="xref" href="index.html#cudnnGetRNNLinLayerBiasParams" shape="rect">cudnnGetRNNLinLayerBiasParams().</a></div>
                              </div>
                           </dd>
                           <dt class="dt dlterm">dimA </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Array of dimension <samp class="ph codeph">nbDims</samp> that contain the
                                 size of the tensor for every dimension. Size along unused dimensions should
                                 be set to 1. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">strideA </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Array of dimension <samp class="ph codeph">nbDims</samp> that contain the
                                 stride of the tensor for every dimension.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The object was set successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the elements of the array <samp class="ph codeph">dimA</samp> was negative
                                 or zero, or <samp class="ph codeph">dataType</samp> has an invalid enumerant value. 
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The parameter <samp class="ph codeph">nbDims</samp> is outside the range [4,
                                 CUDNN_DIM_MAX], or the total size of the tensor descriptor exceeds the
                                 maximim limit of 2 Giga-elements. 
                              </p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSetTensorNdDescriptorEx"><a name="cudnnSetTensorNdDescriptorEx" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetTensorNdDescriptorEx" name="cudnnSetTensorNdDescriptorEx" shape="rect">4.211.&nbsp;cudnnSetTensorNdDescriptorEx</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetTensorNdDescriptorEx(
    cudnnTensorDescriptor_t tensorDesc,
    cudnnTensorFormat_t     format,
    cudnnDataType_t         dataType,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                     nbDims,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>               dimA[])</pre><p class="p">This function initializes an n-D tensor descriptor.</p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">tensorDesc</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Pointer to the tensor descriptor struct to be initialized.
                              </p>
                           </dd>
                           <dt class="dt dlterm">format</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Tensor format.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dataType</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Tensor data type.
                              </p>
                           </dd>
                           <dt class="dt dlterm">nbDims</dt>
                           <dd class="dd">
                              <div class="p"><em class="ph i">Input</em>. Dimension of the tensor. 
                                 <div class="note note"><span class="notetitle">Note:</span> Do not use 2 dimensions. Due to
                                    							historical reasons, the minimum number of dimensions in the filter
                                    							descriptor is three. See also the <a class="xref" href="index.html#cudnnGetRNNLinLayerBiasParams" shape="rect">cudnnGetRNNLinLayerBiasParams().</a></div>
                              </div>
                           </dd>
                           <dt class="dt dlterm">dimA</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Array containing size of each dimension. 
                              </p>
                           </dd>
                        </dl>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The function was successful.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">Tensor descriptor was not allocated properly; or input parameters are not set correctly.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">Dimension size requested is larger than maximum dimension size supported.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSetTensorTransformDescriptor"><a name="cudnnSetTensorTransformDescriptor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSetTensorTransformDescriptor" name="cudnnSetTensorTransformDescriptor" shape="rect">4.212.&nbsp;cudnnSetTensorTransformDescriptor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSetTensorTransformDescriptor(
	cudnnTensorTransformDescriptor_t transformDesc,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> uint32_t nbDims,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorFormat_t destFormat,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> int32_t padBeforeA[],
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> int32_t padAfterA[],
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> uint32_t foldA[],
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnFoldingDirection_t direction);
</pre><p dir="ltr" class="p" id="cudnnSetTensorTransformDescriptor__docs-internal-guid-9f026789-7fff-f743-6efb-0b73e41997ff"><a name="cudnnSetTensorTransformDescriptor__docs-internal-guid-9f026789-7fff-f743-6efb-0b73e41997ff" shape="rect">
                              <!-- --></a>This function
                           			initializes a Tensor transform descriptor that was previously created using the
                           				<a class="xref" href="index.html#cudnnCreateTensorTransformDescriptor" shape="rect">cudnnCreateTensorTransformDescriptor</a> function.
                        </p>
                        <p class="p"><strong class="ph b">Parameters:</strong></p>
                        <div class="tablenoborder"><a name="cudnnSetTensorTransformDescriptor__table_hpj_hcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnSetTensorTransformDescriptor__table_hpj_hcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1"><strong class="ph b">Parameter</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1"><strong class="ph b">Input / Output</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">transformDesc</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Output</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">The Tensor transform descriptor to be initialized.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">nbDims</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">The dimensionality of the transform operands. Must be greater
                                       							than 2. See also <a class="xref" href="https://docs.nvidia.com/deeplearning/sdk/cudnn-developer-guide/index.html#tensor-descriptor" target="_blank" shape="rect"><u class="ph u">https://docs.nvidia.com/deeplearning/sdk/cudnn-developer-guide/index.html#tensor-descriptor</u></a></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">destFormat</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">The desired destination format.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">padBeforeA[]</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">An array that contains the amount of padding that should be added
                                       							before each dimension. Set to NULL for no padding.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">padAfterA[]</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">An array that contains the amount of padding that should be added
                                       							after each dimension. Set to NULL for no padding.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">foldA[]</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">An array that contains the folding parameters for each spatial
                                       							dimension (dimensions 2 and up). Set to NULL for no folding.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">direction</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Selects folding or unfolding. This input has no effect when folding
                                       							parameters are all &lt;= 1. See <a class="xref" href="index.html#cudnnFoldingDirection_t" shape="rect">cudnnFoldingDirection_t</a>.
                                    </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                        <p class="p"><strong class="ph b">Returns:</strong></p>
                        <div class="tablenoborder"><a name="cudnnSetTensorTransformDescriptor__table_usk_kcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnSetTensorTransformDescriptor__table_usk_kcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Return Value</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_SUCCESS</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">The function was launched successfully.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_BAD_PARAM</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">The parameter <samp class="ph codeph">transformDesc</samp> is NULL, or if
                                       								<samp class="ph codeph">direction</samp> is invalid, or <samp class="ph codeph">nbDims</samp> is &lt;=
                                       							2.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_NOT_SUPPORTED</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">If the dimension size requested is larger than maximum dimension size
                                       							supported (i.e., one of the <samp class="ph codeph">nbDims</samp> is larger than
                                       							CUDNN_DIM_MAX), or if <samp class="ph codeph">destFromat</samp> is something other than NCHW
                                       							or NHWC.
                                    </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSoftmaxBackward"><a name="cudnnSoftmaxBackward" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSoftmaxBackward" name="cudnnSoftmaxBackward" shape="rect">4.213.&nbsp;cudnnSoftmaxBackward</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSoftmaxBackward(
    cudnnHandle_t                    handle,
    cudnnSoftmaxAlgorithm_t          algorithm,
    cudnnSoftmaxMode_t               mode,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *alpha,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *yData,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    dyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *dy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *beta,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    dxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *dx)</pre><p class="p">This routine computes the gradient of the softmax function.</p>
                        <div class="note note"><span class="notetitle">Note:</span> In-place operation is allowed for this routine; i.e., <samp class="ph codeph">dy</samp> and
                           <samp class="ph codeph">dx</samp> pointers may be equal. However, this requires
                           <samp class="ph codeph">dyDesc</samp> and <samp class="ph codeph">dxDesc</samp> descriptors to be identical
                           (particularly, the strides of the input and output must match for in-place operation to
                           be allowed).
                        </div>
                        <div class="note note"><span class="notetitle">Note:</span> All tensor formats are supported for all modes and algorithms with 4 and 5D tensors.
                           Performance is expected to be highest with <samp class="ph codeph">NCHW fully-packed</samp> tensors.
                           For more than 5 dimensions tensors must be packed in their spatial dimensions
                        </div>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">algorithm </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Enumerant to specify the softmax algorithm.
                              </p>
                           </dd>
                           <dt class="dt dlterm">mode </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Enumerant to specify the softmax mode.
                              </p>
                           </dd>
                           <dt class="dt dlterm">alpha, beta </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointers to scaling factors (in host memory) used to blend the
                                 computation result with prior value in the output layer as follows: dstValue
                                 = alpha[0]*result + beta[0]*priorDstValue. <a class="xref" href="index.html#general-description" shape="rect">Please refer to this
                                    section for additional details.</a></p>
                           </dd>
                           <dt class="dt dlterm">yDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized input tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">y </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">yDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dyDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized input differential tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dy </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">dyData</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dxDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized output differential tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dx </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the output tensor
                                 descriptor <samp class="ph codeph">dxDesc</samp>.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The function launched successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function does not support the provided configuration.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnSoftmaxBackward__ul_dx5_3xh_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnSoftmaxBackward__ul_dx5_3xh_s1b">
                                 <li class="li">The dimensions <samp class="ph codeph">n,c,h,w</samp> of the <samp class="ph codeph">yDesc</samp>,
                                    <samp class="ph codeph">dyDesc</samp> and <samp class="ph codeph">dxDesc</samp> tensors
                                    differ.
                                 </li>
                                 <li class="li">The strides <samp class="ph codeph">nStride, cStride, hStride, wStride</samp> of the
                                    <samp class="ph codeph">yDesc</samp> and <samp class="ph codeph">dyDesc</samp> tensors
                                    differ.
                                 </li>
                                 <li class="li">The <samp class="ph codeph">datatype</samp> of the three tensors differs.
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function failed to launch on the GPU.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSoftmaxForward"><a name="cudnnSoftmaxForward" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSoftmaxForward" name="cudnnSoftmaxForward" shape="rect">4.214.&nbsp;cudnnSoftmaxForward</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSoftmaxForward(
    cudnnHandle_t                    handle,
    cudnnSoftmaxAlgorithm_t          algorithm,
    cudnnSoftmaxMode_t               mode,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *alpha,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                      *beta,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t    yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                            *y)</pre><p class="p">This routine computes the softmax function.</p>
                        <div class="note note"><span class="notetitle">Note:</span> All tensor formats are supported for all modes and algorithms with 4 and 5D tensors.
                           Performance is expected to be highest with <samp class="ph codeph">NCHW fully-packed</samp> tensors.
                           For more than 5 dimensions tensors must be packed in their spatial dimensions
                        </div>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">algorithm </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Enumerant to specify the softmax algorithm.
                              </p>
                           </dd>
                           <dt class="dt dlterm">mode </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Enumerant to specify the softmax mode.
                              </p>
                           </dd>
                           <dt class="dt dlterm">alpha, beta </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointers to scaling factors (in host memory) used to blend the
                                 computation result with prior value in the output layer as follows: dstValue
                                 = alpha[0]*result + beta[0]*priorDstValue. <a class="xref" href="index.html#general-description" shape="rect">Please refer to this
                                    section for additional details.</a></p>
                           </dd>
                           <dt class="dt dlterm">xDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized input tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">x </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">xDesc</samp>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">yDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized output tensor
                                 descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">y </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the output tensor
                                 descriptor <samp class="ph codeph">yDesc</samp>.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The function launched successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function does not support the provided configuration.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnSoftmaxForward__ul_zvp_2xh_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnSoftmaxForward__ul_zvp_2xh_s1b">
                                 <li class="li">The dimensions <samp class="ph codeph">n,c,h,w</samp> of the input tensor and output
                                    tensors differ.
                                 </li>
                                 <li class="li">The <samp class="ph codeph">datatype</samp> of the input tensor and output tensors
                                    differ.
                                 </li>
                                 <li class="li">The parameters <samp class="ph codeph">algorithm</samp> or <samp class="ph codeph">mode</samp> have
                                    an invalid enumerant value.
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function failed to launch on the GPU.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSpatialTfGridGeneratorBackward"><a name="cudnnSpatialTfGridGeneratorBackward" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSpatialTfGridGeneratorBackward" name="cudnnSpatialTfGridGeneratorBackward" shape="rect">4.215.&nbsp;cudnnSpatialTfGridGeneratorBackward</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSpatialTfGridGeneratorBackward(
    cudnnHandle_t                               handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnSpatialTransformerDescriptor_t   stDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                 *dgrid,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                       *dtheta)</pre><p class="p">This function computes the gradient of a grid generation operation.</p>
                        <div class="note note"><span class="notetitle">Note:</span> Only 2d transformation is supported.
                        </div>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">stDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Previously created spatial transformer descriptor object.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dgrid </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory contains the input differential
                                 data.
                              </p>
                           </dd>
                           <dt class="dt dlterm">dtheta </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Data pointer to GPU memory contains the output differential
                                 data. 
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The call was successful.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnSpatialTfGridGeneratorBackward__ul_uwl_q33_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnSpatialTfGridGeneratorBackward__ul_uwl_q33_s1b">
                                 <li class="li"><samp class="ph codeph">handle</samp> is NULL.
                                 </li>
                                 <li class="li"> One of the parameters <samp class="ph codeph">dgrid, dtheta</samp> is NULL.
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function does not support the provided configuration. See the following
                                 for some examples of non-supported configurations:
                              </p><a name="cudnnSpatialTfGridGeneratorBackward__ul_axl_q33_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnSpatialTfGridGeneratorBackward__ul_axl_q33_s1b">
                                 <li class="li">The dimension of transformed tensor specified in <samp class="ph codeph">stDesc</samp>
                                    &gt; 4.
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function failed to launch on the GPU.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSpatialTfGridGeneratorForward"><a name="cudnnSpatialTfGridGeneratorForward" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSpatialTfGridGeneratorForward" name="cudnnSpatialTfGridGeneratorForward" shape="rect">4.216.&nbsp;cudnnSpatialTfGridGeneratorForward</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSpatialTfGridGeneratorForward(
    cudnnHandle_t                               handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnSpatialTransformerDescriptor_t   stDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                 *theta,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                       *grid)</pre><p class="p">This function generates a grid of coordinates in the input tensor corresponding to each
                           pixel from the output tensor.
                        </p>
                        <div class="note note"><span class="notetitle">Note:</span> Only 2d transformation is supported.
                        </div>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">stDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Previously created spatial transformer descriptor object.
                              </p>
                           </dd>
                           <dt class="dt dlterm">theta </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Affine transformation matrix. It should be of size n*2*3 for a
                                 2d transformation, where n is the number of images specified in
                                 <samp class="ph codeph">stDesc</samp>. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">grid </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. A grid of coordinates. It is of size n*h*w*2 for a 2d
                                 transformation, where n, h, w is specified in <samp class="ph codeph">stDesc</samp>. In
                                 the 4th dimension, the first coordinate is x, and the second coordinate is
                                 y. 
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The call was successful.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnSpatialTfGridGeneratorForward__ul_v1w_m33_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnSpatialTfGridGeneratorForward__ul_v1w_m33_s1b">
                                 <li class="li"><samp class="ph codeph">handle</samp> is NULL.
                                 </li>
                                 <li class="li"> One of the parameters <samp class="ph codeph">grid, theta</samp> is NULL.
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function does not support the provided configuration. See the following
                                 for some examples of non-supported configurations:
                              </p><a name="cudnnSpatialTfGridGeneratorForward__ul_abw_m33_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnSpatialTfGridGeneratorForward__ul_abw_m33_s1b">
                                 <li class="li">The dimension of transformed tensor specified in <samp class="ph codeph">stDesc</samp>
                                    &gt; 4.
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function failed to launch on the GPU.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSpatialTfSamplerBackward"><a name="cudnnSpatialTfSamplerBackward" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSpatialTfSamplerBackward" name="cudnnSpatialTfSamplerBackward" shape="rect">4.217.&nbsp;cudnnSpatialTfSamplerBackward</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSpatialTfSamplerBackward(
    cudnnHandle_t                              handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnSpatialTransformerDescriptor_t  stDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *alpha,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t              xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *beta,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t              dxDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                      *dx,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *alphaDgrid,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t              dyDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *dy,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *grid,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *betaDgrid,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                      *dgrid)</pre><p class="p">This function computes the gradient of a sampling operation.</p>
                        <div class="note note"><span class="notetitle">Note:</span> Only 2d transformation is supported.
                        </div>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">stDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Previously created spatial transformer descriptor object.
                              </p>
                           </dd>
                           <dt class="dt dlterm">alpha,beta </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointers to scaling factors (in host memory) used to blend the
                                 source value with prior value in the destination tensor as follows: dstValue
                                 = alpha[0]*srcValue + beta[0]*priorDstValue. <a class="xref" href="index.html#general-description" shape="rect">Please refer to this
                                    section for additional details.</a></p>
                           </dd>
                           <dt class="dt dlterm">xDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized input tensor descriptor.
                                 
                              </p>
                           </dd>
                           <dt class="dt dlterm">x </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">xDesc</samp>. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">dxDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized output differential tensor
                                 descriptor. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">dx </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the output tensor
                                 descriptor <samp class="ph codeph">dxDesc</samp>. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">alphaDgrid,betaDgrid </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointers to scaling factors (in host memory) used to blend the
                                 gradient outputs dgrid with prior value in the destination pointer as
                                 follows: dstValue = alpha[0]*srcValue + beta[0]*priorDstValue. <a class="xref" href="index.html#general-description" shape="rect">Please refer to this
                                    section for additional details.</a></p>
                           </dd>
                           <dt class="dt dlterm">dyDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized input differential tensor
                                 descriptor. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">dy </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">dyDesc</samp>. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">grid </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A grid of coordinates generated by
                                 <samp class="ph codeph">cudnnSpatialTfGridGeneratorForward</samp>. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">dgrid </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Data pointer to GPU memory contains the output differential
                                 data. 
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The call was successful.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnSpatialTfSamplerBackward__ul_eqg_x33_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnSpatialTfSamplerBackward__ul_eqg_x33_s1b">
                                 <li class="li"><samp class="ph codeph">handle</samp> is NULL.
                                 </li>
                                 <li class="li"> One of the parameters <samp class="ph codeph">x,dx,y,dy,grid,dgrid </samp> is
                                    NULL.
                                 </li>
                                 <li class="li"> The dimension of <samp class="ph codeph">dy</samp> differs from those specified in
                                    <samp class="ph codeph">stDesc</samp></li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function does not support the provided configuration. See the following
                                 for some examples of non-supported configurations:
                              </p><a name="cudnnSpatialTfSamplerBackward__ul_iqg_x33_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnSpatialTfSamplerBackward__ul_iqg_x33_s1b">
                                 <li class="li">The dimension of transformed tensor &gt; 4. </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function failed to launch on the GPU.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnSpatialTfSamplerForward"><a name="cudnnSpatialTfSamplerForward" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnSpatialTfSamplerForward" name="cudnnSpatialTfSamplerForward" shape="rect">4.218.&nbsp;cudnnSpatialTfSamplerForward</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnSpatialTfSamplerForward(
    cudnnHandle_t                              handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnSpatialTransformerDescriptor_t  stDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *alpha,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t              xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *grid,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                *beta,
    cudnnTensorDescriptor_t                    yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                                      *y)</pre><p class="p">This function performs a sampler operation and generates the output tensor using the grid
                           given by the grid generator.
                        </p>
                        <div class="note note"><span class="notetitle">Note:</span> Only 2d transformation is supported.
                        </div>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle</dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">stDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Previously created spatial transformer descriptor object.
                              </p>
                           </dd>
                           <dt class="dt dlterm">alpha,beta </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointers to scaling factors (in host memory) used to blend the
                                 source value with prior value in the destination tensor as follows: dstValue
                                 = alpha[0]*srcValue + beta[0]*priorDstValue. <a class="xref" href="index.html#general-description" shape="rect">Please refer to this
                                    section for additional details.</a></p>
                           </dd>
                           <dt class="dt dlterm">xDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized input tensor descriptor.
                                 
                              </p>
                           </dd>
                           <dt class="dt dlterm">x </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Data pointer to GPU memory associated with the tensor
                                 descriptor <samp class="ph codeph">xDesc</samp>. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">grid </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. A grid of coordinates generated by
                                 <samp class="ph codeph">cudnnSpatialTfGridGeneratorForward</samp>. 
                              </p>
                           </dd>
                           <dt class="dt dlterm">yDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to the previously initialized output tensor descriptor.
                                 
                              </p>
                           </dd>
                           <dt class="dt dlterm">y </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Data pointer to GPU memory associated with the output tensor
                                 descriptor <samp class="ph codeph">yDesc</samp>. 
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The call was successful.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">At least one of the following conditions are met:</p><a name="cudnnSpatialTfSamplerForward__ul_mqz_t33_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnSpatialTfSamplerForward__ul_mqz_t33_s1b">
                                 <li class="li"><samp class="ph codeph">handle</samp> is NULL.
                                 </li>
                                 <li class="li"> One of the parameters <samp class="ph codeph">x, y, grid </samp> is NULL.
                                 </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function does not support the provided configuration. See the following
                                 for some examples of non-supported configurations:
                              </p><a name="cudnnSpatialTfSamplerForward__ul_rqz_t33_s1b" shape="rect">
                                 <!-- --></a><ul class="ul" id="cudnnSpatialTfSamplerForward__ul_rqz_t33_s1b">
                                 <li class="li">The dimension of transformed tensor &gt; 4. </li>
                              </ul>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function failed to launch on the GPU.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnTransformTensor"><a name="cudnnTransformTensor" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnTransformTensor" name="cudnnTransformTensor" shape="rect">4.219.&nbsp;cudnnTransformTensor</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnTransformTensor(
    cudnnHandle_t                  handle,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                    *alpha,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t  xDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                    *x,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                    *beta,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t  yDesc,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>                          *y)</pre><p class="p">This function copies the scaled data from one tensor to another tensor with a different
                           layout. Those descriptors need to have the same dimensions but not necessarily the same
                           strides. The input and output tensors must not overlap in any way (i.e., tensors cannot
                           be transformed in place). This function can be used to convert a tensor with an
                           unsupported format to a supported one. 
                        </p>
                        <p class="p"><strong class="ph b">Parameters</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm">handle </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously created cuDNN context.
                              </p>
                           </dd>
                           <dt class="dt dlterm">alpha, beta </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointers to scaling factors (in host memory) used to blend the
                                 source value with prior value in the destination tensor as follows: dstValue
                                 = alpha[0]*srcValue + beta[0]*priorDstValue. <a class="xref" href="index.html#general-description" shape="rect">Refer to this
                                    section for additional details.</a></p>
                           </dd>
                           <dt class="dt dlterm">xDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor. See <a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">x </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Pointer to data of the tensor described by the
                                 <samp class="ph codeph">xDesc</samp> descriptor.
                              </p>
                           </dd>
                           <dt class="dt dlterm">yDesc </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Input</em>. Handle to a previously initialized tensor descriptor. See <a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a>.
                              </p>
                           </dd>
                           <dt class="dt dlterm">y </dt>
                           <dd class="dd">
                              <p class="p"><em class="ph i">Output</em>. Pointer to data of the tensor described by the
                                 <samp class="ph codeph">yDesc</samp> descriptor.
                              </p>
                           </dd>
                        </dl>
                        <p class="p">The possible error values returned by this function and their meanings are listed
                           below.
                        </p>
                        <p class="p"><strong class="ph b">Returns</strong></p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_SUCCESS</samp></dt>
                           <dd class="dd">
                              <p class="p">The function launched successfully.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_NOT_SUPPORTED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function does not support the provided configuration.</p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_BAD_PARAM</samp></dt>
                           <dd class="dd">
                              <p class="p">The dimensions <samp class="ph codeph">n,c,h,w</samp> or the <samp class="ph codeph">dataType</samp> of
                                 the two tensor descriptors are different.
                              </p>
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">CUDNN_STATUS_EXECUTION_FAILED</samp></dt>
                           <dd class="dd">
                              <p class="p">The function failed to launch on the GPU.</p>
                           </dd>
                        </dl>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="cudnnTransformTensorEx"><a name="cudnnTransformTensorEx" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cudnnTransformTensorEx" name="cudnnTransformTensorEx" shape="rect">4.220.&nbsp;cudnnTransformTensorEx</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div><pre xml:space="preserve">cudnnStatus_t cudnnTransformTensorEx(
	cudnnHandle_t handle,
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorTransformDescriptor_t transDesc,                                    
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *alpha,                                           
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t srcDesc,                        
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *srcData,   
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *beta, 
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> cudnnTensorDescriptor_t destDesc, 
	<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *destData);
</pre><p class="p">This function converts the Tensor layouts between different formats. It can be used to
                           			convert a Tensor with an unsupported layout format to a Tensor with a supported layout
                           			format. 
                        </p>
                        <p class="p">This function copies the scaled data from the input Tensor <samp class="ph codeph">srcDesc</samp> to the
                           			output Tensor <samp class="ph codeph">destDesc</samp> with a different layout. The Tensor descriptors of
                           				<samp class="ph codeph">srcDesc</samp> and <samp class="ph codeph">destDesc</samp> should have the same dimensions
                           			but need not have the same strides. 
                        </p>
                        <div class="p">The <samp class="ph codeph">srcDesc</samp> and <samp class="ph codeph">destDesc</samp> Tensors must not overlap in any
                           			way (i.e., Tensors cannot be transformed in place). 
                           <div class="note note"><span class="notetitle">Note:</span> When performing a folding
                              				transform or a zero-padding transform, the scaling factors<samp class="ph codeph"> (alpha,beta)
                                 				</samp>should be set to (1, 0). However, unfolding transforms support any<samp class="ph codeph">
                                 					(alpha,beta)</samp> values. This function is thread safe. 
                           </div>
                        </div>
                        <p class="p"><strong class="ph b">Parameters:</strong></p>
                        <div class="tablenoborder"><a name="cudnnTransformTensorEx__table_hpj_hcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnTransformTensorEx__table_hpj_hcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1"><strong class="ph b">Parameter</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1"><strong class="ph b">Input / Output</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">handle</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Handle to a previously created cuDNN context. See <a class="xref" href="index.html#cudnnHandle_t" shape="rect">cudnnHandle_t</a>.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">transDesc</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">A descriptor containing the details of the requested Tensor transformation.
                                       							See <a class="xref" href="index.html#cudnnTensorTransformDescriptor_t" shape="rect">cudnnTensorTransformDescriptor_t</a>.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">alpha, beta</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">
                                       <p dir="ltr" class="p">Pointers, in the host memory, to the scaling factors used to scale
                                          								the data in the input Tensor <samp class="ph codeph">srcDesc</samp>.
                                       </p>
                                       <p class="p">Beta is used to scale the destination tensor, while alpha is used to scale the source
                                          								tensor. See <a class="xref" href="index.html#scaling-parameters" shape="rect">Scaling Parameters</a>.
                                       </p>
                                       <p dir="ltr" class="p">The beta scaling value is not honored in the folding and
                                          								zero-padding cases. Unfolding supports any
                                          								<samp class="ph codeph">(alpha,beta)</samp>.
                                       </p>
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">srcDesc, destDesc</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Handles to the previously initialed Tensor descriptors.
                                       								<samp class="ph codeph">srcDesc</samp> and <samp class="ph codeph">destDesc</samp> must not overlap. See
                                       								<a class="xref" href="index.html#cudnnTensorDescriptor_t" shape="rect">cudnnTensorDescriptor_t</a>.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="31.185567010309278%" rowspan="1" colspan="1">srcData, destData</td>
                                    <td class="entry" dir="ltr" valign="top" width="26.804123711340207%" rowspan="1" colspan="1">Input</td>
                                    <td class="entry" dir="ltr" valign="top" width="42.01030927835052%" rowspan="1" colspan="1">Pointers, in the host memory, to the data of the Tensor described by
                                       								<samp class="ph codeph">srcDesc</samp> and <samp class="ph codeph">destData</samp> respectively. 
                                    </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                        <p class="p"><strong class="ph b">Returns:</strong></p>
                        <div class="tablenoborder"><a name="cudnnTransformTensorEx__table_usk_kcc_zfb" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cudnnTransformTensorEx__table_usk_kcc_zfb" class="table" frame="border" border="1" rules="all">
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Return Value</strong></td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1"><strong class="ph b">Description</strong></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_SUCCESS</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">The function was launched successfully.</td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_BAD_PARAM</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">A parameter is uninitialized, or initialized incorrectly, or the
                                       							number of dimensions is different between <samp class="ph codeph">srcDesc</samp> and
                                       								<samp class="ph codeph">destDesc</samp>.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_NOT_SUPPORTED</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">Function does not support the provided configuration. Also, in
                                       							the folding and padding paths, any value other than A=1 and B=0 will result in
                                       							a CUDNN_STATUS_NOT_SUPPORTED.
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">CUDNN_STATUS_EXECUTION_FAILED</td>
                                    <td class="entry" dir="ltr" valign="top" width="50%" rowspan="1" colspan="1">Function failed to launch on the GPU.</td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                     </div>
                  </div>
               </div>
               <div class="topic concept nested0" id="acknowledgments"><a name="acknowledgments" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#acknowledgments" name="acknowledgments" shape="rect">5.&nbsp;Acknowledgments</a></h2>
                  <div class="body conbody">
                     <div class="abstract"><span class="shortdesc"></span></div>
                     <p class="p">Some of the cuDNN library routines were derived from code developed by others and are
                        subject to the following:
                     </p>
                  </div>
                  <div class="topic concept nested1" id="university-of-tennessee"><a name="university-of-tennessee" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#university-of-tennessee" name="university-of-tennessee" shape="rect">5.1.&nbsp;University of Tennessee</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <div class="p"><pre xml:space="preserve">Copyright (c) 2010 The University of Tennessee.

All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are
met:
    * Redistributions of source code must retain the above copyright
      notice, this list of conditions and the following disclaimer.
    * Redistributions in binary form must reproduce the above
      copyright notice, this list of conditions and the following
      disclaimer listed in this license in the documentation and/or
      other materials provided with the distribution.
    * Neither the name of the copyright holders nor the names of its
      contributors may be used to endorse or promote products derived
      from this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
"AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
</pre></div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="university-of-california-berkeley"><a name="university-of-california-berkeley" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#university-of-california-berkeley" name="university-of-california-berkeley" shape="rect">5.2.&nbsp;University of California, Berkeley</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <div class="p"><pre xml:space="preserve">COPYRIGHT

All contributions by the University of California:
Copyright (c) 2014, The Regents of the University of California (Regents)
All rights reserved.

All other contributions:
Copyright (c) 2014, the respective contributors
All rights reserved.

Caffe uses a shared copyright model: each contributor holds copyright over
their contributions to Caffe. The project versioning records all such
contribution and copyright details. If a contributor wants to further mark
their specific copyright on a particular contribution, they should indicate
their copyright solely in the commit message of the change when it is
committed.

LICENSE

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are met: 

1. Redistributions of source code must retain the above copyright notice, this
   list of conditions and the following disclaimer. 
2. Redistributions in binary form must reproduce the above copyright notice,
   this list of conditions and the following disclaimer in the documentation
   and/or other materials provided with the distribution. 

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

CONTRIBUTION AGREEMENT

By contributing to the BVLC/caffe repository through pull-request, comment,
or otherwise, the contributor releases their content to the
license and copyright terms herein.
</pre></div>
                     </div>
                  </div>
                  <div class="topic concept nested1" id="facebook-ai-research"><a name="facebook-ai-research" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#facebook-ai-research" name="facebook-ai-research" shape="rect">5.3.&nbsp;Facebook AI Research, New York</a></h3>
                     <div class="body conbody">
                        <div class="abstract"><span class="shortdesc"></span></div>
                        <div class="p"><pre xml:space="preserve">Copyright (c) 2014, Facebook, Inc. All rights reserved.

Redistribution and use in source and binary forms, with or without modification,
are permitted provided that the following conditions are met:

 * Redistributions of source code must retain the above copyright notice, this
   list of conditions and the following disclaimer.

 * Redistributions in binary form must reproduce the above copyright notice,
   this list of conditions and the following disclaimer in the documentation
   and/or other materials provided with the distribution.

 * Neither the name Facebook nor the names of its contributors may be used to
   endorse or promote products derived from this software without specific
   prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR
ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
</pre></div>
                        <div class="p"><pre xml:space="preserve">Additional Grant of Patent Rights

"Software" means fbcunn software distributed by Facebook, Inc.

Facebook hereby grants you a perpetual, worldwide, royalty-free, non-exclusive,
irrevocable (subject to the termination provision below) license under any
rights in any patent claims owned by Facebook, to make, have made, use, sell,
offer to sell, import, and otherwise transfer the Software. For avoidance of
doubt, no license is granted under Facebookâ€™s rights in any patent claims that
are infringed by (i) modifications to the Software made by you or a third party,
or (ii) the Software in combination with any software or other technology
provided by you or a third party.

The license granted hereunder will terminate, automatically and without notice,
for anyone that makes any claim (including by filing any lawsuit, assertion or
other action) alleging (a) direct, indirect, or contributory infringement or
inducement to infringe any patent: (i) by Facebook or any of its subsidiaries or
affiliates, whether or not such claim is related to the Software, (ii) by any
party if such claim arises in whole or in part from any software, product or
service of Facebook or any of its subsidiaries or affiliates, whether or not
such claim is related to the Software, or (iii) by any party relating to the
Software; or (b) that any right in any patent claim of Facebook is invalid or
unenforceable.
</pre></div>
                     </div>
                  </div>
               </div>
               <div class="topic concept nested0" id="notices-header"><a name="notices-header" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#notices-header" name="notices-header" shape="rect">Notices</a></h2>
                  <div class="topic reference nested1" id="notice"><a name="notice" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#notice" name="notice" shape="rect"></a></h3>
                     <div class="body refbody">
                        <div class="section">
                           <h3 class="title sectiontitle">Notice</h3>
                           <p class="p"><sub class="ph sub">THE INFORMATION IN THIS GUIDE AND ALL OTHER INFORMATION CONTAINED IN NVIDIA
                                 DOCUMENTATION REFERENCED IN THIS GUIDE IS PROVIDED “AS IS.” NVIDIA MAKES NO
                                 WARRANTIES, EXPRESSED, IMPLIED, STATUTORY, OR OTHERWISE WITH RESPECT TO THE
                                 INFORMATION FOR THE PRODUCT, AND EXPRESSLY DISCLAIMS ALL IMPLIED WARRANTIES OF
                                 NONINFRINGEMENT, MERCHANTABILITY, AND FITNESS FOR A PARTICULAR PURPOSE.
                                 Notwithstanding any damages that customer might incur for any reason whatsoever,
                                 NVIDIA’s aggregate and cumulative liability towards customer for the product
                                 described in this guide shall be limited in accordance with the NVIDIA terms and
                                 conditions of sale for the product.</sub></p>
                           <p class="p"><sub class="ph sub">THE NVIDIA PRODUCT DESCRIBED IN THIS GUIDE IS NOT FAULT TOLERANT AND IS NOT
                                 DESIGNED, MANUFACTURED OR INTENDED FOR USE IN CONNECTION WITH THE DESIGN,
                                 CONSTRUCTION, MAINTENANCE, AND/OR OPERATION OF ANY SYSTEM WHERE THE USE OR A
                                 FAILURE OF SUCH SYSTEM COULD RESULT IN A SITUATION THAT THREATENS THE SAFETY OF
                                 HUMAN LIFE OR SEVERE PHYSICAL HARM OR PROPERTY DAMAGE (INCLUDING, FOR EXAMPLE,
                                 USE IN CONNECTION WITH ANY NUCLEAR, AVIONICS, LIFE SUPPORT OR OTHER LIFE
                                 CRITICAL APPLICATION). NVIDIA EXPRESSLY DISCLAIMS ANY EXPRESS OR IMPLIED
                                 WARRANTY OF FITNESS FOR SUCH HIGH RISK USES. NVIDIA SHALL NOT BE LIABLE TO
                                 CUSTOMER OR ANY THIRD PARTY, IN WHOLE OR IN PART, FOR ANY CLAIMS OR DAMAGES
                                 ARISING FROM SUCH HIGH RISK USES.</sub></p>
                           <p class="p"><sub class="ph sub">NVIDIA makes no representation or warranty that the product described in this
                                 guide will be suitable for any specified use without further testing or
                                 modification. Testing of all parameters of each product is not necessarily
                                 performed by NVIDIA. It is customer’s sole responsibility to ensure the product
                                 is suitable and fit for the application planned by customer and to do the
                                 necessary testing for the application in order to avoid a default of the
                                 application or the product. Weaknesses in customer’s product designs may affect
                                 the quality and reliability of the NVIDIA product and may result in additional
                                 or different conditions and/or requirements beyond those contained in this
                                 guide. NVIDIA does not accept any liability related to any default, damage,
                                 costs or problem which may be based on or attributable to: (i) the use of the
                                 NVIDIA product in any manner that is contrary to this guide, or (ii) customer
                                 product designs.</sub></p>
                           <p class="p"><sub class="ph sub">Other than the right for customer to use the information in this guide with the
                                 product, no other license, either expressed or implied, is hereby granted by
                                 NVIDIA under this guide. Reproduction of information in this guide is
                                 permissible only if reproduction is approved by NVIDIA in writing, is reproduced
                                 without alteration, and is accompanied by all associated conditions,
                                 limitations, and notices.</sub></p>
                        </div>
                     </div>
                  </div>
                  <div class="topic reference nested1" id="trademarks"><a name="trademarks" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#trademarks" name="trademarks" shape="rect"></a></h3>
                     <div class="body refbody">
                        <div class="section">
                           <h3 class="title sectiontitle">Trademarks</h3>
                           <p class="p"><sub class="ph sub">NVIDIA, the NVIDIA logo, and cuBLAS, CUDA, cuDNN, cuFFT, cuSPARSE, DALI, DIGITS,
                                 DGX, DGX-1, Jetson, Kepler, NVIDIA Maxwell, NCCL, NVLink, Pascal, Tegra,
                                 TensorRT, and Tesla are trademarks and/or registered trademarks of NVIDIA
                                 Corporation in the Unites States and other countries. Other company and product
                                 names may be trademarks of the respective companies with which they are
                                 associated.</sub></p>
                        </div>
                     </div>
                  </div>
                  <div class="topic reference nested1" id="copyright-present"><a name="copyright-present" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#copyright-present" name="copyright-present" shape="rect"></a></h3>
                     <div class="body refbody">
                        <div class="section">
                           <h3 class="title sectiontitle">Copyright</h3>
                           <p class="p"><sub class="ph sub">© <span class="ph">2019</span> NVIDIA Corporation. All rights reserved.</sub></p>
                        </div>
                     </div>
                  </div>
               </div>
               
               <hr id="contents-end"></hr>
               
            </article>
         </div>
      </div>
      <script language="JavaScript" type="text/javascript" charset="utf-8" src="../common/formatting/common.min.js"></script>
      <script language="JavaScript" type="text/javascript" charset="utf-8" src="../common/scripts/google-analytics/google-analytics-write.js"></script>
      
      <script language="JavaScript" type="text/javascript" charset="utf-8" src="../common/scripts/google-analytics/google-analytics-tracker.js"></script>
      <script type="text/javascript">_satellite.pageBottom();</script><script type="text/javascript">var switchTo5x=true;</script><script type="text/javascript" src="http://w.sharethis.com/button/buttons.js"></script><script type="text/javascript">stLight.options({publisher: "998dc202-a267-4d8e-bce9-14debadb8d92", doNotHash: false, doNotCopy: false, hashAddressBar: false});</script>
      <script type="text/javascript">_satellite.pageBottom();</script></body>
</html>